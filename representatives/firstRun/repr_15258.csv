ID_Article,communityId,ID_RelatedVenue,title,year,abstract
14899,15258,293,Unveiling the patterns of video tweeting: a sina weibo-based measurement study,2013,"Sina Weibo is the most popular Twitter-like microblog service in China. Contents, such as texts, pictures, music, videos, are propagated rapidly by tweeting and retweeting among users. In this paper, we conduct a measurement study on the patterns of video tweeting over the Sina Weibo system. We build a customized measurement platform to collect a huge amount of data (e.g., video tweets, user/video information, etc) from 1 million Weibo users on the Sina Weibo system. Our measurements enable us to understand the sources and characteristics of tweeted videos, geographical distribution of viewers, distribution of viewing devices, popularity dynamics of tweeted videos, etc. We observe frequent flash crowds occur for popular tweeted videos due to social tweeting. We also analyze how social links among Weibo users impact video tweeting and it is found that the majority of viewers are within 3 hops from the original tweet publisher. Finally, we discuss potential implications of our measurement results on the design of future social video distribution infrastructures."
177307,15258,293,Xunlei: peer-assisted download acceleration on a massive scale,2012,"We take a close look at Xunlei, an enormously popular download acceleration application in China. Xunlei forms a complex ecosystem, with Xunlei peers extensively interacting with independent HTTP and FTP servers, cyberlockers (such as megaupload and hotfile), the BitTorrent and eDonkey file-sharing systems, as well as with other Xunlei peers. After performing a protocol analysis on Xunlei, we develop a comprehensive measurement infrastructure, enabling us to gain new insights into the scale of content, swarm sizes, and several unique characteristics of the system mechanisms in Xunlei."
1077848,15258,369,Directional Information Based Mobility Procedure for Throughput Enhancement in Mobile TVWS,2013,"Portable unlicensed devices operating in TV white space must adhere to FCC rules designed to protect licensed devices. These rules decrease the achievable throughput for the portable unlicensed devices because the portable unlicensed devices are required to perform a channel availability query (CAQ) before transmitting. In order to reduce the number of CAQs, the Federal Communications Commission allows a region based mobility procedure (RMP). In this paper, we propose a new-RMP using directional information in order to enhance the achievable throughput. Directional information enables an unlicensed portable device to increase its achievable throughput by considering a uni- directional region that is smaller than an omni-directional region. Simulation results show that the proposed RMPs enhance the achievable throughput compared to the conventional RMPs. In addition, the achievable throughput for the proposed RMP using a navigation system is greatly enhanced compared to the conventional RMPs."
1828998,15258,369,Performance Analysis of Relays in LTE for a Realistic Suburban Deployment Scenario,2011,"Relays are likely to play an important role in the deployment of Beyond 3G networks, such as LTE-Advanced, thanks to the possibility of effectively extending Macro network coverage and fulfilling the expected high data-rate requirements. Up until now, the relay technology potential and its cost-effectiveness have been widely investigated in the literature, considering mainly statistical deployment scenarios, like regular networks with uniform traffic distribution. This paper is envisaged to illustrate the performances of different relay technologies (In-Band/Out-band) in a realistic suburban network scenario with real Macro site positions, user density map and spectrum band availability. Based on a proposed heuristic deployment algorithm, results show that deploying In-band relays can significantly reduce the user outage if high backhaul link quality is ensured, whereas Out-band relaying and the usage of a lower frequency carrier at the Macro layer guarantee better network coverage and capacity improvements."
158198,15258,293,A hands-on look at active probing using the IP prespecified timestamp option,2012,"In the last years, network measurements have shown a growing interest in active probing techniques. Recent works propose approaches based on the IP prespecified timestamp option and consider its support to be enough for their purposes. On the other hand, other works found that IP options are usually filtered, poorly implemented, or not widely supported. In this paper, to shed light on this controversial topic, we investigate the responsiveness obtained targeting more than 1.7M IPs using several probes (ICMP, UDP, TCP, and SKIP ), with and without the IP prespecified timestamp option. Our results show that: (i) the option has a significant impact on the responsiveness to the probes; (ii) a not−negligible amount of targeted addresses return several categories of non RFC−compliant replies; (iii) by considering only the RFC−compliant replies which preserve the option, the probes ranking by responsiveness considerably changes. Finally, we discuss the large−scale applicability of two proposed techniques based on the IP prespecified timestamp option."
1989299,15258,122,Communicating memory transactions,2011,"Many concurrent programming models enable both transactional memory and message passing. For such models, researchers have built increasingly efficient implementations and defined reasonable correctness criteria, while it remains an open problem to obtain the best of both worlds. We present a programming model that is the first to have opaque transactions, safe asynchronous message passing, and an efficient implementation. Our semantics uses tentative message passing and keeps track of dependencies to enable undo of message passing in case a transaction aborts. We can program communication idioms such as barrier and rendezvous that do not deadlock when used in an atomic block. Our experiments show that our model adds little overhead to pure transactions, and that it is significantly more efficient than Transactional Events. We use a novel definition of safe message passing that may be of independent interest."
1867283,15258,369,Implementing Distributed Admission Control in Wireless Ad Hoc Networks,2011,"A distributed approach to perform admission control in multi-hop ad hoc networks is proposed. Existing algorithms normally compute the total amount of available resources in the network, however our method evaluates if there are sufficient resources to satisfy the bandwidth demand of a new incoming flow rather than quantifying the total amount, which is impractical when considering implementation. Our methodology also considers multi-rate scenarios and can be implemented hop-by-hop in a distributed manner, which makes the approach scalable and suitable for wireless ad hoc networks. The distributed admission control algorithm introduced in this paper is assessed via analysis and simulation."
992733,15258,122,Exploring different automata representations for efficient regular expression matching on GPUs,2013,"Regular expression matching is a central task in several networking (and search) applications and has been accelerated on a variety of parallel architectures. All solutions are based on finite automata (either in deterministic or non-deterministic form), and mostly focus on effective memory representations for such automata. Recently, a handful of work has proposed efficient regular expression matching designs for GPUs; however, most of them aim at achieving good performance on small datasets. Nowadays, practical solutions must support the increased size and complexity of real world datasets. In this work, we explore the deployment and optimization of different GPU designs of regular expression matching engines, focusing on large datasets containing a large number of complex patterns."
1608037,15258,8228,Creating personal bandwidth maps using opportunistic throughput measurements,2014,�� �� �� �� �� ��� ��� ��� ��� �� ��� ���� ���� ���� ���� ���� ���� ����������������� ������ ������������� �� ������������� ��������������� � �������������� ���� ��� ��� �� ���� ���� ���� ���� ����� ����� ����� ����� ����� ����� ���� ���� ���� ���� ���� ���� ���� ��� ��� ���� ��� ��� ���������������� � ������������ �� ���� ���� ���� ��� ����� ����� ����� ����� ���� ����� ���� ���� ���� ��� ��� ���� ��� ��� ����� ���������������� � ������������ �� ���� ���� ��� ���� ����� ����� ����� ���� �� � ��� �� ��� �� ��� �� ��� �� ��� �� �� � ��� ��������������� ������� �� ���� ���� ��� ���� ����� ����� ����� ���� �� � ��� �� ��� �� ��� �� ��� �� ��� �� �� � ��� ��������������� �������
1259481,15258,9836,CPUs and GPUs: Who Owns the Future?,2011,"This column addresses issues facing CPUs, GPUs, and how to program them and other computing devices."
2479611,15258,122,Swift/T: scalable data flow programming for many-task applications,2013,"Swift/T, a novel programming language implementation for highly scalable data flow programs, is presented."
1890831,15258,9836,"CPUs, GPUs, and Hybrid Computing",2011,This introduction to the special issue discusses advances and challenges in the field of hybrid CPU/GPU computing.
1032023,15258,9836,Big Chips and Beyond,2011,"This column addresses the issues facing microarchitecture and processor design, including and beyond big chips."
2136905,15258,9836,Standardization Skullduggery Revisited,2011,This paper discusses some of the ways of increasing income streams from patents those are needed to implement IEEE standards.
1148696,15258,9836,Steve Jobs and the Economics of One Entrepreneur,2011,"This column explores Steve Jobs' entrepreneurship and impact, covering various successes and setbacks over his career."
1432892,15258,9836,The Wi-Fi Journey,2011,"This column discusses The Innovation Journey of Wi-Fi: The Road To Global Success, which details the origins of Wi-Fi."
1561359,15258,9836,"Effective Communication [review of .....Trees, Maps, and Theorems: Effective Commuincation for Rational Minds (Doumont, J.-L.; 2009)]",2011,"This column reviews Trees, Maps, and Theorems: Effective Communication for Rational Minds, which discusses effective communication methods."
881885,15258,11330,Author retrospective for cooperative cache partitioning for chip multiprocessors,2014,"In this paper, we reflect on our experiences and the lessons learned in designing and evaluating the cooperative cache partitioning technique for chip multiprocessors."
1507628,15258,9836,Hot Chips 22,2011,This introduction to the special issue on Hot Chips 22 briefly discusses the conference and introduces the articles selected for publication.
1403696,15258,9836,Hot Chips 23,2012,This introduction to the special issue on Hot Chips 23 briefly discusses the conference and introduces the articles selected for publication.
1565312,15258,9836,An Honest Policy Wonk,2011,"This column addresses regulatory capture, examining when the regulatory environment works in spite of it due to the presence of an honest policy wonk."
2502769,15258,9748,Improving Perfect Parallelism,2013,We reconsider the familiar problem of executing a perfectly parallel workload consisting of N independent tasks on a parallel computer with P << N processors. We show that there are memory-bo ...
1716237,15258,23836,HCW 2012 Keynote Talk: Analyzing massive data using heterogeneous computing,2012,Summary form only given. The keynote speach was not made available for publication as part of the conference proceedings. Only a professional biography of the speaker is presented.
1559018,15258,9836,"New Blood, Cool Chips, and Heterogeneous Designs",2011,"This column discusses cool chips, and their place in the history of computing and current heterogeneous systems. This column also introduces the new Editorial Board members."
641199,15258,9836,The Secret Life of Wally Madhavani,2012,"Borrowing The Secret Life of Walter Mitty by James Thurber, this column explores what a typical day would be like for a Mitty-like programmer in the Silicon Valley of today."
1853843,15258,9836,Asymptotic stability of the positive switched 2D linear systems described by the Roesser models,2011,The positive switched 2D linear systems described by the Roesser models are addressed. Necessary and sufficient conditions for the asymptotic stability of the positive switched 2D linear systems described by the Roesser models for any switching are established. The considerations are illustrated by numerical examples.
1163989,15258,122,Programming parallel embedded and consumer applications in OpenMP superscalar,2012,"In this paper, we evaluate the performance and usability of the parallel programming model OpenMP Superscalar (OmpSs), apply it to 10 different benchmarks and compare its performance with corresponding POSIX threads implementations."
769259,15258,122,Verification of software barriers,2012,This paper describes frontiers in verification of the software barrier synchronization primitive. So far most software barrier algorithms have not been mechanically verified. We show preliminary results in automatically proving the correctness of the major software barriers.
1653677,15258,8912,The architecture of a resilience infrastructure for computing and communication systems,2013,The resilience infrastructure is a physically and functionally separate add-on to a “Client” computing and/or communication system that provides resilience to the Client system. This short paper summarizes the main features of the architecture of a resilience infrastructure.
1290026,15258,20774,Brief announcement: a partitioned ticket lock,2011,"We introduce the partitioned ticket lock, a first-in-first-enabled FIFO lock with semi-local spinning. Our lock has fixed memory over-head, is extremely simple, and exhibits performance competitive with other local spinning locks."
897047,15258,11330,Author retrospective for search and replication in unstructured peer-to-peer networks,2014,"Does academic research impact popular open-source peer-to-peer systems? Looking back, we find that the simple technique expanding ring does find its use in Gnutella and many other contexts."
1031374,15258,9836,Hot Chips and Remembering a Pioneer,2011,This column briefly introduces the issue's selections from the 22nd annual Hot Chips conference. It also discusses the IEEE's new B. Ramakrishna Rau Award and solicits appropriate nominations.
2174220,15258,9836,Gestures recognition by using ultrasonic range-finders,2011,In this paper an approach to gesture recognition is presented. It is based on application of simple ultrasonic range-finders. A set of five gestures is described which can be distinguish in this way. The described method has been implemented for a mobile robot PeopleBot.
2322741,15258,20754,Data Provenance and Security,2011,"An unanticipated consequence of the Internet age is a pervasive loss of context. Users and organizations receive information in incredible volumes from both internal processes and far-flung, untrusted, and sometimes unknown sources."
1841072,15258,122,Weak atomicity under the x86 memory consistency model,2011,"We consider the problem of building a weakly atomic Software Transactional Memory (STM), that provides Single (Global) Lock Atomicity (SLA) while adhering to the x86 memory consistency model (x86-MM)."
1432465,15258,11330,Author retrospective for a global resource-constrained parallelization technique,2014,"Looking back over the last 25 years, we will reflect below on our 1989 paper, A global resource-constrained parallelization technique published in the Third International Conference on Supercomputing, held in Crete, June 1989."
2264055,15258,8912,A new symbolic approach for network reliability analysis,2012,"In this paper we propose an improved BDD approach to the network reliability analysis, that allows the user to compute an exact solution or an approximation based on reliability bounds when network complexity makes the former solution practically impossible."
1684842,15258,22288,A Theoretical Approach to the Data-Oriented Scheduling Strategies across Multiple Clouds,2013,This paper proposes a decentralized scheduling architecture across multiple clouds with data-oriented strategies. A theoretical model is especially presented to determine the optimal cardinality of the clouds set which is used to accomplish the task.
1761528,15258,20754,A Comparison of Intrusion-Tolerant System Architectures,2011,"With the advancing sophistication of security attacks, protecting open systems is increasingly challenging. Intrusion tolerance should be part of overall in-depth security. This article compares three types of intrusion tolerant system architectures."
1642416,15258,9836,"Top Picks, Columnists, and Artists",2012,This column discusses the process of choosing articles from the computer architecture conferences of 2011 for the Top Picks issue. It also acknowledges the 100th column of Micro Economics and the new cover artist for IEEE Micro.
2124705,15258,20754,Ethics in Data Sharing: Developing a Model for Best Practice,2014,"As an outcome of a seminar on the 'Ethics in Data Sharing', we sketch a model of best practice for sharing data in research. We illustrate this model with two current and timely real-life cases from the context of computer and network security."
2916707,15258,22288,Attribute characteristics of combined formal contexts,2012,"The combination and decomposition of database are two important problems in knowledge discovery and data mining, and their mathematic model are the combination and decomposition of information tables. In this paper, by giving the definitions of object-combined formal contexts and attribute-combined formal contexts, we discuss the relationship of attribute characteristic between object-combined formal contexts and the original formal contexts, attribute-combined formal contexts and the original formal contexts, respectively."
2266104,15258,22288,Control algorithm based on shape recognition,2011,"This paper compared and improved different control algorithm in flatness measurement system. And an improved threshold control algorithm was proposed, based on simple moving average algorithm. Experimental data show that the improved algorithm has good stability and controllability in flatness measurement system."
2974885,15258,22288,Study of soft sets category and it's properties,2012,"Because soft set and information system are both dealing with objects and attributes or parameters, they must have the intimate connections. However, this connection is still not completely understood. we will study the relations between soft set and information system. In this paper, The category SS(U) of soft sets over U is discussed, then we prove that the category SS(U) is a topos."
1997829,15258,8912,MILS-related information flow control in the avionic domain: A view on security-enhancing software architectures,2012,Electronic architectures in the aerospace domain get more and more integrated and interconnected due to functional and architectural reasons. Such a tight integration raises the need to control information flows between different security domains on-board and off-board aircraft.
2543276,15258,9748,Plasma: Shared Memory Dynamic Allocation and Bank-Conflict-Free Access in GPUs,2012,In this paper we present a library for shared-memory dynamic allocation and bank-conflict free accesses for NVIDIA GPUs. The system allows an order of magnitude faster pointer chasing operations for small and medium sized arrays.
2024457,15258,23836,Cyberinfrastructure Usage Modalities on the TeraGrid,2011,"This paper is intended to explain how the Tera Grid would like to be able to measure usage modalities. We would like to (and are beginning to) measure these modalities to understand what objectives our users are pursuing, how they go about achieving them, and why, so that we can make changes in the Tera Grid to better support them."
935521,15258,9704,New bounds for the Relaxed Traveling Tournament Problems using an artificial immune algorithm,2011,"In this paper we tackle the Relaxed Traveling Tournament Problem by an artificial immune algorithm. We introduce new moves that allow the algorithm to group byes when it is useful. We have tested the algorithm in the recently proposed instances of the problem, the results obtained are very encouraging."
2916381,15258,22288,An approach to improve process algebra based protocol composition model,2012,"On basis of analyzing a CSP based protocol composition model, we make the improvement from basic components, combined component interaction rules, responder process, and add in responder interactive process and data receiving process, in order to make this model more completeness."
429761,15258,22288,A simulation knowledge management system with the application of semantic matching algorithm based on ontology,2014,"With the rapid development of simulation science, knowledge reuse in this domain becomes a challenge. This paper concentrates on the system design of a simulation knowledge base management system. Furthermore, a semantic matching algorithm based on ontology has also been proposed for simulation knowledge retrieval."
2254383,15258,9836,Singularities in feedback linearisation of an underactuated 3-link pendulum,2011,Paper presents global feedback linearisation problem for a 3-link underactuated pendulum. Singularities of decoupling matrix are analysed and removed by additional physical parameters requirements. Preliminaries for the class of nonlinear singularity-free feedback linearisation controlled systems are estimated.
1013577,15258,11330,Author retrospective on energy conservation techniques for disk array-based servers,2014,"This is a retrospective on our original paper titled Energy Conservation Techniques for Disk Array-based Servers, which was published in the Proceedings of the International Conference on Supercomputing in 2004.   Original paper: http://dx.doi.org/10.1145/2591635.2591666"
2679663,15258,20358,Designing a high-performance mobile cloud web browser,2014,"A mobile cloud web browser is a web browser that enables mobile devices with constrained resources to support complex web pages by performing most of resource demanding operations on a cloud web server. In this paper, we present a design of a mobile web cloud browser with efficient data structure."
2293676,15258,9836,Topological derivatives for contact problems in ℝ 3,2011,Formulae for the first order expansions of the Steklov-Poincare operators in the case of the Laplace operator and of the elasticity boundary value problems in singularly perturbed domains in ℝ 3  are presented. Such expansions are required for the evaluation of topological derivatives of the energy shape functionals.
2036670,15258,122,Mechanizing the expert dense linear algebra developer,2012,The efforts of an expert to parallelize and optimize a dense linear algebra algorithm for distributed-memory targets are largely mechanical and repetitive. We demonstrate that these efforts can be encoded and automatically applied to obviate the manual implementation of many algorithms in high-performance code.
2138873,15258,23749,Pseudo Random Number Generation for Parallelized Jobs on Clusters,2012,"Pseudo random number generators designed for use in programs to be run serially do not function as intended when multiple instances of the programs are run in parallel. We discuss two techniques to address this issue. Further, we verify our techniques using a case study involving statistical analysis."
1920792,15258,9836,Frequency response identification in the case of periodic disturbances,2011,In the paper an approach to discrete-time frequency response identification in the case of periodic disturbances is presented. A focus on almost sure convergence of the identified discrete-time frequency response to true plant is given. The presented discussion is illustrated by an example showing effectiveness of the presented approach.
1414525,15258,20649,Architecting Dynamic Power Management to be Formally Verifiable,2014,"Many computer systems employ dynamic power management (DPM) to maximize power efficiency. DPM offers great opportunities, but deploying it carries significant risks if the DPM scheme is not completely verified. We propose architecting the DPM scheme such that it can be formally verified regardless of the size of the system."
2129216,15258,9836,Top Picks from the 2011 Computer Architecture Conferences,2012,This special issue is the ninth in an important tradition in the computer architecture community: IEEE Micro's Top Picks from the Computer Architecture Conferences. This tradition provides a means for sharing a sample of the best papers published in computer architecture in 2011 with the IEEE Micro readership and researchers in the computer architecture community.
2053839,15258,122,Towards an energy estimator for fault tolerance protocols,2013,"Checkpointing protocols have different energy consumption depending on parameters like application features and platform characteristics. To select a protocol for a given execution, we propose an energy estimator that relies on an energy calibration of the considered platform and a user description of the execution settings."
1620460,15258,11330,Multi-layered unstructured mesh generation,2013,"Finite Element Mesh Generation is a critical component for many (bio-)engineering and science applications. In this project we will develop a novel framework for guaranteed quality mesh generation for 3D and 4D Finite Element (FE) analysis, able to scale to thousands of cores."
2921990,15258,22288,The research on the control algorithm of IOT based bicycle parking system,2012,"How to manage the bicycles in a university campus is a very big challenge. This paper suggests the Intelligent Bicycle Parking System based on IoT, and mainly discusses the logistic processes based on the Intelligent Bicycle Parking System, presents in detail the modules of composition and the algorithm of implement. Also, the paper illustrates the whole work flow of Bicycle Parking System and analyses the advantages of design."
923747,15258,11330,Addressing bandwidth contention in SMT multicores through scheduling,2014,"To mitigate the impact of bandwidth contention, which in some processes can yield to performance degradations up to 40%, we devise a scheduling algorithm that tackles main memory and L1 bandwidth contention. Experimental evaluation on a real system shows that the proposal achieves an average speedup by 5% with respect to Linux."
891050,15258,11330,The ARMv8 simulator,2013,"In this work, we implement an ARMv8 function and performance simulator based on gem5 infrastructure, which is the first open source ARMv8 simulator. All the ARMv8 A64 instructions other than SIMD are implemented using gem5 ISA description language. The ARMv8 simulator supports multiple CPU models, multiple memory systems, and McPAT power model."
909196,15258,8806,Inter cloud capable dynamic resource management with model of behavior,2013,"This paper introduces a dynamic load and power management (LPM) for virtual machines (VM), which can be used in inter cloud architectures. In addition, a model is introduced, which abstracts the behavior of the LPM concerning the server allocation. This model can be consulted for forecasts, with an average precision of 92%."
2969300,15258,22288,The credibility research of capability index system for weapon equipment SOS,2012,The capability index system of weapon equipment SoS is constructed in this paper. The questionnaire survey is taken to give out the comprehensive evaluations of credibility about weapon equipment SoS capability index system. The mean value method and factor analysis method are used to compute the credibility and the score are 4.03 and 4.04 respectively. The results demonstrate that the capability index system of weapon equipment SoS constructed in this paper is credible.
2973556,15258,22288,An integrated runtime monitoring method for Internet-Based Virtual Computing Environment,2012,"This paper designs a new integrated runtime monitoring method for the Internet-Based Virtual Computing Environment (iVCE). This method consolidates basic state monitoring of virtual resources and application state monitoring of virtual tasks. To validate our methodology, we developed a monitoring system for an iVCE testbed of more than 1000 nodes."
2438904,15258,20774,Brief announcement: cache-oblivious scheduling of streaming pipelines,2014,"This paper considers the problem of cache-obliviously scheduling streaming pipelines on uniprocessors with the goal of minimizing cache misses. Our recursive algorithm is not parameterized by cache size, yet it achieves the asymptotically minimum number of cache misses with constant factor memory augmentation."
2571876,15258,9836,Address Translation Aware Memory Consistency,2011,Computer systems with virtual memory are susceptible to design bugs and runtime faults in their address translation systems. Detecting bugs and faults requires a clear specification of correct behavior. A new framework for address translation aware memory consistency models addresses this need.
1478720,15258,9836,Top Picks [Guest editors' introduction],2011,This special issue is the eighth in an important tradition in the computer architecture community: IEEE Micro's Top Picks from the Computer Architecture Conferences. This tradition provides a means for sharing a sample of the best papers published in computer architecture during the past year with the IEEE Micro readership and researchers in the computer architecture community.
1962822,15258,9836,Constrained predictive control of a levitation system,2011,In this paper a method of an predictive controller design for the control of constrained MIMO levitation system is presented. The proposed control strategy is based on combining feedback linearization and LQ method with modifying reference signal allowing to keep variables inside constrained region.
2415576,15258,9836,Sparc T4: A Dynamically Threaded Server-on-a-Chip,2012,"The Sparc T4 is the next generation of Oracle's multicore, multithreaded 64-bit Sparc server processor. It delivers significant performance improvements over its predecessor, the Sparc T3 processor. The authors describe Sparc T4's key features and detail the microarchitecture of the dynamically threaded S3 processor core, which is implemented on Sparc T4."
2180887,15258,8228,Scheduling cloud applications under uncertain available bandwidth,2013,This paper introduces a task scheduler for clouds which considers that estimations of the available network bandwidth are not precise. The efficacy of the scheduler was evaluated with different type of applications and degree of uncertainty of available bandwidth estimations. Results show that the proposed scheduler is robust to imprecise input information.
1059838,15258,9475,Game couplings: Learning dynamics and applications,2011,"Modern engineering systems (such as the Internet) consist of multiple coupled subsystems. Such subsystems are designed with local (possibly conflicting) goals, with little or no knowledge of the implementation details of other subsystems. Despite the ubiquitous nature of such systems very little is formally known about their properties and global dynamics."
1274636,15258,9748,An OpenMP Analyzer for Detecting Concurrency Errors,2012,"With the increasing popularity of multi-core machines, more and more sequential programs are being parallelized using OpenMP. However, it is not easy for programmers to write parallel programs correctly. Concurrency errors, such as data races and deadlocks. This paper presents a novel technique to detect data races and deadlocks using hybrid program analysis."
1906600,15258,9836,Finite approximations of a discrete-time fractional derivative,2011,"This paper presents new results in finite-memory modeling of a discrete-time fractional derivative. The introduced normalized finite fractional derivative is shown to properly approximate its fractional derivative original, in particular in terms of the steady-state properties. A stability analysis is also presented as well as a recursive computation algorithm is offered for finite fractional derivatives."
1550697,15258,122,Programming with hardware lock elision,2013,We present a simple yet effective technique for improving performance of lock-based code using the  hardware lock elision  (HLE) feature in Intel's upcoming Haswell processor.   We also describe how to extend Haswell's HLE mechanism to achieve a similar effect to our lock elision scheme entirely in hardware.
1315375,15258,9836,What GPU Computing Means for High-End Systems,2011,"This column examines how GPU computing might affect the architecture of future exascale supercomputers. Specifically, the authors argue that a system with slower but better-balanced processors might yield higher performance and consume less energy than a system with very fast but imbalanced processors."
1385168,15258,9836,(Re)Designing Data-Centric Data Centers,2012,A grand challenge facing computing today is to design future systems to efficiently manage and harvest useful insights from the growing amount of information. Emerging technology inflections provide a unique opportunity to address this challenge through novel redesign at both the hardware and software levels.
1649009,15258,9836,The GreenDroid Mobile Application Processor: An Architecture for Silicon's Dark Future,2011,This article discusses about Greendroid mobile Application Processor. Dark silicon has emerged as the fundamental limiter in modern processor design. The Greendroid mobile application processor demonstrates an approach that uses dark silicon to execute general-purpose smart phone applications with less energy than today's most energy efficient designs.
1273498,15258,23497,Research directions for 21st century computer systems: asplos 2013 panel,2013,"Four recent efforts call out architectural challenges and opportunities up and down the software/hardware stack. This panel will discuss,  What should the community do to facilitate, transcend, or refute these partially overlapping visions?  The panel is chaired by Mark D. Hill with other panel members not finalized for the ASPLOS'13 proceedings."
710572,15258,9836,Scalable and Efficient Fine-Grained Cache Partitioning with Vantage,2012,"The Vantage cache-partitioning technique enables configurability and quality-of-service guarantees in large-scale chip multiprocessors with shared caches. Caches can have hundreds of partitions with sizes specified at cache line granularity, while maintaining high associativity and strict isolation among partitions."
1073527,15258,22288,Introducing STRATOS: A Cloud Broker Service,2012,"This paper introduces a cloud broker service (STRATOS) which facilitates the deployment and runtime management of cloud application topologies using cloud elements/services sourced on the fly from multiple providers, based on requirements specified in higher level objectives. Its implementation and use is evaluated in a set of experiments."
2003074,15258,23836,A Codesigned Fault Tolerance System for Heterogeneous Many-Core Processors,2011,This paper presents an efficient fault tolerance system for heterogeneous many-core processors. The efficiencies and coverage of the presented fault tolerance are optimized by customizing the techniques for different types of components in the highest layers of system abstractions and codesigning the techniques in a way that separates algorithms and mechanisms.
1728295,15258,9748,Comparison Study of Scalable and Cost-Effective Interconnection Networks for HPC,2012,"This work attempts to compare size and cost of two network topologies proposed for large-radix routers: concentrated torus and dragonflies. We study and compare the scalability, cost and fault tolerance of each network. On average, we found that a concentrated torus can be a cost-efficient option for middle-range networks."
1017307,15258,11330,Author retrospective for bloom filtering cache misses for accurate data speculation and prefetching,2014,"In this paper, we provide the authors? retrospective analysis of the paper Bloom Filtering Cache Misses for Accurate Data Speculative and Prefetching which was published in the proceedings of 2002 International Conference on Supercomputing.   DOI: http://dx.doi.org/10.1145/514191.514219"
978844,15258,9836,"A Solid Past, A Vital Future",2011,"The new Editor in Chief of IEEE Micro introduces himself and the first issue of 2011. He thanks the outgoing Editor in Chief, David Albonesi, for his outstanding work during his tenure. He discusses developments to the magazine and future issues, and asks readers for their suggestions on topics the magazine should cover in coming issues."
1991618,15258,20649,Enforcing architectural contracts in high-level synthesis,2011,"We present a high-level synthesis technique that takes as input two  orthogonal  descriptions: (a) a behavioral architectural contract between the implementation and the user, and (b) a microarchitecture on which the architectural contract can be implemented. We describe a prototype compiler that generates control required to enforce the contract, and thus, synthesizes the pair of descriptions to hardware."
1831736,15258,8806,An XML-based protocol for improving trust negotiation between Web Services,2012,This paper aims to propose an XML-based protocol for two Web Services to utilise TN to establish a trust relationship between them. The main contribution of this protocol is towards preventing failed TN caused by the file format interoperability problem by checking file formats before TN processes. This will increase communication efficiency between WS.
915917,15258,22288,A Tiered Strategy for Auditing in the Cloud,2012,"In this paper, we outline a tiered approach to auditing information in the cloud. The approach provides perspectives on auditable events that may include compositions of independently formed audit trails. Filtering and reasoning over the audit trails can manifest potential security vulnerabilities and performance attributes as desired by stakeholders."
1724530,15258,122,Decomposition techniques for optimal design-space exploration of streaming applications,2013,"Streaming data programs are an important class of applications, for which queueing network models are frequently available. While the design space can be large, decomposition techniques can be effective at design space reduction. We introduce two decomposition techniques called convex decomposition and unchaining and present implications for a biosequence search application."
1235358,15258,9078,Diagonal vectorisation of 2-D wavelet lifting,2014,"With the start of the widespread use of discrete wavelet transform in image processing, the need for its efficient implementation is becoming increasingly more important. This work presents a novel SIMD vectorisation of 2-D discrete wavelet transform through a lifting scheme. For all of the tested platforms, this vectorisation is significantly faster than other known methods, as shown in the results of the experiments."
1862330,15258,8912,Latent fault detection in large scale services,2012,"Unexpected machine failures, with their resulting service outages and data loss, pose challenges to datacenter management. Existing failure detection techniques rely on domain knowledge, precious (often unavailable) training data, textual console logs, or intrusive service modifications."
1394676,15258,9772,Towards a performance-as-a-service cloud,2013,"Motivation  While the pay-as-you-go model of Infrastructure-as-a-Service (IaaS) clouds is more flexible than an in-house IT infrastructure, it still has a resource-based interface towards users, who can rent virtual computing resources over relatively long time scales. There is a fundamental mismatch between this resource-based interface and what users really care about: performance."
925695,15258,20338,OFSS: Skampling for the Flow Size Distribution,2014,"We introduce a new method for flow size estimation, the Optimised Flow Sampled Sketch, which combines the optimal properties of Flow Sampling with the computational advantages of a counter array sketch. Using Fisher Information as a definitive basis of comparison, we show that it is superior to alternatives in both model and traffic based comparisons."
1289612,15258,9748,A Theoretical Design for SSD Texture Storage,2012,"Large textures are becoming ubiquitous in good graphics. Modern textures are exceedingly beyond the size that can be stored on a GPU's memory. In this paper we present an idea for flash based texture storage on the graphics card, eliminating the need to traverse the system busses to get to hard disk or main memory."
2541847,15258,9836,Standardization Skullduggery Never Ends: Apple v. Motorola,2012,"In February 2012, Apple sued Motorola to block the latter's alleged standardization skullduggery of the 3G/UMTS technology. This column examines the charges and explores the issues of patent rights; standards-essential patents; and what are fair, reasonable, and nondiscriminatory (FRAND) terms and conditions."
2933876,15258,22288,Research of improved SVM model based on GA in E-learning emotion classification,2012,"Aiming at the problem of different learning emotions in the integrated emotion model of the emotion recognition interactive E-learning system, this paper proposed an improved SVM classification algorithm to classify the learning emotions, optimized the parameters of the SVM classifier with Genetic Algorithm, and applied it to the emotion classification of E-learning system. It has achieved good results based on relevant experiments."
1371377,15258,9748,PAPI-V: Performance Monitoring for Virtual Machines,2012,"This paper describes extensions to the PAPI hardware counter library for virtual environments, called PAPI-V. The extensions support timing routines, I/O measurements, and processor counters. The PAPI-V extensions will allow application and tool developers to use a familiar interface to obtain relevant hardware performance monitoring information in virtual environments."
1363750,15258,22288,Content Based SLAs in Cloud Computing Environments,2012,"In this paper, we address the problem of managing SLAs in cloud computing environments. The idea is to take advantage of the content terms that concern the objects and support more efficient capabilities, such as quicker search and retrieval of the objects. As a result, the operational cost is reduced and consequently this fact lessens the customer's charge."
2107035,15258,23749,Integration of Workflow Partitioning and Resource Provisioning,2012,The recent increased use of workflow management systems by large scientific collaborations presents the challenge of scheduling large-scale workflows onto distributed resources. This work aims to partition large-scale scientific workflows in conjunction with resources provisioning to reduce the workflow make span and resource cost.
1618668,15258,20774,Brief announcement: locality-enhancing loop transformations for tree traversal algorithms,2011,"In this paper, we discuss transformations that can be applied to irregular programs that perform tree traversals, which can be seen as analogs of the popular regular transformations of loop tiling. We demonstrate the utility of these transformations on two tree traversal algorithms, the Barnes-Hut algorithm and raytracing, achieving speedups of up to 237% over the baseline implementation."
1675354,15258,20774,Brief announcement: speedups for parallel graph triconnectivity,2012,"We present a parallel solution to the problem of determining the triconnected components of an undirected graph. We obtain significant speedups over the only published optimal (linear-time) serial implementation of a triconnected components algorithm running on a modern CPU. This is accomplished on the PRAM-inspired XMT many-core architecture. To our knowledge, no other parallel implementation of a triconnected components algorithm has been published for any platform."
1365572,15258,9836,On stationarity of elementary bilinear time-series,2011,In the paper stationarity of random processes obtained from elementary bilinear time-series models is analysed. It is shown in the presented analysis that elementary bilinear time-series models can be interpreted as linear time-series with time varying random parameters. The analysis is illustrated by simulation experiments showing time dependencies of some statistical moments of the discussed random processes.
1844358,15258,9836,Deterimination of positive stable realizations with system Metzler matrices,2011,Conditions for the existence of positive stable realizations with system Metzler matrices for linear continuous-time systems are established. A procedure for finding a positive stable realization with system Metzler matrix based on similarity transformation of proper transfer matrices is proposed and demonstrated on numerical examples. It is shown that if the poles of stable transfer matrix are real then the classical Gilbert method can be used to find the positive stable realization.
1495482,15258,9836,The Tofu Interconnect,2012,"The Tofu interconnect uses a 6D mesh/torus topology in which each cubic fragment of the network has the embeddability of a 3D torus graph, allowing users to run multiple topology-aware applications. This article describes the Tofu interconnect architecture, the Tofu network router, the Tofu network interface, and the Tofu barrier interface, and presents preliminary evaluation results."
1144645,15258,20774,Balls-into-bins with nearly optimal load distribution,2013,We consider sequential  balls-into-bins  processes that randomly allocate  m  balls into  n  bins. We analyze two allocation schemes that achieve a close to optimal maximum load of ⌈ m / n ⌉ + 1 and require only  O(m)  (expected) allocation time. These parameters should be compared with the classic  d -choice-process which achieves a maximum load of  m / n  + log log  n / d  +  O (1) and requires  m  •  d  allocation time.
770028,15258,9836,Cohesion: An Adaptive Hybrid Memory Model for Accelerators,2011,"Cohesion is a hybrid memory model that enables fine-grained temporal data reassignment between hardware- and software-managed coherence domains, allowing systems to support both. Cohesion can dynamically adapt to the sharing needs of both applications and runtimes requiring neither copy operations nor multiple address spaces."
2045048,15258,122,Scalable statistics counters,2013,"Naive statistics counters that are commonly used to monitor system events and performance become a scalability bottleneck as systems become larger and more NUMA; furthermore some are so inaccurate that they are not useful. We present a number of techniques to address these problems, evaluating solutions in terms of performance, scalability, space overhead, and accuracy."
2541877,15258,23749,Automatic Adaptive Page-Size Control for Remote Memory Paging,2012,An automatic adaptive page size control methodology is proposed for remote memory paging. It estimates a working data set and changes page size dynamically and adaptively to each processing part of an application during it is running. It is highly effective to prevent memory server thrashing when the size of local memory is limited.
1239568,15258,8335,Thermal management for dependable on-chip systems,2013,Dependability has become a growing concern in the nano-CMOS era due to elevated temperatures and an increased susceptibility to temperature of the small structures. We present an overview of temperature-related effects that threaten dependability and a methodology for reducing the dependability concerns through thermal management utilizing the concept of aging budgeting.
1013355,15258,9475,Intruder capturing game on a topological map assisted by information networks,2011,"Intruder capturing games on a topological map of a workspace with obstacles are investigated. Assuming that a searcher can access the position of any intruder utilizing information networks, we provide theoretical upper bounds for the minimum number of searchers required to capture all intruders on a Voronoi graph. Intruder capturing algorithms are proposed and demonstrated through an online computer game."
1912868,15258,23749,Integrating HLA and Service-Oriented Architecture in a Simulation Framework,2012,The High-Level Architecture (HLA) is the de-facto standard in simulation interoperability. This paper presents a possible way for HLA to integrate with a service-oriented architecture (SOA) in the context of a smart building project. The paper discusses the design of an HLA federate for the inclusion of a service oriented smart building controller in the simulation loop.
2916255,15258,22288,Research and designed of a structured scalable robot control system based on real-time bus,2012,"Aimed at the problems of poor transferring capabilities and maintainability in heterogeneous robot platforms, a structured scalable robot control system based on real-time bus, such as RS485bus is proposed, which can be adapted to a number of heterogeneous robot platform. The hardware and software design is elaborated and using this, a Guide Robot is developed to prove the interchangeability, adaptation and extensibility of the system."
460489,15258,22288,Study on building library personalized subject service platform in big data environment—Lib 2.0 solutions based on Hadoop framework,2014,"Taking the personalized subject service platform of the Second Military Medical University Library for example, this paper analyses the demands and challenges to construct a library personalized subject service platform in big data environment, discusses solutions of building library personalized subject service platform on Hadoop big data storage and processing framework and proposes new ideas to solve the problem of how the library personalized subject service platform can adapt to increasing data of information resources cheaply and efficiently."
1731403,15258,22288,SLA-Guided Data Integration on Cloud Environments,2014,"Existing data integration techniques have to be revisited to query big data collections on the Cloud. Service Level Agreements implement the contracts between the cloud provider and the users, and between the cloud and service providers. Given SLA heterogeneity and data integration scalability problems, we propose an SLA guided data integration for querying data on multiple clouds."
2354035,15258,9836,"What is Happening to Power, Performance, and Software?",2012,"Systematically exploring power, performance, and energy sheds new light on the clash of two trends that unfolded over the past decade: the rise of parallel processors in response to technology constraints on power, clock speed, and wire delay; and the rise of managed high-level, portable programming languages."
184916,15258,9748,Using Quadratic Approximations in an Interval Method for Solving Underdetermined and Well-Determined Nonlinear Systems,2013,"This paper considers quadratic approximation as a narrow- ing tool in an interval branch-and-prune method. We seek the roots of such an approximate equation - a quadratic equation with interval para- meters. Heuristics to decide, when to use the developed operator, are proposed. Numerical results for some benchmark problems are presented and analyzed."
2093217,15258,9836,Boundary control of parabolic-hyperbolic systems with integral time delays appearing in the boundary conditions,2011,Optimal boundary control problems for linear parabolic-hyperbolic systems with the Neumann boundary conditions involving integral time delays are considered. Sufficient conditions for the existence of a unique solution for such parabolic-hyperbolic systems are proved. Necessary and sufficient conditions of optimality are derived for the Neumann problem. The problem of determining of the optimal control is discussed.
416591,15258,9748,A Parallel Solver for the Time-Periodic Navier–Stokes Equations,2013,"We investigate parallel algorithms for the solution of the Navier–Stokes equations in space-time. For periodic solutions, the discretized problem can be written as a large non-linear system of equations. This system of equations is solved by a Newton iteration. The Newton correction is computed using a preconditioned GMRES solver. The parallel performance of the algorithm is illustrated."
1022736,15258,23712,Virtual routing tables polymerization for lookup and update,2012,"Virtual router research has drawn increasing attention in recent years, and the most challenging issues of virtual routers are compression, lookup, and incremental update of 10∼200 routing tables. In this paper, we propose a set of solutions to achieve that storage, lookup time, and update time don't expand to 10∼200 times, but reduce to 1∼2 times."
2016079,15258,9836,Modeling of heat transfer process by using discrete fractional-order neural networks,2011,This paper deals with a discrete fractional-order neural network and its application for modeling of a heat transfer process. Proposed neural network is implemented in Matlab/Simulink and applied to the heater which is a part of the equipment Armfield PCT40. Results obtained from experiments presented in the article show that the fractional-order neural network properly modeled the unknown dynamics.
1213799,15258,11058,"Herding cats: modelling, simulation, testing, and data-mining for weak memory",2014,"There is a joke where a physicist and a mathematician are asked to herd cats. The physicist starts with an infinitely large pen which he reduces until it is of reasonable diameter yet contains all the cats. The mathematician builds a fence around himself and declares the outside to be the inside. Defining memory models is akin to herding cats: both the physicist's or mathematician's attitudes are tempting, but neither can go without the other."
1501130,15258,9748,Cycles Embedding of Twisted Cubes,2013,"The twisted cube TQ n  is an alternative to the popular hypercube network and some interesting properties of TQ n  were investigated recently. The problem of how to embed cycles into a host graph has attracted a great attention in recent years. However, there are few systematic methods proposed to generate the desired cycles in TQ n . In this paper, we provide two kinds of systematic methods of embedding cycles into TQ n ."
1640928,15258,23634,Quantum 3-SAT Is QMA1-Complete,2013,"Quantum satisfiability is a constraint satisfaction problem that generalizes classical boolean satisfiability. In the quantum k-SAT problem, each constraint is specified by a k-local projector and is satisfied by any state in its nullspace. Bravyi showed that quantum 2-SAT can be solved efficiently on a classical computer and that quantum k-SAT with k ≥ 4 is QMA 1 -complete [4]. Quantum 3-SAT was known to be contained in QMA 1  [4], but its computational hardness was unknown until now. We prove that quantum 3-SAT is QMA 1 -hard, and therefore complete for this complexity class."
1652294,15258,9836,Data Marshaling for Multicore Systems,2011,"Dividing a program into segments and executing each segment at the core best suited to run it can improve performance and save power. When consecutive segments run on different cores, accesses to intersegment data incur cache misses. Data Marshaling eliminates such cache misses by identifying and marshaling the necessary intersegment data when a segment is shipped to a remote core."
1468525,15258,22288,A Security PaaS Container with a Customized JVM,2014,"PaaS is known as an application engine which third party developers can deploy their application onto. Security of PaaS becomes important as applications shares resources. How to secure and isolation the resources become an important topic. In this paper, a security PaaS container is proposed which is based on a customized JVM. This container is fully implemented and evaluated in real setting."
2060470,15258,122,Optimistic transactional boosting,2014,"Herlihy and Koskinen's transactional boosting methodology addressed the challenge of converting concurrent data structures into transactional ones. We present an optimistic methodology for boosting concurrent collections. Optimistic boosting allows greater data structure-specific optimizations, easier integration with STM frameworks, and lower restrictions on the boosted operations than the original boosting methodology."
854118,15258,9836,The IBM Blue Gene/Q Interconnection Fabric,2012,"This article describes the IBM Blue Gene/Q interconnection network and message unit. Blue Gene/Q is the third generation in the IBM Blue Gene line of massively parallel supercomputers and can be scaled to 20 petaflops and beyond. For better application scalability and performance, Blue Gene/Q has new routing algorithms and techniques to parallelize the injection and reception of packets in the network interface."
2208709,15258,23712,DFLOW: Low latency congestion control,2013,"This paper provides an overview of the DFlow congestion control algorithm, which aims to provide for lower delay and lower loss media transport. We provide an evaluation of the algorithm in a simulator which shows that it can provide for self-fairness and low delay operation. Furthermore we demonstrate that it can maintain reasonable throughput against TCP Vegas and LEDBAT."
742161,15258,9836,Fermi GF100 GPU Architecture,2011,"The Fermi GF100 is a GPU architecture that provides several new capabilities beyond the Nvidia GT200 or Tesla architecture. The Fermi architecture offers up to 512 CUDA cores and special features for gaming and high-performance computing. This article describes the GPU's new capabilities for tessellation, physics processing, and computational graphics."
842310,15258,339,11th workshop on privacy in the electronic society,2012,"The need for privacy-aware policies, regulations, and techniques has been widely recognized. This workshop discusses the problems of privacy in the global interconnected societies and possible solutions. The 2012 Workshop, held in conjunction with the ACM CCS conference, is the eleventh in a yearly forum for papers on all the different aspects of privacy in today's electronic society."
776776,15258,23836,The Spanish Parallel Programming Contests and its Use as an Educational Resource,2012,The first Spanish Parallel Programming Contest was organized in September 2011 within the Spanish Jornadas de Paralelismo. The aim of the contest is to disseminate parallelism among Computer Science students. The website and the material generated can be used for educational purposes. This paper comments on the organization of the contest and summarizes some training activities in which the material of the contest is being or can be used.
1765199,15258,9836,Automated Full-System Power Characterization,2011,"A new framework automatically generates full-system multicore powermarks, or synthetic programs with desired power characteristics on multicore server platforms. The framework constructs full-system power models with error bounds on the power estimates and guides the design of energy-efficient and cost-efficient server and data center infrastructures."
122942,15258,293,Spatial and temporal locality of swarm dynamics in bittorrent,2013,"The locality in BitTorrent refers to how much disparity exists in swarm dynamics from the spatial and temporal perspectives. According to [1], 30 observed for more than 45 peers are biased to local peers. [2] found that (1) substantial BitTorrent traffic does not reach higher-tier ISPs, and (2) BitTorrent's temporal usage patterns vary in a diurnal fashion."
2199861,15258,9836,IBM Power Edge of Network Processor: A Wire-Speed System on a Chip,2011,"The IBM Power Edge of Network processor combines the attributes of a general-purpose processing subsystem with function accelerators and networking interfaces to create a system on a chip that's targeted for applications at the edge of network. This article discusses in detail the processing, accelerator, and network interface subsystems and explores applications well suited to the PowerEN processor."
348950,15258,22288,An improved k-subset algorithm for load balance problems in Cloud Computing,2014,Cloud Computing has earned more and more attention for its important role in the modern network development process. It can be seen as a new distributed computing mode based on virtualization process. One of the problems for Cloud Computing is load balance. An improved k-subset algorithm is proposed in this paper for this problem. Good performance in experiments on CloudSim platform shows its efficiency
879576,15258,9836,Designing a Multicore and Multiprocessor Individual-Based Simulation Engine,2012,"This article describes the design of an individual-based simulation engine that can harness the full potential of modern general-purpose multicore and multiprocessor computers. This design aims to enable interactive simulations of highly dynamic multiagent systems in which entities can move, change, appear, disappear, and interact with one another and the user at any time."
1538055,15258,22260,Update Management in Decentralized Social Networks,2013,"Decentralized social networks in the form of blogs and wikis often replicate dynamic content through caching. Maintaining replicated data in these systems is challenging due to the high cost of update management. We propose a technique that provides a structure to support efficient updates for cached data, and we demonstrate the efficacy of our approach through performance studies."
2990381,15258,22288,Theory of α-truth degrees in 3-valued prerough logic,2012,"The theory of α-truth degrees in 3-valued Pre-rough logical system is studied in this paper. Firstly, the definition of α-truth degrees is proposed. Secondly, the general reasoning rules about α-truth degrees are obtained. Lastly, the α-similarity degree and α-pseudometric between two formulas are defined by means of the concept of α-truth degrees, and their properties are discussed. This offers a theory framework for approximate reasoning in 3-valued Pre-rough logic."
826019,15258,20754,The Probabilistic Provenance Graph,2013,"Previous provenance models have assumed that there is complete certainty in the provenance relationships. But what if this assumption does not hold? In this work, emaiwe propose a probabilistic provenance graph (PPG) model to characterize scenarios where provenance relationships are uncertain. We describe two motivating examples. The first example demonstrates the uncertainty associated with the provenance of an email. The second example demonstrates and characterizes the uncertainty associated with the provenance of statements in documents."
1091058,15258,9836,Kilo TM: Hardware Transactional Memory for GPU Architectures,2012,"Programming GPUs is challenging for applications with irregular fine-grained communication between threads. To improve GPUs' programmability and thus extend their usage to a wider range of applications, the authors propose to enable transactional memory (TM) on GPUs via Kilo TM, a novel hardware TM system that scales to thousands of concurrent transactions."
2219291,15258,23836,Policy Based Data Placement in High Performance Scientific Computing,2011,"The recent increased use of workflow management systems by large scientific collaborations presents the challenge of highly dynamic data placement in distributed systems. Such data placement may be constrained by the enforcement of data placement policies. We present a Policy based Data Placement Service that enforces data placement policies, interfaces with workflow managers and improves workflow efficiency by offloading data staging jobs from workflows."
2960109,15258,22288,The simple optimization of WLC algorithm based on LVS cluster system,2012,"Linux Virtual Server (LVS) cluster technology is commonly used to provide highperformance web service. In LVS cluster, WLC scheduling algorithm is often adopted and has good effect. Based on the WLC scheduling algorithm, this paper presents a kind of simple optimization method by using server's performance indexes to calculate server's weight. The performance of the LVS cluster can be effectively improved by the optimized method."
1203251,15258,9836,GPUs and the Future of Parallel Computing,2011,"This article discusses the capabilities of state-of-the art GPU-based high-throughput computing systems and considers the challenges to scaling single-chip parallel-computing systems, highlighting high-impact areas that the computing research community can address. Nvidia Research is investigating an architecture for a heterogeneous high-performance computing system that seeks to address these challenges."
44292,15258,9748,Algorithms for In-Place Matrix Transposition,2013,"This paper presents an implementation of an in-place swap- based algorithm for transposing rectangular matrices, and a proof of correctness is also sketched. The implementation is based on an algorithm described by Tretyakov and Tyrtyshnikov (4), but we have introduced a number of variations. In particular, we show how the original algorithm can be modified to require constant additional memory. We also identify opportunities for exploiting parallelism."
2312580,15258,8494,TV energy management by camera-based viewer monitoring,2011,"This paper presents a new method of energy management in television set. The method keeps TV screen active only if someone is watching it. When no viewer is present in front of the camera, the TV screen is dimmed to save power while keeping the audio ON. Experiments show that the method can reduce the TV power consumption significantly especially when TV set is left ON unwatched."
1732257,15258,9836,Eliminating Redundant Computation and Exposing Parallelism through Data-Triggered Threads,2012,"Unlike threads in parallel programs created by conventional programming, data-triggered threads are initiated when a memory value is changed. By expressing computation through these threads, computation is executed only when the data changes and is skipped whenever the data does not change. The authors' model achieves performance speedups of up to 5.9x, averaging 45.6 percent, with SPEC2000 benchmarks."
851640,15258,9475,"Switching scheme, equivalence, and analog validation of the alternative fractional variable-order derivative definition",2013,"In this paper, an alternative definition of variable-order differ-integral is proposed, both in a difference equation and matrix form. The derivation and explanation of the identity between the alternative definition and the reductive-switching scheme of variable-order derivative is introduced. Based on the switching scheme, an analog realization of the proposed variable-order derivative definition is presented. Moreover, obtained experimental results of the analog realization are compared with the numerical results."
2542370,15258,9836,CHOP: Integrating DRAM Caches for CMP Server Platforms,2011,"Integrating large DRAM caches is a promising way to address the memory bandwidth wall issue in the many-core era. However, organizing and implementing a large DRAM cache imposes a trade-off between tag space overhead and memory bandwidth consumption. CHOP (Caching Hot Pages) addresses this trade-off through three filter-based DRAM-caching techniques."
1193616,15258,22288,A rule-based method for commas' disambiguation in Chinese patent text,2012,We described a rule-based method for disambiguating Chinese commas in patent text which will be beneficial to the work on Chinese-English Patent MT. We annotated ten thousand sentences of patent text and made a number of rules according to the annotated results. Experiments were conducted on 5 intact patent documents containing 1219 commas and our model achieves an accuracy of over 90% overall.
1217608,15258,9856,Separation virtual machine monitors,2012,"Separation kernels are the strongest known form of separation for virtual machines. We agree with NSA's Information Assurance Directorate that while separation kernels are stronger than any other alternative, their construction on modern commodity hardware is no longer justifiable. This is because of orthogonal feature creep in modern platform hardware. We introduce the separation VMM as a response to this situation and explain how we prototyped one."
316023,15258,22288,MF-PDP: Multi-function provable data possession scheme in cloud computing,2014,"This paper proposed a multi-function provable data possession (MF-PDP), which supports public verification, data dynamic, unlimited times verification and sampling verification. The detail design is provided and the theory analysis about the correctness, security and performance are also described. The experiment emulation and compare analysis suggest the feasibility and advantage."
2370248,15258,9836,Medical Ultrasound Imaging: To GPU or Not to GPU?,2011,Medical ultrasound imaging stands out from other modalities in providing real-time diagnostic capability at an affordable price while being physically portable. This article explores the suitability of using GPUs as the primary signal and image processors for future medical ultrasound imaging systems. A case study on synthetic aperture (SA) imaging illustrates the promise of using high-performance GPUs in such systems.
1956430,15258,8806,A design method for modular energy-aware software,2013,"Nowadays reducing the overall energy consumption of software is important. A well-known solution is extending the functionality of software with energy optimizers, which monitor the energy consumption of software and adapt it accordingly. To make such extensions manageable and to cope with the complexity of the software, modular design of energy-aware software is necessary. Therefore, this paper proposes a dedicated design method for energy-aware software."
2057327,15258,9836,Generation of linear cartesian trajectories for robots using industrial motion-controllers,2011,"The paper focuses on the problem of Cartesian trajectory generation for manipulators. The proposed solution relies on the computation of spline coefficients both in the Cartesian and joint spaces. The method takes into account motor capabilities by checking maximum velocity and acceleration constraints. The solution was experimentally verified on a novel manipulator with hybrid, parallel-serial kinematic structure."
751849,15258,8806,Nested atomic sections with thread escape: a formal definition,2014,"We consider a simple imperative language with fork/join parallelism and lexically scoped nested atomic sections from which threads can escape. In this context, our contribution is the precise definition of atomicity, well-synchronisation and the proof that the latter implies the strong form of the former. A formalisation of our results in the  Coq  proof assistant is also available."
1021672,15258,8912,Model-based evaluation of system resilience,2013,"The notion of system resilience is receiving increased attention in domains ranging from safety-critical applications to ubiquitous computing. After reviewing how resilience has been defined in various contexts, we focus on a dependability-based definition and a performability-based extension thereof. Modeling problems posed by the quantitative evaluation of system resilience are then discussed, along with some suggestions as to how they might be solved."
2947239,15258,22288,Synthetic evaluation on the performance of network coordinate systems,2012,"Network coordinate systems can improve the performance of large distributed applications on the Internet. However, the current methods for performance evaluation on network coordinate systems are based on static and individual indicators, which cannot fully show their performance. In this paper, we firstly study some evaluation indicators on network distance prediction, and point out their disadvantages. Then, a synthetic evaluation indicator is proposed to evaluate the performance of network coordinate systems. At last we give an example to show how the synthetic evaluation indicator works."
1871492,15258,8228,A Comparison of Channel Switching Schemes for IPTV Systems,2011,"One of the main challenges in IPTV systems is the reduction of startup delays, especially in channel switchings. While this problem does not exist in traditional television, in IPTV systems it is relevant, due to bandwidth limitation as well as to buffering. This paper proposes three novel schemes for fast channel switching that reduces the occurrences of latencies caused by buffers and overlay structures."
1422543,15258,23836,"An Experience of Early Initiation to Parallelism in the Computing Engineering Degree at the University of Murcia, Spain",2012,"This paper presents an on-going experience in early introduction to parallelism in the Computing Engineering Degree. Four courses of the second year and a computing centre participate in the experience. The courses are given by three departments. Students are introduced to parallelism for the first time in the second year, and with our experience we aim to approach different topics of parallelism in a coordinated and practical way."
691315,15258,9836,AMD Fusion APU: Llano,2012,"The Llano variant of the AMD Fusion accelerated processor unit (APU) deploys AMD Turbo CORE technology to maximize processor performance within the system's thermal design limits. Low-power design and performance/watt ratio optimization were key design approaches, and power gating is implemented pervasively across the APU."
1674926,15258,8806,Internet of things: a process calculus approach,2013,"This paper presents a process calculus specifically designed to model systems based on the Internet of Things paradigm. We define a formal syntax and semantics for the calculus, and show how it can be used to reason about relevant examples. We also define two notions of bisimilarity, one capturing the behavior seen by the end user of the system, and one allowing compositional reasoning."
2933245,15258,22288,SOA based cloud computing trust model research with a curve fitting method,2012,"This paper proposes a cloud computing trust model based-on SOA by combining the characteristics of SOA, and discusses the relation between the service and users in the cloud computing. Meanwhile, proposes a curve fitting based trust selecting and updating mechanism to ensure the authenticity and accuracy of the trust relation. Finally, verifies the rationality of the trust model in terms of the curve fitting function and mathematical experiment analysis of this trust model."
1825059,15258,9836,Dark Silicon and the End of Multicore Scaling,2012,"A key question for the microprocessor research and design community is whether scaling multicores will provide the performance and value needed to scale down many more technology generations. To provide a quantitative answer to this question, a comprehensive study that projects the speedup potential of future multicores and examines the underutilization of integration capacity-dark silicon-is timely and crucial."
2136806,15258,8306,Race logic: a hardware acceleration for dynamic programming algorithms,2014,"We propose a novel computing approach, dubbed Race Logic, in which information, instead of being represented as logic levels, as is done in conventional logic, is represented as a timing delay. Under this new information representation, computations can be performed by observing the relative propagation times of signals injected into the circuit (i.e. the outcome of races). Race Logic is especially suited for solving problems related to the"
1563383,15258,9836,Toward Dark Silicon in Servers,2011,"Server chips will not scale beyond a few tens to low hundreds of cores, and an increasing fraction of the chip in future technologies will be dark silicon that we cannot afford to power. Specialized multicore processors, however, can leverage the underutilized die area to overcome the initial power barrier, delivering significantly higher performance for the same bandwidth and power envelopes."
1666718,15258,22288,Trusting the Cloud: A PROV + RBAC Approach,2014,"This paper describes a provenance-based access control system for the cloud. The system relies on provenance (PROV-DM, PROV-O) and access-control models (RBAC) together with a distributed rule-based mechanism. The system allows rule propagation (in the cloud) and uses a central execution engine for enforcing security and trustworthiness. This paper provides a comparison between PROV-DM and PROV-O in terms of efficiency and expressiveness regarding Provenance graphs."
1335107,15258,8912,A study of fault-tolerance characteristics of data center networks,2012,"We present an evaluation of the fault-tolerance characteristics of several important data center network topologies, including Fat-tree, DCell, HyperBCube and BCube using several metrics, including average path length, aggregated bottleneck throughput and connection failure ratio. These enable us to present an objective comparison of the network topologies under faulty conditions."
2925096,15258,22288,Mandarin isolated words recognition method based on pitch contour,2012,"In this paper, we attempt to use pitch contour in Mandarin isolated words recognition by matching candidate pitch contour with a set of templates. To apply it in speaker-independent speech recognition, we propose a remedy algorithm to weaken speaker information in pitch contour. Speaker-dependent and - independent speech recognition experiments are carried out to evaluate performance of pitch contour and MFCC. Score fusion of MFCC and revised pitch contour are implemented. Experimental results demonstrate that pitch contour performs comparably with MFCC in speaker-dependent speech recognition. Through score fusion, the revised pitch contour helps in improving performance in speaker-independent speech recognition."
1892804,15258,23749,Pricing and Resource Allocation in a Cloud Computing Market,2012,The problem is identified as a pricing driven virtual machine (VM) revenue maximization problem with Markovian traffics in a cloud market composed of hybrid cloud and public cloud. A pooled resource allocation model is built followed by numerical tests. The results indicate that hybrid cloud performs the best and the resource allocation model helps optimally allocate the pooled resources.
2939327,15258,22288,The design of agricultural product's production antecedents acquisition terminal based on Hi3511 and 3G technology,2012,"The agricultural products' production link, the production antecedents data is the foundation of the traceability system. In the process of agricultural products' production antecedents acquisition, according to the fact that the single acquisition method, the low collection efficiency, and the antecedents data was easy to tamper. This paper designs an agricultural products' production antecedents acquisition terminal based on Hi3511 and 3G technology. The terminal equipment can be realized agricultural products' production multimedia production antecedents data Acquisition of text, picture and video format. The result of using it in practice indicates that the equipment can meet the requirement of real-time and multi-source production antecedents acquisition."
1535613,15258,9836,Resource Management on Multicore Systems: The ACTORS Approach,2011,"High-performance embedded systems require the execution of many applications on multicore platforms and are subject to stringent restrictions and constraints. The ACTORS project approach provides temporal isolation through resource reservation over a multicore platform, adapting the available resources on the basis of the overall quality requirements. The architecture is fully operational on both ARM MPCore and x86 multicore platforms."
2074705,15258,9748,Self-stabilization versus robust self-stabilization for clustering in ad-hoc network,2011,"In this paper, we compare the two fault tolerant approaches: self-stabilization and robust self-stabilization, and we investigate their performances in dynamic networks. We study the behavior of four clustering protocols; two self-stabilizing GDMAC and BSC, and their robust self-stabilizing version R-GDMAC and R-BSC. The performances of protocols are compared in terms of their cluster-heads number, availability of both minimal and optimum services and the stabilization time."
2190593,15258,23749,Design and Implementation of a Secure Healthcare Social Cloud System,2012,"Two cutting edge technologies are cloud computing and social media. Healthcare is a promising application of these technologies. In this paper, we describe our design and prototype implementation of a social healthcare network over the cloud. The system is secured with a trust-aware role-based access control. Our work addresses an unmet need in social healthcare networking -- emotional support, and demonstrates social healthcare network application in a real cloud computing environment."
1197832,15258,507,Data management over flash memory,2011,"Flash SSDs are quickly becoming mainstream and emerge as alternatives to magnetic disks. It is therefore imperative to incorporate them seamlessly into the enterprise. We present the salient results of research in the area, touching all aspects of the data management stack: from the fundamentals of flash technology, through storage for database systems and the manipulation of SSD-resident data, to query processing."
2456206,15258,22288,An incremental algorithm for formation a concept lattice based on the intent waned value,2011,The intent waned value is a connection between concepts. In this article a kind of incremental algorithm of concept lattice formation calculated by waned value altogether with extent and intent is provided. As in this algorithm the intend waned value is contained in intermediate result so it is easy and rapid to determine if the concept is a “top element” and the speed of “top element” checking will be very quick. Therefore the speed of concept lattice formation is improved obviously.
2224914,15258,9836,New method of fractional order integrator analog modeling for orders 0.5 and 0.25,2011,"In the paper a novel method of analog modeling of fractional order integrators is presented. In particular, two special cases are discussed, i.e. integrators of order α = 0.25, and α = 0.5. The method proposed is based on the domino ladder approximation of irrational transfer function. It allows to obtain an analog model using only electric elements like resistors and capacitors of standard produced values."
2216071,15258,8494,A low-power dual-rail inputs write method for bit-interleaved memory cells,2011,"We propose a dual-rail data write technique for bit-interleaved memory cells to reduce power dissipation for the write operation without affecting the read operation. The proposed technique can be applied to two reported bit-interleaved memory cells with a write power reduction range from 30% to 45%, depending on memory cells and operations. In addition, in the proposed technique, a subthreshold non bit-interleaved memory cell is modified to be bit-interleaved without increasing the number of transistors in memory cell."
1168532,15258,23836,An Analysis of Multicore Specific Optimization in MPI Implementations,2012,"We first introduced the multicore specific optimization modules of two common MPI implementations &#x00E2; MPICH2 and Open MPI, and then tested their performance on one multicore computer. By enabling and disabling these modules, we provided their performance, including bandwidth and latency, under different circumstances. Finally, we analyzed the two MPI implementations and discussed the choice of MPI implementations and possible improvements."
2066042,15258,22288,An automatic facial feature point localization method,2011,"This paper proposes an automatic facial feature point localization method that based on calculating the similarity. In a complicated illumination condition, beard interference and small angle facial tilt, this system which mentioned in this paper is still robust. It is not necessary to train the sample set which localize the facial feature points manually. The experimental results demonstrate that this system have a good performance and high accuracy."
982817,15258,11330,An optimal distributed load balancing algorithm for homogeneous work units,2014,"Many parallel applications, for example, Adaptive Mesh Refinement simulations, need dynamic load balancing during the course of their execution because of dynamic variation in the computational load. We propose a novel tree-based fully distributed algorithm for load balancing homogeneous work units. The proposed algorithm achieves perfect load balance while doing minimum number of migrations of work units."
1116757,15258,11330,Exploiting reuse information to reduce refresh energy in on-chip eDRAM caches,2013,"This work introduces a novel refresh mechanism that leverages reuse information to decide which blocks should be refreshed in an energy-aware eDRAM last-level cache. Experimental results show that, compared to a conventional eDRAM cache, the energy-aware approach achieves refresh energy savings up to 71%, while the reduction on the overall dynamic energy is by 65% with negligible performance losses."
2597654,15258,11321,Modality neutral techniques for brain image understanding,2011,"With the influx of available multi-modality neuroimaging data, the need to mine large databases for interesting features in a modality neutral way across many brain disorders is of interest. In this paper I present some examples of applying models originating in the computer vision and text mining communities to neuroimaging data which are not tuned for a particular imaging modality and are agnostic to the underlying brain disorder."
837850,15258,22288,An approach to the computation of distance of concept lattice by utilizing waned value of intension,2011,"Concept lattice, which is a core data structure of the theory of formal concept analysis, has been widely applied to many fields. By computing the distance between concepts of a concept lattice, objects of the formal context can be analyzed clusteredly, so that the required data of the users can be obtained. In the concept lattice, a new approach to computing the distance between concepts is proposed, and the mathematical induction is used to prove this. The approach firstly computes the waned value of intension between concepts, and then computes the distance between concepts of a concept lattice by using the addition of the waned value of intension."
389198,15258,9748,Subsquares Approach - Simple Scheme for Solving Overdetermined Interval Linear Systems,2013,"In this work we present a new simple but efficient scheme - Subsquares approach - for development of algorithms for enclosing the solution set of overdetermined interval linear systems. We are going to show two algorithms based on this scheme and discuss their features. We start with a simple algorithm as a motivation, then we continue with a sequential algorithm. Both algorithms can be easily parallelized. The features of both algorithms will be discussed and numerically tested."
1218132,15258,8912,Improving the dependability of FPGA-based real-time embedded systems with partial dynamic reconfiguration,2013,"This paper explores advances in reconfiguration properties of SRAM-based FPGAs to improve the resilience of real-time embedded systems that use this technology. The effects of radiation on these devices are described and the applicability of the most used fault tolerance approaches is investigated. It finishes proposing a few improvements on these methodologies and discusses the roadmap to reach that goal, presenting the on-going and the future work."
1430436,15258,8335,Deflection routing in 3D Network-on-Chip with TSV serialization,2013,"This paper proposes a deflection routing for 3D NoC with serialized TSVs. Bufferless deflection routing provides area- and power-efficient communication under low to medium traffic load. Under 3D circumstances, the bufferless deflection routing can yield even better performance than buffered routing when key aspects are properly taken into account. Evaluation of the proposed scheme shows its effectiveness in throughput, latency, and energy consumption."
921417,15258,22260,AODV and OLSR Routing Protocols in MANET,2013,"The growing of wireless and mobile technologies has resulted in more and more active researches to be done on scalability, performance, and compatibility of packet routing with minimal changes to the network. In this paper, we review two well known routing protocols in mobile ad hoc networks i.e., Ad hoc On-Demand Distance Vector and Optimized Link State Routing Protocols and compare them in terms of performance."
2092408,15258,9748,Barrier Coverage Constructions for Border Security Systems Using Wireless Sensors,2011,"In this paper, we propose network construction methods of sensor nodes for Border Security Systems. A Border Security System watches intruders by using sensor nodes with communication function. The detection of some intruders and the use of a long-term operation system are required in this system. In this paper, we propose two methods to reduce the power consumption of the whole network system by effective control of sensor nodes. By computer simulation, we show that the proposed network construction methods are suitable for Border Security Systems."
2898083,15258,22288,A web service discovery computational method for IOT system,2012,"This paper analyzes the needs of service discovery for Internet of Things (IOT) systems, and raises a service matching algorithm based on ontology. The proposed algorithm combines the characteristics of semantic similarity and semantic relativity, which can better complete the business of the services discovery capabilities of IOT. In addition, the algorithm has good scalability, and it can be applied to different fields only need to replace the domain ontology."
2897230,15258,22288,Algorithm of identifying opinion leaders in BBS,2012,"Opinion leaders play a very important role in online communities, which can guide the direction of public opinion. This paper proposes a method to identify opinion leaders, which combine the content influence with the emotion influence as the total influence. Then we take the result as the authority value as the weight of the link between users. On this basis, an algorithm named ISRank is proposed to identify the opinion leaders in BBS, and experiments indicate that ISRank algorithm can effectively improve the accuracy of mining opinion leaders."
1371519,15258,9244,Orthrus: a framework for implementing high-performance collective I/O in the multicore clusters,2013,"This paper presents a framework, Orthrus, that can accommodate multiple collective-I/O implementations, each optimized for some performance aspects, and dynamically select the best performing one accordingly to current workload and system performance bottleneck. We have implemented Orthrus in the ROMIO library. Our experimental results with representative MPI-IO benchmarks show that  Orthrus  can significantly improve the performance of collective I/O under various workloads and system scenarios."
2390665,15258,22021,Exact scalar minimum storage coordinated regenerating codes,2012,"We study the exact and optimal repair of multiple failures in codes for distributed storage. More particularly, we examine the use of interference alignment to build exact scalar minimum storage coordinated regenerating codes (MSCR). We show that it is possible to build codes for the case of k = 2 and d ≥ k by aligning interferences independently but that this technique cannot be applied as soon as k ≥ 3 and d > k. Our results also apply to adaptive regenerating codes."
1330240,15258,23836,Mega Data Center for Elastic Internet Applications,2014,"This paper outlines a scalable architecture that supports datacenter-wide resource management for elastic Internet applications in a mega data center. Our architecture includes a scalable load-balancing fabric and provides effective knobs to balance load among the applications, servers, access links, as well as the load-balancing components themselves--the low-level resource managers and switches in the load-balancing fabric."
2417090,15258,9836,Multi-GPU DGEMM and High Performance Linpack on Highly Energy-Efficient Clusters,2011,"High Performance Linpack can maximize requirements throughout a computer system. An efficient multi-GPU double-precision general matrix multiply (DGEMM), together with adjustments to the HPL, is required to utilize a heterogeneous computer to its full extent. The authors present the resulting energy-efficiency measurements and suggest a cluster design that can utilize multiple GPUs."
2926771,15258,22288,The optional routing optimization strategy of Distributed Mobility Management,2012,This paper presents a review for Distributed Mobility Management (DMM). Mobility Management is one of the key technologies in Mobile Network. DMM can solve the problems of traditional Centralized Mobility Management (CMM) such as non-optimal route and single point of failure and attack. There are several DMM approaches in recent researches. Some are based on MIP and some on PMIP. We summarize and present an optional optimization (O2) strategy in this paper.
945705,15258,208,Improving Virtual Machine Migration via Deduplication,2014,"For this study the techniques of virtual machine migration are understood and the affects deduplication has on migration are evaluated. The benefits of using deduplication and compression on virtual machines show in the metric of space saved during migrating. Deduplication is computationally expensive so we evaluate how to group virtual machines with similar elements in order to improve migration. From this study, grouping virtual machines based on similar elements improves the overhead from deduplication and compression but estimates which virtual machines are best grouped together."
1636457,15258,339,POSTER: On the Resilience of DNS Infrastructure,2014,"We study the operational characteristics of the DNS infrastructure:  transitive-trust ,  coresidence  and  servers placement . We discuss how these factors impact resilience, stability and security of the DNS services. As our study indicates, common configuration choices, that domain operators make, result in a fragile DNS infrastructure, susceptible to malicious attacks and benign failures. We provide recommendations for improving robustness of DNS."
1776050,15258,9836,Beyond Traditional Microprocessors for Geoscience High-Performance Computing Applications,2011,"The oil and gas industry is a major user of high-performance computing, and geoscience computational cycles are dominated by kernels that are relatively few and well defined. This project explores accelerating geoscience applications using FPGA-based hardware, optimizing the algorithm and the hardware to achieve maximum performance. This approach can deliver speedup of 20 to 70 times compared with a conventional HPC node."
1382306,15258,9836,Virtualized ECC: Flexible Reliability in Main Memory,2011,"Virtualized error checking and correcting (ECC) is a scheme that virtualizes memory-error correction. Unlike traditional uniform ECC, which provides a fixed level of error tolerance, virtualized ECC enables flexible memory protection by mapping redundant information needed for correcting errors onto the memory namespace. Additionally, virtualized ECC enables error-correction mechanisms that can adapt to user and system demands."
1975220,15258,8228,Cooperative Regenerating Codes for Distributed Storage Systems,2011,"When there are multiple storage node failures in distributed storage system, regenerating them individually is suboptimal as far as repair bandwidth minimization is concerned. The tradeoff between storage and repair bandwidth is derived in the case where data exchange among the newcomers is enabled. The tradeoff curve with cooperation is strictly better than the one without cooperation. An explicit construction of cooperative regenerating code is given."
420203,15258,22288,Prefix-maximized query-tree anti-collision algorithm with robust estimation for RFID system,2014,"In RFID systems, tag anti-collision algorithm is significantly important for fast tag identification. In this paper, we research a robust tag estimation method and the PRQT algorithm, and propose prefix-maximized query-tree (PMQT) tag anti-collision protocol. The simulation results show that the system efficiency of PMQT is higher than the previous protocol about 18%–30%. In addition, PMQT algorithm has tolerance to the inaccuracy of tag estimation."
2635731,15258,9748,A Square Block Format for Symmetric Band Matrices,2013,"This contribution describes a Square Block, SB, format for storing a banded symmetric matrix. This is possible by rearranging “in place” LAPACK Band Layout to become a SB layout: store submatrices as a set of square blocks. The new format reduces storage space, provides higher locality of memory accesses, results in regular access patterns, and exposes parallelism."
2438454,15258,122,Theoretical analysis of classic algorithms on highly-threaded many-core GPUs,2014,"The Threaded many-core memory (TMM) model provides a framework to analyze the performance of algorithms on GPUs. Here, we investigate the effectiveness of the TMM model by analyzing algorithms for 3 classic problems -- suffix tree/array for string matching, fast Fourier transform, and merge sort -- under this model. Our findings indicate that the TMM model can explain and predict previously unexplained trends and artifacts in experimental data."
1146278,15258,9836,Coordinating DRAM and Last-Level-Cache Policies with the Virtual Write Queue,2011,"To alleviate bottlenecks in this era of many-core architectures, the authors propose a virtual write queue to expand the memory controller's scheduling window through visibility of cache behavior. Awareness of the physical main memory layout and a focus on writes can shorten both read and write average latency, reduce memory power consumption, and improve overall system performance."
2086789,15258,23836,Efficient Parallel Scheduling of Malleable Tasks,2011,"We give an $O(n + \min\{n,m\} \log{m})$ work algorithm for scheduling $n$ tasks with flexible amount of parallelism on $m$ processors, provided the speedup functions of the tasks are concave. We give efficient parallelizations of the algorithm that run in polylogarithmic time. Previous algorithms were sequential and required quadratic work. This is in some sense a best-possible result since the problem is NP-hard for more general speedup functions."
1694483,15258,20774,In search of parallel dimensions,2012,"Performance matters. But how we improve it is changing. Historically, transparent hardware improvements would mean software just ran faster. That may not necessarily be true in the future. To continue the pace of innovation, the future will need to be increasingly parallel--nvolving parallelism across data, threads, cores, and nodes. This talk will explore some of the dimensions of parallelism, and the opportunities and challenges they pose."
956473,15258,20754,Identity Management--In Privacy We Trust: Bridging the Trust Gap in eHealth Environments,2013,"Identity management solutions that control the data that users provide to individual healthcare services raise trust and privacy concerns, such as who owns user data, how to control its spread, and how to build trustworthy associations between care providers. Reputation systems can enhance eHealth systems by bridging the gap between strong contractual agreements and first-time domain exchanges."
2906981,15258,22288,A novel visual servoing microassembly system,2012,"The focus of this paper is the design and development of an automatic system for microassembly. The automatic processing is made possible by (i) the development of a machine vision algorithm to identify the targets and end-effectors, (ii) an uncalibrated visual servoing algorithm to lead the end-effector to grasp the micro-pieces and then assemble the target. The experimental results demonstrate that this prototype microassembly system is effective and practicable for automatic microassembly applications."
1983552,15258,9836,An unscented Kalman filter approach to designing GMDH neural networks: Application to the tunnel furnace,2011,"This paper presents an identification method of dynamic systems based on the Group Method of Data Handing. In particular, a new structure of the dynamic neuron in pole representation is proposed. Moreover, a new training algorithm based on the Unscented Kalman Filter is presented. The final part of this work contains an illustrative example regarding the application of the proposed approach to an identification of the tunnel furnace."
1436212,15258,9244,ACIC: automatic cloud I/O configurator for parallel applications,2013,"To tackle the highlighted I/O bottleneck problem in cloud, we proposes ACIC, a system which automatically searches for optimized I/O system configurations from many candidates for each individual application running on a given cloud platform. The top ACIC-recommended configuration improves the applications? performance by a factor of up to 10.5 (3.0 on average), and cost saving of up to 89% (53% on average), compared with a commonly used baseline."
241806,15258,293,Scaling Bandwidth Estimation to High Speed Networks,2014,"Existing bandwidth estimation tools fail to perform well at gigabit and higher network speeds. In this paper we study several sources of noise that must be overcome by these tools in high-speed envrionments and propose strategies for addressing them. We evaluate our Linux implementation on 1 and 10Gbps testbed networks, showing that our strategies help significantly in scaling bandwidth estimation to high-speed networks."
886292,15258,8912,A view on the past and future of fault injection,2013,"Fault injection is a well-known technology that enables assessing dependability attributes of computer systems. Many works on fault injection have been developed in the past, and fault injection has been used in different application domains. This fast abstract briefly revises previous applications of fault injection, especially for embedded systems, and puts forward ideas on its future use, both in terms of application areas and business markets."
2285635,15258,22288,A domestic speech recognition based on Hidden Markov Model,2011,"Based on HMM (Hidden Markov Model), this paper proposed a domestic speech recognizer, which can be used at home to do some simple tasks, such as turning on/off the light, opening/closing the doors and turning up/down air conditioners' temperature according to voice commands. Compared to traditional speech recognizers, it achieves a high recognition rate and low computational cost, which are important for the domestic application."
2392930,15258,11058,Reagents: expressing and composing fine-grained concurrency,2012,"Efficient communication and synchronization is crucial for fine grained parallelism. Libraries providing such features, while indispensable, are difficult to write, and often cannot be tailored or composed to meet the needs of specific users. We introduce  reagents , a set of combinators for concisely expressing concurrency algorithms. Reagents scale as well as their hand-coded counterparts, while providing the composability existing libraries lack."
1063163,15258,23836,SlimCodeML: An Optimized Version of CodeML for the Branch-Site Model,2012,"CodeML (part of the PAML package) implements a maximum likelihood-based approach to detect positive selection on a specific branch of a given phylogenetic tree. While CodeML is widely used, it is very compute-intensive. We present SlimCodeML, an optimized version of CodeML for the branch-site model. Our performance analysis shows that SlimCodeML substantially outperforms CodeML (up to 9.38 times faster), especially for large-scale genomic analyses."
2193328,15258,22288,Tourist flows analysis and decision support system based on intelligent mobile phone,2011,"In this paper, we propose and establish an analysis and decision support system based on smart phone for tourist flows, including smart phone based area traffic monitoring and real-time decision support subsystem, traveling by car passenger analysis and decision support subsystem. We give out the system architecture, software design, and related research and design algorithm. We achieve the tourists flow data acquisition and control, distribution within the tourist area, tourist characteristics and rules of analysis and decision support."
2555290,15258,8912,5th international workshop on adaptive and dependable mobile ubiquitous systems ADAMUS 2011,2011,"The vision of mobile and ubiquitous systems is becoming a reality thanks to the recent advances in wireless communication and device miniaturization. However, the widespread industrial uptake of these systems is still compromised by the highly error-prone and heterogeneous mobile provisioning environments, which induce several impairments to normal operation. Thus, how to improve the dependability of these systems is still an open issue."
1552070,15258,23712,A diversified and correct-by-construction broadcast service,2012,"We present a fault-tolerant ordered broadcast service that is correct-by-construction. Our broadcast service allows for diversity in space, whereby the participants in the broadcast protocol run different code, as well as in time, whereby the protocol itself is changed periodically. We use the Nuprl proof assistant to specify the service, prove correctness, and synthesize the code. The paper includes initial performance results."
1119312,15258,22288,Multi-characters interaction based on honeycomb,2012,"This paper introduces an approach to create a scene where avatars are fighting/ competing with unknown-numbers of opponents whose actions are unknown-types based on honeycomb and four-gates principle. Honeycomb-based method includes: honeycomb-based scenes, representations of interactive positions and honeycomb-based finite state machine. The honeycomb-based scenes describe how to combine multi-characters animation with honeycomb, and representations of interactive positions and honeycomb-based finite state machine are used for mechanism of synthesizing avatars' response actions in the scenes. And using four-gates principle (combine with honeycomb) deals with uncertainty types of attack."
1925636,15258,9836,Direct adaptive fuzzy control for a two-link space robot,2011,An adaptive fuzzy logic control scheme is developed for tracking a square trajectory by the endpoint of a two-link rigid joint space robot. The control strategy is based on a direct adaptive control scheme in which the controller gains are adapted in real-time according to fuzzy logic systems such that the tracking errors between a reference model and the actual robot system outputs are brought to zero.
2116270,15258,9836,MMF of six phase induction motors for rectangular current supply,2011,The problem of diminishing the pulsating torques in high power induction motor drives are investigated. This paper describes analysis and numerical results of MMF in three and six phase AC machines supplying by sinusoidal and nonsinusoidal currents. Analysis of six phase machines are for different angle between three phase stator windings and different time angles between currents in both three phase systems.
956610,15258,122,Initial study of multi-endpoint runtime for MPI+OpenMP hybrid programming model on multi-core systems,2014,"State-of-the-art MPI libraries rely on locks to guarantee thread-safety. This discourages application developers from using multiple threads to perform MPI operations. In this paper, we propose a high performance, lock-free multi-endpoint MPI runtime, which can achieve up to 40\% improvement for point-to-point operation and one representative collective operation with minimum or no modifications to the existing applications."
313627,15258,9748,A perspective on the CoreGRID grid component model,2011,"The Grid Component Model is a software component model designed partly in the context of the CoreGRID European Network of Excellence, as an extension of the Fractal model, to target the programming of large-scale distributed infrastructures such as computing grids [3]. These distributed memory infrastructures, characterized by high latency, heterogeneity and sharing of resources, suggest the efficient use of several CPUs at once to obtain high performances."
2341838,15258,22288,Reserch on fundamental theory of spatial directional relation,2011,"Spatial directional relation is an important content of spatial relation research, but its fundamental theories were still not perfect; most of the relevant references gave their emphasis to formal description models of directional relation but neglected the fundamental theories system based on directional relation itself. To make deeper investigation into the issue, this paper in detail proposes definition, reference frame, properties, influence factors, and classification of directional relation; these conceptual issues provide theory basis for formal description models of directional relation and applications of relevant research."
1089768,15258,11330,Author retrospective for counting solutions to linear and nonlinear constraints through ehrhart polynomials: applications to analyze and transform scientific programs,2014,"Ehrhart polynomials are amazing mathematical objects that I discovered in the early 90's and that have many applications in computer science. This retrospective relates my personal and scientific experience regarding this research work, my meeting with the mathematician Eugene Ehrhart, and addresses some extensions and perspectives of further developments.   Original paper: http://dx.doi.org/10.1145/237578.237617"
1977037,15258,23836,A Self-stabilizing Algorithm for the Maximal 2-packing in a Cactus Graph,2012,"In this paper we present a time optimal self-stabilizing algorithm for the maximal 2-packing in a cactus graph. The cactus is a network topology such that any edge belongs to at most one cycle. The cactus has important applications in telecommunication networks, location problems, biotechnology, among others. The execution time of this algorithm is proportional to the diameter of the cactus. To the best of our knowledge, this algorithm outperforms current algorithms presented in the literature for this problem and in this topology."
2547095,15258,9748,Direct GPU/FPGA Communication via PCI Express,2012,"Parallel processing has hit mainstream computing in the form of CPUs, GPUs and FPGAs. While explorations proceed with all three platforms individually and with the CPU-GPU pair, little exploration has been performed with the synergy of GPU-FPGA. This is due in part to the cumbersome nature of communication between the two. This paper presents a mechanism for direct GPU-FPGA communication and characterizes its performance in a full hardware implementation."
920276,15258,9836,Wavelet transform based pre-processing for side channel analysis,2012,"We suggest, in a methodological manner, the use of Wavelet transforms to improve side channel analysis (SCA). The proposed applications are involved in several side channel analysis aspects: storage of traces, patterns detection and noise filtering. We show that all these aspects are useful to improve evaluation of information leakages from embedded devices. In particular, we show how wavelets favour practical secret key recovery."
2940435,15258,22288,Network coding link optimization problems based on genetic and particle swarm algorithm,2012,"Considering a multicast scenario, we want to minimize the coding nodes used for network coding while achieving the desired throughput. By using the genetic and particle swarm algorithm, this article solves the optimization of the network coding. According to the simulation results, it can be concluded that the genetic and particle swarm algorithm has faster convergence speed than the genetic algorithm in solving the problem of network coding optimization, and it can get better suboptimal value in a shorter period of time."
174769,15258,9748,Parallelization of Encryption Algorithm Based on Chaos System and Neural Networks,2013,"In this paper, the results of parallelizing of encryption algo- rithm based on a chaos system and neural networks are presented. A data dependence analysis of loops was applied in order to parallelize the algo- rithm. The parallelism of the algorithm is demonstrated in accordance with the OpenMP standard. As a result of my study, it was stated that the most time-consuming loops of the algorithm are suitable for paral- lelization. The efficiency measurement of a parallel program is showed."
1215112,15258,9836,Peach: A Multicore Communication System on Chip with PCI Express,2011,"The PCI Express Adaptive Communication Hub (Peach) is an eight-core communication system on chip with four PCI Express Revision 2.0 ports, each with four lanes. Peach realizes a high-performance, power-aware, highly dependable network that uses PCI Express not only for connecting peripheral devices but also as a communication link between computing nodes. This approach opens up new possibilities for a range of communications."
2946809,15258,22288,An IBE-based security scheme on Internet of Things,2012,"Internet of Things (IoT) is a novel concept with widespread concern representing a rich field of research problems. In particular, a number of problems related to privacy and security remain unsolved. In this paper, a brief introduction to the Internet of Things of the concept and the key technology is made, and a survey on some privacy and security problems is stated. Finally I propose a possible solution based on IBE cryptosystem to some of the problems."
1255740,15258,23836,Two Edge Coloring Algorithms Using a Simple Matching Discovery Automata,2012,"We here present two probabilistic edge coloring algorithms for a message passing model of distributed computing. The algorithms use a simple automata for finding a matching on a graph to produce the colorings. Our first algorithm for edge coloring finds an edge coloring of a graph which is guaranteed to use no more than 2? - 1 colors and completes in O(?) communication rounds using only one hop information, where ? is the greatest degree of the graph. Our second algorithm finds a strong edge coloring of a symmetric digraph in O(?) communication rounds, using only one hop information."
1401324,15258,8335,Efficient feasibility analysis of DAG scheduling with real-time constraints in the presence of faults,2014,Tasks in hard real-time systems are required to meet deadlines in the presence of faults. We conclude that a sufficient condition of a task set experiencing its worst-case finish time (WCFT) is that its critical task (CT) incurs all faults. An algorithm is presented to identify the CT and the WCFT in O(N 2 ) with N being the task number. A common practice that bet the WCFT using the task with the longest re-execution time could under estimate by up-to 35%!
1414344,15258,9836,MOPED: Accelerating Data Communication on Future CMPs,2011,"The Message Orchestration and Performance Enhancement Device (MOPED) provides an explicit hardware communication mechanism that offloads synchronization and data communication from CPUs to enable overlap between computation and communication, while also transferring data efficiently. The device achieves significant improvement in performance of real applications and reduction of on-chip cache misses, off-chip memory misses, and application execution time."
921021,15258,9836,"Attaining Single-Chip, High-Performance Computing through 3D Systems with Active Cooling",2011,This article explores the benefits and the challenges of 3D design and discusses novel techniques to integrate predictive cooling control with chip-level thermal-management methods such as job scheduling and voltage frequency scaling. Using 3D liquid-cooled systems with intelligent runtime management provides an energy-efficient solution for designing single-chip many-core architectures.
1628312,15258,8335,On real-time STM concurrency control for embedded software with improved schedulability,2013,"We consider software transactional memory (STM) concurrency control for embedded multicore real-time software, and present a novel contention manager for resolving transactional conflicts, called PNF. We upper bound transactional retries and task response times. Our implementation in RSTM/real-time Linux reveals that PNF yields shorter or comparable retry costs than competitors."
1687110,15258,8228,Promotion of content availability by playlist viewers in CDN-P2P systems,2013,"This paper assesses the effectiveness of playlists for improving the content availability in CDN-P2P networks that distributes YouTube-like videos. Real data collected from YouTube was used and the popularity patterns of playlists and first page videos were characterized. Moreover, the impact of playlist viewers on content availability was evaluated. Results show that the improvement in content availability is about 40% for highly connected playlist viewers. For systems with less connected playlist viewers, the improvement exceeds 20% for different scenarios."
2975026,15258,22288,Compatability study on broadcasting system interfering with LTE system,2012,"DTMB is the Chinese TV standard for mobile and fixed terminals used. TD-LTE is a homegrown 4G mobile-telecommunications technology and standard developed by China. This paper evaluates the interference from TV stations to TD-LTE system when the two systems coexist in the UHF band. This paper adopts the Monte-Carlo simulation methodology, and provides the simulation results and analysis."
2132855,15258,22288,Improved moving objects indexing model in mobile computing environment,2011,"When we take cognizance of the regular track of moving objects within a limited area, we put forward an improved moving objects indexing model in mobile computing environment based on Time-Parameterized R-tree (GG TPR-tree). With the GG TPR-tree, we can index moving objects which are neighbors and will run to the same direction in the future to improve the efficiency. So, we put forward the indexing model for the moving objects, and moving objects indexing maintenance algorithm and moving objects indexing update algorithm. Experimental results show that the performance of GG TPR-tree's indexing moving inexing is better than the other indexing model on managing a great capacity of moving objects within a limited area."
2351167,15258,8494,A reconfigurable and deadlock-free routing algorithm for 2D Mesh Network-on-Chip,2011,"This paper presents a reconfigurable and deadlock-free routing (RDR) algorithm. It can be reconfigured to adapt to the modification of the topology due to faulty routers. It is evaluated from the point of view of performance penalty under various fault patterns. Meanwhile deadlock-freedom and reconfigure mechanism issues are addressed. Fault-tolerance capability, re-configurability and scalability are further evaluated and compared to several other routing algorithms."
1654487,15258,9836,Supporting Very Large DRAM Caches with Compound-Access Scheduling and MissMap,2012,This work efficiently enables conventional block sizes for very large die-stacked DRAM caches with two innovations: it makes hits faster with compound-access scheduling and misses faster with a MissMap. The combination of these mechanisms enables the new organization to deliver performance comparable to that of an idealistic DRAM cache that employs an impractically large SRAM-based on-chip tag array.
2906919,15258,22288,Research based on improved fuzzy immune PID algorithm optimized copper electrolysis rectifier system,2012,"Aiming at the nonlinear time variable property of the copper electrolysis rectifier system, this paper puts forward the new controlling means to optimize copper electrolysis rectifier system by using improved fuzzy immune PID algorithm based on the investigation and analysis on the situation and tendencies of high-power electrolytic equipment home and abroad. Simulation and experimental results proves that the algorithm used is an effective and advanced control algorithm."
615596,15258,9748,A lower bound technique for communication on BSP with application to the FFT,2012,"Communication complexity is defined, within the Bulk Synchronous Parallel (BSP) model of computation, as the sum of the degrees of all the supersteps. A lower bound to the communication complexity is derived for a given class of DAG computations in terms of the switching potential of a DAG, that is, the number of permutations that the DAG can realize when viewed as a switching network. The proposed technique yields a novel and tight lower bound for the FFT graph."
1694599,15258,9836,Implementing Domain-Specific Languages for Heterogeneous Parallel Computing,2011,"Domain-specific languages offer a solution to the performance and the productivity issues in heterogeneous computing systems. The Delite compiler framework simplifies the process of building embedded parallel DSLs. DSL developers can implement domain-specific operations by extending the DSL framework, which provides static optimizations and code generation for heterogeneous hardware. The Delite runtime automatically schedules and executes DSL operations on heterogeneous hardware."
1780266,15258,8912,Online detection of multi-component interactions in production systems,2011,"We present an online, scalable method for inferring the interactions among the components of large production systems. We validate our approach on more than 1.3 billion lines of log files from eight unmodified production systems, showing that our approach efficiently identifies important relationships among components, handles very large systems with many simultaneous signals in real time, and produces information that is useful to system administrators."
1533482,15258,8912,Performability analysis of RAID10 versus RAID6,2013,"Design of storage system configuration is one of the key issues for providing dependable IT systems. An appropriate RAID storage configuration should consider both performance and availability. To assist the design, this paper presents the performability models for RAID10 and RAID6 that can be used to compare the configuration quantitatively. A performability advantage of RAID6 over RAID10 in sequential read access is discovered by the numerical study in conjunction with performance benchmark results."
864761,15258,23497,Inside windows azure: the challenges and opportunities of a cloud operating system,2014,"Cloud operating systems provide on-demand, scalable compute and storage resources. They allow service developers to focus on their business logic by simplifying many portions of their service, including resource management, provisioning, monitoring, and application lifecycle management. This talk describes some of the technical challenges faced, as well as emergent opportunities created, by Microsoft's cloud operating system Windows Azure."
619692,15258,9748,Statistical Estimates for the Conditioning of Linear Least Squares Problems,2013,In this paper we are interested in computing linear least squares (LLS) condition numbers to measure the numerical sensitivity of an LLS solution to perturbations in data. We propose a statistical estimate for the norm-wise condition number of an LLS solution where perturbations on data are measured using the Frobenius norm for matrices and the Euclidean norm for vectors. We also explain how condition numbers for the components of an LLS solution can be computed. We present numerical experiments that compare the statistical condition estimates with their corresponding exact values.
2393829,15258,9589,Providing Reliable FIB Update Acknowledgments in SDN,2014,"In this paper, we first show that transient, but grave problems such as violations of security policies can occur with real switches even when using consistent updates to Software Defined Networks. Next, we present techniques that are effective in ameliorating this problem. Our key insight is in creating a transparent layer that relies on control and data plane measurements to confirm rule updates only when the rule is visible in the data plane."
1797779,15258,122,A wait-free NCAS library for parallel applications with timing constraints,2011,"We introduce our major ideas of a wait-free, linearizable, and disjoint access parallel NCAS library, called rtNCAS. It focuses the construction of wait-free data structure operations (DSO) in real-time circumstances. rtNCAS is able to conditionally swap multiple independent words (NCAS) in an atomic manner. It allows us, furthermore, to implement arbitrary DSO by means of their sequential specification."
2018044,15258,22288,Study on food safety semantic retrieval system based on domain ontology,2011,"From aspects of domain ontology construction, concept similarity computation based on ontology and semantic query expansion study the related technologies of information retrieval system based on ontology; establish food safety domain ontology and ontology-based concept similarity computation model, put forward a new semantic query expansion method based on concept similarity computation; design and implement food safety semantic retrieval system. The experiments show that this food safety semantic retrieval system is superior to the retrieval system based on keywords both in the recall ratio and the precision, and realize certain intelligent retrieval."
991662,15258,9836,Energy-Aware Accounting and Billing in Large-Scale Computing Facilities,2011,"Proposals have focused on reducing energy requirements for large-scale computing facilities (LSCFs), but little research has addressed the need for energy-usage-based accounting. Energy-aware accounting and billing benefits LSCF owners and users. This article makes a case for accurate cost accounting and billing, which accounts for user-specific energy usage, and identifies the hardware- and software-level changes necessary to support energy-aware accounting."
2939612,15258,22288,SocialRank: Social network influence ranking method,2012,"The influence of an individual in the social network is a both subjective and objective matter, which depends on the quality of his web pages and the altitudes of the others. But there is still much that can be said objectively about the relative influence of every individual in the social network. This paper describes SocialRank, a method for measuring the influence of an individual objectively and mechanically using his attributes and the relations between him and the others. We give the compartments of SocialRank to basic attributes and PageRank. We show how accurately SocialRank access relative influence."
2951437,15258,22288,Combining hand-drawn concept maps with RFID tags,2012,"As concept maps are useful for knowledge organization, representation and sharing, people used to draw concept maps by pen in their daily life. And some concept maps are closely related to physical world. In this paper, we propose a kind of context-aware hand-drawn concept map with RFID tags, which is especially useful for pen-based mobile devices. First, the structure of the hand-drawn concept map is extracted. And then users can assign RFID tags to concept nodes. With the RFID labeled concept nodes, concept maps are linked to the physical world, which can facilitate users' understanding and retrieval of hand-drawn concept maps."
2208338,15258,23836,A Matching Based Automata for Distributed Graph Algorithms,2011,"A consistent problem with distributed algorithms for graph problems is scalability. Here we present a scalable automata that can easily be modified to solve a number of problems. We focus on the Minimum Weighted Vertex Cover problem, showing that our approach improves on the best known algorithm, reducing the number of communication rounds from ( O(log n) ) to ( O(log Delta) ). We then show how our framework can be modified to solve for Edge Coloring and Independent Set."
449569,15258,22288,A study on the software Test Case Reuse Model of feature oriented,2014,"In this paper, a test case reuse model, Test Case Reuse Model , is proposed as a solution to the normative, effectiveness and efficiency issues for the design of test cases for software. Test Case Reuse Model is a refinery, extraction and expression of design methods of test cases in test case sets with similar features of test requirements. Test Case Reuse Model consists of five components, which are the model reuse index, the basic information for model reuse, the test data body, the test protocol body and the execution body. Test Case Reuse Model is developed by testing expert based on test assets such as test term sand cases in the library. Based on Test Case Reuse Model , not only are testers able to increase the efficiency of the design for test terms and cases with the same features, but also can guarantee the normativeness and effectiveness of test design."
1395309,15258,8806,STM concurrency control for multicore embedded real-time software: time bounds and tradeoffs,2012,"We consider software transactional memory (STM) for concurrency control in multicore embedded real-time software. We investigate real-time contention managers (CMs) for resolving transactional conflicts, including those based on dynamic and fixed priorities, and establish upper bounds on transactional retries and task response times. We identify the conditions under which STM (with the proposed CMs) is superior to lock-free synchronization."
609065,15258,20349,Scaling Memcache at Facebook,2013,"Memcached is a well known, simple, in-memory caching solution. This paper describes how Facebook leverages memcached as a building block to construct and scale a distributed key-value store that supports the world's largest social network. Our system handles billions of requests per second and holds trillions of items to deliver a rich experience for over a billion users around the world."
1434837,15258,8228,CCNxServ: Dynamic service scalability in information-centric networks,2012,"Content-centric networks promise to address content networking issues in a better way than today's host-based networking architecture. But content-centric networking does not inherently address the issue of services, particularly service scalability and mobility. We present our work on CCNxServ, a system that allows for dynamic service deployment and scalability in a content-centric networking implementation (CCNx) through an intuitive use of the content naming scheme. It thus extends the concept of content-centric networking towards services."
2974445,15258,22288,A functional framework for software and system of systems method,2012,"This paper focuses on large scale application software systems based on Internet of Things and cloud computing. It proposes framework methods to further describe systems' characteristics, as well as the refinement and formalization of the abstract description. It also discusses the functional frameworks and its applications in system disintegrations, system architecture, and stable intermediate forms. It points out that the frameworks contribute to improvement of building, deployment, and maintenance of these applications."
1732607,15258,8806,A preliminary assessment of Haskell's software transactional memory constructs,2013,"In recent years, usage of multicore architectures has boosted the need for concurrency. Many researchers have pointed out Software Transactional Memory (STM) as an easy way to achieve it. This study presents a preliminary evaluation of Haskell's STM constructs against its lock-based alternative. Subjects which used STM committed significantly fewer mistakes and required on average 12% less time to finish their assignments."
189426,15258,9748,Evaluation of Autoparallelization Toolkits for Commodity GPUs,2013,"In this paper we evaluate the performance of the OpenACC and Mint toolkits against C and CUDA implementations of the standard PolyBench test suite. Our analysis reveals that performance is similar in many cases, but that a certain set of code constructs impede the ability of Mint to generate optimal code. We then present some small improve- ments which we integrate into our own GPSME toolkit (which is derived from Mint) and show that our toolkit now out-performs OpenACC in the majority of tests."
510537,15258,9748,Multi-GPU parallel memetic algorithm for capacitated vehicle routing problem,2014,The goal of this paper is to propose and test a new memetic algorithm for the capacitated vehicle routing problem in parallel com- puting environment. In this paper we consider a simple variation of the vehicle routing problem in which the only parameter is the capacity of the vehicle and each client only needs one package. We analyze the efficiency of the algorithm using the hierarchical Parallel Random Access Machine (PRAM) model and run experiments with code written in CUDA.
1742093,15258,22288,On the Accuracy of Time Measurements in Virtual Machines,2013,"While cloud computing permits access to a large pool of experimental infrastructure, the most common form - virtual machines - has been shown to exhibit substantial deficits with respect to the accuracy of time measurements. In our ongoing work, we provide a detailed analysis of these deficits based on various machine configurations. Preliminary results indicate that not the use of virtualization as such, but the potentially uncontrollable utilization of the physical host is a decisive factor for the accuracy of time measurements."
2155655,15258,343,Information-centric networking: seeing the forest for the trees,2011,"There have been many recent papers on data-oriented or content-centric network architectures. Despite the voluminous literature, surprisingly little clarity is emerging as most papers focus on what differentiates them from other proposals. We begin this paper by identifying the existing commonalities and important differences in these designs, and then discuss some remaining research issues. After our review, we emerge skeptical (but open-minded) about the value of this approach to networking."
2533755,15258,9836,"Rigel: A 1,024-Core Single-Chip Accelerator Architecture",2011,"Rigel is a single-chip accelerator architecture with 1,024 independent processing cores targeted at a broad class of data- and task-parallel computation. This article discusses Rigel's motivation, evaluates its performance scalability as well as power and area requirements, and explores memory systems in the context of 1,024-core single-chip accelerators. The authors also consider future opportunities and challenges for large-scale designs."
2523889,15258,23749,Development of a Metamodel for Medical Database Management on a Grid Network: Application to Health Watch and Epidemiology for Cancer and Perinatal Health,2012,"Centralized management of patient data is no more a viable solution. In many countries, patient identification restrictions due to privacy laws implies developing thorough mechanism to avoid duplicates and information loss. In this paper we present a work in progress dealing with a grid distributed medical data base. GPU based identification algorithms for disease surveillance, medical data exchange and epidemiological analyses."
927462,15258,11157,MORSE: Multi-objective reconfigurable self-optimizing memory scheduler,2012,"We propose a systematic and general approach to designing self-optimizing memory schedulers that can target arbitrary figures of merit (e.g., performance, throughput, energy, fairness). Using our framework, we instantiate three memory schedulers that target three important metrics: performance and energy efficiency of parallel workloads, as well as throughput/fairness of multiprogrammed workloads. Our experiments show that the resulting hardware significantly outperforms the state of the art in all cases."
2259917,15258,9748,On the Performance of Greedy Algorithms for Power Consumption Minimization,2011,"We revisit the well-known greedy algorithm for scheduling independent jobs on parallel processors, with the objective of minimizing the power consumption. We assess the performance of the online version, as well as the performance of the offline version, which sorts the jobs by non-increasing size before execution. We derive new approximation factors, as well as examples that show that these factors cannot be improved, thereby completely characterizing the performance of the algorithms."
2241616,15258,22288,A study on the reliability allocation algorithm based on range,2011,"The most important thing in the designing of Quality Assurance System is the assurance of quality and reliability. In this paper, we apply the three time design to the structure of reliability design according to the characters of Quality Assurance System when we are dealing with the three designs in the computability project and establish an algorithm of choosing optimal parameter. In this way, we can determine the important degree factors in reliability predicting and allocation. Therefore, we can get the outcome more scientific and rational."
2197846,15258,20649,MARSS: a full system simulator for multicore x86 CPUs,2011,"We present MARSS, an open source, fast, full system simulation tool built on QEMU to support cycle-accurate simulation of superscalar homogeneous and heterogeneous multicore x86 processors. MARSS includes detailed models of coherent caches, interconnections, chipsets, memory and IO devices. MARSS simulates the execution of all software components in the system, including unmodified binaries of applications, OS and libraries."
408575,15258,22288,A system for web page sensitive keywords detection,2014,"In the current diversity and complexity of the network information environment, the technology of web page sensitive keywords detection is an important and immediate way to manage public opinion online. We propose a system for web page sensitive keywords detection. This system can detect sensitive keywords in the web pages timely and effectively. And it will mark the position of the keywords in web pages and writes the related information such as detection results and detection time to the detection result table in order to help managers of websites to take measures to filter sensitive keywords in time."
83890,15258,11187,A preliminary analysis and simulation of load balancing techniques applied to parallel genetic programming,2011,"This paper addresses the problem of Load-balancing when Parallel Genetic Programming is employed. Although load-balancing techniques are regularly applied in parallel and distributed systems for reducing makespan, their impact on the performance of different structured Evolutionary Algorithms, and particularly in Genetic Programming, have been scarcely studied. This paper presents a preliminary study and simulation of some recently proposed load balancing techniques when applied to Parallel Genetic Programming, with conclusions that may be extended to any Parallel or Distributed Evolutionary Algorithm."
2236965,15258,9836,A methodology of estimating hybrid black-box - prior knowledge models of an industrial processes,2011,"The paper presents a combined prior knowledge - black-box approach to modeling of the dynamic systems. Proposed methodology assumes two basic steps: first an optimization of a physical model, using Particle Swarm Optimization algorithm is performed. Next, a black-box model is estimated so as to reduce the remaining error of the physical model. Proposed methodology was presented on the example of improving the accuracy of a pneumatic actuator physical model."
1814648,15258,23827,Certification-based development of critical systems,2012,"Safety-critical systems certification is a complex endeavor. Regulating agencies are moving to goal-based standards in an effort to remedy significant problems of prescriptive standards. However, goal-based standards introduce new difficulties into the development and certification processes. In this work I introduce Certification-Based Development, or CBD. CBD is a process framework designed to mitigate these difficulties by meeting the needs of a specific certifying agency with regard to a specific system."
1226139,15258,21022,Everything you always wanted to know about synchronization but were afraid to ask,2013,"This paper presents the most exhaustive study of synchronization to date. We span multiple layers, from hardware cache-coherence protocols up to high-level concurrent software. We do so on different types of architectures, from single-socket -- uniform and non-uniform -- to multi-socket -- directory and broadcast-based -- many-cores. We draw a set of observations that, roughly speaking, imply that scalability of synchronization is mainly a property of the hardware."
1443229,15258,20774,"The PCL theorem: transactions cannot be parallel, consistent and live",2014,"We show that it is impossible to design a transactional memory system which ensures parallelism, i.e. transactions do not need to synchronize unless they access the same application objects, while ensuring very little consistency, i.e. a consistency condition, called weak adaptive consistency, introduced here and which is weaker than snapshot isolation, processor consistency, and any other consistency condition stronger than them (such as opacity, serializability, causal serializability, etc.), and very little liveness, i.e. that transactions eventually commit if they run solo."
2435757,15258,9080,A survey on sustainability in ICT: a computing perspective,2014,"The rise of the data centers industry, together with the emergence of large cloud computing that require large quantities of resources to be maintained, brought the need of providing a sustainable development process. Through this paper we aim to provide an introductory insight on the status and tools available to tackle this perspective within the evolutionary and genetic algorithms community. Existing advancements are also emphasized and perspectives outlined."
2158780,15258,8306,Navigating the cache hierarchy with a single lookup,2014,"Modern processors optimize for cache energy and performance by employing multiple levels of caching that address bandwidth, low-latency and high-capacity. A request typically traverses the cache hierarchy, level by level, until the data is found, thereby wasting time and energy in each level. In this paper, we present the Direct-to-Data (D2D) cache that locates data across the entire cache hierarchy with a single lookup."
1310730,15258,9856,DNS authentication as a service: preventing amplification attacks,2014,"We present the first defence against DNS-amplification DoS attacks, which is compatible with the common DNS servers configurations and with the (important standard) DNSSEC. We show that the proposed DNS-authentication system is efficient, and effectively prevents DNS-based amplification DoS attacks abusing DNS name servers. We present a game-theoretic model and analysis, predicting a wide-spread adoption of our design, sufficient to reduce the threat of DNS amplification DoS attacks. To further reduce costs and provide additional defences for DNS servers, we show how to deploy our design as a cloud based service."
2950920,15258,22288,Sentiment classification on Chinese reviews based on ambiguous sentiment confined library,2012,Sentiment bag of words plays an important role in sentiment analysis. In the paper we propose a method to construct an AMBIGUOUS SENTIMENT CONFINED LIBRARY without hard work. Followed by preprocessing and extracting features based on our AMBIGUOUS SENTIMENT CONFINED LIBRARY Maximum Entropy classifier is trained by our selected corpus and used to classify Chinese review sentiment. Comparing with extracting features based on National Taiwan University Sentiment Dictionary experiments show that our method can evidently improve the performance of Chinese review sentiment classification.
1681308,15258,20649,Assessing the performance limits of parallelized near-threshold computing,2012,"Supply voltage scaling has stagnated in recent technology nodes, leading to so-called dark silicon. In this paper, we investigate the limit of voltage scaling together with task parallelization to maintain task completion latency. When accounting for parallelization overheads, minimum task energy is obtained at near threshold supply-voltages across 6 commercial technology nodes and provides 4X improvement in overall CMP performance."
2077449,15258,11470,Embedded system for TV power reduction by viewer monitoring,2011,"This paper presents a simple yet efficient implementation of a camera-based viewer monitoring system for reducing power consumption of television set. The system keeps TV screen active only if someone is watching it. When nobody is present in front of the camera, the TV is dimmed to save power while keeping the audio ON. Experiments show that the system can reduce the TV power consumption significantly especially when TV set is left ON unwatched."
2096601,15258,8912,Unified debugging of distributed systems with Recon,2011,"To scale to today's complex distributed software systems, debugging and replaying techniques mostly focus on single facets of software, e.g., local concurrency, distributed messaging, or data representation. This forces developers to tediously combine different technologies such as instruction-level dynamic tracing, event log analysis, or global state reconstruction to gradually explain non-trivial defects."
2900410,15258,22288,Research on RCS characteristic of three kinds of metal plate,2012,"Metal plate reflectors often are used as calibration objects in RCS measurements. In this paper, three kinds of metal plate reflectors are taken into account, including circular, rectangular and triangular plate. The radar cross sections of them are computed by the physical optics method. At first, they are compared under the same specified condition. And then RCS characteristics of metal plate reflectors with a series of parameter changing are also analyzed. An accurate conclusion can be obtained about choosing an appropriate metal plate scaler in RCS measurement. And the results also can be efficiently used for RCS reduction."
144499,15258,293,Characterization of blacklists and tainted network traffic,2013,"Threats to the security and availability of the network have contributed to the use of Real-time Blackhole Lists (RBLs) as an attractive method for implementing dynamic filtering and blocking. While RBLs have received considerable study, little is known about the impact of these lists in practice. In this paper, we use nine different RBLs from three different categories to perform the evaluation of RBL tainted traffic at a large regional Internet Service Provider."
875350,15258,9836,FabScalar: Automating Superscalar Core Design,2012,"Providing multiple superscalar core types on a chip, each tailored to different classes of instruction-level behavior, is an exciting direction for increasing processor performance and energy efficiency. Unfortunately, processor design and verification effort increases with each additional core type, limiting the microarchitectural diversity that can be practically implemented. FabScalar aims to automate superscalar core design, opening up processor design to microarchitectural diversity and its many opportunities."
1387434,15258,9099,Towards efficient resource utilization in internet mobile streaming,2011,"Internet video streaming to mobile devices is challenging because of device heterogeneity, resource constraints, and limited battery power supply of mobile devices. From mobile users' perspective, we examine the power efficiency of existing streaming protocols, and propose to reduce the power consumed by data transmission. Moreover, from the service provider's perspective, we propose to efficiently utilize resources at server side to better serve mobile users."
467686,15258,22288,A distributed video share system based on Hadoop,2014,"The paper present a framework for video playing and video storage based on Hadoop. Our framework consist of 3 layers. CDN for receiving clinets' requests; CCN for connecting clients and sending data; Hadoop cluster for data storage. This kind of structure helps to provide high availablility services, which could support high concurrent access and play smooth streaming media in mobile terminals."
2391038,15258,9836,A QoS-Enabled On-Die Interconnect Fabric for Kilo-Node Chips,2012,"To meet rapidly growing performance demands and energy constraints, future chips will likely feature thousands of on-die resources. Existing network-on-chip solutions weren't designed for scalability and will be unable to meet future interconnect demands. A hybrid network-on-chip architecture called Kilo-NoC co-optimizes topology, flow control, and quality of service to achieve significant gains in efficiency."
1700580,15258,9772,Design of interlock-free combined allocators for Networks-on-Chip,2012,"This paper presents a thorough investigation of the combined allocator design for Networks-on-Chip (NoC). Particularly, we discuss the interlock of the combined NoC allocator, which is caused by the lock mechanism of priority updating between the local and global arbiters. Architectures and implementations of three interlock-free combined allocators are presented in detail. Their cost, critical path, as well as networklevel performance are demonstrated based on 65-nm standard cell technology."
1395517,15258,9836,ReMAP: A Reconfigurable Architecture for Chip Multiprocessors,2011,"ReMAP is a reconfigurable architecture for accelerating and parallelizing applications within a heterogeneous chip multiprocessor (CMP). Clusters of cores share a common reconfigurable fabric adaptable for individual thread computation or fine-grained communication with integrated computation. ReMAP demonstrates significantly higher performance and energy efficiency than hard-wired communication-only mechanisms, and over allocating the fabric area to additional or more powerful cores."
1462766,15258,9836,Active Low-Power Modes for Main Memory with MemScale,2012,"Main memory accounts for a growing fraction of server energy usage. Investigating active low-power modes for managing main memory, with a system called MemScale, the authors offer a solution for performance-aware energy management. By creating a set of low-power modes, hardware mechanisms and software policies, MemScale trades memory bandwidth for energy savings while tightly limiting the associated performance impact."
1557484,15258,9836,The reversibility condition for elementary bilinear time-series model based on output sequence alone,2011,"Reversibility of elementary bilinear time-series model is very important issue in parametric model identification based on minimisation of mean square value of prediction error. The reason is that estimation of parameters of irreversible time-series model is irreversible it is difficult. There is already very well known mathematical reversibility condition expressed as a function of the model's coefficient, which has to be identified. The paper contains a discussion of simple condition, which can provide information about model's reversibility before its identification."
1026698,15258,23836,Message from the HCW Steering Committee Chair,2011,"These are the proceedings of the “20th Heterogeneity in Computing Workshop,” also known as HCW 2011. A few years ago, the title of the workshop was changed from the original title of “Heterogeneous Computing Workshop” to reflect the breadth of the impact of heterogeneity, as well as to stress that the focus of the workshop is on the management and exploitation of heterogeneity. All of this is, of course, taken in the context of the parent conference, the International Parallel and Distributed Processing Symposium (IPDPS), and so explores heterogeneity in parallel and distributed computing systems."
1891395,15258,8335,Line sharing cache: Exploring cache capacity with frequent line value locality,2013,"This paper proposes a new last level cache architecture called line sharing cache (LSC), which can reduce the number of cache misses without increasing the size of the cache memory. It stores lines which contain the identical value in a single line entry, which enables to store greater amount of lines. Evaluation results show performance improvements of up to 35% across a set of SPEC CPU2000 benchmarks."
861286,15258,9475,Adaptive switching controllers for tracking with hybrid communication protocols,2012,The focus of this paper is on the co-design of control and communication protocol for the control of multiple applications with unknown parameters using a distributed embedded system. The co-design consists of an adaptive switching controller and a hybrid communication architecture that switches between a time-triggered and event-triggered protocol. It is shown that the overall co-design leads to an overall switching adaptive system that has bounded solutions and ensures tracking in the presence of a class of disturbances.
140466,15258,9748,Parallel Multi-objective Memetic Algorithm for Competitive Facility Location,2013,A hybrid genetic algorithm for global multi-objective opti- mization is parallelized and applied to solve competitive facility location problems. The impact of usage of the local search on the performance of the parallel algorithm has been investigated. An asynchronous version of the parallel genetic algorithm with the local search has been proposed and investigated by solving competitive facility location problem utiliz- ing hybrid distributed and shared memory parallel programming model on high performance computing system.
779812,15258,343,An Information-Theoretic Approach to Routing Scalability,2014,"Many of our computer networks, not the least of which the Internet, are built upon hop-by-hop routing. At the moment, it is not clear whether we will be able to scale these networks into the future economically. In this paper, we propose a new information-theoretic model to study routing scalability, we present preliminary analysis suggesting that hop-by-hop routing tolerates network growth surprisingly efficiently, and we sketch the scalability map of the Internet which we then use to make some bold predictions."
1845843,15258,22288,Two novel 60 GHz coplanar waveguide structure filters with electric and magnetic coupling,2011,"The theory of asymmetric λ/2 coupling filter is presented. According to the both coupling modes of electric and magnetic, two novel coplanar waveguide (CPW) structure filters, the center frequency is 60GHz, is obtained based on the theory of asymmetric λ/2 coupling. The harmonic suppression technology is introduced in the design process. The parasitic frequency and second harmonic are effectively suppressed by the harmonic suppression technology. The bandwidth of the electric coupling filter is 1.5GHz and the insertion loss is 0.6 dB. The bandwidth of the magnetic coupling filter is 12GHz and the insertion loss is 0.3 dB."
1968336,15258,8228,Tuning KVM to enhance virtual routing performance,2013,"This paper shows how to use an open virtualisation architecture to analyse and improve the forwarding performance of a virtual router. In particular, the forwarding performance of the Linux kernel running inside a KVM virtual machine and the performance of some more advanced architectures based on virtual routers aggregation are analysed, showing how increasing the number of used CPU core can improve performance and how properly setting the CPU affinity of the various virtualisation activities affects virtual router throughput."
1396348,15258,20774,Brief announcement: parallelization of asynchronous variational integrators forshared memory architectures,2014,"Asynchronous variational integrators (AVIs) are used in computational mechanics and graphics to solve complex contact mechanics problems. The parallelization of AVI is difficult problem because it is not possible to build a dependence graph for AVI either at compile-time or at runtime. However, we show that if the dependence graph for AVI can be updated incrementally as the computation is performed, it is possible to parallelize AVI in a systematic way. Using this approach, we are able to obtain speedups of up to 20 on 24 cores for relatively small AVI problems."
987961,15258,9080,Imprecise selection and fitness approximation in a large-scale evolutionary rule based system for blood pressure prediction,2013,"We present how we have strategically allocated fitness evaluations in a large-scale rule based evolutionary system called ECStar. We describe a strategy that culls potentially weaker solutions early, then later only compete with solutions which have equivalent fitness evaluations, as they are evaluated on more fitness cases. Despite incurring some imprecision in fitness comparison, which arises from not evaluating on all the fitness cases or even the same ones, the strategy allows our system to make effective progress when the resources at its disposal are unpredictably available."
2343370,15258,22288,Creating a Chinese emotion lexicon based on corpus Ren-CECps,2011,"As a basic emotion resource, an emotion lexicon plays a very important role in the classification and recognition of emotion in text. This paper proposes an automatic approach to create a Chinese emotion lexicon with tag of emotion intensity based on the emotion corpus Ren-CECps 1.0. We present a new algorithm of emotion vector computation by making use of two language dictionaries Tongyici Cilin and HowNet. Comparing with the experimental results on verbs by SVM classification method, our approach is proved feasible and effective."
861787,15258,11330,Author retrospective for semantical interprocedural parallelization: an overview of the PIPS project,2014,"The PIPS project was started in 1988 to investigate the automatic detection of medium- and large-grain parallelism in scientific programs thanks to summarization techniques based on convex array regions. By 1992 the PIPS system had reached its original goals, but it has morphed into a comprehensive, open-source platform still in use today. What were the key scientific and engineering decisions that made this possible in spite of some inevitable shortcomings?"
2466222,15258,23836,Evaluation of the Energy Performance of Dense Linear Algebra Kernels on Multi-core and Many-Core Processors,2011,"We evaluate the power consumption of three key kernels from several tuned dense linear algebra libraries on three general-purpose multi-core processors and a graphics processor, representative of the state-of-the-art in computing technology. The results of this study provide basic insights on the energy scalability of multi- and many-core designs and multi-threaded software as the building blocks of future EXAFLOPS systems."
2281954,15258,11330,Hybrid approach for data-flow analysis of MPI programs,2013,"With the increasing cost of developing robust HPC software, precise data-flow analysis for MPI programs -- the mainstay of HPC programming -- are essential. The knowledge of communication is essential for precise data-flow analysis and the difficulty of statically determining it makes the conventional techniques insufficient. Hybrid methods combining static and dynamic techniques are needed and in this work we demonstrate one such approach in building the parallel control-flow graph which can then be used to leverage the precision of data-flow analyses for MPI programs."
1429212,15258,9836,Control theoretic approach to combined anticancer therapies,2011,A model of a combination of antiangiogenic treatment and chemotherapy is proposed and analyzed. The model is a modified Hahnfeldt model and the analysis has two goals: first of all we check stability of the equilibrium point of the model to find conditions leading to tumour eradication for constant dosing and periodic treatment then we propose an optimization problem and give necessary conditions of its solution. We discuss modifications of the model which enable more realistic description of treatment effects.
2556678,15258,23836,Improving Performance of Deterministic Single-Path Routing on 2-Level Generalized Fat-Trees,2011,"This paper focuses on deterministic single-path routing schemes on 2-level generalized fat-trees. We develop a routing algorithm that is optimal in terms of worst-case permutation performance. In comparison to existing routing schemes for such topologies, our algorithm also improves the average performance of common communication patterns including bisect patterns, full permutation patterns, and dissemination (Bruck) patterns on various 2-level generalized fat-trees as demonstrated in our evaluation results."
1730945,15258,9836,PEPPHER: Efficient and Productive Usage of Hybrid Computing Systems,2011,"PEPPHER, a three-year European FP7 project, addresses efficient utilization of hybrid (heterogeneous) computer systems consisting of multicore CPUs with GPU-type accelerators. This article outlines the PEPPHER performance-aware component model, performance prediction means, runtime system, and other aspects of the project. A larger example demonstrates performance portability with the PEPPHER approach across hybrid systems with one to four GPUs."
1403211,15258,22288,A Family of Truthful Greedy Mechanisms for Dynamic Virtual Machine Provisioning and Allocation in Clouds,2013,"Designing efficient mechanisms for Virtual Machine (VM) provisioning and allocation is a major challenging problem that needs to be solved by cloud providers. We formulate the VM provisioning and allocation problem in clouds as an integer program and design truthful greedy mechanisms that solve it. We show that the proposed mechanisms are truthful, that is, the users do not have incentives to lie about their requested bundles of VM instances and their valuations. We perform extensive experiments in order to investigate the performance of the proposed mechanisms."
836481,15258,20754,The Menlo Report,2012,"On 28 December 2011, the US Department of Homeland Security, Science and Technology, Cyber Security Division released The Menlo Report: Ethical Principles Guiding Information and Communication Technology Research to the Federal Register to elicit the public's feedback. In this article, the authors briefly describe the road to this milestone, summarize the report and its companion document, and describe the next steps we should take as a community."
963650,15258,11166,Tuple MapReduce: Beyond Classic MapReduce,2012,"This paper proposes Tuple Map Reduce, a new foundational model extending Map Reduce with the notion of tuples. Tuple Map Reduce allows to bridge the gap between the low-level constructs provided by Map Reduce and higher-level needs required by programmers, such as compound records, sorting or joins. This paper presents as well Pangool, an open-source framework implementing Tuple Map Reduce. Pangool eases the design and implementation of applications based on Map Reduce and increases their flexibility, still maintaining Hadoop's performance."
1064923,15258,9836,Thread Cluster Memory Scheduling,2011,"Memory schedulers in multicore systems should carefully schedule memory requests from different threads to ensure high system performance and fair, fast progress of each thread. No existing memory scheduler provides both the highest system performance and highest fairness. Thread Cluster Memory scheduling is a new algorithm that achieves the best of both worlds by differentiating latency-sensitive threads from bandwidth-sensitive ones and employing different scheduling policies for each."
1009893,15258,8335,VFCC: A verification framework of cache coherence using parallel simulation,2013,"A cache coherence protocol is a vital component of a multiprocessor to maintain the data consistency. In this paper, we proposed VFCC, which is a simulation framework to validate a cache-coherence protocol implementation of a commercial 64-bit superscalar multiprocessor. It exploits multiple-level parallelism to accelerate validation without overheads among threads. Our experimental results demonstrate VFCC has a 5.0× speedup than a traditional simulator on a conventional 16-core host machine."
2279340,15258,23836,Decentralized Network Bandwidth Prediction and Node Search,2011,"My PhD research addresses how to exploit network bandwidth information and increase the performance of data-intensive wide-area distributed applications. The goal is to solve four specific problems: i) design a decentralized algorithm for network bandwidth prediction, ii) design a decentralized algorithm to find bandwidth-constrained clusters, iii) design a decentralized algorithm to find bandwidth-constrained centroids, and iv) develop a wide-area MapReduce system with optimized data locality as an application of the three algorithms for bandwidth prediction and node search."
1393166,15258,23749,Network Traffic-Aware Virtual Machine Placement with Availability Guarantees Based on Shadows,2014,"Virtual Machine Placement (VMP) is critical for resource management in data centers. Network traffic and availability of VMs are key factors should be considered in VMP. The Shadow-Based Solution (SBS) guarantees the high-availability goals of VMP. However, the resource constraints of SBS are not applicable to network capacity. To solve this problem, we proposed a shadow-based VMP model with network traffic constraints for both real and shadow VMs. The experimental results show that the proposed model is more feasible than the original SBS model."
2925365,15258,22288,A novel H-infinity filtering for road constrained target tracking,2012,"This paper is concerned with the H ∞  filtering for road constrained target tracking problem. The additional information of road can improve the estimation accuracy when it is properly incorporated into the estimation process. In this paper, two constrained H ∞  filtering methods considering the road constraints as prior information are proposed. The new approaches achieve not only higher accuracy, but also robustness against model uncertainty. Two simulation examples are present to illustrate the performance of the proposed approaches."
1741485,15258,8228,How to validate traffic generators,2013,Network traffic generators are widely used in networking research and they are validated by a very broad range of metrics (mainly traffic characteristics). In this paper we overview the state of the art of these metrics and unveil that there is no consensus in the research community how to validate these traffic generators and which metric to choose for validation purpose. This situation makes it extremely difficult to evaluate validation results and compare different traffic generators. We advocate the research for finding a common set of metrics for the validation and comparative evaluation of traffic generators.
2909356,15258,22288,BCBPI: A noval behavior chain based protocol identification method,2012,"Protocol identification is critical for managing the network, from traffic classification to intrusion detection. However, the traditional protocol identification techniques have become less effective as more and more new network applications have adopted complex interaction and encrypted techniques in recent years. In this paper, we address behavior chains of the protocols, and propose a novel method based on behavior chain to identify some kinds of protocols. The experimental results show that the protocol behavior chain exists and can be used to identify the different application."
1306596,15258,8912,IOCheck: A framework to enhance the security of I/O devices at runtime,2013,"Securing hardware is the foundation for implementing a secure system. However, securing hardware devices remains an open research problem. In this paper, we present IOCheck, a framework to enhance the security of I/O devices at runtime. It leverages System Management Mode (SMM) to quickly check the integrity of I/O configurations and firmware. IOCheck does not rely on the operating system and is OS-agnostic. In our preliminary results, IOCheck takes 4 milliseconds to switch to SMM which introduces low performance overhead."
2315896,15258,343,How to improve your network performance by asking your provider for worse service,2013,"TCP's congestion control is deliberately cautious, avoiding overloads by starting with a small initial window and then iteratively ramping up. As a result, it often takes flows several round-trip times to fully utilize the available bandwidth. In this paper we propose using several levels of lower priority service and a modified TCP behavior to achieve significantly improved flow completion times while preserving fairness."
2187854,15258,11330,SRC: automatic extraction of SST/macro skeleton models,2011,The utilization of large scale parallel event simulators such as SST/macro requires that skeleton models of underlying software systems and architectures be created. Implementing such models by abstracting the designs of large scale parallel applications requires a substantial manual effort and introduces the hazards of human errors. We outline an approach for the automatic extraction of SST/macro skeleton models from large scale parallel applications. Our methodology for deriving SST/macro skeleton models is based on the use of extensible and open-source ROSE compiler infrastructure. The SST/macro skeleton models are then combined with appropriate models of the network and hardware configurations.
985698,15258,23836,The Empirical Research of Virtual Enterprise Knowledge Transfer's Effectiveness Faced to the Independent Innovation Ability,2014,"Based on the theory of knowledge transfer and with the organizational characteristics, the paper makes member enterprises' knowledge transfer behaviors and the innovation of knowledge, technology and management as research objects to study the practical effectiveness of promoting enterprises' independent innovation ability by the successful use of Virtual Enterprise Knowledge Transfer. Having analyzed the Virtual Enterprise Knowledge Transfer's influence to the independent innovation ability of enterprises, the paper constructs a concept mode about Virtual Enterprise Knowledge Transfer 's effectiveness to promote the ability. Meanwhile, it exemplifies the study by using structure equation model and statistical software. The result indicates that the coalition of Virtual Enterprise Knowledge Transfer has a great promotion on the knowledge and technology innovation of member enterprises. Furthermore, the paper is to offer the solution and suggestion during the process of Virtual Enterprise Knowledge Transfer to improve the independent innovation ability of member enterprises."
2626867,15258,23836,Efficient GPU Implementation for Particle in Cell Algorithm,2011,Particle in cell (PIC) algorithm is a widely used method in plasma physics to study the trajectories of charged particles under electromagnetic fields. The PIC algorithm is computationally intensive and its time requirements are proportional to the number of charged particles involved in the simulation. The focus of the paper is to parallelize the PIC algorithm on Graphics Processing Unit (GPU). We present several performance trade-offs related to small shared memory and atomic operations on the GPU to achieve high performance.
209847,15258,22288,Cloud Services Platform of Public Resources Trading Integration,2013,"Considering China's public resources trading platform does not implement in the true sense of integration, information sharing still exist in isolation, security is not strong, large resources, poor timeliness, and efficiency is low, so we put forward a public resources trading platform based on cloud services. This system not only realize the public resources trading center insider, wealth, and the unity of the business process management, meanwhile to achieve resource virtualization, services can be quantified, and one-stop service online."
37697,15258,20332,Parallel restarted search,2014,"We consider the problem of parallelizing restarted backtrack search. With few notable exceptions, most commercial and academic constraint programming solvers do not learn no-goods during search. Depending on the branching heuristics used, this means that there are little to no side-effects between restarts, making them an excellent target for parallelization. We develop a simple technique for parallelizing restarted search deterministically and demonstrate experimentally that we can achieve near-linear speed-ups in practice."
392480,15258,22288,Finite-time consensus of multi-agent systems with double integrator dynamics using only relative position measurements,2014,"In this paper, we study the finite time consensus problem for multi-agent systems with double-integrator dynamics under an undirected graph. Both the leaderless consensus problem and the coordinated tracking problem with a dynamic leader are considered without velocity measurements. Based on an observer for each agent, we present two distributed control protocols for the two cases which can solve the consensus problem in finite time. Simulation examples for the two cases are provided to illustrate the effectiveness of the proposed algorithms."
1282441,15258,9836,Tianhe-1A Interconnect and Message-Passing Services,2012,"The petascale supercomputer Tianhe-1A, which features hybrid multicore CPU and GPU computing, achieves an optimized balance of computation and communication capabilities through a proprietary high-bandwidth, low-latency interconnect fabric. The authors' message-passing service, based on scalable user-level communication and offloaded operations for large-scale, low-latency collective communication, has achieved a unidirectional bandwidth of 6,340 Mbytes/s."
702463,15258,20774,"Brief announcement: read invisibility, virtual world consistency and permissiveness are compatible",2011,"This brief announcement studies the relation between two STM properties (read invisibility and permissiveness) and two consistency conditions for STM systems, namely, opacity and virtual world consistency. A read operation issued by a transaction is invisible if it does not entail shared memory modifications. An STM system is permissive with respect to a consistency condition if it accepts every history that satisfies the condition. The brief announcement first shows that read invisibility, permissiveness and opacity are incompatible. It then shows that invisibility, permissiveness and virtual world consistency are compatible."
1838930,15258,9836,Model of power quality control circuit in isolated limit capacity electric networks,2011,"Firstly, the technology of harmonic suppression in a traditional civil electric network is introduced. Then the characteristics of an isolated electric network is analyzed, and afterwards, a model of combined harmonic suppression and power factor correction circuit is designed, which integrates the method of solving problems on its own initiative with the method of solving problems passively, to solve the harmonic pollution of an isolated small capacity electric network. The results of relevant simulation experiment show that the model of designed circuit is suitable for the power quality improvement of an isolated electric network."
1386954,15258,23836,High Speed -- Low Power Optical Configuration on an ORGA with a Phase-modulation Type Holographic Memory,2012,"Optically reconfigurable gate arrays (ORGAs) with an amplitude-modulation type holographic memory have been developed as a type of multi-context field programmable gate array. The ORGA's programmable gate array can be reconfigured in nanosecond-order, with more than 100 reconfiguration contexts. However, the diffraction efficiency of the amplitude-modulation type holographic memory is not good because the holographic memory decreases its transmission light intensity depending on the modulation level. About half of the power of the laser is consumed by the holographic memory. Therefore, this paper presents a high-speed -- low-power optical configuration capability of an ORGA with a phase-modulation type holographic memory."
1075865,15258,23836,An Opportunistic MAC Protocol Based on Statistical Spectrum Analysis,2012,"The current spectrum allocation model aims to avoid interferences in licensed spectrum communications without further concerns regarding spectrum usage. Because the radio spectrum is a finite resource, several approaches have been presented in order to improve the effectiveness of its utilization. The main contribution of this work is to present an opportunistic approach to spectrum sensing and allocation. Compared to other alternatives, our approach presents significant improvements in the spectrum access and utilization, improving network throughput up to 16 times."
2156838,15258,9772,Leveraging sharding in the design of scalable replication protocols,2013,"Most if not all datacenter services use sharding and replication for scalability and reliability. Shards are more-or-less independent of one another and individually replicated. In this paper, we challenge this design philosophy and present a replication protocol where the shards interact with one another: A protocol running within shards ensures linearizable consistency, while the shards interact in order to improve availability. We provide a specification for the protocol, prove its safety, analyze its liveness and availability properties, and evaluate a working implementation."
1472761,15258,9836,Bulldozer: An Approach to Multithreaded Compute Performance,2011,"AMD bulldozer module represents a new direction in microarchitecture and includes a number of firsts for AMD, including AMD multithreaded X86 processor, implementation of a shared level 2 cache, and X86 processor to incorporate floating-point multiply-accumulate (FMAC). This article discusses the module multithreading architecture, power-efficient micro architecture, and subblocks, including the various microarchitectural latencies, bandwidths, and structure sizes."
261605,15258,9748,Slowest Server Emulation Syndrome: A Hidden Cost of Load Imbalance,2014,"We model a certain class of distributed shared nothing service in the presence of heavily loaded clients, and show, through mathematical models and simulation, that the system throughput can drop to the point that all servers process tasks at the rate of the slowest server. We also run experiments on an instrumented deployment of a commercially available database and find this same result. We present formulas for equilibrium values and for the time constants that characterize the approach to equilibrium."
2232084,15258,8228,ISP-Supported Traffic Reduction for Application-Level Multicast,2011,"The paper proves that it is possible to optimize application-level multicast operation from the viewpoint of traffic flows. A modification of the FreePastry/Scribe application is proposed to enable cooperation with the IETF ALTO (Application- Layer Traffic Optimization) protocol. Consequently, the overlay topology is constructed taking into account the underlying network topology. The presented results show that costly traffic types can be reduced while the increase of the delay is not harmful."
992410,15258,22021,Repairing multiple failures in the Suh-Ramchandran regenerating codes,2013,"Using the idea of interference alignment, Suh and Ramchandran constructed a class of minimum-storage regenerating codes which can repair one systematic or one parity-check node with optimal repair bandwidth. With the same code structure, we show that in addition to single node failure, double node failures can be repaired collaboratively with optimal repair bandwidth as well. We give an example of how to repair double failures in the Suh-Ramchandran regenerating code with six nodes, and give the proof for the general case."
996155,15258,507,Rethinking eventual consistency,2013,"There has been a resurgence of work on replicated, distributed database systems to meet the demands of intermittently-connected clients and of disaster-tolerant databases that span data centers. Many systems weaken the criteria for replica-consistency or isolation, and in some cases add new mechanisms, to improve partition-tolerance, availability, and performance. We present a framework for comparing these criteria and mechanisms, to help architects navigate through this complex design space."
207424,15258,22288,A hierarchical intention recognition model for situated dialogue system,2014,"Analysis of the speaker's intention plays a crucial role in implementation of high-quality dialogue systems. Whether or not the utterance is situated in the environment is a very important factor for the precise intention analysis in situated dialogue systems. For our teaching system we propose a hierarchical intention taxonomy. First, we separate the intention into two categories by checking whether it is situated, after that we classify the intentions into more fine-grained categories. The experimental results show that, compared with the flat classifier, the hierarchical classifier gives a better performance."
216096,15258,9748,Influence of a Topology of a Spring Network on its Ability to Learn Mechanical Behaviour,2013,"We discuss how the topology of the spring system/network affects its ability to learn a desired mechanical behaviour. To ensure such a behaviour, physical parameters of springs of the system are adjusted by an appropriate gradient descent learning algorithm. We find the between- ness centrality measure particularly convenient to describe topology of the spring system structure with the best mechanical properties. We apply our results to refine an algorithm generating the structure of a spring network. We also present numerical results confirming our statements."
1723977,15258,8912,Automatic collection of failure data from the iOS platform,2013,"The increasing complexity of smart phones makes them more susceptible to accidental failures. However, there is still little understanding on the dependability behavior of modern smart phones. In this paper, we propose the design and implementation of a logger to collect relevant failure data from iOS devices, such as iPhone and iPad. The preliminary use of the logger on real-world devices shows that it is able to collect meaningful failure data and to provide interesting insight on the dependability behavior of iOS."
1596849,15258,22288,Inter-cloud Media Storage and Media Cloud Architecture for Inter-cloud Communication,2014,"The rapid increase in digital content, specially multimedia, calls now for standardization of Media Cloud and Inter-Cloud computing, for better provisioning of services. Inter-Cloud computing faces some key challenges in terms of handling multimedia, which are discussed in this paper along with our research status towards their solutions. We also present Inter-Cloud basic architecture and Media Cloud storage design considerations. Some key findings on storage heterogeneity are also part of this paper."
1117075,15258,9475,Fast convergence of quantized consensus using Metropolis chains,2014,"We consider the quantized consensus problem on undirected connected graphs and study its expected convergence time to the set of consensus points. As compared with earlier results on the problem, we improve the convergence speed of the dynamics by a factor of n, where n is the number of agents involved in the dynamics. In particular, we show that when the edges of the network are activated based on a Poisson processes with Metropolis rates, the expected convergence time to the consensus set is at most O(n 2  log n). This upper bound is better than all available results for randomized quantized consensus."
887441,15258,20754,Security Event Monitoring in a Distributed Systems Environment,2013,"Today, organizations depend much more on IT than they did in the past. Services such as internal portals, email communication, and financial and HR systems rely on computers to move businesses forward. These systems are under pressure to be securer than ever to protect organizations' operational environment. One aspect to consider in this situation is IT security event management. This article presents the design and implementation of two security event monitoring approaches in a distributed systems environment."
2478272,15258,122,Performance analysis of parallel constraint-based local search,2012,"We present a parallel implementation of a constraint-based local search algorithm and investigate its performance results for hard combinatorial optimization problems on two different platforms up to several hundreds of cores. On a variety of classical CSPs benchmarks, speedups are very good for a few tens of cores, and good up to a hundred cores. More challenging problems derived from reallife applications (Costas array) shows even better speedups, nearly optimal up to 256 cores."
1031272,15258,11104,Compute cloud based weather detection and warning system,2012,"Compute cloud platforms pay-as-you-use model suits applications which require resources sporadically. Severe weather detection and prediction is one such application. Since severe weather events are rare, dedicating servers for such application wastes resources. In this paper, we present the feasibility of using commercial cloud services for severe weather detection and prediction. We show that commercial cloud services provide the required network capability to perform the real-time operation of weather detection and prediction from the radars to the cloud service instance. We automate the process of weather prediction on the cloud based on the results of our weather detection algorithms."
25258,15258,374,X.509 Forensics: Detecting and Localising the SSL/TLS Men-in-the-Middle,2012,"Although recent compromises and admissions have given new credibility to claimed encounters of Man-in-the-middle (MitM) attacks on SSL/TLS, very little proof exists in the public realm. In this pa- per, we report on the development and deployment of Crossbear, a tool to detect MitM attacks on SSL/TLS and localise their position in the network with a fair degree of confidence. MitM attacks are detected us- ing a notary approach. For the localisation, we use a large number of traceroutes, conducted from so-called hunters from many positions on the Internet. Crossbear collects this data, orchestrates the hunting from a central point and provides the data for analysis. We outline the design of Crossbear and analyse the degree of effectivity that Crossbear achieves against attackers of different kinds and strengths. We also explain how analysis can make use of out-of-band sources like lookups of Autonom- ous Systems and geo-IP-mapping. Crossbear is already available, and 150 hunters have been deployed on the global PlanetLab testbed."
1406987,15258,339,Toward a cyber-physical topology language: applications to NERC CIP audit,2013,"Our Cyber-Physical Topology Language (CPTL) provides a language that utilities can use to programmatically analyze current and future cyber-physical architectures. The motivation for our research emerged from the importance and limitations of several audit scenarios: account management, vulnerability assessment, and configuration management. Those scenarios occur in the context of the North American Electric Reliability Corporation's Critical Infrastructure Protection (NERC CIP) audits. The NERC CIP standards define security controls by which utilities must be audited. Although the standards were designed to make power control networks less vulnerable to cyber attack and to decrease the chance of outages, the audit process is manual and costly. In order to save utilities and auditors time and money, we used the limitations of those audit scenarios in formally specifying and implementing CPTL, which consists of both a representation of cyber-physical assets and operations upon that representation. First, CPTL uses graph theory to represent a network of cyber-physical assets; we currently implement this representation in GraphML. Second, CPTL defines operations upon that representation. In this paper, we introduce operators to process attributes by expanding and contracting components of a network, and implement these operations using the Boost Graph Library (BGL). In order to demonstrate the potential for CPTL to save auditors and utilities time and money, we provide a detailed example of how CPTL could help with vulnerability assessment and discuss additional applications beyond the audit scenarios mentioned above. We describe current approaches to those scenarios and argue that CPTL improves upon both the state-of-the-art and current practice. In fact, we intend CPTL to enable a broad range of new research on realistic cyber-physical architectures by giving utilities, auditors, managers, and researchers a common language with which to communicate and analyze those architectures."
2131415,15258,122,DOJ: dynamically parallelizing object-oriented programs,2012,"We present Dynamic Out-of-Order Java (DOJ), a dynamic parallelization approach. In DOJ, a developer annotates code blocks as tasks to decouple these blocks from the parent execution thread. The DOJ compiler then analyzes the code to generate heap examiners that ensure the parallel execution preserves the behavior of the original sequential program. Heap examiners dynamically extract heap dependences between code blocks and determine when it is safe to execute a code block.   We have implemented DOJ and evaluated it on twelve benchmarks. We achieved an average compilation speedup of 31.15 times over OoOJava and an average execution speedup of 12.73 times over sequential versions of the benchmarks."
1824495,15258,507,Report from the second workshop on scalable workflow enactment engines and technology (SWEET'13),2013,"This report summarizes the presentations and discussions of SWEET 2012, the First InternationalWorkshop on ScalableWorkflow Enactment Engines and Technologies. SWEET was held in conjunction with the 2012 SIGMOD conference in Scottsdale, Arizona, USA on May 20th, 2012. The goal of the workshop was to bring together researchers and practitioners to explore the state of the art in workflow-based programming for data-intensive applications, and the potential of cloud-based computing in this area. The program featured two very well attended invited talks by Pawel Garbacki from Google and Jimmy Lin from the University of Maryland, on leave at Twitter at the time, as well as a tutorial on Oozie, Yahoo's workflow engine based on  Hadoop , by Mohammad Islam from Yahoo/Cloudera."
1611324,15258,339,"From Patches to Honey-Patches: Lightweight Attacker Misdirection, Deception, and Disinformation",2014,"Traditional software security patches often have the unfortunate side-effect of quickly alerting attackers that their attempts to exploit patched vulnerabilities have failed. Attackers greatly benefit from this information; it expedites their search for unpatched vulnerabilities, it allows them to reserve their ultimate attack payloads for successful attacks, and it increases attacker confidence in stolen secrets or expected sabotage resulting from attacks. To overcome this disadvantage, a methodology is proposed for reformulating a broad class of security patches into honey-patches - patches that offer equivalent security but that frustrate attackers' ability to determine whether their attacks have succeeded or failed. When an exploit attempt is detected, the honey-patch transparently and efficiently redirects the attacker to an unpatched decoy, where the attack is allowed to succeed. The decoy may host aggressive software monitors that collect important attack information, and deceptive files that disinform attackers. An implementation for three production-level web servers, including Apache HTTP, demonstrates that honey-patching can be realized for large-scale, performance-critical software applications with minimal overheads."
2303764,15258,339,Forensic investigation of the OneSwarm anonymous filesharing system,2011,"OneSwarm is a system for anonymous p2p file sharing in use by thousands of peers. It aims to provide Onion Routing-like privacy and BitTorrent-like performance. We demonstrate several flaws in OneSwarm's design and implementation through three different attacks available to forensic investigators. First, we prove that the current design is vulnerable to a novel timing attack that allows just two attackers attached to the same target to determine if it is the source of queried content. When attackers comprise 15% of OneSwarm peers, we expect over 90% of remaining peers will be attached to two attackers and therefore vulnerable. Thwarting the attack increases OneSwarm query response times, making them longer than the equivalent in Onion Routing. Second, we show that OneSwarm's vulnerability to traffic analysis by colluding attackers is much greater than was previously reported, and is much worse than Onion Routing. We show for this second attack that when investigators comprise 25% of peers, over 40% of the network can be investigated with 80% precision to find the sources of content. Our examination of the OneSwarm source code found differences with the technical paper that significantly reduce security. For the implementation in use by thousands of people, attackers that comprise 25% of the network can successfully use this second attack against 98% of remaining peers with 95% precision. Finally, we show that a novel application of a known TCP-based attack allows a single attacker to identify whether a neighbor is the source of data or a proxy for it. Users that turn off the default rate-limit setting are exposed. Each attack can be repeated as investigators leave and rejoin the network. All of our attacks are successful in a forensics context: Law enforcement can use them legally ahead of a warrant. Furthermore, private investigators, who have fewer restrictions on their behavior, can use them more easily in pursuit of evidence for such civil suits as copyright infringement."
471627,15258,293,Comparison of user traffic characteristics on mobile-access versus fixed-access networks,2012,"We compare Web traffic characteristics of mobile- versus fixed-access end-hosts, where herein the term mobile refers to access via cell towers, using for example the 3G/UMTS standard, and the term fixed includes Wi-Fi access. It is well-known that connection speeds are in general slower over mobile-access networks, and also that often there is higher packet loss. We were curious whether this leads mobile-access users to have smaller connections. We examined the bytes-per-connection and packet loss based on packet retransmissions from a sampling of logs from servers of Akamai Technologies. We obtained 149 million connections, across 51 countries. The mean bytes-per-connection was typically larger for fixed-access: for two-thirds of the countries, it was at least one-third larger. Regarding distributions, we found that the difference between the bytes-per-connection for mobile- versus fixed-access was statistically significant for each of the countries, and likewise for packet loss. However, the difference is typically small. For some countries, mobile-access had the larger connections. As expected, mobile-access often had higher packet loss than fixed-access, but the reverse pertained for some countries. Typically packet loss increased during the busy period of the day, when mobile-access had a larger increase."
2019916,15258,293,Measuring query latency of top level DNS servers,2013,"We surveyed the latency of upper DNS hierarchy from 19593 vantage points around the world to investigate the impact of uneven distribution of top level DNS servers on end-user latency. Our findings included: 1) generally top level DNS servers served Internet users efficiently, with median latency 20.26ms for root, 42.64ms for .com/.net, 39.07ms for .org; 2) quality of service was uneven, Europe and North America were the best while Africa and South America were 3 to 6 times worse; 3) most of the root servers performed well in Europe and North America, but only F, J, L roots showed low query latency in other continents; 4) query latency of F and L roots showed that only about 60 resolvers were routed to the nearest anycast instances. We also revealed two problems that lead to constantly large query latency (6s~18s) for resolvers. One was buggy implementation of some resolvers on IPv4/IPv6 dual-stack hosts, the other was misconfigured middle-boxes that filtered large or fragmented DNSSEC packets."
2350951,15258,369,Channel Feasibility for Outdoor Non-Line-of-Sight mmWave Mobile Communication,2012,"Due to the scarcity of spectrum below 3 GHz for wireless communications, there have been proposals to explore millimeter wave (mmWave) spectrum (3- 300GHz) for commercial mobile applications. MmWave spectrum provides unique advantages such as availability of GHz bandwidth and use of antenna arrays with beamforming to compensate for path loss. While there exist well-established models for mmWave indoor non-line-of-sight (60 GHz) and mmWave outdoor line-of-sight (backhaul) communication, mmWave channels for outdoor, non-line-of-sight, mobile communication have not been explored sufficiently. We present penetration and reflection measurements for different materials and line-of-sight and non- line-of-sight measurements for outdoor mmWave mobile communication. We find that while well-known lossy objects such as human body and concrete can have poor penetration, they are good reflectors at these frequencies, enabling the receiver to capture secondary reflections for non-line-of-sight communication. We also show that a wide beam width, low gain antenna at the mobile receiver can capture more energy in scattered non-line-of-sight environments and thus, can provide more gain than a narrow beam, high gain antenna for mobile communication. Our initial measurements motivate utilizing mmWave frequencies for outdoor non-line- of-sight mobile communication."
1088072,15258,343,On the risk of misbehaving RPKI authorities,2013,"The RPKI is a new security infrastructure that relies on  trusted authorities  to prevent some of the most devastating attacks on interdomain routing. The threat model for the RPKI supposes that authorities are trusted and routing is under attack. Here we discuss the risks that arise when this threat model is flipped: when RPKI authorities are faulty, misconfigured, compromised, or compelled to misbehave. We show how design decisions that elegantly address the vulnerabilities in the original threat model have unexpected side effects in this flipped threat model. In particular, we show new targeted attacks that allow RPKI authorities, under certain conditions, to limit access to IP prefixes, and discuss the risk that transient RPKI faults can take IP prefixes offline. Our results suggest promising directions for future research, and have implications on the design of security architectures that are appropriate for the untrusted and error-prone Internet."
1476385,15258,122,Parallel programming with big operators,2013,"In the sciences, it is common to use the so-called big operator notation to express the iteration of a binary operator (the reducer) over a collection of values. Such a notation typically assumes that the reducer is associative and abstracts the iteration process. Consequently, from a programming point-of-view, we can organize the reducer operations to minimize the depth of the overall reduction, allowing a potentially parallel evaluation of a big operator expression. We believe that the big operator notation is indeed an effective construct to express parallel computations in the Generate/Map/Reduce programming model, and our goal is to introduce it in programming languages to support parallel programming. The effective definition of such a big operator expression requires a simple way to generate elements, and a simple way to declare algebraic properties of the reducer (such as its identity, or its commutativity). In this poster, we want to present an extension of Scala with support for big operator expressions. We show how big operator expressions are defined and how the API is organized to support the simple definition of reducers with their algebraic properties."
2114929,15258,339,Deanonymisation of Clients in Bitcoin P2P Network,2014,"Bitcoin is a digital currency which relies on a distributed set of miners to mint coins and on a peer-to-peer network to broadcast transactions. The identities of Bitcoin users are hidden behind pseudonyms (public keys) which are recommended to be changed frequently in order to increase transaction unlinkability.   We present an efficient method to deanonymize Bitcoin users, which allows to link user pseudonyms to the IP addresses where the transactions are generated. Our techniques work for the most common and the most challenging scenario when users are behind NATs or firewalls of their ISPs. They allow to link transactions of a user behind a NAT and to distinguish connections and transactions of different users behind the same NAT. We also show that a natural countermeasure of using Tor or other anonymity services can be cut-off by abusing anti-DoS countermeasures of the Bitcoin network. Our attacks require only a few machines and have been experimentally verified. The estimated success rate is between 11% and 60% depending on how stealthy an attacker wants to be. We propose several countermeasures to mitigate these new attacks."
1792164,15258,122,Efficient deterministic multithreading without global barriers,2014,"Multithreaded programs execute nondeterministically on conventional architectures and operating systems. This complicates many tasks, including debugging and testing. Deterministic multithreading (DMT) makes the output of a multithreaded program depend on its inputs only, which can totally solve the above problem. However, current DMT implementations suffer from a common inefficiency: they use frequent global barriers to enforce a deterministic ordering on memory accesses. In this paper, we eliminate that inefficiency using an execution model we call deterministic lazy release consistency (DLRC). Our execution model uses the Kendo algorithm to enforce a deterministic ordering on synchronization, and it uses a deterministic version of the lazy release consistency memory model to propagate memory updates across threads. Our approach guarantees that programs execute deterministically even when they contain data races. We implemented a DMT system based on these ideas (RFDet) and evaluated it using 16 parallel applications. Our implementation targets C/C++ programs that use POSIX threads. Results show that RFDet gains nearly 2x speedup compared with DThreads-a start-of-the-art DMT system."
2191371,15258,369,Protocol Impact of LTE Relays on User Performance,2012,"Relays are introduced for LTE Rel-10 in order to improve cell edge bitrates and coverage. 3GPP has specified both inband and outband relays. In this paper, we study the protocol level aspects of relays as well as cell-edge performance of a mobile terminal with system simulations. The results indicate that when a user is performing TCP downloads and uploads, in addition to potential subframe split between the backhaul and access link, also the adopted protocol solution and increased delays have impact on the user performance. Due to this, the bitrates may degrade even with outband relays if the UE having decent macro coverage is connected to a relay. However, when the UE has bad macro coverage, then there are gains from both inband and outband relays."
1454404,15258,507,Deterministic regular expressions in linear time,2012,"Deterministic regular expressions are widely used in XML processing. For instance, all regular expressions in DTDs and XML Schemas are required to be deterministic. In this paper we show that determinism of a regular expression  e  can be tested in linear time. The best known algorithms, based on the Glushkov automaton, require  O (σ| e |) time, where σ is the number of distinct symbols in  e . We further show that matching a word  w  against an expression  e  can be achieved in combined linear time  O (| e |+| w |), for a wide range of deterministic regular expressions: (i) star-free (for multiple input words), (ii) bounded-occurrence, i.e., expressions in which each symbol appears a bounded number of times, and (iii) bounded plus-depth, i.e., expressions in which the nesting depth of alternating plus (union) and concatenation symbols is bounded. Our algorithms use a new structural decomposition of the parse tree of  e . For matching arbitrary deterministic regular expressions we present an  O (| e | + | w |log log| e |) time algorithm."
2481985,15258,8228,Identifying Influential Nodes in Online Social Networks Using Principal Component Centrality,2011,"Identifying the most influential nodes in social networks is a key problem in social network analysis. However, without a strict definition of centrality the notion of what constitutes a central node in a network changes with application and the type of commodity flowing through a network. In this paper we identify social hubs, nodes at the center of influential neighborhoods, in massive online social networks using principal component centrality (PCC). We compare PCC with eigenvector centrality's (EVC), the de facto measure of node influence by virtue of their position in a network. We demonstrate PCC's performance by processing a friendship graph of 70, 000 users of Google's Orkut social networking service and a gaming graph of 143, 020 users obtained from users of Facebook's 'Fighters Club' application."
1823273,15258,343,The energy and emergy of the internet,2011,"Recent years have seen a flurry of energy-efficient networking research. But does decreasing the energy used by the Internet actually save society much energy? To answer this question, we estimate the Internet's energy consumption. We include embodied energy (emergy)---the energy required to construct the Internet---a quantity that has often been ignored in previous work. We find that while in absolute terms the Internet uses significant energy, this quantity is negligible when compared with society's colossal energy use."
964339,15258,343,LOUP: who's afraid of the big bad loop?,2012,"We consider the intra-AS route dissemination problem from first principles, and illustrate that when known route dissemination techniques propagate even a single external routing change, they can cause transient anomalies. These anomalies are not fundamental; they are artifacts of the  order  in which existing proposals disseminate routes. We show that carefully ordering route updates avoids transient looping and black holes. Perhaps surprisingly, this ordering may be enforced in a completely distributed fashion, while retaining familiar correctness, scalability, and convergence properties."
849651,15258,369,Handoff Rates for Millimeterwave 5G Systems,2014,"Millimeterwave band is a promising candidate for 5th generation wireless access technology to deliver peak and cell-edge data rates of the order of 10 Gbps and 100 Mbps, respectively, and to meet the future capacity demands. The main advantages of the millimeterwave band are availability of large blocks of contiguous bandwidth and the opportunity of using large antenna arrays composed of very small antenna elements to provide large antenna gains. The line-of-sight operation requirement in this band, due to its unique propagation characteristics, makes it necessary to build the network with enough redundancy of access points and the users may have to frequently handoff from one access point to another whenever its radio link is disrupted by obstacles. In this paper we investigate the handoff rate in such an access network. Based on analysis of various deployment scenarios, we observe that, typical average handoff interval is several seconds, although for certain types of user actions the average handoff interval can be as low as 0.75 sec."
1960176,15258,343,XIA: an architecture for an evolvable and trustworthy internet,2011,"Motivated by limitations in today's host-based IP network architecture, recent studies have proposed clean-slate network architectures centered around alternative first-class principals, such as content, services, or users. However, much like the host-centric IP design, elevating one principal type above others hinders communication between other principals and inhibits the network's capability to evolve. Our work presents the eXpressive Internet Architecture (XIA), an architecture with native support for multiple principals and the ability to evolve its functionality to accommodate new, as yet unforeseen, principals over time. XIA also provides intrinsic security: communicating entities validate that their underlying intent was satisfied correctly without relying on external databases or configuration.   In this paper, we focus on core architectural issues in the XIA data plane. We outline key design requirements relating to native support for multiple principals and intrinsic security. We then use case studies to demonstrate how the XIA design facilitates evolvability and flexibility."
1933015,15258,122,Transaction communicators: enabling cooperation among concurrent transactions,2011,"In this paper, we propose to extend transactional memory with  transaction communicators , special objects through which concurrent transactions can communicate: changes by one transaction to a communicator can be seen by concurrent transactions before the first transaction commits. Although isolation of transactions is compromised by such communication, we constrain the effects of this compromise by tracking dependencies among transactions, and preventing any transaction from committing unless every transaction whose changes it saw also commits. In particular, mutually dependent transactions must commit or abort together, and transactions that do not communicate remain isolated. To help programmers synchronize accesses to communicators, we also provide special  communicator-isolating transactions , which ensure isolation even for accesses to communicators. We propose language features to help programmers express the communicator constructs. We implemented a novel communicators-enabled STM runtime in the Maxine VM. Our preliminary evaluation demonstrates that communicators can be used in diverse settings to improve the performance of transactional programs, and to empower programmers with the ability to safely express within transactions important programming idioms that fundamentally require compromise of transaction isolation (e.g., CSP-style synchronous communication)."
131276,15258,293,Effect of competing TCP traffic on interactive real-time communication,2013,"Providing acceptable quality level for interactive media flows such as interactive video or audio is challenging in the presence of TCP traffic. Volatile TCP traffic such as Web traffic causes transient queues to appear and vanish rapidly introducing jitter to the packets of the media flow. Meanwhile long-lived TCP connections cause standing queues to form which increases the one-way delay for the media flow packets. To get insights into this problem space we conducted experiments in a real high-speed cellular network. Our results confirm the existence of issues with both Web-like traffic and long-lived TCP connections and highlight that current trend of using several parallel connections in Web browsers tends to have high cost on media flows. In addition, the recent proposal to increase the initial window of TCP to ten segments, if deployed, is going to make the jitter problem even worse."
127121,15258,293,Modern Application Layer Transmission Patterns from a Transport Perspective,2014,"We aim to broadly study the ways that modern applications use the underlying protocols and networks. Such an understanding is necessary when designing and optimizing lower-layer protocols. Traditionallyas prior work showsapplications have been well represented as bulk transfers, often preceded by application-layer handshaking. Recent suggestions posit that application evolution has eclipsed this simple model, and a typical pattern is now a series of transactions over a single transport layer connection. In this initial study we examine application transmission patterns via packet traces from two networks to better understand the ways that modern applications use TCP."
620954,15258,20349,XIA: efficient support for evolvable internetworking,2012,"Motivated by limitations in today's host-centric IP network, recent studies have proposed clean-slate network architectures centered around alternate first-class principals, such as content, services, or users. However, much like the host-centric IP design, elevating one principal type above others hinders communication between other principals and inhibits the network's capability to evolve. This paper presents the eXpressive Internet Architecture (XIA), an architecture with native support for multiple principals and the ability to evolve its functionality to accommodate new, as yet unforeseen, principals over time. We describe key design requirements, and demonstrate how XIA's rich addressing and forwarding semantics facilitate flexibility and evolvability, while keeping core network functions simple and efficient. We describe case studies that demonstrate key functionality XIA enables."
402472,15258,293,Omnify: investigating the visibility and effectiveness of copyright monitors,2011,"The arms race between copyright agencies and P2P users is an ongoing and evolving struggle. On the one hand, content providers are using several techniques to stealthily find unauthorized distribution of copyrighted work in order to deal with the problem of Internet piracy. On the other hand, P2P users are relying increasingly on blacklists and anonymization methods in order to avoid detection. In this work, we propose a number of techniques to reveal copyright monitors' current approaches and evaluate their effectiveness. We apply these techniques on data we collected from more than 2.75 million BitTorrent swarms containing 71 million IP addresses. We provide strong evidence that certain nodes are indeed copyright monitors, show that monitoring is a world-wide phenomenon, and devise a methodology for generating blacklists for paranoid and conservative P2P users."
812549,15258,343,NetEgg: Programming Network Policies by Examples,2014,"The emergence of programmable interfaces to network controllers offers network operators the flexibility to implement a variety of policies. We propose NetEgg, a programming framework that allows a network operator to specify the desired functionality using example behaviors. Our synthesis algorithm automatically infers the state that needs to be maintained to exhibit the desired behaviors along with the rules for processing network packets and updating the state. We report on an initial prototype of NetEgg. Our experiments evaluate the proposed framework based on the number of examples needed to specify a variety of policies considered in the literature, the computational requirements of the synthesis algorithm to translate these examples to programs, and the overhead introduced by the generated implementation for processing packets. Our results show that NetEgg can generate implementations that are consistent with the example behaviors, and have performance comparable to equivalent imperative implementations."
2035651,15258,8228,A Mobile Agent Fault-Tolerant Method Based on the Ring Detection & Backup Chain for Mobile IPv6 Networks,2011,"The home agent can be a single point of failure in mobile IPv6 networks. Fault tolerance can be used to provide reliable home agent service. This paper proposes a home agent fault-tolerant method for mobile IPv6 networks. All home agents are formed into the structure of ring detection & backup chain by sorting them using a deterministic sorting algorithm, in which each home agent backups its bindings on the next adjacent home agent and its validation is monitored by the adjacent home agents. Each home agent is not only an active home agent, but also a standby one. Service takeover is fleetly implemented by the single replica of mobility bindings. Simulation results show that our method has less service break time and less global signal cost."
2066079,15258,293,Measuring home networks with homenet profiler,2013,"This paper designs HomeNet Profiler, a software that runs on any computer connected inside a home network, to collect a wide range of measurements about home networks including the set of devices, the set of services (with UPnP and Zeroconf), and the characteristics of theWiFi environment. To attract a larger number of users, HomeNet Profiler runs one-shot measurements upon user demand. We evaluate this design choice against periodic measurements taken from six home networks. Data collected from these six homes and with Home- Net Profiler in more than 1,600 homes in France shed light on the diversity of devices that connect to home networks and of the WiFi neighborhood across home networks."
2212864,15258,369,Multihop Wireless Channel Models Suitable for Stochastic Petri Nets and Markov State Analysis,2011,"In this paper the system analysis of modern wireless systems is simplified by providing simple yet powerful models for the wireless channel in the environment of higher layer abstract system descriptions with generalized stochastic Petri nets (SPN). This modeling approach is capable of deriving performance metrics in terms of packet delays even under heterogeneous, asymmetric, bursty and underutilized traffic conditions, because they are easy to model with SPN. The missing link in wireless systems are suitable channel models, which can now be used as a plug-in submodel inside a larger composite Petri net model. A number of models are proposed, starting from the finite-state Markov channel model approach. Performance results for a multihop relayed transmission under varied traffic load show the utility of this modeling approach."
347354,15258,293,FACT: flow-based approach for connectivity tracking,2011,"More than 20 years after the launch of the public Internet, operator forums are still full of reports about temporary unreachability of complete networks. We propose FACT, a system that helps network operators to track connectivity problems with remote autonomous systems, networks, and hosts. In contrast to existing solutions, our approach relies solely on flow-level information about observed traffic, is capable of online data processing, and is highly efficient in alerting only about those events that actually affect the studied network or its users.#R##N##R##N#We evaluate FACT based on flow-level traces from a medium-sized ISP. Studying a time period of one week in September 2010, we explain the key principles behind our approach. Ultimately, these can be leveraged to detect connectivity problems and to summarize suspicious events for manual inspection by the network operator. In addition, when replaying archived traces from the past, FACT reliably recognizes reported connectivity problems that were relevant for the studied network."
46525,15258,293,On 60 GHz wireless link performance in indoor environments,2012,"The multi-Gbps throughput potential of 60 GHz wireless interfaces make them an attractive technology for next-generation gigabit WLANs. For increased coverage, and improved resilience to human-body blockage, beamsteering with high-gain directional antennas is emerging to be an integral part of 60 GHz radios. However, the real-world performance of these state-of-the-art radios in typical indoor environments has not previously been explored well in open literature.#R##N##R##N#To this end, in this paper, we address the following open questions: how do these radios perform in indoor line-of-sight(LOS) and non-line-of-sight (NLOS) locations? how sensitive is performance to factors such as node orientation or placement? how robust is performance to human-body blockage and mobility? Our measurement results from a real office setting, using a first-of-its-kind experimental platform (called Presto), show that, contrary to conventional perception, state-of-the-art 60 GHz radios perform well even in NLOS locations, in the presence of human-body blockage and LOS mobility. While their performance is affected by node (or more precisely, antenna array) orientation, simply using a few more antenna arrays and dynamically selecting amongst them shows potential to address this issue. The implications of these observations is in lowering the barriers to their adoption in next-generation gigabit WLANs."
568400,15258,293,On the feasibility of bandwidth detouring,2011,"Internet applications that route data over default Internet paths can often increase performance by sending their traffic over alternative detour paths. Previous work has shown that applications can use detour routing to improve end-to-end metrics such as latency and path availability. However, the potential of detour routing has yet to be applied where it may be most important: improving TCP throughput.#R##N##R##N#In this paper, we study the feasibility of bandwidth detouring on the Internet. We find that bandwidth detours are prevalent: between 152 Planetlab nodes, 74.8% of the paths can benefit from detours with at least 1Mbps and 20% improvement. To understand how to exploit bandwidth detours in practice, we explore the trade-offs between networkand transport-level mechanisms for detouring. We show, both analytically and experimentally, that direct, TCP-based detour routing improves TCP throughput more than encapsulated, IP-based tunneling, although the latter provides a more natural interface."
1429756,15258,369,RTMB/CTMB: A Collision Avoidance Scheme for VANET Broadcast,2011,"Traditional directional broadcast protocols for VANETs always select redundant nodes and thus are not very efficient. Road-based directional broadcast was proposed to solve this problem. The basic idea is to categorize vehicles based on road topology and select a relay for each road. It improves the efficiency significantly, but data propagation could fail due to collisions. In this paper, we aim to add reliability to road-based directional broadcast protocol. A MAC layer collision avoidance scheme is proposed to reduce the chance of collision between the sender and the selected relay nodes, while other nodes can receive data opportunistically. By limiting the number of selected relays, this scheme improves the delivery ratio than that of traditional broadcast protocols while keeping the efficiency at a comparable level."
2543459,15258,369,Practical Link Reliability for Ad Hoc Routing Protocol,2011,"Due to the unreliability characteristics of wireless communications, and nodes mobility, mobile ad hoc networks demand robust protocol design. Hence, routing protocol choosing the most reliable route between two terminals have been proposed in order to minimize the path failure occurrence. The interest of this approach has been shown, in research literature, mainly by simulation in terms of delay or packet delivery ratio. Meanwhile, there is a problem to put in practice the route reliability paradigm. The route reliability depends on links reliability. The motivation of this paper is to determine a measure of the link reliability. In this paper, we study the link reliability formulation in order to propose a realistic wireless link parameters modeling. The modeling takes into account the mobility, the transmission quality, and the communication load. Reliability can be computed without extra signaling by each node."
1806341,15258,122,Enhanced speculative parallelization via incremental recovery,2011,"The widespread availability of multicore systems has led to an increased interest in speculative parallelization of sequential programs using software-based thread level speculation. Many of the proposed techniques are implemented via state separation where non-speculative computation state is maintained separately from the speculative state of threads performing speculative computations. If speculation is successful, the results from speculative state are committed to non-speculative state. However, upon misspeculation, discard-all scheme is employed in which speculatively computed results of a thread are discarded and the computation is performed again. While this scheme is simple to implement, one disadvantage of discard-all is its inability to tolerate high misspeculation rates due to its high runtime overhead. Thus, it is not suitable for use in applications where misspeculation rates are input dependent and therefore may reach high levels.   In this paper we develop an approach for incremental recovery in which, instead of discarding all of the results and reexecuting the speculative computation in its entirety, the computation is restarted from the earliest point at which a misspeculation causing value is read. This approach has two advantages. First, the cost of recovery is reduced as only part of the computation is reexecuted. Second, since recovery takes less time, the likelihood of future misspeculations is reduced. We design and implement a strategy for implementing incremental recovery that allows results of partial computations to be efficiently saved and reused. For a set of programs where misspeculation rate is input dependent, our experiments show that with inputs that result in misspeculation rates of around 40% and 80%, applying incremental recovery technique results in 1.2x-3.3x and 2.0x-6.6x speedups respectively over the discard-all recovery scheme. Furthermore, misspeculations observed during discard-all scheme are reduced when incremental recovery is employed -- reductions range from 10% to 85%."
117555,15258,293,Efficient IP-Level network topology capture,2013,"Large-scale distributed network route tracing systems obtain the IP-level internet topology and can be used to monitor and understand network behavior. However, existing approaches require one or more days to obtain a full graph of the public IPv4 internet, which is too slow to capture important network dynamics. This paper presents a new approach to topology capture that aims at obtaining the graph rather than full routes, and that employs partial rather than full route tracing to achieve this aim. Our NTC (Network Topology Capture) heuristics use information from previous tracing rounds to guide probing in future rounds. Through simulations based upon two months of traces that we obtained, we find that the heuristics improve significantly on the state of the art for reducing probing overhead while maintaining good graph coverage. We also conduct the first study of how such a distributed tracing system performs in its ability to capture network dynamics."
1722101,15258,369,Prolonging WSN Lifetime with Data-Location Similarity and Weakest Node Protection,2014,"Each sensor node in a wireless sensor network (WSN) mainly consumes energy to sense the environment and convey or relay the sensed data to a sink node. Once the resident energy in a sensor node is drained, this may cause incomplete sensing coverage, resulting in WSN failure. The lifetime of a network begins when the network starts working and ends when the first node becomes ineffective from energy exhaustion caused by any of the sensor nodes in the WSN. This paper proposes a scheme that clusters sensor nodes by node reading and by node location. By using the resident energy and coverage of each node, the scheme proposes a weakest node protection mechanism to balance the energy consumed by each node, to extend the network's lifetime. The evaluation results validate the proposed concept and show the proposed scheme can even obtain additional 12.5% network lifetime compared to other existing ones."
1329638,15258,8228,Performance evaluation and analysis of bundle protocol in cislunar communications,2012,"The bundle protocol (BP) is developed to solve the new problems in deep space exploration. To date, little work has been done in evaluating the performance of BP applied to an interplanetary Internet involving frequent link disruptions. This paper builds a PC-based Deep Space Communication Test-bed. It consists of three parts, the space link simulator, the high-speed Ethernet switch and the Linux-based personal computers. Compared with the simulation in OPNET, NS2 and other simulation software, the experimental results from the Test-bed will be closer to the real environment. The paper presents an experimental evaluation of BP over a typical three-node interplanetary structure involving frequent link disruptions. The performances were analyzed to compare the throughput of BP with custody transfer and BP without custody transfer under the various scenarios. The results show that BP without custody performs better than BP with custody in a cislunar environment."
1928288,15258,122,SCCMulti: an improved parallel strongly connected components algorithm,2014,"Tarjan's famous linear time, sequential algorithm for finding the strongly connected components (SCCs) of a graph relies on depth first search, which is inherently sequential. Deterministic parallel algorithms solve this problem in logarithmic time using matrix multiplication techniques, but matrix multiplication requires a large amount of total work. Randomized algorithms based on reachability -- the ability to get from one vertex to another along a directed path -- greatly improve the work bound in the average case. However, these algorithms do not always perform well; for instance, Divide-and-Conquer Strong Components (DCSC), a scalable, divide-and-conquer algorithm, has good expected theoretical limits, but can perform very poorly on graphs for which the maximum reachability of any vertex is small. A related algorithm, MultiPivot, gives very high probability guarantees on the total amount of work for all graphs, but this improvement introduces an overhead that increases the average running time. This work introduces SCCMulti, a multi-pivot improvement of DCSC that offers the same consistency as MultiPivot without the time overhead. We provide experimental results demonstrating SCCMulti's scalability; these results also show that SCCMulti is more consistent than DCSC and is always faster than MultiPivot."
728025,15258,369,Cellular Energy Efficiency Evaluation Framework,2011,"In order to quantify the energy savings in wireless networks, the power consumption of the entire system needs to be captured and an appropriate energy efficiency evaluation framework must be defined. In this paper, the necessary enhancements over existing performance evaluation frameworks are discussed, such that the energy efficiency of the entire network comprising component, node and network level contributions can be quantified. The most important addendums over existing frameworks include a sophisticated power model for various base station (BS) types, which maps the RF output power radiated at the antenna elements to the total supply power of a BS site. We also consider an approach to quantify the energy efficiency of large geographical areas by using the existing small scale deployment models along with long term traffic models. Finally, the proposed evaluation framework is applied to quantify the energy efficiency of the downlink of a 3GPP LTE radio access network."
2515761,15258,8228,Certificateless Secure Upload for Drive-Thru Internet,2011,"Vehicular ad hoc networks have attracted a lot of attention in recent years, in either vehicle-to-vehicle or vehicle-to-infrastructure scenarios. In this paper, we focus on the latter, particularly for vehicles to upload to roadside units, the so-called drive-thru Internet, in a secure and efficient manner. Due to the ad hoc nature and wireless communications, traditional certificate-based security schemes are either infeasible or inefficient in this scenario. Thus we propose a certificateless approach to secure upload in a drive-thru Internet. We discuss the attack model and the desired security properties, and how to achieve these properties through the proposed certificateless scheme. We implement and evaluate the proposed scheme, and also investigate how to mitigate the security overhead through the separation of security association and data transfer in a drive-thru Internet."
1569060,15258,8228,Measuring link characteristics of power line communication systems,2013,"Knowing link characteristics of a network connection is essential for the efficient design, management, and usage of a network. In view of the proliferation of power line communication systems, in this work, we propose a novel measurement approach, called PLC-Probe, to concurrently measure link capacity and available bandwidth of PLC links. PLC-Probe uses `train-chirps' to probe the network, and it combines the strengths of the packet train and packet chirp approaches for estimation of link characteristics. Using testbed experiment, we evaluate the proposed approach and show that PLC-Probe is accurate, stable, and robust against cross traffic. Moreover, PLC-Probe is simple, effective, and applicable to other multi-rated PLC-like networks."
1482860,15258,208,Enabling Real-Time In-Situ Processing of Ubiquitous Mobile-Application Workflows,2013,"The heterogeneous sensing and computing capabilities of sensor nodes, mobile handhelds, as well as computing and storage servers in remote data centers can be harnessed to enable innovative mobile applications that rely on real-time in-situ processing of data generated in the field. There is, however, uncertainty associated with the quality and quantity of data from mobile sensors as well as with the availability and capabilities of mobile computing resources on the field. Data and computing-resource uncertainty, if unchecked, may propagate up the raw-data→information→knowledge chain and have an adverse effect on the relevance of the generated results. A unified uncertainty-aware framework for data and computing-resource management is proposed to enable in-situ processing of application workflows on mobile sensing and computing platforms and, hence, to generate actionable knowledge from raw data within realistic time bounds. A two-phase solution that captures the propagation of data-uncertainty up the data-processing chain using interval arithmetic in the first phase and that employs multi-objective optimization for task allocation in the second phase is presented and evaluated in detail."
709902,15258,122,StreamScan: fast scan algorithms for GPUs without global barrier synchronization,2013,"Scan (also known as prefix sum) is a very useful primitive for various important parallel algorithms, such as sort, BFS, SpMV, compaction and so on. Current state of the art of GPU based scan implementation consists of three consecutive Reduce-Scan-Scan phases. This approach requires at least two global barriers and 3N (N is the problem size) global memory accesses. In this paper we propose StreamScan, a novel approach to implement scan on GPUs with only one computation phase. The main idea is to restrict synchronization to only adjacent workgroups, and thereby eliminating global barrier synchronization completely. The new approach requires only 2N global memory accesses and just one kernel invocation. On top of this we propose two important op-timizations to further boost performance speedups, namely thread grouping to eliminate unnecessary local barriers, and register optimization to expand the on chip problem size. We designed an auto-tuning framework to search the parameter space automatically to generate highly optimized codes for both AMD and Nvidia GPUs. We implemented our technique with OpenCL. Compared with previous fast scan implementations, experimental results not only show promising performance speedups, but also reveal dramatic different optimization tradeoffs between Nvidia and AMD GPU platforms."
2454978,15258,122,Auto-tuning of fast fourier transform on graphics processors,2011,"We present an auto-tuning framework for FFTs on graphics processors (GPUs). Due to complex design of the memory and compute subsystems on GPUs, the performance of FFT kernels over the range of possible input parameters can vary widely. We generate several variants for each component of the FFT kernel that, for different cases, are likely to perform well. Our auto-tuner composes variants to generate kernels and selects the best ones. We present heuristics to prune the search space and profile only a small fraction of all possible kernels. We compose optimized kernels to improve the performance of larger FFT computations. We implement the system using the NVIDIA CUDA API and compare its performance to the state-of-the-art FFT libraries. On a range of NVIDIA GPUs and input sizes, our auto-tuned FFTs outperform the NVIDIA CUFFT 3.0 library by up to 38x and deliver up to 3x higher performance compared to a manually-tuned FFT."
1019739,15258,343,3D beamforming for wireless data centers,2011,"Contrary to prior assumptions, recent measurements show that data center traffic is not constrained by network bisection bandwidth, but is instead prone to congestion loss caused by short traffic bursts. Compared to the cost and complexity of modifying data center architectures, a much more attractive option is to augment wired links with flexible wireless links in the 60 GHz band. Current proposals, however, are severely constrained by two factors. First, 60 GHz wireless links are limited by line-of-sight, and can be blocked by even small obstacles between the endpoints. Second, even beamforming links leak power, and potential interference will severely limit concurrent transmissions in dense data centers. In this paper, we explore the feasibility of a new wireless primitive for data centers,  3D beamforming . We explore the design space, and show how bouncing 60 GHz wireless links off reflective ceilings can address both link blockage and link interference, thus improving link range and number of current transmissions in the data center."
2211635,15258,122,FlexBFS: a parallelism-aware implementation of breadth-first search on GPU,2012,"In this paper, we present FlexBFS, a parallelism-aware implementation for breadth-first search on GPU. Our implementation can adjust the computation resources according to the feedback of available parallelism dynamically. We also optimized our program in three ways: (1)a simplified two-level queue management,(2)a combined kernel strategy and (3)a high-degree vertices specialization approach. Our experimental results show that it can achieve 3~20 times speedup against the fastest serial version, and can outperform the TBB based multi-threading CPU version and the previous most effective GPU version on all types of input graphs."
2401917,15258,122,Extracting logical structure and identifying stragglers in parallel execution traces,2014,"We introduce a new approach to automatically extract an idealized  logical structure  from a parallel execution trace. We use this structure to define intuitive metrics such as the  lateness  of a process involved in a parallel execution. By analyzing and illustrating traces in terms of logical steps, we leverage a developer's understanding of the happened-before relations in a parallel program. This technique can uncover dependency chains, elucidate communication patterns, and highlight sources and propagation of delays, all of which may be obscured in a traditional trace visualization."
792619,15258,507,Dynamic management of resources and workloads for RDBMS in cloud: a control-theoretic approach,2012,"As cloud computing environments become explosively popular, dealing with unpredictable changes, uncertainties, and disturbances in both systems and environments turns out to be one of the major challenges facing the concurrent computing industry. My research goal is to dynamically manage resources and workloads for RDBMS in cloud computing environments in order to achieve ``better performance but lower cost, i.e., better service level compliance but lower consumption of virtualized computing resource(s).   Nowadays, although control theory offers a principled way to deal with the challenge based on feedback mechanisms, a controller is typically designed based on the system designer's domain knowledge and intuition instead of the behavior of the system being controlled. My research approach is based on the essence of control theory but transcends state-of-the-art control-theoretic approaches by leveraging interdisciplinary areas, especially from machine learning. While machine learning is often viewed merely as a toolbox that can be deployed for many data-centric problems, my research makes efforts to incorporate machine learning as a full-fledged engineering discipline into control-theoretic approaches for realizing my research goal.   My PhD thesis work implements two solid systems by leveraging machine learning techniques, namely, ActiveSLA and SmartSLA. ActiveSLA is an automatic controller featuring risk assessment admission control to obtain the most profitable service-level compliance. SmartSLA is an automatic controller featuring cost-sensitive adaptation to achieve the lowest total cost. The experimental results show that both of the two systems outperform the state-of-the-art methods."
17547,15258,374,Detangling Resource Management Functions from the TCB in Privacy-Preserving Virtualization,2014,"Recent research has developed virtualization architectures to protect the privacy of guest virtual machines. The key technology is to include an access control matrix in the hypervisor. However, existing approaches have either lim- ited functionalities in the hypervisor or a Trusted Computing Base (TCB) which is too large to secure. In this paper, we propose a new architecture, MyCloud SEP, to separate resource allocation and management from the hypervisor in or- der to reduce the TCB size while supporting privacy protection. In our design, the hypervisor checks all resource accesses against an access control matrix in the hypervisor. While providing flexibility of plugging-in resource management modules, the size of TCB is significantly reduced compared with commercial hy- pervisors. Using virtual disk manager as an example, we implement a prototype on x86 architecture. The performance evaluation results also show acceptable overheads."
1060176,15258,369,An Efficient Metric for Reliable Routing with Link Dependencies,2012,"To improve the robustness and adaptation to node mobility, ad hoc routing protocol uses as route selection criterion, the route reliability metric between end points. In the first part of this paper, we derive an analytical closed form expression for the computation of route reliability metric, that takes into account dependencies between adjacent links. Based on our analytical formulation, the route reliability metric computation does not introduce any complexity. Simulations show that our model can obtain more accurate results than the traditional methods. However, the route reliability metric increases network resources used in terms of intermediate nodes between source and destination. It may also increase packet delay. Moreover, the interference and collision probability between packet increase when the number of relays in the same range increases. In order to overcome these inconveniences, in the second part of this paper, we propose a new routing metric which combines reliability and hop count criteria. Simulations results show that the introduced metric allows better results."
2382356,15258,8228,Empowering Software Defined Network controller with packet-level information,2013,"Packet level information, such as packet content and inter-arrival time, are necessary for some network monitoring and control applications. However, current Software Defined Networks (SDN) such as OpenFlow provide limited access to packet-level information in the controller. In this paper, we propose an extension that enables the controller to access packet-level information through per-flow sampling. Our extension is flexible and powerful, yet it can be implemented entirely in the data plane at line rate. We present a set of possible applications that can take advantage of this new packet-level information, including examples that are extremely difficult, if not impossible in current SDN."
2695586,15258,343,Active security,2013,"In this paper we introduce  active security , a new methodology which introduces programmatic control within a novel feedback loop into the defense infrastructure. Active security implements a unified programming environment which provides interfaces to (i) protect the infrastructure under common attack scenarios ( e.g. , configure a firewall), (ii) sense the current state of the infrastructure through a wide variety of information, (iii) adjust the configuration of the infrastructure at run time based on sensed information, (iv) collect forensic evidence on-demand, at run-time for attribution, and (v) counter the attack through more advanced mechanisms such as migrating malicious code to a quarantined system. We built an initial prototype that extends the FloodLight software-defined networking controller to automatically interface with the Snort intrusion detection system to detect anomalies, the Linux Memory Extractor to collect forensic evidence at run-time, and the Volatility parsing tool to extract an executable from physical memory and analyze information about the malware (which can then be used by the active security system to better secure the infrastructure)."
88137,15258,293,Trying broadband characterization at home,2013,"In recent years the quantity and diversity of Internet-enabled consumer devices in the home have increased significantly. These trends complicate device usability and home resource management and have implications for crowdsourced approaches to broadband characterization.#R##N##R##N#The UPnP protocol has emerged as an open standard for device and service discovery to simplify device usability and resource management in home networks. In this work, we leverage UPnP to understand the dynamics of home device usage, both at a macro and micro level, and to sketch an effective approach to broadband characterization that runs behind the last meter.#R##N##R##N#Using UPnP measurements collected from over 13K end users, we show that while home networks can be quite complex, the number of devices that actively and regularly connect to the Internet is limited. Furthermore, we find a high correlation between the number of UPnP-enabled devices in home networks and the presence of UPnP-enabled gateways, and show how this can be leveraged for effective broadband characterization."
2258227,15258,8228,MI: Cross-Layer Malleable Identity,2011,"Access to Internet services is granted based on application-layer user identities, which also offer accountability. The revered layered network model dictates a disparate network-layer identity scheme for systems. We challenge this religious layered model adherence by demonstrating the practical benefits derived from a cross-layer identity scheme. Instead of a rigid identity, our malleable identity (MI) scheme empowers a traffic originator to fine-tune, on a per-case basis if necessary, her 3rd-party issued identity attributes embedded in an identity voucher (IV). When tagged to traffic, IVs benefit users, the Internet and services. A user can (a) control her traffic identifiability, ranging from anonymous, pseudonymous to personally-identifiable through attributes fine-tuning and (b) enjoy Internet-wide Single-Sign On (SSO) to network-layer Internet resources and application-layer services through IV persistence, without privacy loss naturally associated with SSO. The Internet and services can prioritize traffic, using IV attributes, as defense against Denial-of-Capability (DoC), Distributed Denial-of-Service (DDoS) and Border Gateway Protocol (BGP) prefix hijack/route forgery. MI is protocol/architecture agnostic, and backwards/forwards compatible."
792001,15258,339,Formal verification of information flow security for a simple arm-based separation kernel,2013,"A separation kernel simulates a distributed environment using a single physical machine by executing partitions in isolation and appropriately controlling communication among them. We present a formal verification of information flow security for a simple separation kernel for ARMv7. Previous work on information flow kernel security leaves communication to be handled by model-external means, and cannot be used to draw conclusions when there is explicit interaction between partitions. We propose a different approach where communication between partitions is made explicit and the information flow is analyzed in the presence of such a channel. Limiting the kernel functionality as much as meaningfully possible, we accomplish a detailed analysis and verification of the system, proving its correctness at the level of the ARMv7 assembly. As a sanity check we show how the security condition is reduced to noninterference in the special case where no communication takes place. The verification is done in HOL4 taking the Cambridge model of ARM as basis, transferring verification tasks on the actual assembly code to an adaptation of the BAP binary analysis tool developed at CMU."
424037,15258,293,Understanding the Reachability of IPv6 Limited Visibility Prefixes,2014,"The main functionality of the Internet is to provide global connectivity for every node attached to it. In light of the IPv4 address space depletion, large networks are in the process of deploying IPv6. In this paper we perform an extensive analysis of how BGP route propagation affects global reachability of the active IPv6 address space in the context of this unique transition of the Internet infrastructure. We propose and validate a methodology for testing the reachability of an IPv6 address block active in the routing system. Leveraging the global visibility status of the IPv6 prefixes evaluated with the BGP Visibility Scanner, we then use this methodology to verify if the visibility status of the prefix impacts its reachability at the interdomain level. We perform active measurements using the RIPE Atlas platform. We test destinations with different BGP visibility degrees (i.e., limited visibility - LV, high visibility - HV and dark prefixes). We show that the IPv6 LV prefixes (v6LVPs) are generally reachable, mostly due to a less-specific HV covering prefix (v6HVP). However, this is not the case of the dark address space, which, by not having a covering v6HVP is largely unreachable."
1937404,15258,293,Is Our Ground-Truth for Traffic Classification Reliable?,2014,"The validation of the different proposals in the traffic classification literature is a controversial issue. Usually, these works base their results on a ground-truth built from private datasets and labeled by techniques of unknown reliability. This makes the validation and comparison with other solutions an extremely difficult task. This paper aims to be a first step towards addressing the validation and trustworthiness problem of network traffic classifiers. We perform a comparison between 6 well-known DPI-based techniques, which are frequently used in the literature for ground-truth generation. In order to evaluate these tools we have carefully built a labeled dataset of more than 500 000 flows, which contains traffic from popular applications. Our results present PACE, a commercial tool, as the most reliable solution for ground-truth generation. However, among the open-source tools available, NDPI and especially Libprotoident, also achieve very high precision, while other, more frequently used tools (e.g., L7-filter) are not reliable enough and should not be used for ground-truth generation in their current form."
1971654,15258,122,A decomposition for in-place matrix transposition,2014,"We describe a decomposition for in-place matrix transposition, with applications to Array of Structures memory accesses on SIMD processors. Traditional approaches to in-place matrix transposition involve cycle following, which is difficult to parallelize, and on matrices of dimension m by n require O(mn log mn) work when limited to less than O(mn) auxiliary space. Our decomposition allows the rows and columns to be operated on independently during in-place transposition, reducing work complexity to O(mn), given O(max(m, n)) auxiliary space. This decomposition leads to an efficient and naturally parallel algorithm: we have measured median throughput of 19.5 GB/s on an NVIDIA Tesla K20c processor. An implementation specialized for the skinny matrices that arise when converting Arrays of Structures to Structures of Arrays yields median throughput of 34.3 GB/s, and a maximum throughput of 51 GB/s.   Because of the simple structure of this algorithm, it is particularly suited for implementation using SIMD instructions to transpose the small arrays that arise when SIMD processors load from or store to Arrays of Structures. Using this algorithm to cooperatively perform accesses to Arrays of Structures, we measure 180 GB/s throughput on the K20c, which is up to 45 times faster than compiler-generated Array of Structures accesses.   In this paper, we explain the algorithm, prove its correctness and complexity, and explain how it can be instantiated efficiently for solving various transpose problems on both CPUs and GPUs."
2188097,15258,339,POSTER: A Proactive Cloud-Based Cross-Reference Forensic Framework,2014,"Traditional computer forensic tools suffer from several drawbacks: 1) information recorded by the operating system and application may not be enough for performing exact forensics, because such information is not tailored for forensic purpose; 2) evidence extraction is based on single computer; 3) evidence is vulnerable to be tampered; 4) volatile yet important evidence may not be recorded for forensic analysis. To overcome these limitations, this paper proposes a cloud-based proactive forensics framework to record state information across a set of computers (such as the cluster of computers that consist a cloud) for cross forensic analysis. Our forensic framework is built on Microsoft Azure and can be scaled easily to accommodate the increase or decrease of forensic targets. The information recorded by our proposed forensics framework may be volatile and the recording frequency can be customized. When a digital crime occurs, there is no need to speculate what happened, instead we can analyze and cross reference the recorded information to reconstruct the events occurred. We have conducted an experiment to assess the feasibility of our framework and found the result to be satisfactory."
1305441,15258,122,TigerQuoll: parallel event-based JavaScript,2013,"JavaScript, the most popular language on the Web, is rapidly moving to the server-side, becoming even more pervasive. Still, JavaScript lacks support for shared memory parallelism, making it challenging for developers to exploit multicores present in both servers and clients. In this paper we present TigerQuoll, a novel API and runtime for parallel programming in JavaScript. TigerQuoll features an event-based API and a parallel runtime allowing applications to exploit a mutable shared memory space. The programming model of TigerQuoll features automatic consistency and concurrency management, such that developers do not have to deal with shared-data synchronization. TigerQuoll supports an innovative transaction model that allows for eventual consistency to speed up high-contention workloads. Experiments show that TigerQuoll applications scale well, allowing one to implement common parallelism patterns in JavaScript."
1925736,15258,293,Operating a network link at 100,2011,"Internet speed at the edge is increasing fast with the spread of fiberbased broadband technology. The appearance of bandwidth-consuming applications, such as peer-to-peer file sharing and video streaming, has made traffic growth a serious concern like never before. Network operators fear congestion at their links and try to keep them underutilized while no concrete report exists about performance degradation at highly utilized links until today. In this paper, we reveal the degree of performance degradation at a 100% utilized link using the packet-level traces collected at our campus network link. The link has been fully utilized during the peak hours for more than three years. We have found that per-flow loss rate at our border router is surprisingly low, but 30 ∼ 50 msec delay is added. The increase in delay results in overall RTT increase and degrades user satisfaction for domestic web flows. Comparison of two busy traces shows that the same 100% utilization can result in different amount of performance loss according to the traffic conditions. This paper stands as a good reference to the network administrators facing future congestion in their networks."
1905307,15258,122,Programming the memory hierarchy revisited: supporting irregular parallelism in sequoia,2011,"We describe two novel constructs for programming parallel machines with multi-level memory hierarchies: call-up, which allows a child task to invoke computation on its parent, and spawn, which spawns a dynamically determined number of parallel children until some termination condition in the parent is met. Together we show that these constructs allow applications with irregular parallelism to be programmed in a straightforward manner, and furthermore these constructs complement and can be combined with constructs for expressing regular parallelism. We have implemented spawn and call-up in Sequoia and we present an experimental evaluation on a number of irregular applications."
1087703,15258,343,The great IPv4 land grab: resource certification for the IPv4 grey market,2011,"The era of free IPv4 address allocations has ended and the grey market in IPv4 addresses is now emerging. This paper argues that one cannot and should not try to regulate who sells addresses and at what price, but one does need to provide some proof of ownership in the form of resource certification. In this paper we identify key requirements of resource certification, gained from both theoretical analysis and operational history. We further argue these requirements can be achieved by making use of the existing reverse DNS hierarchy, enhanced with DNS Security. Our analysis compares reverse DNS entries and BGP routing tables and shows this is both feasible and achievable today; an essential requirement as the grey market is also emerging today and solutions are needed now, not years in the future."
2027422,15258,122,Scalable deterministic replay in a parallel full-system emulator,2013,"Full-system emulation has been an extremely useful tool in developing and debugging systems software like operating systems and hypervisors. However, current full-system emulators lack the support for deterministic replay, which limits the reproducibility of concurrency bugs that is indispensable for analyzing and debugging the essentially multi-threaded systems software.   This paper analyzes the challenges in supporting deterministic replay in parallel full-system emulators and makes a comprehensive study on the sources of non-determinism. Unlike application-level replay systems, our system, called ReEmu, needs to log sources of non-determinism in both the guest software stack and the dynamic binary translator for faithful replay. To provide scalable and efficient record and replay on multicore machines, ReEmu makes several notable refinements to the CREW protocol that replays shared memory systems. First, being aware of the performance bottlenecks in frequent lock operations in the CREW protocol, ReEmu refines the CREW protocol with a seqlock-like design, to avoid serious contention and possible starvation in instrumentation code tracking dependence of racy accesses on a shared memory object. Second, to minimize the required log files, ReEmu only logs minimal local information regarding accesses to a shared memory location, but instead relies on an offline log processing tool to derive precise shared memory dependence for faithful replay. Third, ReEmu adopts an automatic lock clustering mechanism that clusters a set of uncontended memory objects to a bulk to reduce the frequencies of lock operations, which noticeably boost performance.   Our prototype ReEmu is based on our open-source COREMU system and supports scalable and efficient record and replay of full-system environments (both x64 and ARM). Performance evaluation shows that ReEmu has very good performance scalability on an Intel multicore machine. It incurs only 68.9% performance overhead on average (ranging from 51.8% to 94.7%) over vanilla COREMU to record five PARSEC benchmarks running on a 16-core emulated system."
1330142,15258,369,On the Impact of Sleep Modes and BW Variation on the Energy Consumption of Radio Access Networks,2012,"This paper tries to analyze the energy saving capabilities of two common power saving techniques being suggested - introduction of sleep modes and bandwidth (BW) variation. The framework for this analysis assumes users and base stations (BSs) to be independently marked point processes in R2. The relationship between spatially averaged rate, user density, and base station density, which is an extension of findings in [1], is used in an affine power model to estimate the energy that can be saved by the two methods under consideration. The primary contribution of this paper constitutes an analytic relationship between spatially averaged rate, user density, BS density, transmit power, and the noise power. Another key contribution is a proof that shows that power saved by using sleep modes (or turning off BSs) is always greater than the power saved by varying the BW, for a system model implementing an affine power model (described here) when traffic densities below full load are considered."
1040121,15258,507,How to stop under-utilization and love multicores,2014,"Designing scalable database management systems on modern hardware has been a challenge for almost a decade. Hardware trends oblige software to overcome three major challenges against systems scalability: (1) Exploiting the abundant thread-level parallelism provided by multicores, (2) Achieving predictively efficient execution despite the variability in communication latencies among cores on multisocket multicores, and (3) Taking advantage of the aggressive micro-architectural features. In this tutorial, we shed light on the above three challenges and survey recent proposals to alleviate them. First, we present a systematic way of eliminating scalability bottlenecks based on minimizing unbounded communication and show several techniques that minimize bottlenecks in major components of database management systems. In addition, we demonstrate methods to parallelize major database operations. Then, we analyze the problems that arise from the non-uniform nature of communication latencies on modern multisockets and ways to address them for systems that already scale well on multicores. Finally, we examine the sources of under-utilization within a modern processor and present insights and techniques to better exploit the micro-architectural resources of a processor by improving cache locality at the right level of the memory hierarchy."
2459927,15258,122,Adapting the polyhedral model as a framework for efficient speculative parallelization,2012,"In this paper, we present a Thread-Level Speculation (TLS) framework whose main feature is to be able to speculatively parallelize a sequential loop nest in various ways, by re-scheduling its iterations. The transformation to be applied is selected at runtime with the goal of minimizing the number of rollbacks and maximizing performance. We perform code transformations by applying the polyhedral model that we adapted for speculative and runtime code parallelization. For this purpose, we design a parallel code pattern which is patched by our runtime system according to the profiling information collected on some execution samples. Adaptability is ensured by considering chunks of code of various sizes, that are launched successively, each of which being parallelized in a different manner, or run sequentially, depending on the currently observed behavior for accessing memory.   We show on several benchmarks that our framework yields good performance on codes which could not be handled efficiently by previously proposed TLS systems."
1486200,15258,369,BER Analysis with an Appropriate Friis Formula for Multi-Hop ALOHA Dense Ad Hoc Networks,2012,This paper investigates multi-hop wireless ALOHA ad hoc networks evaluating the bit error rate (BER). It is proposed an alteration of the Friis propagation model which allows its application to any node density with random network topology and obeys the law of conservation of energy. The results show that the adapted model appropriately describes the BER performance for dense networks. It was also verified that the increase of transmission power in dense networks without augment in transmission band does not improve the BER performance and it has importance to sensor networks in which energy consumption is crucial.
1880915,15258,122,ScalaExtrap: trace-based communication extrapolation for spmd programs,2011,"Performance modeling for scientific applications is important for assessing potential application performance and systems procurement in high-performance computing (HPC). Recent progress on communication tracing opens up novel opportunities for communication modeling due to its lossless yet scalable trace collection. Estimating the impact of scaling on communication efficiency still remains non-trivial due to execution-time variations and exposure to hardware and software artifacts. This work contributes a fundamentally novel modeling scheme. We synthetically generate the application trace for large numbers of nodes by extrapolation from a set of smaller traces. We devise an innovative approach for topology extrapolation of single program, multiple data (SPMD) codes with stencil or mesh communication. The extrapolated trace can subsequently be (a) replayed to assess communication requirements before porting an application, (b) transformed to auto-generate communication benchmarks for various target platforms, and (c) analyzed to detect communication inefficiencies and scalability limitations. To the best of our knowledge, rapidly obtaining the communication behavior of parallel applications at arbitrary scale with the availability of timed replay, yet without actual execution of the application at this scale is without precedence and has the potential to enable otherwise infeasible system simulation at the exascale level."
2516233,15258,122,Fast concurrent queues for x86 processors,2013,"Conventional wisdom in designing concurrent data structures is to use the most powerful synchronization primitive, namely compare-and-swap (CAS), and to avoid contended hot spots. In building concurrent FIFO queues, this reasoning has led researchers to propose  combining-based  concurrent queues.   This paper takes a different approach, showing how to rely on fetch-and-add (F&A), a less powerful primitive that is available on x86 processors, to construct a  nonblocking (lock-free) linearizable concurrent FIFO queue  which, despite the F&A being a contended hot spot, outperforms combining-based implementations by 1.5x to 2.5x in all concurrency levels on an x86 server with four multicore processors, in both single-processor and multi-processor executions."
1230250,15258,369,Discovering Mobile Applications in Device-to-Device Communications: Hash Function-Based Approach,2014,"In this paper, we propose a code-based discovery protocol for device-to-device (D2D) communications. To realize proximity-based services in D2D communications, such as mobile social networks and mobile marketing, each device should first discover nearby devices, which have mobile applications of interest, by using a discovery protocol. The proposed discovery protocol makes use of a hash function-based discovery code that contains compressed information of mobile applications in a device. When a device receives a discovery code broadcasted by the other device, the device can approximately find out the mobile applications in the other device. The proposed protocol is capable of quickly discovering massive number of devices while consuming a relatively small amount of radio resources. By simulation, we show that the proposed protocol greatly outperforms a simple name-based protocol."
1148174,15258,122,Automatic communication optimizations through memory reuse strategies,2012,"Modern parallel architectures are emerging with sophisticated hardware consisting of hierarchically placed parallel processors and memories. The properties of memories in a system vary wildly, not only quantitatively (size, latency, bandwidth, number of banks) but also qualitatively (scratchpad, cache). Along with the emergence of such architectures comes the need for effectively utilizing the parallel processors and properly managing data movement across memories to improve memory bandwidth and hide data transfer latency. In this paper, we describe some of the high-level optimizations that are targeted at the improvement of memory performance in the R-Stream compiler, a high-level source-to-source automatic parallelizing compiler. We direct our focus in this paper on optimizing communications (data transfers) by improving memory reuse at various levels of an explicit memory hierarchy. This general concept is well-suited to the hardware properties of GPGPUs, which is the architecture that we concentrate on for this paper. We apply our techniques and obtain performance improvement on various stencil kernels including an important iterative stencil kernel in seismic processing applications where the performance is comparable to that of the state-of-the-art implementation of the kernel by a CUDA expert."
2038803,15258,122,"Portable, MPI-interoperable coarray fortran",2014,"The past decade has seen the advent of a number of parallel programming models such as Coarray Fortran (CAF), Unified Parallel C, X10, and Chapel. Despite the productivity gains promised by these models, most parallel scientific applications still rely on MPI as their data movement model. One reason for this trend is that it is hard for users to incrementally adopt these new programming models in existing MPI applications. Because each model use its own runtime system, they duplicate resources and are potentially error-prone. Such independent runtime systems were deemed necessary because MPI was considered insufficient in the past to play this role for these languages.   The recently released MPI-3, however, adds several new capabilities that now provide all of the functionality needed to act as a runtime, including a much more comprehensive one-sided communication framework. In this paper, we investigate how MPI-3 can form a runtime system for one example programming model, CAF, with a broader goal of enabling a single application to use both MPI and CAF with the highest level of interoperability."
2355826,15258,293,Understanding mobile app usage patterns using in-app advertisements,2013,"Recent years have seen an explosive growth in the number of mobile devices such as smart phones and tablets. This has resulted in a growing need of the operators to understand the usage patterns of the mobile apps used on these devices. Previous studies in this area have relied on volunteers using instrumented devices or using fields in the HTTP traffic such as User-Agent to identify the apps in network traces. However, the results of the former approach are difficult to be extrapolated to real-world scenario while the latter approach is not applicable to platforms like Android where developers generally use generic strings, that can not be used to identify the apps, in the User-Agent field. In this paper, we present a novel way of identifying Android apps in network traces using mobile in-app advertisements. Our preliminary experiments with real world traces show that this technique is promising for large scale mobile app usage pattern studies. We also present an analysis of the official Android market place from an advertising perspective."
208614,15258,293,Assessing DNS Vulnerability to Record Injection,2014,"The Domain Name System (DNS) is a critical component of the Internet infrastructure as it maps human-readable names to IP addresses. Injecting fraudulent mappings allows an attacker to divert users from intended destinations to those of an attacker's choosing. In this paper, we measure the Internet's vulnerability to DNS record injection attacksincluding a new attack we uncover. We find that record injection vulnerabilities are fairly commoneven years after some of them were first uncovered."
1812810,15258,343,DNS Resolvers Considered Harmful,2014,"The Domain Name System (DNS) is a critical component of the Internet infrastructure that has many security vulnerabilities. In particular, shared DNS resolvers are a notorious security weak spot in the system. We propose an unorthodox approach for tackling vulnerabilities in shared DNS resolvers: removing shared DNS resolvers entirely and leaving recursive resolution to the clients. We show that the two primary costs of this approach---loss of performance and an increase in system load---are modest and therefore conclude that this approach is beneficial for strengthening the DNS by reducing the attack surface."
2448931,15258,343,Applying operating system principles to SDN controller design,2013,"Rather than creating yet another network controller which provides a framework in a specific (potentially new) programming language and runs as a monolithic application, in this paper we extend an existing operating system and leverage its software ecosystem in order to serve as a practical SDN controller. This paper introduces  yanc , a controller platform for software-defined networks which exposes the network configuration and state as a file system, enabling user and system applications to interact through standard file I/O, and to easily take advantage of the tools available on the host operating system. In  yanc , network applications are separate processes, are provided by multiple sources, and may be written in any language. Applications benefit from common and powerful technologies such as the virtual file system (VFS) layer, which we leverage to layer a distributed file system on top of, and Linux namespaces, which we use to isolate applications with different views ( e.g. , slices). In this paper we present the goals and design of  yanc . Our initial prototype is built with the FUSE file system in user space on Linux and has been demonstrated with a simple static flow pusher application. Effectively, we are making Linux the network operating system."
2012011,15258,122,Compact data structure and scalable algorithms for the sparse grid technique,2011,"The sparse grid discretization technique enables a compressed representation of higher-dimensional functions. In its original form, it relies heavily on recursion and complex data structures, thus being far from well-suited for GPUs. In this paper, we describe optimizations that enable us to implement compression and decompression, the crucial sparse grid algorithms for our application, on Nvidia GPUs. The main idea consists of a bijective mapping between the set of points in a multi-dimensional sparse grid and a set of consecutive natural numbers. The resulting data structure consumes a minimum amount of memory. For a 10-dimensional sparse grid with approximately 127 million points, it consumes up to 30 times less memory than trees or hash tables which are typically used. Compared to a sequential CPU implementation, the speedups achieved on GPU are up to 17 for compression and up to 70 for decompression, respectively. We show that the optimizations are also applicable to multicore CPUs."
2010794,15258,122,Scalable parallel debugging with statistical assertions,2012,"Traditional debuggers are of limited value for modern scientific codes that manipulate large complex data structures. This paper discusses a novel debug-time assertion, called a Statistical Assertion, that allows a user to reason about large data structures, and the primitives are parallelised to provide an efficient solution. We present the design and implementation of statistical assertions, and illustrate the debugging technique with a molecular dynamics simulation. We evaluate the performance of the tool on a 12,000 cores Cray XE6."
630215,15258,293,How to reduce smartphone traffic volume by 30,2013,"The unprecedented growth in smartphone usage has fueled a massive increase in cellular network traffic volumes. We investigate the feasibility of applying Redundancy Elimination (RE) for today's smartphone traffic, using packet traces collected from 20 real mobile users for five months. For various RE techniques including caching, file compression, delta encoding, and packet stream compression, we present the first characterization of their individual effectiveness, the interaction among multiple jointly applied RE techniques, and their performance on mobile handsets. By leveraging several off-the-shelf RE techniques operating at different layers, we can achieve an overall reduction of smartphone traffic by more than 30%."
1063616,15258,122,"Kremlin: like gprof, but for parallelization",2011,"This paper overviews Kremlin, a software profiling tool designed to assist the parallelization of serial programs. Kremlin accepts a serial source code, profiles it, and provides a list of regions that should be considered in parallelization. Unlike a typical profiler, Kremlin profiles not only work but also parallelism, which is accomplished via a novel technique called hierarchical critical path analysis. Our evaluation demonstrates that Kremlin is highly effective, resulting in a parallelized program whose performance sometimes outperforms, and is mostly comparable to, manual parallelization. At the same time, Kremlin would require that the user parallelize significantly fewer regions of the program. Finally, a user study suggests Kremlin is effective in improving the productivity of programmers."
1836925,15258,122,X10 and APGAS at Petascale,2014,"X10 is a high-performance, high-productivity programming language aimed at large-scale distributed and shared-memory parallel applications. It is based on the Asynchronous Partitioned Global Address Space (APGAS) programming model, supporting the same fine-grained concurrency mechanisms within and across shared-memory nodes.   We demonstrate that X10 delivers solid performance at petascale by running (weak scaling) eight application kernels on an IBM Power 775 supercomputer utilizing up to 55,680 Power7 cores (for 1.7 Pflop/s of theoretical peak performance). We detail our advances in distributed termination detection, distributed load balancing, and use of high-performance interconnects that enable X10 to scale out to tens of thousands of cores.   For the four HPC Class 2 Challenge benchmarks, X10 achieves 41% to 87% of the system's potential at scale (as measured by IBM's HPCC Class 1 optimized runs). We also implement K-Means, Smith-Waterman, Betweenness Centrality, and Unbalanced Tree Search (UTS) for geometric trees. Our UTS implementation is the first to scale to petaflop systems."
1395856,15258,339,POSTER: Mining Elephant Applications in Unknown Traffic by Service Clustering,2014,"Network traffic classification is of great importance for fine-grained network management and network security. However, with the rapid development of new network applications in recent years, traffic that cannot be identified by classifiers accounts for an increasing ratio, which brings a great challenge for network operators. Most of the unknown traffic is usually generated by only a few or some certain kinds of applications. We call this kind of traffic as the elephant traffic. It is generally recognized that traffic sharing the same server IP and server port is generated by the same application. In this paper, we say that they are belonging to the same service. Therefore, we propose a novel method, in which service-based statistical features are used for cluster analysis, to classify these elephant traffic. Preliminary results on a real network traffic dataset show that our method is able to automatically identify similar unknown applications. We believe that classifying unknown traffic in service perspective is a promising direction."
1648528,15258,369,Moving Towards Mmwave-Based Beyond-4G (B-4G) Technology,2013,"Availability of large untapped spectrum resources in the millimeter wave (Mmwave) band is suitable for providing a gigabit experience with true local feel using high capacity small cells. Unlike traditional cellular systems, millimeter wave transmissions do not benefit from diffraction and dispersion making it difficult for them to propagate around obstacles thus resulting in higher shadowing loss. They also have less favorable link budgets due to lower power amplifier (PA) output powers and greater pathloss at these higher frequencies. Also, current costs of the Mmwave circuits are higher, but the costs will become much lower when the technology becomes mainstream. One advantage of millimeter wave, however, is that the smaller wavelengths allow for the fabrication of antenna arrays having a much higher number of antenna elements in a much smaller area than is typical at microwave bands. In this article, we outline a framework for Beyond-4G (B-4G) local area network in the millimeter wave band for both access and backhaul including air-interface, antenna-arrays and IC technology. It is shown that Mmwave B-4G small cell technology can provide peak and cell edge rates greater than 10 Gbps and 100 Mbps respectively with latency less than 1msec for local area network."
1054618,15258,343,BitTorrent for the less privileged,2011,"BitTorrent is a hugely popular peer-to-peer file sharing system. In countries where broadband Internet is widespread, BitTorrent accounts for as much as 70% of the overall Internet traffic. In contrast, in developing countries, BitTorrent is almost unusable on the typically low bandwidth dialup connections.   In this paper, we present a BitTorrent client called BitMate that is designed to enhance the performance of hosts with low-bandwidth connections. Importantly, BitMate enhances the performance of low-bandwidth nodes without cheating, circumventing the fairness policy of BitTorrent or adversely affecting the performance of other peers. In fact, BitMate drives its performance by scrupulously implementing the fairness philosophy of BitTorrent.   BitMate outperforms vanilla BitTorrent by as much as 70% in download performance, while at the same time improving upload contribution by as much as 1000%! BitMate also outperforms strategic clients like BitTyrant in low-bandwidth conditions by as much as 60% in download performance."
1380512,15258,343,Software-defined internet architecture: decoupling architecture from infrastructure,2012,"In current networks, a domain can effectively run a network architecture only if it is explicitly supported by the network infrastructure. This coupling between architecture and infrastructure means that any significant architectural change involves sizable costs for vendors (for development) and network operators (for deployment), creating a significant barrier to architectural evolution.   In this paper we advocate decoupling architecture from infrastructure by leveraging the recent advances in SDN, the re-emergence of software forwarding, and MPLS's distinction between network's core and edge. We sketch our design, called Software-Defined Internet Architecture (SDIA), and show how it would ease the adoption of various new Internet architectures and blur the distinction between architectures and services."
2248469,15258,122,PARRAY: a unifying array representation for heterogeneous parallelism,2012,"This paper introduces a programming interface called PARRAY (or Parallelizing ARRAYs) that supports system-level succinct programming for heterogeneous parallel systems like GPU clusters. The current practice of software development requires combining several low-level libraries like Pthread, OpenMP, CUDA and MPI. Achieving productivity and portability is hard with different numbers and models of GPUs. PARRAY extends mainstream C programming with novel array types of distinct features: 1) the dimensions of an array type are nested in a tree, conceptually reflecting the memory hierarchy; 2) the definition of an array type may contain references to other array types, allowing sophisticated array types to be created for parallelization; 3) threads also form arrays that allow programming in a Single-Program-Multiple-Codeblock (SPMC) style to unify various sophisticated communication patterns. This leads to shorter, more portable and maintainable parallel codes, while the programmer still has control over performance-related features necessary for deep manual optimization. Although the source-to-source code generator only faithfully generates low-level library calls according to the type information, higher-level programming and automatic performance optimization are still possible through building libraries of sub-programs on top of PARRAY. The case study on cluster FFT illustrates a simple 30-line code that 2x outperforms Intel Cluster MKL on the Tianhe-1A system with 7168 Fermi GPUs and 14336 CPUs."
490064,15258,293,NAT usage in residential broadband networks,2011,"Many Internet customers use network address translation (NAT) when connecting to the Internet. To understand the extend of NAT usage and its implications, we explore NAT usage in residential broadband networks based on observations from more than 20,000 DSL lines. We present a unique approach for detecting the presence of NAT and for estimating the number of hosts connected behind a NAT gateway using IP TTLs and HTTP user-agent strings. Furthermore, we study when each of the multiple hosts behind a single NAT gateway is active. This enables us to detect simultaneous use. In addition, we evaluate the accuracy of NAT analysis techniques when fewer information is available.#R##N##R##N#We find that more than 90% of DSL lines use NAT gateways to connect to the Internet and that 10% of DSL lines have multiple hosts that are active at the same time. Overall, up to 52% of lines have multiple hosts. Our findings point out that using IPs as host identifiers may introduce substantial errors and therefore should be used with caution."
2106821,15258,122,Deterministic parallel random-number generation for dynamic-multithreading platforms,2012,"Existing concurrency platforms for dynamic multithreading do not provide repeatable parallel random-number generators. This paper proposes that a mechanism called  pedigrees  be built into the runtime system to enable efficient deterministic parallel random-number generation. Experiments with the open-source MIT Cilk runtime system show that the overhead for maintaining pedigrees is negligible. Specifically, on a suite of 10 benchmarks, the relative overhead of Cilk with pedigrees to the original Cilk has a geometric mean of less than 1%.   We persuaded Intel to modify its commercial C/C++ compiler, which provides the Cilk Plus concurrency platform, to include pedigrees, and we built a library implementation of a deterministic parallel random-number generator called DotMix that compresses the pedigree and then RC6-mixes the result. The statistical quality of DotMix is comparable to that of the popular Mersenne twister, but somewhat slower than a nondeterministic parallel version of this efficient and high-quality serial random-number generator. The cost of calling DotMix depends on the spawn depth of the invocation. For a naive Fibonacci calculation with  n=40  that calls DotMix in every node of the computation, this price of determinism is a factor of 2.65 in running time, but for more realistic applications with less intense use of random numbers -- such as a maximal-independent-set algorithm, a practical samplesort program, and a Monte Carlo discrete-hedging application from QuantLib -- the observed price was less than 5%. Moreover, even if overheads were several times greater, applications using DotMix should be amply fast for debugging purposes, which is a major reason for desiring repeatability."
2136795,15258,293,Unveiling the bittorrent performance in mobile WiMAX networks,2011,"As mobile Internet environments are becoming widespread, how to revamp peer-to-peer (P2P) operations for mobile hosts is gaining more attention. In this paper, we carry out empirical measurement of BitTorrent users in a commercial WiMAX network. We investigate how handovers in WiMAX networks impact the BitTorrent performance, how BitTorrent peers perform from the aspects of connectivity, stability and capability, and how the BitTorrent protocol behaves depending on user mobility. We observe that the drawbacks of BitTorrent for mobile users are characterized by poor connectivity among peers, short download session times, small download throughput, negligible upload contributions, and high signaling overhead."
134190,15258,293,Characterizing large-scale routing anomalies: a case study of the china telecom incident,2013,"China Telecom's hijack of approximately 50,000 IP prefixes in April 2010 highlights the potential for traffic interception on the Internet. Indeed, the sensitive nature of the hijacked prefixes, including US government agencies, garnered a great deal of attention and highlights the importance of being able to characterize such incidents after they occur. We use the China Telecom incident as a case study, to understand (1) what can be learned about large-scale routing anomalies using public data sets, and (2) what types of data should be collected to diagnose routing anomalies in the future. We develop a methodology for inferring which prefixes may be impacted by traffic interception using only control-plane data and validate our technique using data-plane traces. The key findings of our study of the China Telecom incident are: (1) The geographic distribution of announced prefixes is similar to the global distribution with a tendency towards prefixes registered in the Asia-Pacific region, (2) there is little evidence for subprefix hijacking which supports the hypothesis that this incident was likely a leak of existing routes, and (3) by preferring customer routes, providers inadvertently enabled interception of their customer's traffic."
2274120,15258,122,Lock-free and scalable multi-version software transactional memory,2011,"Software Transactional Memory (STM) was initially proposed as a lock-free mechanism for concurrency control. Early implementations had efficiency limitations, and soon obstruction-free proposals appeared, to tackle this problem, often simplifying STM implementation. Today, most of the modern and top-performing STMs use blocking designs, relying on locks to ensure an atomic commit operation. This approach has revealed better in practice, in part due to its simplicity. Yet, it may have scalability problems when we move into many-core computers, requiring fine-tuning and careful programming to avoid contention. In this paper we present and discuss the modifications we made to a lock-based multi-version STM in Java, to turn it into a lock-free implementation that we have tested to scale at least up to 192 cores, and which provides results that compete with, and sometimes exceed, some of today's top-performing lock-based implementations. The new lock-free commit algorithm allows write transactions to proceed in parallel, by allowing them to run their validation phase independently of each other, and by resorting to helping from threads that would otherwise be waiting to commit, during the write-back phase. We also present a new garbage collection algorithm to dispose of old unused object versions that allows for asynchronous identification of unnecessary versions, which minimizes its interference with the rest of the transactional system."
118012,15258,293,Towards an Automated Investigation of the Impact of BGP Routing Changes on Network Delay Variations,2014,"Understanding fluctuations in network performance is important as many applications, including streaming, conferencing, gaming, and financial transactions, rely on timely delivery of data. Awareness of the effect of routing changes on network delays is key to this understanding, but research in this area is often based on empirical observations that cannot be easily extended to everyday network scenarios.#R##N##R##N#We study the relationship between BGP routing changes and round-trip times (RTTs), bringing several contributions: 1) an automated methodology that exploits state-of-the-art statistical methods to determine if a routing change caused a significant RTT variation; 2) an application of our methodology on massive RIPE RIS and RIPE Atlas data sets, showing its effectiveness in the wild (for example, at least 72.5% of the unique routing changes were consistently associated with an RTT increase  or decrease  in all their occurrences); 3) various a-posteriori analyses leading to interesting findings for several practical applications."
2170433,15258,293,The Need for End-to-End Evaluation of Cloud Availability,2014,"People's computing lives are moving into the cloud, making understanding cloud availability increasingly critical. Prior studies of Internet outages have used ICMP-based pings and traceroutes. While these studies can detect network availability, we show that they can be inaccurate at estimating cloud availability. Without care, ICMP probes can underestimate availability because ICMP is not as robust as application-level measurements such as HTTP. They can overestimate availability if they measure reachability of the cloud's edge, missing failures in the cloud's back-end. We develop methodologies sensitive to five nines of reliability, and then we compare ICMP and end-to-end measurements for both cloud VM and storage services. We show case studies where one fails and the other succeeds, and our results highlight the importance of application-level retries to reach high precision. When possible, we recommend end-to-end measurement with application-level protocols to evaluate the availability of cloud services."
2499578,15258,122,Heterogeneous computing: what does it mean for compiler research?,2014,"The current trend in computer architecture is to increase the number of cores, to create specialized types of cores within a single machine, and to network such machines together in very fluid web/cloud computing arrangements. Compilers have traditionally focused on optimizations to code that improve performance, but is that the right target to speed up real applications? Consider loading a web page (like starting GMAIL) the page is transferred to the client, any JavaScript is compiled, the JavaScript executes, and the page gets displayed. The classic compiler model (which was first developed in the late 50's) was a great fit for single core machines but has fallen behind architecture, and language. For example how do you compile a single program for a machine that has both a CPU and a graphics coprocessor (a GPU) with a very different programming and memory model? Together with the changes in architecture there have been changes in programming languages. Dynamic languages are used more, static languages are used less. How does this effect compiler research? In this talk, I'll review a number of traditional compiler research challenges that have (or will) become burning issues and will describe some new problems areas that were not considered in the past. For example language specifica-tions are large complex technical documents that are difficult for non-experts to follow. Application programmers are often not willing to read these documents; can a compiler bridge the gap?"
2069716,15258,122,Triolet: a programming system that unifies algorithmic skeleton interfaces for high-performance cluster computing,2014,"Functional algorithmic skeletons promise a high-level programming interface for distributed-memory clusters that free developers from concerns of task decomposition, scheduling, and communication. Unfortunately, prior distributed functional skeleton frameworks do not deliver performance comparable to that achievable in a low-level distributed programming model such as C with MPI and OpenMP, even when used in concert with high-performance array libraries. There are several causes: they do not take advantage of shared memory on each cluster node; they impose a fixed partitioning strategy on input data; and they have limited ability to fuse loops involving skeletons that produce a variable number of outputs per input.   We address these shortcomings in the Triolet programming language through a modular library design that separates concerns of parallelism, loop nesting, and data partitioning. We show how Triolet substantially improves the parallel performance of algorithms involving array traversals and nested, variable-size loops over what is achievable in Eden, a distributed variant of Haskell. We further demonstrate how Triolet can substantially simplify parallel programming relative to C with MPI and OpenMP while achieving 23--100% of its performance on a 128-core cluster."
2253172,15258,122,Automatic semantic locking,2014,"In this paper, we consider concurrent programs in which the shared state consists of instances of linearizable ADTs (abstract data types). We develop a novel automated approach to concurrency control that addresses a common need: the need to atomically execute a code fragment, which may contain multiple ADT operations on multiple ADT instances. In our approach, each ADT implements ADT-specific semantic locking operations that serve to exploit the semantics of ADT operations. We develop a synthesis algorithm that automatically inserts calls to these locking operations in a set of given code fragments (in a client program) to ensure that these code fragments execute atomically without deadlocks, and without rollbacks.   We have implemented the synthesis algorithm and several general-purpose ADTs with semantic locking. We have applied the synthesis algorithm to several Java programs that use these ADTs. Our results show that our approach enables efficient and scalable synchronization."
2185713,15258,339,Eliminating the hypervisor attack surface for a more secure cloud,2011,"Cloud computing is quickly becoming the platform of choice for many web services. Virtualization is the key underlying technology enabling cloud providers to host services for a large number of customers. Unfortunately, virtualization software is large, complex, and has a considerable attack surface. As such, it is prone to bugs and vulnerabilities that a malicious virtual machine (VM) can exploit to attack or obstruct other VMs -- a major concern for organizations wishing to move to the cloud. In contrast to previous work on hardening or minimizing the virtualization software, we eliminate the hypervisor attack surface by enabling the guest VMs to run natively on the underlying hardware while maintaining the ability to run multiple VMs concurrently. Our NoHype system embodies four key ideas: (i) pre-allocation of processor cores and memory resources, (ii) use of virtualized I/O devices, (iii) minor modifications to the guest OS to perform all system discovery during bootup, and (iv) avoiding indirection by bringing the guest virtual machine in more direct contact with the underlying hardware. Hence, no hypervisor is needed to allocate resources dynamically, emulate I/O devices, support system discovery after bootup, or map interrupts and other identifiers. NoHype capitalizes on the unique use model in cloud computing, where customers specify resource requirements ahead of time and providers offer a suite of guest OS kernels. Our system supports multiple tenants and capabilities commonly found in hosted cloud infrastructures. Our prototype utilizes Xen 4.0 to prepare the environment for guest VMs, and a slightly modified version of Linux 2.6 for the guest OS. Our evaluation with both SPEC and Apache benchmarks shows a roughly 1% performance gain when running applications on NoHype compared to running them on top of Xen 4.0. Our security analysis shows that, while there are some minor limitations with cur- rent commodity hardware, NoHype is a significant advance in the security of cloud computing."
1265320,15258,122,Work Stealing Strategies For Multi-Core Parallel Branch-and-Bound Algorithm Using Factorial Number System,2014,"Many real-world problems in different industrial and economic fields are permutation combinatorial optimization problems. Solving to optimality large instances of these problems, such as the flowshop problem, is a challenge for multi-core computing.   This paper proposes four work stealing strategies for the multithreaded factoradic-based branch-and-bound (B&B) algorithm to solve permutation combinatorial problems on multi-core processors. The factoradic, called also factorial number system, is a mixed radix numeral system adapted to numbering permutations. In our new parallel strategies, the B&B is based on a matrix of integers instead of a pool of permutations, and work units exchanged between threads are intervals of factoradics instead of sets of nodes.   The experiments show that the strategy based on selecting the largest interval is better than the three other strategies in terms of the number of interval sharing events. Furthermore, the worst factoradic-based strategy spends on average 7.2 times less time managing the pool of subproblems than a conventional pool-based parallel B&B algorithm."
1613600,15258,369,Peer-Assisted Content Distribution with Random Linear Network Coding,2014,"Peer-to-peer networks constitute a widely used, cost-effective and scalable technology to distribute bandwidth-intensive content. The technology forms a great platform to build distributed cloud storage without the need of a central provider. However, the majority of todays peer-to-peer systems require complex algorithms to schedule what parts of obtained content to forward to other peers. Random Linear Network Coding can greatly simplify these algorithm by removing the need for coordination between the distributing nodes. In this paper we propose and evaluate the structure of the BRONCO peer-to-peer system, which applies random linear network coding. We focus on an experimental evaluation of the performance on 36 real nodes. The evalution shows that BRONCO outperforms regular HTTP transfers, and, with a extremely simple protocol structure, performs equivalently to bittorrent distribution. Furthermore, we evaluate the performance of different parameters and suggest a suitable trade- off between CPU utilization and network overhead. Within the limitations of the used test environment, we have shown that networkc coding is usable in peer-assisted content distribution and we suggest further improvements to reduce redundancy overhead."
2320642,15258,343,A Call to Arms for Management Plane Analytics,2014,"Over the last few decades, the networking community has developed numerous techniques for understanding how real networks behave through analyzing their data and control planes. In this paper, we call upon the community to similarly develop techniques to analyze the network management plane, that is, activities that underlie network design and operation. Such analytics can shed light on why a network behaves as observed and the relative merits of different management practices. While the management plane is often not directly observable, we argue that many relevant aspects can be inferred through data that most networks already gather (e.g., snapshots of configurations). Using preliminary analysis of such data from many large networks, we demonstrate the feasibility and the value of management plane analytics."
1096045,15258,343,Live migration of an entire network (and its hosts),2012,"Live virtual machine (VM) migration can move applications from one location to another without a disruption in service. However, applications often consist of multiple VMs and rely on the state of the underlying network for basic reachability, access control, and QoS functionality. Rather than migrating an individual VM, we show how to migrate an  ensemble ---the VMs, the network, and the management system---to a different set of physical resources. Our LIME (LIve Migration of Ensembles) design leverages recent advances in Software Defined Networking (SDN) for a clear separation between the controller and the data-plane state in the switches. Transparent to the application running on the controller, LIME clones the data-plane state to a new set of switches, and then incrementally migrates the traffic sources ( e.g ., the VMs). During this transition, both networks deliver traffic and LIME maintains synchronized state. Experiments with our initial prototype, built on the Floodlight OpenFlow controller, suggest that network migration does not have to be a disruptive, middle-of-the-night maintenance event, but can become an integral network management mechanism completely transparent to applications."
1491768,15258,122,Concurrent tries with efficient non-blocking snapshots,2012,"We describe a non-blocking concurrent hash trie based on shared-memory single-word compare-and-swap instructions. The hash trie supports standard mutable lock-free operations such as insertion, removal, lookup and their conditional variants. To ensure space-efficiency, removal operations compress the trie when necessary.   We show how to implement an efficient lock-free snapshot operation for concurrent hash tries. The snapshot operation uses a single-word compare-and-swap and avoids copying the data structure eagerly. Snapshots are used to implement consistent iterators and a linearizable size retrieval. We compare concurrent hash trie performance with other concurrent data structures and evaluate the performance of the snapshot operation."
131107,15258,293,Scaling out the performance of service monitoring applications with blockmon,2013,"To cope with real-time data analysis as the amount of data being exchanged over the network increases, an idea is to re-design algorithms originally implemented on the monitoring probe to work in a distributed manner over a stream-processing platform. In this paper we show preliminary performance analysis of a Twitter trending algorithm when running over BlockMon, an open-source monitoring platform which we extended to run distributed data-analytics algorithms: we show that it performs up to 23.5x and 34.2x faster on BlockMon than on Storm and Apache S4 respectively, two emerging stream-processing platforms."
2473819,15258,122,A domain-specific approach to heterogeneous parallelism,2011,"Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases."
2524180,15258,23836,A Multi-core Parallel Branch-and-Bound Algorithm Using Factorial Number System,2014,"Many real-world problems in different industrial and economic fields are permutation combinatorial optimization problems. Solving to optimality large instances of these problems, such as flowshop problem, is a challenge for multi-core computing. This paper proposes a multi-threaded factoradic-based branch-and-bound algorithm to solve permutation combinatorial problems on multi-core processors. The factoradic, called also factorial number system, is a mixed radix numeral system adapted to numbering permutations. In this new parallel algorithm, the B&B is based on a matrix of integers instead of a pool of permutations, and work units exchanged between threads are intervals of factoradics instead of sets of nodes.Compared to a conventional pool-based approach, the obtained results on flowshop instances demonstrate that our new factoradic-based approach, on average, uses about 60 times less memory to store the pool of subproblems, generates about 1.3 times less page faults, waits about 7 times less time to synchronize the access to the pool, requires about 9 times less CPU time to manage this pool, and performs about 30,000 times less context switches."
2198665,15258,122,A methodology for creating fast wait-free data structures,2012,"Lock-freedom is a progress guarantee that ensures overall program progress. Wait-freedom is a stronger progress guarantee that ensures the progress of each thread in the program. While many practical lock-free algorithms exist, wait-free algorithms are typically inefficient and hardly used in practice. In this paper, we propose a methodology called  fast-path-slow-path  for creating efficient wait-free algorithms. The idea is to execute the efficient lock-free version most of the time and revert to the wait-free version only when things go wrong. The generality and effectiveness of this methodology is demonstrated by two examples. In this paper, we apply this idea to a recent construction of a wait-free queue, bringing the wait-free implementation to perform in practice as efficient as the lock-free implementation. In another work, the fast-path-slow-path methodology has been used for (dramatically) improving the performance of a wait-free linked-list."
792656,15258,122,The boat hull model: adapting the roofline model to enable performance prediction for parallel computing,2012,"Multi-core and many-core were already major trends for the past six years, and are expected to continue for the next decades. With these trends of parallel computing, it becomes increasingly difficult to decide on which architecture to run a given application.   In this work, we use an algorithm classification to predict performance  prior  to algorithm implementation. For this purpose, we modify the  roofline model  to include class information. In this way, we enable architectural choice through performance prediction prior to the development of architecture specific code. The new model, the  boat hull model , is demonstrated using a GPU as a target architecture. We show for 6 example algorithms that performance is predicted accurately without requiring code to be available."
127371,15258,20349,Recursively cautious congestion control,2014,"TCP's congestion control is deliberately cautious, avoiding network overloads by starting with a small initial window and then iteratively ramping up. As a result, it often takes flows several round-trip times to fully utilize the available bandwidth. In this paper we propose RC3, a technique to quickly take advantage of available capacity from the very first RTT. RC3 uses several levels of lower priority service and a modified TCP behavior to achieve near-optimal throughputs while preserving TCP-friendliness and fairness. We implement RC3 in the Linux kernel and in NS-3. In common wide-area scenarios, RC3 results in over 40% reduction in average flow completion times, with strongest improvements - more than 70% reduction in flow completion time - seen in medium to large sized (100KB - 3MB) flows."
1401307,15258,339,POSTER: TLS Proxies: Friend or Foe?,2014,"The use of TLS proxies to intercept encrypted traffic is controversial since the same mechanism can be used for both benevolent purposes, such as protecting against malware, and for malicious purposes, such as identity theft or warrantless government surveillance. To understand the prevalence and uses of these proxies, we build a TLS proxy measurement tool and deploy it via a Google AdWords campaign. We generate 2.9 million certificate tests and find that 1 in 250 TLS connections are proxied. The majority of these proxies appear to be benevolent, however we identify over 1,000 cases where three malware products are using this technology nefariously. We also find numerous instances of negligent and duplicitous behavior, some of which degrade security for users without their knowledge."
1311860,15258,343,Inaccurate spectrum databases?: public transit to its rescue!,2013,"Unlicensed, secondary users of TV whitespaces today rely on spectrum occupancy databases to determine what spectrum they can use for their communication needs. In this paper, we first show that such spectrum databases (that depend solely on propagation models as per guidelines of the FCC in the USA) can be quite inaccurate leading to under-utilization of spectrum. Next, we propose that these spectrum databases can be significantly augmented using opportunistic measurements when possible. Instead of incorporating primary detection functions in each secondary device, we propose to use vehicle-mounted spectrum sensors that collect and report measurements from the road, which can serve as useful anchor points to enhance existing propagation models.   We have currently deployed a version of our system on a single public transit bus traveling across Madison, WI, in the USA. Based on measurements collected at over 1 million locations across a 100 square-km area, we find commercial databases tend to over-predict the coverage of certain TV broadcasts, unnecessarily blocking the usage of whitespace spectrum over large area (up to 42% measured locations). We further propose a model-fitting approach that refines existing propagation models with measurements, reclaiming a substantial amount of wasted area (up to 33% measured locations)."
2180767,15258,293,Probe and pray: using UPnP for home network measurements,2012,"Network measurement practitioners increasingly focus their interest on understanding and debugging home networks. The Universal Plug and Play (UPnP) technology holds promise as a highly efficient way to collect and leverage measurement data and configuration settings available from UPnP-enabled devices found in home networks. Unfortunately, UPnP proves less available and reliable than one would hope. In this paper, we explore the usability of UPnP as a means to measure and characterize home networks. We use data from 120,000 homes, collected with the HomeNet Profiler and Netalyzr troubleshooting suites. Our results show that in the majority of homes we could not collect any UPnP data at all, and when we could, the results were frequently inaccurate or simply wrong. Whenever UPnP-supplied data proved accurate, however, we demonstrate that UPnP provides an array of useful measurement techniques for inferring home network traffic and losses, for identifying home gateway models with configuration or implementation issues, and for obtaining ground truth on access link capacity."
2455258,15258,343,No silver bullet: extending SDN to the data plane,2013,"The data plane is in a continuous state of flux. Every few months, researchers publish the design of a new high-performance queueing or scheduling scheme that runs inside the network fabric. Many such schemes have been queen for a day, only to be surpassed soon after as methods --- or evaluation metrics --- evolve.   The lesson, in our view: there will never be a conclusive victor to govern queue management and scheduling inside network hardware. We provide quantitative evidence by demonstrating bidirectional cyclic preferences among three popular contemporary AQM and scheduling configurations.   We argue that the way forward requires carefully extending Software-Defined Networking to control the fast-path scheduling and queueing behavior of a switch. To this end, we propose adding a small FPGA to switches. We have synthesized, placed, and routed hardware implementations of CoDel and RED. These schemes require only a few thousand FPGA slices to run at 10 Gbps or more --- a minuscule fraction of current low-end FPGAs --- demonstrating the feasibility and economy of our approach."
577551,15258,293,Volume-Based Transit Pricing: Is 95 the Right Percentile?,2014,"The 95 th percentile billing mechanism has been an industry de facto standard for transit providers for well over a decade. While the simplicity of the scheme makes it attractive as a billing mechanism, dramatic evolution in traffic patterns, associated interconnection practices and industry structure over the last two decades motivates an obvious question: is it still appropriate? In this paper, we evaluate the 95 th percentile pricing mechanism from the perspective of transit providers, using a decade of traffic statistics from SWITCH (a large research/academic network), and more recent traffic statistics from 3 Internet Exchange Points (IXPs). We find that over time, heavy-inbound and heavy-hitter networks are able to achieve a lower 95th-to-average ratio than heavy-inbound and moderate-hitter networks, possibly due to their ability to better manage their traffic profile. The 95 th percentile traffic volume also does not necessarily reflect the cost burden to the provider, motivating our exploration of an alternative metric that better captures the costs imposed on a network. We define the provision ratio for a customer, which captures its contribution to the provider's peak load."
17838,15258,293,Detecting Intentional Packet Drops on the Internet via TCP/IP Side Channels,2014,"We describe a method for remotely detecting intentional packet drops on the Internet via side channel inferences. That is, given two arbitrary IP addresses on the Internet that meet some simple requirements, our proposed technique can discover packet drops (e.g., due to censorship) between the two remote machines, as well as infer in which direction the packet drops are occurring. The only major requirements for our approach are a client with a global IP Identifier (IPID) and a target server with an open port. We require no special access to the client or server. Our method is robust to noise because we apply intervention analysis based on an autoregressive-moving-average (ARMA) model. In a measurement study using our method featuring clients from multiple continents, we observed that, of all measured client connections to Tor directory servers that were censored, 98% of those were from China, and only 0.63% of measured client connections from China to Tor directory servers were not censored. This is congruent with current understandings about global Internet censorship, leading us to conclude that our method is effective."
1650522,15258,343,Using Video-Based Measurements to Generate a Real-Time Network Traffic Map,2014,"We envision a real-time network traffic map for the Internet, where each network link is annotated with its capacity and its current utilization, with an interface that networked applications can query to inform their control decisions. While this goal is simple to state, it has been out of our reach due to concerns over measurement overhead and coverage. Our insight is that the rise of Internet video and the availability of measurements from video players present an unprecedented opportunity to address these issues. We outline a preliminary roadmap to build on this opportunity to realize a global traffic map."
2365711,15258,122,Using hardware transactional memory to correct and simplify and readers-writer lock algorithm,2013,"Designing correct synchronization algorithms is notoriously difficult, as evidenced by a bug we have identified that has apparently gone unnoticed in a well-known synchronization algorithm for nearly two decades. We use hardware transactional memory (HTM) to construct a corrected version of the algorithm. This version is significantly simpler than the original and furthermore improves on it by eliminating usage constraints and reducing space requirements. Performance of the HTM-based algorithm is competitive with the original in normal conditions, but it does suffer somewhat under heavy contention. We successfully apply some optimizations to help close this gap, but we also find that they are incompatible with known techniques for improving progress properties. We discuss ways in which future HTM implementations may address these issues. Finally, although our focus is on how effectively HTM can correct and simplify the algorithm, we also suggest bug fixes and workarounds that do not depend on HTM."
75115,15258,293,Performance implications of unilateral enabling of IPv6,2013,"While some IPv6-enabled Web sites such as Google require an explicit opt-in by IPv6-enabled clients before serving them over the IPv6 protocol, we quantify performance implications of unilateral enabling of IPv6 by a Web site. In this approach, the Web site enables dual-stack IPv4/6 support and resolves DNS queries for IPv6 addresses with the IPv6 addresses of its Web servers, and legacy DNS queries for IPv4 addresses with the IPv4 addresses. Thus, clients indicating the willingness to communicate over IPv6 are allowed to immediately do so. Although the existence of the end-to-end IPv6 path between these clients and the Web site is currently unlikely, we found no evidence of performance penalty (subject to 1sec. granularity of our measurement) for this unilateral IPv6 adoption. We hope our findings will help facilitate the IPv6 transition and prove useful to the sites considering their IPv6 migration strategy."
1990595,15258,122,GRace: a low-overhead mechanism for detecting data races in GPU programs,2011,"In recent years, GPUs have emerged as an extremely cost-effective means for achieving high performance. Many application developers, including those with no prior parallel programming experience, are now trying to scale their applications using GPUs. While languages like CUDA and OpenCL have eased GPU programming for non-graphical applications, they are still explicitly parallel languages. All parallel programmers, particularly the novices, need tools that can help ensuring the correctness of their programs. Like any multithreaded environment, data races on GPUs can severely affect the program reliability. Thus, tool support for detecting race conditions can significantly benefit GPU application developers. Existing approaches for detecting data races on CPUs or GPUs have one or more of the following limitations: 1) being illsuited for handling non-lock synchronization primitives on GPUs; 2) lacking of scalability due to the state explosion problem; 3) reporting many false positives because of simplified modeling; and/or 4) incurring prohibitive runtime and space overhead. In this paper, we propose GRace, a new mechanism for detecting races in GPU programs that combines static analysis with a carefully designed dynamic checker for logging and analyzing information at runtime. Our design utilizes GPUs memory hierarchy to log runtime data accesses efficiently. To improve the performance, GRace leverages static analysis to reduce the number of statements that need to be instrumented. Additionally, by exploiting the knowledge of thread scheduling and the execution model in the underlying GPUs, GRace can accurately detect data races with no false positives reported. Based on the above idea, we have built a prototype of GRace with two schemes, i.e., GRace-stmt and GRace-addr, for NVIDIA GPUs. Both schemes are integrated with the same static analysis. We have evaluated GRace-stmt and GRace-addr with three data race bugs in three GPU kernel functions and also have compared them with the existing approach, referred to as B-tool. Our experimental results show that both schemes of GRace are effective in detecting all evaluated cases with no false positives, whereas Btool reports many false positives for one evaluated case. On the one hand, GRace-addr incurs low runtime overhead, i.e., 22-116%, and low space overhead, i.e., 9-18MB, for the evaluated kernels. On the other hand, GRace-stmt offers more help in diagnosing data races with larger overhead."
1782516,15258,339,Letting applications operate through attacks launched from compromised drivers,2012,"With the rapid prevalence of E-Commerce, MMO and social networking, the demand on service availability and continuity is increasingly crucial to production servers or data centers. Hence, software failure recovery systems are thoroughly studied. However, stimulated by significant commercial revenue, attackers begin trying to evade the existing auditing/recovering techniques by manipulating the service applications through the compromised kernel. Nowadays, device drivers account for more than half (could be as high as 70%) of the source code of most commodity operating system kernels, with much more exploitable vulnerabilities than other kernel code [2]. This renders the attackers the opportunity to exploit the driver vulnerability and leverage the kernel privilege of the compromised drivers. With the unrestricted access to the whole (kernel/user) memory address space, successful attackers can launch denial of service attack by incurring driver fault, manipulating critical code/data or even the metadata of the service application process."
712992,15258,343,EONA: Experience-Oriented Network Architecture,2014,"There is a growing recognition among researchers, industry practitioners, and service providers of the need to optimize user-perceived application experience. Network infrastructure owners (i.e., ISPs) have traditionally been left out of this equation, leading to repeated tussles between content providers and ISPs. In parallel, application providers have to deploy complex workarounds that reverse engineer the network's impact on application-level metrics. In this work, we make the case for EONA, a new network paradigm where application providers and network providers can collaborate meaningfully to improve application experience. We observe a confluence of technology trends that are enablers for EONA: the ability to collect large volumes of client-side application measurements, the emergence of novel big data platforms for real-time analytics, and new control plane capabilities for ISPs (e.g., SDN, IXPs, NFV). We highlight the challenges and opportunities in designing suitable EONA interfaces between infrastructure and application providers and EONA-enhanced control loops that leverage these interfaces to optimize user experience."
2527645,15258,507,DynamicCloudSim: simulating heterogeneity in computational clouds,2013,"Simulation has become a commonly employed first step in evaluating novel approaches towards resource allocation and task scheduling on distributed architectures. However, existing simulators fall short in their modeling of the instability common to shared computational infrastructure, such as public clouds. In this work, we present DynamicCloudSim which extends the popular simulation toolkit CloudSim with several factors of instability, including inhomogeneity and dynamic changes of performance at runtime as well as failures during task execution. As a use case and validation of the introduced functionality, we simulate the impact of instability on scientific workflow scheduling by assessing and comparing the performance of four schedulers in the course of several experiments. Results indicate that our model seems to adequately capture the most important aspects of cloud performance instability, though a validation on real hardware is still pending. The source code of DynamicCloudSim and the examined schedulers is available at https://code.google.com/p/dynamiccloudsim/."
2033302,15258,122,Well-structured futures and cache locality,2014,"In  fork-join parallelism , a sequential program is split into a directed acyclic graph of tasks linked by directed dependency edges, and the tasks are executed, possibly in parallel, in an order consistent with their dependencies. A popular and effective way to extend fork-join parallelism is to allow threads to create  {futures . A thread creates a future to hold the results of a computation, which may or may not be executed in parallel. That result is returned when some thread  touches  that future, blocking if necessary until the result is ready. Recent research has shown that while futures can, of course, enhance parallelism in a structured way, they can have a deleterious effect on cache locality. In the worst case, futures can incur Ω(P T∞ + t T∞) deviations, which implies Ω(C P T∞ + C t T∞) additional cache misses, where C is the number of cache lines, P is the number of processors, t is the number of touches, and T∞ is the  computation span . Since cache locality has a large impact on software performance on modern multicores, this result is troubling.   In this paper, however, we show that if futures are used in a simple, disciplined way, then the situation is much better: if each future is touched only once, either by the thread that created it, or by a later descendant of the thread that created it, then parallel executions with work stealing can incur at most O(C P T 2 ∞) additional cache misses, a substantial improvement. This structured use of futures is characteristic of many (but not all) parallel applications."
257224,15258,507,Hybrid HBase: leveraging flash SSDs to improve cost per throughput of HBase,2012,"Column-oriented data stores, such as BigTable and HBase, have successfully paved the way for managing large key-value datasets with random accesses. At the same time, the declining cost of flash SSDs have enabled their use in several applications including large databases. In this paper, we explore the feasibility of introducing flash SSDs for HBase. Since storing the entire user data is infeasible due to impractically large costs, we perform a qualitative and supporting quantitative assessment of the implications of storing the system components of HBase in flash SSDs. Our proposed Hybrid HBase system performs 1.5-2 times better than a complete disk-based system on the YCSB benchmark workloads. This increase in performance comes at a relatively low cost overhead. Consequently, Hybrid HBase exhibits the best performance in terms of cost per throughput when compared to either a complete HDD-based or a complete flash SSD-based system."
1859429,15258,339,DCast: sustaining collaboration in overlay multicast despite rational collusion,2012,"A key challenge in large-scale collaborative distributed systems is to properly incentivize the rational/selfish users so that they will properly collaborate. Within such a context, this paper focuses on designing incentive mechanisms for overlay multicast systems. A key limitation shared by existing proposals on the problem is that they are no longer able to provide proper incentives and thus will collapse when rational users collude or launch sybil attacks.   This work explicitly aims to properly sustain collaboration despite collusion and sybil attacks by rational users. To this end, we propose a new decentralized DCast multicast protocol that uses a novel mechanism with debt-links and circulating debts. We formally prove that the protocol offers a novel concept of safety-net guarantee: A user running the protocol will always obtain a reasonably good utility despite the deviation of any number of rational users that potentially collude or launch sybil attacks. Our prototyping as well as simulation demonstrates the feasibility and safety-net guarantee of our design in practice."
2914529,15258,8228,Experimental demonstration of content sharing on service-oriented optical internet,2012,"Increasing data centers need deep cooperation with optical backbone. In this paper, we choose video content distribution as the application to drive optical network directly. A service-oriented optical internet prototype network is built up, which can establish a dynamic wavelength path for video content block downloading. The experimental demonstration of the novel control scheme is presented in this work. Results show that optical network can serve application layer with quickly dynamic connections."
157097,15258,293,Geolocating IP addresses in cellular data networks,2012,"Smartphones connected to cellular networks are increasingly being used to access Internet-based services. Using data collected from smartphones running a popular location-based application, we examine IP address allocation in cellular data networks, with emphasis on understanding the applicability of IP-based geolocation techniques. Our dataset has GPS-based location data for approximately 29,000 cellular network assigned IP addresses in 50 different countries. Using this dataset, we provide insights into the global deployment of cellular networks. For instance, we find that Network Address Translation (NAT) is commonplace in cellular networks. We also find several instances of service differentiation with operators assigning public IP addresses to some devices and private IP addresses to other devices. We also evaluate the error of geolocation databases when determining the position of the smartphones, and find that the error is 100km or more for approximately 70% of our measurements. Further, there is potential for errors at the scale of inter-country and inter-continent distances. We believe this dataset may be of value to the research community, and provide a subset of the dataset to the community."
835573,15258,343,Bandwidth on demand for inter-data center communication,2011,"Cloud service providers use replication across geographically distributed data centers to improve end-to-end performance as well as to offer high reliability under failures. Content replication often involves the transfer of huge data sets over the wide area network and demands high backbone transport capacity. In this paper, we discuss how a  G lobally  R econfigurable  I ntelligent  P hotonic  N etwork (GRIPhoN) between data centers could improve operational flexibility for cloud service providers. The proposed GRIPhoN architecture is an extension of earlier work [34] and can provide a bandwidth-on-demand service ranging from low data rates (e.g., 1 Gbps) to high data rates (e.g., 10-40 Gbps). The inter-data center communication network which is currently statically provisioned could be dynamically configured based on demand. Today's backbone optical networks can take several weeks to provision a customer's private line connection. GRIPhoN would enable cloud operators to dynamically set up and tear down their connections (sub-wavelength or wavelength rates) within a few minutes. GRIPhoN also offers cost-effective restoration capabilities at wavelength rates and automated bridge-and-roll of private line connections to minimize the impact of planned maintenance activities."
946933,15258,339,Fides: selectively hardening software application components against kernel-level or process-level malware,2012,"Protecting commodity operating systems against software exploits is known to be challenging, because of their sheer size. The same goes for key software applications such as web browsers or mail clients. As a consequence, a significant fraction of internet-connected computers is infected with malware.   To mitigate this threat, we propose a combined approach of (1) a run-time security architecture that can efficiently protect fine-grained software modules executing on a standard operating system, and (2) a compiler that compiles standard C source code modules to such protected binary modules.   The offered security guarantees are significant: relying on a TCB of only a few thousand lines of code, we show that the power of arbitrary kernel-level or process-level malware is reduced to interacting with the module through the module's public API. With a proper API design and implementation, modules are fully protected.   The run-time architecture can be loaded on demand and only incurs performance overhead when it is loaded. Benchmarks show that, once loaded, it incurs a 3.22% system-wide performance cost. For applications that make intensive use of protected modules, and hence benefit most of the security guarantees provided, the performance cost is up to 14%."
2327633,15258,122,Programming the cloud,2011,"Client + cloud computing is a disruptive, new computing platform, combining diverse client devices -- PCs, smartphones, sensors, and single-function and embedded devices -- with the unlimited, on-demand computation and data storage offered by cloud computing services such as Amazon's AWS or Microsoft's Windows Azure. As with every advance in computing, programming is a fundamental challenge as client + cloud computing combines many difficult aspects of software development. Systems built for this world are inherently parallel and distributed, run on unreliable hardware, and must be continually available -- a challenging programming model for even the most skilled programmers. How then do ordinary programmers develop software for the Cloud? This talk presents one answer, Orleans, a software framework for building client + cloud applications. Orleans encourages use of simple concurrency patterns that are easy to understand and implement correctly, building on an actor-like model with declarative specification of persistence, replication, and consistency and using lightweight transactions to support the development of reliable and scalable client + cloud software."
160445,15258,293,What SNMP data can tell us about edge-to-edge network performance,2013,"With the high speeds of today's networks, monitoring information is most of the time either summarized or sampled. This policy is even more profound in network backbones, where aggregation of data from several sources and in very high speeds is often observed. The Simple Network Management Protocol (SNMP) [5] is widely used to provide aggregated link usage data from network components. These data, even without a great amount of detail, provide a valuable source for network administrators, aiding decisions about network routing, provisioning and configuration. SNMP data are simple to collect and maintain, providing a low disk space for historical network usage log."
1892916,15258,507,MITRA: byzantine fault-tolerant middleware for transaction processing on replicated databases,2014,"Replication is often considered a cost-effective solution for building dependable systems with off-the-shelf hardware. Replication software is usually designed to tolerate crash faults, but Byzantine (or arbitrary) faults such as software bugs are well-known to affect transactional database management systems (DBMSs) as many other classes of software. Despite the maturity of replication technology, Byzantine fault-tolerant replication of databases remains a challenging problem. The paper presents MITRA, a middleware for replicating DBMSs and making them tolerant to Byzantine faults. MITRA is designed to offer transparent replication of off-theshelf DBMSs with replicas from different vendors."
2036792,15258,122,Data-only flattening for nested data parallelism,2013,"Data parallelism has proven to be an effective technique for high-level programming of a certain class of parallel applications, but it is not well suited to irregular parallel computations. Blelloch and others proposed  nested data parallelism  (NDP) as a language mechanism for programming irregular parallel applications in a declarative data-parallel style. The key to this approach is a compiler transformation that flattens the NDP computation and data structures into a form that can be executed efficiently on a wide-vector SIMD architecture. Unfortunately, this technique is ill suited to execution on today's multicore machines. We present a new technique, called  data-only flattening , for the compilation of NDP, which is suitable for multicore architectures. Data-only flattening transforms nested data structures in order to expose programs to various optimizations while leaving control structures intact. We present a formal semantics of data-only flattening in a core language with a rewriting system. We demonstrate the effectiveness of this technique in the Parallel ML implementation and we report encouraging experimental results across various benchmark applications."
1797954,15258,339,LogGC: garbage collecting audit log,2013,"System-level audit logs capture the interactions between applications and the runtime environment. They are highly valuable for forensic analysis that aims to identify the root cause of an attack, which may occur long ago, or to determine the ramifications of an attack for recovery from it. A key challenge of audit log-based forensics in practice is the sheer size of the log files generated, which could grow at a rate of Gigabytes per day. In this paper, we propose LogGC, an audit logging system with garbage collection (GC) capability. We identify and overcome the unique challenges of garbage collection in the context of computer forensic analysis, which makes LogGC different from traditional memory GC techniques. We also develop techniques that instrument user applications at a small number of selected places to emit additional system events so that we can substantially reduce the false dependences between system events to improve GC effectiveness. Our results show that LogGC can reduce audit log size by 14 times for regular user systems and 37 times for server systems, without affecting the accuracy of forensic analysis."
748744,15258,122,OpenMP-style parallelism in data-centered multicore computing with R,2012,"R 1  is a domain specific language widely used for data analysis by the statistics community as well as by researchers in finance, biology, social sciences, and many other disciplines. As R programs are linked to input data, the exponential growth of available data makes high-performance computing with R imperative. To ease the process of writing parallel programs in R, code transformation from a sequential program to a parallel version would bring much convenience to R users. In this paper, we present our work in semi-automatic parallelization of R codes with user-added OpenMP-style pragmas. While such pragmas are used at the frontend, we take advantage of multiple parallel backends with different R packages. We provide flexibility for importing parallelism with plug-in components, impose built-in MapReduce for data processing, and also maintain code reusability. We illustrate the advantage of the on-the-fly mechanisms which can lead to significant applications in data-centered parallel computing."
1905638,15258,122,Detecting silent data corruption through data dynamic monitoring for scientific applications,2014,"Parallel programming has become one of the best ways to express scientific models that simulate a wide range of natural phenomena. These complex parallel codes are deployed and executed on large-scale parallel computers, making them important tools for scientific discovery. As supercomputers get faster and larger, the increasing number of components is leading to higher failure rates. In particular, the miniaturization of electronic components is expected to lead to a dramatic rise in soft errors and data corruption. Moreover, soft errors can corrupt data silently and generate large inaccuracies or wrong results at the end of the computation. In this paper we propose a novel technique to detect silent data corruption based on data monitoring. Using this technique, an application can learn the normal dynamics of its datasets, allowing it to quickly spot anomalies. We evaluate our technique with synthetic benchmarks and we show that our technique can detect up to 50% of injected errors while incurring only negligible overhead."
2135678,15258,122,Designing and auto-tuning parallel 3-D FFT for computation-communication overlap,2014,"This paper presents a method to design and auto-tune a new parallel 3-D FFT code using the non-blocking MPI all-to-all operation. We achieve high performance by optimizing computation-communication overlap. Our code performs fully asynchronous communication without any support from special hardware. We also improve cache performance through loop tiling. To cope with the complex trade-off regarding our optimization techniques, we parameterize our code and auto-tune the parameters efficiently in a large parameter space. Experimental results from two systems confirm that our code achieves a speedup of up to 1.76x over the FFTW library."
1587333,15258,343,Data-driven network connectivity,2011,"Routing on the Internet combines  data plane  mechanisms for forwarding traffic with  control plane  protocols for guaranteeing connectivity and optimizing routes ( e.g ., shortest-paths and load distribution). We propose  data-driven connectivity  (DDC), a new routing approach that achieves the fundamental connectivity guarantees in the data plane rather than the control plane, while keeping the more complex requirements of route optimization in the control plane. DDC enables faster recovery from failures and easier implementation of control plane optimization."
2182642,15258,122,CSX: an extended compression format for spmv on shared memory systems,2011,"The Sparse Matrix-Vector multiplication (SpMV) kernel scales poorly on shared memory systems with multiple processing units due to the streaming nature of its data access pattern. Previous research has demonstrated that an effective strategy to improve the kernel's performance is to drastically reduce the data volume involved in the computations. Since the storage formats for sparse matrices include metadata describing the structure of non-zero elements within the matrix, we propose a generalized approach to compress metadata by exploiting substructures within the matrix. We call the proposed storage format Compressed Sparse eXtended (CSX). In our implementation we employ runtime code generation to construct specialized SpMV routines for each matrix. Experimental evaluation on two shared memory systems for 15 sparse matrices demonstrates significant performance gains as the number of participating cores increases. Regarding the cost of CSX construction, we propose several strategies which trade performance for preprocessing cost making CSX applicable both to online and offline preprocessing."
2157689,15258,8228,Dynamic Optimization Solution for Green Service Migration in Data Centres,2011,"While many aspects of the Future Internet are uncertain, one thing that is clear is that service demand will continue to rise. Also, advances in mobile devices and service technology will almost certainly cause service usage patterns to vary considerably. Another issue that the Future Internet community must be acutely aware of is the huge movement towards more sustainable forms of computing and communications technology. With the recent attention that has been put on IT energy consumption (data-centres in particular), all computing and communications systems need to consider their environmental impact from the outset. With that in mind, we propose a solution for determining the optimal placement of services in data-centre network, in order to maximize the overall renewable energy usage and minimize the cooling energy consumption. We then perform a series of experiments in order to evaluate our solution, incorporating dynamic service request profiles and actual weather and renewable energy production values."
2296432,15258,122,S: a scripting language for high-performance RESTful web services,2012,"There is an urgent need for novel programming abstractions to leverage the parallelism in modern multicore machines. We introduce  S , a new domain-specific language targeting the server-side scripting of high-performance RESTful Web services.  S  promotes an innovative programming model based on explicit (control-flow) and implicit (process-level) parallelism control, allowing the service developer to specify which portions of the control-flow should be executed in parallel. For each service, the choice of the best level of parallelism is left to the runtime system. We assess performance and scalability by implementing two non-trivial composite Web services in  S . Experiments show that S-based Web services can handle thousands of concurrent client requests on a modern multicore machine."
1729171,15258,208,Uno: A Privacy-Aware Distributed Storage and Replication Middleware for Heterogeneous Computing Platforms,2013,"Cloud computing is an emerging research area that has drawn considerable interest in recent years. However, the current infrastructure raises significant concerns about how to protect users' privacy, in part due to that users are storing their data in the cloud vendors' servers. In this paper, we address this challenge by proposing and implementing a novel middleware, called Uno, which separates the storage of physical data and their associated metadata. In our design, users' physical data are stored locally on those devices under a user's full control, while their metadata can be uploaded to the commercial cloud. To ensure the reliability of users' data, we develop a novel fine-grained file replication algorithm that exploits both data access patterns and device state patterns. Based on a quantitative analysis of the data set from Rice University [1], this algorithm replicates data intelligently in different time slots, so that it can not only significantly improve data availability, but also achieve a satisfactory performance on load balancing and storage diversification. We implement the Uno system on a heterogeneous testbed composed of both host servers and mobile devices, and demonstrate the programmability of Uno through implementation and evaluation of two sample applications, Uno@Home and Uno@Sense."
2333626,15258,122,Communication avoiding successive band reduction,2012,"The running time of an algorithm depends on both arithmetic and communication (i.e., data movement) costs, and the relative costs of communication are growing over time. In this work, we present both theoretical and practical results for tridiagonalizing a symmetric band matrix: we present an algorithm that asymptotically reduces communication, and we show that it indeed performs well in practice.   The tridiagonalization of a symmetric band matrix is a key kernel in solving the symmetric eigenvalue problem for both full and band matrices. In order to preserve sparsity, tridiagonalization routines use annihilate-and-chase procedures that previously have suffered from poor data locality. We improve data locality by reorganizing the computation, asymptotically reducing communication costs compared to existing algorithms. Our sequential implementation demonstrates that avoiding communication improves runtime even at the expense of extra arithmetic: we observe a 2x speedup over Intel MKL while doing 43% more floating point operations.   Our parallel implementation targets shared-memory multicore platforms. It uses pipelined parallelism and a static scheduler while retaining the locality properties of the sequential algorithm. Due to lightweight synchronization and effective data reuse, we see 9.5x scaling over our serial code and up to 6x speedup over the PLASMA library, comparing parallel performance on a ten-core processor."
2497238,15258,122,Automatic datatype generation and optimization,2012,"Many high performance applications spend considerable time packing noncontiguous data into contiguous communication buffers. MPI Datatypes provide an alternative by describing noncontiguous data layouts. This allows sophisticated hardware to retrieve data directly from application data structures. However, packing codes in real-world applications are often complex and specifying equivalent datatypes is difficult, time-consuming, and error prone. We present an algorithm that automates the transformation. We have implemented the algorithm in a tool that transforms packing code to MPI Datatypes, and evaluated it by transforming 90 packing codes from the NAS Parallel Benchmarks. The transformation allows easy porting of applications to new machines that benefit from datatypes, thus improving programmer productivity."
2170934,15258,8228,An Epidemic Model of Bit Torrent with Control,2011,"Despite its existing incentives for leecher cooperation, BitTorrent file sharing fundamentally relies on the presence of seeder peers. Seeder peers essentially operate outside the BitTorrent incentives, with two caveats: slow downlinks lead to increased numbers of ``temporary seeders (who left their console, but will terminate their seeder role when they return), and the copyright liability boon that file segmentation offers for permanent seeders. Using a simple epidemic model for a two-segment BitTorrent swarm, we focus on the BitTorrent rule to disseminate the (locally) rarest segments first. With our model, we show that the rarest-segment first rule minimizes transition time to seeder (complete file acquisition) and equalizes the segment populations in steady-state. We discuss how alternative dissemination rules may {\em beneficially increase} file acquisition times causing leechers to remain in the system longer (particularly as temporary seeders). The result is that leechers are further enticed to cooperate. This eliminates the threat of extinction of rare segments which is prevented by the needed presence of permanent seeders. Our model allows us to study the corresponding trade-offs between performance improvement, load on permanent seeders, and content availability, which we leave for future work."
462039,15258,374,Security of Patched DNS,2012,"In spite of the availability of DNSSEC, which protects against cache poisoning even by MitM attackers, many caching DNS resolvers still rely for their security against poisoning on merely validating that DNS responses contain some 'unpredictable' values, copied from the re- quest. These values include the 16 bit identifier field, and other fields, randomised and validated by different 'patches' to DNS. We investigate the prominent patches, and show how attackers can circumvent all of them, namely: - We show how attackers can circumvent source port randomisation, in the (common) case where the resolver connects to the Internet via different NAT devices. - We show how attackers can circumvent IP address randomisation, using some (standard-conforming) resolvers. - We show how attackers can circumvent query randomisation, including both randomisation by prepending a random nonce and case randomisation (0x20 encoding). We present countermeasures preventing our attacks; however, we believe that our attacks provide additional motivation for adoption of DNSSEC (or other MitM-secure defenses)."
2333920,15258,8228,Avoiding Speedup from Bandwidth Overhead in a Practical Output-Queued Packet Switch,2011,"This paper adopts a time-slotted and synchronous output-queued (SS-OQ) switch, which avoids memory speedup through the use of dedicated lines connecting inputs to outputs, to show that the performance of an S-OQ switch approaches that of an ideal OQ switch, or asynchronous OQ (A-OQ) switch. An A-OQ switch forwards packets to their destined outputs at arrival but it is costly to implement as immediate packet forwarding requires very high-speed hardware to identify the destination output and memory synchronization at the outputs. The dedicated lines of the SS-OQ switch induce the use of virtual input queues (VIQs) at the outputs, and time slotting requires the use of segmentation queues at the inputs. The segmentation of variable-length IP packets into fixed length cells causes transmission overhead that can be compensated with additional but undesirable speedup. However, segmentation queues can also be used for packet concatenation to reduce transmission overhead. This paper evaluates the improvement of bandwidth utilization in the concatenating SS-OQ (CS-OQ) switch through packet concatenation and segment length selection to decrease additional speedup needed to overcome the transmission overhead. The presented results show that a suitable segmentation length can be combined with packet concatenation to pair up the performance of the CS-OQ switch to that of an A-OQ switch."
187614,15258,293,Nightlights: Entropy-Based Metrics for Classifying Darkspace Traffic Patterns,2014,"An IP darkspace is a globally routed IP address space with no active hosts. All traffic destined to darkspace addresses is unsolicited and often originates from network scanning or attacks. A sudden increases of different types of darkspace traffic can serve as indicator of new vulnerabilities, misconfigurations or large scale attacks. In our analysis we take advantage of the fact that darkspace traffic typically originates from processes that use randomly chosen addresses or ports (e.g. scanning) or target a specific address or port (e.g. DDoS, worm spreading). These behaviors induce a concentration or dispersion in feature distributions of the resulting traffic aggregate and can be distinguished using entropy as a compact representation. Its lightweight, unambiguous, and privacy-compatible character makes entropy a suitable metric that can facilitate early warning capabilities, operational information exchange among network operators, and comparison of analysis results among a network of distributed IP darkspaces."
913325,15258,339,Why eve and mallory (also) love webmasters: a study on the root causes of SSL misconfigurations,2014,"Previous research showed that the SSL infrastructure is a fragile system: X.509 certificate validation fails for a non-trivial number of HTTPS-enabled websites resulting in SSL warning messages presented to users. Studies revealed that warning messages do not provide easy-to-understand information or are ignored by webbrowser users. SSL warning messages are a critical component in the HTTPS infrastructure and many attempts have been made to improve these warning messages. However, an important question has not received sufficient attention yet: Why do webmasters (deliberately) deploy non-validating, security-critical X.509 certificates on publicly available websites? In this paper, we conduct the first study with webmasters operating non-validating X.509 certificates to understand their motives behind deploying those certificates. We extracted the non-validating certificates from Google's webcrawler body of X.509 certificates, informed webmasters about the problem with the X.509 certificate configuration on their website and invited a random sample of the respective webmasters to participate in our study. 755 webmasters participated, allowing us insight into their motives. While one third of them admitted to having misconfigured their webserver accidentally, two thirds of them gave reasons for deliberately using a non-validating X.509 certificate."
1865972,15258,343,Having your cake and eating it too: routing security with privacy protections,2011,"Internet Service Providers typically do not reveal details of their interdomain routing policies due to security concerns, or for commercial or legal reasons. As a result, it is difficult to hold ISPs accountable for their contractual agreements. Existing solutions can check basic properties, e.g., whether route announcements correspond to valid routes, but they do not verify how these routes were chosen. In essence, today's Internet forces us to choose between per-AS privacy and verifiability.   In this paper, we argue that making this difficult tradeoff is unnecessary. We propose  private and verifiable routing  (PVR), a technique that enables ISPs to check whether their neighbors are fulfilling their contractual promises to them, and to obtain evidence of any violations,  without  disclosing information that the routing protocol does not already reveal. As initial evidence that PVR is feasible, we sketch a PVR system that can verify some simple BGP policies. We conclude by highlighting several research challenges as future work."
138730,15258,293,Re-wiring activity of malicious networks,2012,"This paper studies the AS-level re-wiring dynamics (changes in the connectivity) of malicious networks. Anecdotal evidence suggests that some malicious ASes that are primarily involved in nefarious activities on the Internet, were sequentially de-peered by providers before their final cut-off (as occurred in the well-publicized cases of Atrivo/Intercage). We present the first systematic study of the re-wiring dynamics of malicious ASes. We tracked the ASes that were listed by Hostexploit over the last two years and compared their AS-level re-wiring dynamics with non-reported ASes. Using a publicly available dataset of Customer-Provider (CP) relations in the Internet's AS graph, we studied how interconnection between autonomous systems evolves, both for ASes that provide connectivity for attackers and ASes that were not reported as malicious. We find that malicious networks are more aggressive both in forming links with providers and changing their upstream connectivity than other ASes. Our results indicate that the re-wiring dynamics of the networks that host attacks are stable over time, despite the evolving nature of the attacks themselves, which suggests that existing defense mechanisms could benefit from incorporating these features."
885158,15258,343,FUBAR: Flow Utility Based Routing,2014,"We present FUBAR, a system that reduces congestion and maximizes the utility of the entire network by installing new routes and changing the traffic load on existing ones. FUBAR works offline to periodically adjust the distribution of traffic on paths. It requires neither changes to end hosts nor precise prior knowledge of the traffic matrix. We demonstrate that even in the presence of traffic from all network devices to all other devices, FUBAR can optimize a real-world core-level network in a matter of minutes."
1615341,15258,390,Blind deconvolution of 3D data in wide field fluorescence microscopy,2012,In this paper we propose a blind deconvolution algorithm for wide field fluorescence microscopy. The 3D PSF is modeled after a parametrized pupil function. The PSF parameters are estimated jointly with the object in a maximum a posteriori framework. We illustrate the performances of our algorithm on experimental data and show significant resolution improvement notably along the depth. Quantitative measurements on images of calibration beads demonstrate the benefits of blind deconvolution both in terms of contrast and resolution compared to non-blind deconvolution using a theoretical PSF.
1891854,15258,339,PixelVault: Using GPUs for Securing Cryptographic Operations,2014,"Protecting the confidentiality of cryptographic keys in the event of partial or full system compromise is crucial for containing the impact of attacks. The Heartbleed vulnerability of April 2014, which allowed the remote leakage of secret keys from HTTPS web servers, is an indicative example. In this paper we present PixelVault, a system for keeping cryptographic keys and carrying out cryptographic operations exclusively on the GPU, which allows it to protect secret keys from leakage even in the event of full system compromise. This is possible by exposing secret keys only in GPU registers, keeping PixelVault's critical code in the GPU instruction cache, and preventing any access to both of them from the host. Due to the non-preemptive execution mode of the GPU, an adversary that has full control of the host cannot tamper with PixelVault's GPU code, but only terminate it, in which case all sensitive data is lost. We have implemented a PixelVault-enabled version of the OpenSSL library that allows the protection of existing applications with minimal modifications. Based on the results of our evaluation, PixelVault not only provides secure key storage using commodity hardware, but also significantly speeds up the processing throughput of cryptographic operations for server applications."
1166469,15258,369,Evaluation of Efficient Modes of Operation of GSM/GPRS Modules for M2M Communications,2013,"The field of machine-to-machine (M2M) communications has gained wide popularity and is steadily growing. This paper studies the feasibility of using the Global System for Mobile Communications and in particular the General Packet Radio Service (GPRS) for a low data rate long- lasting battery-powered operation of M2M devices. A model is introduced to estimate the power consumption of a GPRS connection. It allows the identification and evaluation of optimizations of the data transmission procedures. Two M2M modes of GPRS operation are introduced. For applications with frequent transmissions, an Always- on-mode turns out to be most reasonable. For infrequent transmissions, e.g., one transmission every 2 hours, an On/off-mode reduces the power consumption of M2M devices by 93% as compared to the Always-on-mode. With a 3-cell battery providing 25.9 Wh of energy and considering only the power consumption of the communication module, a battery lifetime of up to 5 years is feasible. Measurements show that usually 40% of the energy spent for a short data transmission is wasted by one particular GPRS procedure called non-DRX period. Avoiding this saves up to 35% of total average power, depending on the rate of data transmissions."
1058335,15258,422,Streamed approximate counting of distinct elements: beating optimal batch methods,2014,"Counting the number of distinct elements in a large dataset is a common task in web applications and databases. This problem is difficult in limited memory settings where storing a large hash table table is intractable. This paper advances the state of the art in probabilistic methods for estimating the number of distinct elements in a streaming setting New streaming algorithms are given that provably beat the optimal errors for Min-count and HyperLogLog while using the same sketch.   This paper also contributes to the understanding and theory of probabilistic cardinality estimation introducing the concept of an area cutting process and the martingale estimator. These ideas lead to theoretical analyses of both old and new sketches and estimators and show the new estimators are optimal for several streaming settings while also providing accurate error bounds that match those obtained via simulation. Furthermore, the area cutting process provides a geometric intuition behind all methods for counting distinct elements which are not affected by duplicates. This intuition leads to a new sketch, Discrete Max-count, and the analysis of a class of sketches, self-similar area cutting decompositions that have attractive properties and unbiased estimators for both streaming and non-streaming settings.   Together, these contributions lead to multi-faceted advances in sketch construction, cardinality and error estimation, the theory, and intuition for the problem of approximate counting of distinct elements for both the streaming and non-streaming cases."
2178127,15258,122,Array dataflow analysis for polyhedral X10 programs,2013,"This paper addresses the static analysis of an important class of X10 programs, namely those with finish/async parallelism, and affine loops and array reference structure as in the polyhedral model. For such programs our analysis can certify whenever a program is deterministic or flags races.   Our key contributions are (i) adaptation of array dataflow analysis from the polyhedral model to programs with finish/async parallelism, and (ii) use of the array dataflow analysis result to certify determinacy. We distinguish our work from previous approaches by combining the precise statement instance-wise and array element-wise analysis capability of the polyhedral model with finish/async programs that are more expressive than doall parallelism commonly considered in the polyhedral literature. We show that our approach is exact (no false negative/positives) and more precise than previous approaches, but is limited to programs that fit the polyhedral model."
1631358,15258,8228,A harmony-seeking firefly swarm to the periodic replacement of damaged sensors by a team of mobile robots,2012,"Mobile robots nowadays can assist wireless sensor networks (WSNs) in many jeopardizing scenarios that unexpectedly arise during their operational lifetime. We focus on an emerging kind of cooperative networking system in which a small team of robotic agents lies at a base station. Their mission is to service an already-deployed WSN by periodically replacing all damaged sensors in the field with passive, spare ones so as to preserve the existing network coverage. This novel application scenario is here baptized as “multiple-carrier coverage repair” (MC 2 R) and modeled as a new generalization of the vehicle routing problem. A hybrid metaheuristic algorithm is put forward to derive nearly-optimal sensor replacement trajectories for the robotic fleet in a short running time. The composite scheme relies on a swarm of artificial fireflies in which each individual follows the exploratory principles featured by Harmony Search. Infeasible candidate solutions are gradually driven into feasibility under the influence of a weak Pareto dominance relationship. A repair heuristic is finally applied to yield a full-blown solution. To the best of our knowledge, our scheme is the first one in literature that tackles MC 2 R instances. Empirical results indicate that promising solutions can be achieved in a limited time span."
1411451,15258,8228,A low-cost large-scale framework for cognitive radio routing protocols testing,2013,"Cognitive radio networks (CRNs) provide a solution to increase the utilization of the scarce radio frequency spectrum. Building testbeds for CRNs is one of the main challenges that can affect the wide deployability of such networks. In this paper, we present the design, implementation, and evaluation of CogFrame: a framework that facilitates the development of cost-efficient large-scale CRNs routing protocols testbeds. The framework allows the designers to focus on the CRNs routing protocols by abstracting the PHY and MAC layers while providing the necessary cross layer functionalities. CogFrame works with standard computers and WiFi cards to reduce the cost while allowing integration with other special hardware for more flexibility. In addition, CogFrame provides different modules for implementing and emulating complex scenarios such as regulatory authority policies, mobility management, and topology management. We benchmark the performance of CogFrame and compare it to standard ns-2 simulations and USRP2 implementations. In addition, we case study a location-aided routing protocol for CRNs using both CogFrame and ns-2 simulations. Our results highlight the ease of implementation, low-cost, and realistic replication of the CRN environment, showing the promise of CogFrame as a testbed for future CRNs implementations."
1983956,15258,339,ARMlock: Hardware-based Fault Isolation for ARM,2014,"Software fault isolation (SFI) is an effective mechanism to confine untrusted modules inside isolated domains to protect their host applications. Since its debut, researchers have proposed different SFI systems for many purposes such as safe execution of untrusted native browser plugins. However, most of these systems focus on the x86 architecture. Inrecent years, ARM has become the dominant architecture for mobile devices and gains in popularity in data centers.Hence there is a compellingneed for an efficient SFI system for the ARM architecture. Unfortunately, existing systems either have prohibitively high performance overhead or place various limitations on the memory layout and instructions of untrusted modules.   In this paper, we propose ARMlock, a hardware-based fault isolation for ARM. It uniquely leverages the memory domain support in ARM processors to create multiple sandboxes. Memory accesses by the untrusted module (including read, write, and execution) are strictly confined by the hardware,and instructions running inside the sandbox execute at the same speed as those outside it. ARMlock imposes virtually no structural constraints on untrusted modules. For example, they can use self-modifying code, receive exceptions, and make system calls. Moreover, system calls can be interposed by ARMlock to enforce the policies set by the host. We have implemented a prototype of ARMlock for Linux that supports the popular ARMv6 and ARMv7 sub-architecture. Our security assessment and performance measurement show that ARMlock is practical, effective, and efficient."
2228507,15258,343,Consistent updates for software-defined networks: change you can believe in!,2011,"Configuration changes are a common source of instability in networks, leading to broken connectivity, forwarding loops, and access control violations. Even when the initial and final states of the network are correct, the update process often steps through intermediate states with incorrect behaviors. These problems have been recognized in the context of specific protocols, leading to a number of point solutions. However, a piecemeal attack on this fundamental problem, while pragmatic in the short term, is unlikely to lead to significant long-term progress.   Software-Defined Networking (SDN) provides an exciting opportunity to do better. Because SDN is a clean-slate platform, we can build general, reusable abstractions for network updates that come with strong semantic guarantees. We believe SDN desperately needs such abstractions to make programs simpler to design, more reliable, and easier to validate using automated tools. Moreover, we believe these abstractions should be provided by a runtime system, shielding the programmer from these concerns. We propose two simple, canonical, and effective update abstractions, and present implementation mechanisms. We also show how to integrate them with a network programming language, and discuss potential applications to program verification."
877358,15258,369,A Robust Broadcast Scheme for VANET One-Hop Emergency Services,2011,"IEEE- and ASTM-adopted Dedicated Short Range Communications (DSRC) vehicle safety-related communication services, which require reliable and fast message delivery, usually demand broadcast communications in vehicular ad hoc networks (VANETs). In this paper, we propose and justify a distributive robust scheme for DSRC one-hop safety-critical services. The new scheme enhances broadcast reliability using dynamic receiver-oriented packet repetitions and mini-slot within DIFS in IEEE 802.11 for one-hop emergency warning message dissemination. In addition, we investigate the reliability and performance of the proposed broadcast scheme for DSRC VANET safety-related services on highway analytically and by simulations. The analytic model accounts for the impact of the beacon message broadcast and the fading channel conditions on the reliability and performance."
50766,15258,293,Remotely gauging upstream bufferbloat delays,2013,"Bufferbloat is the growth in buffer size that has led Internet delays to occasionally exceed the light propagation delay from the Earth to the Moon. Manufacturers have built in large buffers to prevent losses on Wi-Fi, cable and ADSL links. But the combination of some links' limited bandwidth with TCP's tendency to saturate that bandwidth results in excessive queuing delays. In response, new congestion control protocols such as BitTorrent's uTP/LEDBAT aim at explicitly limiting the delay that they add over the bottleneck link. This work proposes and validate a methodology to monitor the upstream queuing delay experienced by remote hosts, both those using LEDBAT, through LEDBAT's native one-way delay measurements, and those using TCP (via the Timestamp Option)."
553223,15258,374,Optimizing mixing in pervasive networks: a graph-theoretic perspective,2011,"One major concern in pervasive wireless applications is location privacy, where malicious eavesdroppers, based on static device identifiers, can continuously track users. As a commonly adopted countermeasure to prevent such identifier-based tracking, devices regularly and simultaneously change their identifiers in special areas called mixzones. Although mix-zones provide spatio-temporal de-correlations between old and new identifiers, pseudonym changes, depending on the position of the mix-zone, can incur a substantial cost on the network due to lost communications and additional resources such as energy. In this paper, we address this trade-off by studying the problem of determining an optimal set of mix-zones such that the degree of mixing in the network is maximized, whereas the overall network-wide mixing cost is minimized. We follow a graph-theoretic approach and model the optimal mixing problem as a novel generalization of the vertex cover problem, called the Mix Cover (MC) problem. We propose three bounded-ratio approximation algorithms for the MC problem and validate them by an empirical evaluation of their performance on real data. The combinatorics-based approach followed here enables us to study the feasibility of determining optimal mix-zones regularly and under dynamic network conditions."
212644,15258,293,Distributed Active Measurement of Internet Queuing Delays,2014,"Despite growing link capacities, over-dimensioned buffers are still causing, in the Internet of the second decade of the third millennium, hosts to suffer from severe queuing delays (or bufferbloat). While maximum bufferbloat possibly exceeds few seconds, it is far less clear how often this maximum is hit in practice. This paper reports on our ongoing work to build a spatial and temporal map of Internet bufferbloat, describing a system based on distributed agents running on PlanetLab that aims at providing a quantitative answer to the above question."
888318,15258,339,Low-fat pointers: compact encoding and efficient gate-level implementation of fat pointers for spatial safety and capability-based security,2013,"Referencing outside the bounds of an array or buffer is a common source of bugs and security vulnerabilities in today's software. We can enforce spatial safety and eliminate these violations by inseparably associating bounds with every pointer (fat pointer) and checking these bounds on every memory access. By further adding hardware-managed tags to the pointer, we make them unforgeable. This, in turn, allows the pointers to be used as capabilities to facilitate fine-grained access control and fast security domain crossing. Dedicated checking hardware runs in parallel with the processor's normal datapath so that the checks do not slow down processor operation (0% runtime overhead). To achieve the safety of fat pointers without increasing program state, we compactly encode approximate base and bound pointers along with exact address pointers for a 46b address space into one 64-bit word with a worst-case memory overhead of 3%. We develop gate-level implementations of the logic for updating and validating these compact fat pointers and show that the hardware requirements are low and the critical paths for common operations are smaller than processor ALU operations. Specifically, we show that the fat-pointer check and update operations can run in a 4 ns clock cycle on a Virtex 6 (40nm) implementation while only using 1100 6-LUTs or about the area of a double-precision, floating-point adder."
1847682,15258,8228,A secure message delivery scheme with path tracking for delay tolerant networks,2012,"In delay tolerant networks (DTNs), message delivery is operated in an opportunistic way through store-carry and forward relaying, and every DTN node is in anticipation of cooperation for data forwarding from others. Unfortunately, there always exist some selfish nodes that are reluctant to contribute to this cooperative data forwarding procedure so as to save their valuable storage buffer, limited computation power and precious energy. In order to stimulate nodes' willingness to participate in data forwarding, a number of incentive schemes have been proposed recently. However, most existing incentive schemes simply ignore efforts of nodes involved in message delivery if messages delivered fail to reach their destinations. Due to the nature of DTN, such as intermittent connectivity, it is not unusual to have unreliable message delivery, which results in unrewarded or wasted efforts for participating nodes and may discourage them from participating in future data forwarding. Therefore, it is crucial to recognize contribution of every node involved in a data forwarding procedure even the message it helps to forward doesn't successfully reach its destination. However, how to track all delivery paths so as to give every intermediate node some incentive for their cooperative efforts of data forwarding is still an open research problem. To address this problem, we propose a secure message forwarding scheme with path tracking. The proposed method is end-to-end secure with data source and identity authentication. In addition, it can thwart some well known attacks including edge inserting attack, sibling inserting attack and free riding attack."
2195769,15258,8228,An in-depth measurement and analysis of popular private tracker systems in China,2013,"In recent years, a novel BitTorrent (BT) technology, Private Tracker (PT), has received extensive attentions in academia. Due to its huge amount of traffic volumes and population, it is essential to understand the characteristics for system management. In this paper, by using the data crawled from a number of well-known PT sites in China, we present an in-depth measurement and analysis on the PT system, in terms of resources characteristics and user behavior characteristics. Our analysis on the activity and age distribution of torrents reveals that the sequence of torrent activities follows a power-law distribution and the sequence of torrent ages follows a linear distribution. By investigating the characteristics of the core users and the resources in different PT sites, two observations have been made. Firstly, every PT site has a number of users with stable levels who contribute to the survivability and popularity of the site. Secondly, a large amount of redundancy exists among the distributed resources and many popular resources are duplicated among these sites, which leads to the quick spread of pirate resources. Based on the measurement results, we analyze the drawbacks of PT mechanisms and propose useful suggestions to promote the healthy development and performance of PT."
2433881,15258,293,Can network characteristics detect spam effectively in a stand-alone enterprise?,2011,"Previous work has shown that the network dynamics experienced by both the initial packet and an entire connection carrying an email can be leveraged to classify the email as spam or ham. In the case of packet properties, the prior work has investigated their efficacy based on models of traffic collected from around the world. In this paper, we first revisit the techniques when only using information from a single enterprise's vantage point and find packet properties to be less useful. We also show that adding flow characteristics to a model of packet features adds modest discriminating power, and some flow features' information is captured by packet features."
1122280,15258,369,CarbonRecorder: A Mobile-Social Vehicular Carbon Emission Tracking Application Suite,2011,"Excessive Green House Gas emission and high fuel consumption from vehicles has become not only an environmental but also an economic issue. This work demonstrates CarbonRecorder, a mobile-social application suite that is designed to enable individuals to track their daily vehicular carbon emission, and share them on social networks. It is intended to not only raise social awareness of vehicular carbon emission and encourage more efficient driving behavior, but also serve as a platform for data collection for research in vehicular traffic management, carbon emission, and user behavior analysis in social network based applications."
1551731,15258,507,SpatialHadoop: towards flexible and scalable spatial processing using mapreduce,2014,"Recently, MapReduce frameworks, e.g., Hadoop, have been used extensively in different applications that include tera-byte sorting, machine learning, and graph processing. With the huge volumes of spatial data coming from different sources, there is an increasing demand to exploit the efficiency of Hadoop, coupled with the flexibility of the MapReduce framework, in spatial data processing. However, Hadoop falls short in supporting spatial data efficiently as the core is unaware of spatial data properties. This paper describes SpatialHadoop; a full-edged MapReduce framework with native support for spatial data. SpatialHadoop is a comprehensive extension to Hadoop that injects spatial data awareness in each Hadoop layer, namely, the language, storage, MapReduce, and operations layers. In the language layer, SpatialHadoop adds a simple and ex- pressive high level language for spatial data types and operations. In the storage layer, SpatialHadoop adapts traditional spatial index structures, Grid, R-tree and R+-tree, to form a two-level spatial index. SpatialHadoop enriches the MapReduce layer by two new components, SpatialFileSplitter and SpatialRecordReader, for efficient and scalable spatial data processing. In the operations layer, SpatialHadoop is already equipped with a dozen of operations, including range query, kNN, and spatial join. The flexibility and open source nature of SpatialHadoop allows more spatial operations to be implemented efficiently using MapReduce. Extensive experiments on a real system prototype and real datasets show that SpatialHadoop achieves orders of magnitude better performance than Hadoop for spatial data processing."
2076518,15258,343,Network support for resource disaggregation in next-generation datacenters,2013,"Datacenters have traditionally been architected as a collection of servers wherein each server aggregates a fixed amount of computing, memory, storage, and communication resources. In this paper, we advocate an alternative construction in which the resources within a server are  disaggregated  and the datacenter is instead architected as a collection of standalone resources.   Disaggregation brings greater modularity to datacenter infrastructure, allowing operators to optimize their deployments for improved efficiency and performance. However, the key enabling or blocking factor for disaggregation will be the network since communication that was previously contained within a single server now traverses the datacenter fabric. This paper thus explores the question of whether we can build networks that enable disaggregation at datacenter scales."
260151,15258,293,Investigating IPv6 traffic: what happened at the world IPv6 day?,2012,"While the IETF standardized IPv6 more than fifteen years ago, IPv4 is still the prevalent Internet protocol today. On June 8th, 2011, several large content and service providers coordinated a large-scale IPv6 test-run, by enabling support for IPv6 simultaneously: the World IPv6 Day. In this paper, we compare IPv6 activity before, during, and after the event. We examine traffic traces recorded at a large European Internet Exchange Point (IXP) and on the campus of a major US university; analyzing volume, application mix, and the use of tunneling protocols for transporting IPv6 packets.#R##N##R##N#For the exchange point we find that native IPv6 traffic almost doubled during the World IPv6 Day while changes in tunneled traffic were limited. At the university, IPv6 traffic increased from 3---6 GB/day to over 130 GB/day during the World IPv6 Day, accompanied by a significant shift in the application and HTTP destination mix. Our results also show that a significant number of participants at the World IPv6 Day kept their IPv6 support online even after the test period ended, suggesting that they did not encounter any significant problems."
1864463,15258,8228,Energy Efficient Architecture for Green Handsets in Next Generation IP-Based Wireless Networks,2011,"Next generation wireless networks are expected to integrate harmoniously in an IP-based core network. Such paradigm shift will amalgamate several distinct radio access technologies into a unifying composite network. However, this creates a fundamental problem for handsets which manifests in high power consumption due to network discovery that is typically carried out by performing scanning operations. Since handsets are naturally constrained by its battery lifetime, this paper analyzes the impact of network discovery on the handsets' power consumption from the network architecture perspective. Particular, we focus on network discovery through the scanning (information pulling) and broadcasting (information pushing) approaches. In this context, we extend a unified analytical model to evaluate the performance comparison of energy efficiency be- tween the legacy and terminal oriented network-assisted (TONA) architectures. Comprehensive numerical and simulation results show that the TONA handover architecture provides an energy saving of 8 - 35% to promote green handsets under various network load and scanning intervals."
2305590,15258,8228,Taking a Peek at Bandwidth Usage on Encrypted Links,2011,"In this paper we describe a practical yet effective technique to monitor the amount of bytes that several classes of protocols, such as peer-to-peer, e-mail, etc., transmit over encrypted virtual links, such as IPSec tunnels. The experiments described in this paper demonstrate that our regression-tree-based bandwidth estimator is effective enough to create usage models inherently robust to changes in path, number of users and type of protocols multiplexed over the encrypted link. In other words, our experimental results indicate that training data obtained from a test IPSec tunnel can be successfully used to monitor bandwidth usage on other encrypted tunnels where only the ciphertext is available."
172357,15258,293,On Searching for Patterns in Traceroute Responses,2014,"We study active traceroute measurements from more than 1,000 vantage points towards a few targets over 24 hours or more. Our aim is to detect patterns in the data that correspond to significant operational events. Because traceroute data is complex and noisy, little work in this area has been published to date. First we develop a measure for the differences between successive traceroute measurements, then we use this measure to cluster changes across all vantage points and assess the meaning and descriptive power of these clusters. Large-scale operational events stand out clearly in our 3D visualisations; our clustering technique could be developed further to make such events visible to the operator community in near-real time."
1772363,15258,8228,Concrete synthetic modeling of vehicular networks as random geometric graphs,2012,"Random graphs are often used to model vehicular networks. However, their applicability has been limited because it is difficult to express and instantiate parameters of graph models of vehicular networks using real-life data. In this paper, we consider using random geometric graphs to model vehicular networks where vehicle movements are constrained to a road system. We show that vehicles form a random geometric graph with edge probability p that can be expressed as a closed-form expression or as an algorithmically computable expression with parameters that are known or easily measurable in real life. This enables one to answer essential questions, such as questions related to routing and placement of mobile nodes required to detect malicious parties in vehicular communications, as a function of practically measurable and computable parameters."
2026850,15258,122,COREMU: a scalable and portable parallel full-system emulator,2011,"This paper presents the open-source COREMU, a scalable and portable parallel emulation framework that decouples the complexity of parallelizing full-system emulators from building a mature sequential one. The key observation is that CPU cores and devices in current (and likely future) multiprocessors are loosely-coupled and communicate through well-defined interfaces. Based on this observation, COREMU emulates multiple cores by creating multiple instances of existing sequential emulators, and uses a thin library layer to handle the inter-core and device communication and synchronization, to maintain a consistent view of system resources. COREMU also incorporates lightweight memory transactions, feedback-directed scheduling, lazy code invalidation and adaptive signal control to provide scalable performance. To make COREMU useful in practice, we also provide some preliminary tools and APIs that can help programmers to diagnose performance problems and (concurrency) bugs. A working prototype, which reuses the widely-used QEMU as the sequential emulator, is with only 2500 lines of code (LOCs) changes to QEMU. It currently supports x64 and ARM platforms, and can emulates up to 255 cores running commodity OSes with practical performance, while QEMU cannot scale above 32 cores. A set of performance evaluation against QEMU indicates that, COREMU has negligible uniprocessor emulation overhead, performs and scales significantly better than QEMU. We also show how COREMU could be used to diagnose performance problems and concurrency bugs of both OS kernel and parallel applications."
1825385,15258,343,Outsourcing the routing control logic: better internet routing based on SDN principles,2012,"Inter-domain routing is based on a fully decentralized model, where multiple Autonomous Systems (AS) interact via the BGP protocol. Although BGP is the glue of the Internet, it faces a lot of problems regarding its fully distributed nature, policy enforcement capabilities, scalability, security and complexity. Due to the widespread adoption of BGP, only incrementally deployable solutions are feasible. Taking this observation into account, we describe a new, backwards-compatible routing model which is based on outsourcing and logically centralizing the routing control plane. We claim that outsourcing enables enhanced inter-domain routing. As multiple ASes outsource their routing control plane to the same outsourcing service contractor, AS clusters are being gradually formed. A logically centralized multi-AS routing control platform based on Software Defined Networking (SDN) principles is the natural point for taking efficient routing decisions, detecting policy conflicts, troubleshooting routing problems, and evolving BGP. We present the technical and financial incentives which support the feasibility of the model and also propose an implementation scheme to facilitate it."
2135088,15258,339,Security Vulnerability in Processor-Interconnect Router Design,2014,"Servers that consist of multiple nodes and sockets are interconnected together with a high-bandwidth, low latency processor interconnect network, such as Intel QPI or AMD Hypertransport technologies. The different nodes exchange packets through routers which communicate with other routers. A key component of a router is the routing table which determines which output port an arriving packet should be forwarded through. However, because of the flexibility (or programmability) of the routing tables, we show that it can result in security vulnerability. We describe the procedures for how the routing tables in a processor-interconnect router can be modified. Based on these modifications, we propose new system attacks in a server, which include both performance attacks by degrading the latency and/or the bandwidth of the processor interconnect as well as a livelock attack that hangs the system. We implement these system on an 8-node AMD server and show how performance can be significantly degraded. Based on this vulnerability, we propose alternative solutions that provide various trade-off in terms of flexibility and cost while minimizing the routing table security vulnerability."
290794,15258,374,DriverGuard: a fine-grained protection on I/O flows,2011,"Most commodity peripheral devices and their drivers are geared to achieve high performance with security functions being opted out. The absence of security measures invites attacks on the I/O data and consequently threats those applications feeding on them, such as biometric authentication. In this paper, we present the design and implementation of DriverGuard, a hypervisor based protection mechanism which dynamically shields I/O flows such that I/O data are not exposed to the malicious kernel. Our design leverages a composite of cryptographic and virtualization techniques to achieve fine-grained protection. DriverGuard is lightweight as it only needs to protect around 2% of the driver code's execution. We have tested DriverGuard with three input devices and two output devices. The experiments show that DriverGuard induces negligible overhead to the applications."
2355783,15258,8228,The hidden cost of network low power idle,2013,"This paper deeply and experimentally analyzes the efficiency of low power idle techniques when applied to packet processing engines of network devices. To this purpose, we set up a complex testbed that allowed us to perform several measurements on energy- and network-performance indexes. The reference device platforms that we selected for this evaluation are new generation software routers based on component-off-the-shelf hardware, since they already include advanced power management capabilities, and can be considered as a significant example for next-generation green network devices. The results collected in the measurement campaign allowed us not only (i) to provide an in-depth energy consumption profiling of SR data-plane, but also (ii) to clearly outline energy costs due to the use of low power idle techniques. Among other interesting aspects, we completely characterized the energy consumption due to wakeup transitions, which may cause instantaneous consumption spikes higher than 4 times the power energy requirement when active."
2513603,15258,8228,Stochastic packet collision modeling in coexisting wireless networks for link quality evaluation,2013,"The packet delivery ratio (PDR) performance of a wireless communication network interfered by a coexisting network is determined by the collision-time. In this paper, we propose a stochastic collision-time model for coexisting wireless networks, and analyze it in particular for coexisting low-rate wireless personal area network (LR-WPAN) and WLAN. Although, the packet collision-time of the interfered network is a complex process, as it depends on the packet size and packet inter-arrival time distributions of both networks, its properties can be inferred by modeling the interference as an alternating renewal process, leading to a stochastic collision-time model. The proposed collision-time model is utilized to derive the theoretical collision-time distributions for periodic, exponential and gamma inter-arrivals. The comparison of the theoretical and simulation based collision-time distributions for the studied inter-arrivals suggests that the proposed collision-time model can be used for performance analysis of coexisting wireless networks. In order to investigate the effects on the collision-time distribution in a realistic multi-terminal WLAN traffic shaped by the CSMA/CA mechanisms, heavy tailed hyper-Erlang and gamma distributions are fitted to an experimental inter-arrival times data-set. The goodness-of-fit tests of both distributions show that the gamma distributed inter-arrivals model the observed interfering traffic good enough, which allows analytical evaluation of LR-WPAN link quality using the derived collision-time model."
1193709,15258,507,A batch of PNUTS: experiences connecting cloud batch and serving systems,2011,"Cloud data management systems are growing in prominence, particularly at large Internet companies like Google, Yahoo!, and Amazon, which prize them for their scalability and elasticity. Each of these systems trades off between low-latency serving performance and batch processing throughput. In this paper, we discuss our experience running batch-oriented Hadoop on top of Yahoo's serving-oriented PNUTS system instead of the standard HDFS file system. Though PNUTS is optimized for and primarily used for serving, a number of applications at Yahoo! must run batch-oriented jobs that read or write data that is stored in PNUTS.   Combining these systems reveals several key areas where the fundamental properties of each system are mismatched. We discuss our approaches to accommodating these mismatches, by either bending the batch and serving abstractions, or inventing new ones. Batch systems like Hadoop provide coarse task-level recovery, while serving systems like PNUTS provide finer record or transaction-level recovery. We combine both types to log record-level errors, while detecting and recovering from large-scale errors. Batch systems optimize for read and write throughput of large requests, while serving systems use indexing to provide low latency access to individual records. To improve latency-insensitive write throughput to PNUTS, we introduce a batch write path. The systems provide conflicting consistency models, and we discuss techniques to isolate them from one another."
1537444,15258,343,On consistent updates in software defined networks,2013,"We argue for the development of efficient methods to update the data plane state of an SDN, while maintaining desired consistency properties (e.g., no packet should be dropped). We highlight the inherent trade-off between the strength of the consistency property and dependencies it imposes among rules at different switches; these dependencies fundamentally limit how quickly data plane can be updated. For one basic consistency property---no packet should loop---we develop an update algorithm that has provably minimal dependency structure. We also sketch a general architecture for consistent updates that separates the twin concerns of consistency and efficiency."
2437060,15258,8228,Rate Based Feedback: Some Experimental Evaluation with NetFPGA,2011,"Transport protocols that use explicit rate feedback are a promising alternative to the algorithms which use implicit, packet loss based feedback. A key issue in the design of rate controlled communication networks is how new flows may be admitted at a fair and high starting rate. In this paper, for the management of new flows we present a modified NetFPGA Rate Control Protocol (RCP) implementation for a recently proposed admission management process at the routers. Using this implementation, we perform an evaluation of the admission of new flows in rate controlled networks. We conduct experimental tests across a range of bandwidth-delay product environments, and also deal with the arrival of a large number of flows. Our work serves to exhibit that the proposed admission management process appears to be an attractive method for dealing with the admission of new flows while maintaining small queues. Additionally, the algorithm allows the routers to maintain a specified target link utilisation. A consequence of such small queues is that buffers, in routers, may be dimensioned to be much smaller than the current, bandwidth-delay product, buffer sizing rule."
2095541,15258,343,A new approach to interdomain routing based on secure multi-party computation,2012,"Interdomain routing involves coordination among mutually distrustful parties, leading to the requirements that BGP provide policy autonomy, flexibility, and privacy. BGP provides these properties via the distributed execution of policy-based decisions during the iterative route computation process. This approach has poor convergence properties, makes planning and failover difficult, and is extremely difficult to change. To rectify these and other problems, we propose a radically different approach to interdomain-route computation, based on secure multi-party computation (SMPC). Our approach provides stronger privacy guarantees than BGP and enables the deployment of new policy paradigms. We report on an initial exploration of this idea and outline future directions for research."
2242270,15258,8228,Knowledge Dissemination for Autonomic Network,2011,"Autonomic computing is a new paradigm inspired by the biological world. It allows networks to self-organize control decisions. To ensure an efficient self-organization, an autonomic network must define a new distributed and decentralized plane containing all the network knowledge, called knowledge plane. In this paper, we propose a new knowledge dissemination mechanisms in order to maintain this knowledge plane. The developed approach is composed by three modules to address scalability and interoperability issues: (1) cluster the network nodes and elect a leader for each cluster to contain the knowledge, (2) use an overlay network to disseminate knowledge between leaders for interoperability concerns and, (3)disseminate only useful knowledge to nodes in each cluster to reduce the amount of knowledge to be distributed. To evaluate our approach, we construct a knowledge plan based on QoE measurement. Numerical results obtained for IPTV different traffics level merged on operators network show that our approach improves clearly performances regarding load balancing charges."
2437149,15258,293,Evolution of cache replacement policies to track heavy-hitter flows,2011,"Several important network applications cannot easily scale to higher data rates without requiring focusing just on the large traffic flows. Recent works have discussed algorithmic solutions that trade-off accuracy to gain efficiency for filtering and tracking the so-called heavyhitters. However, a major limit is that flows must initially go through a filtering process, making it impossible to track state associated with the first few packets of the flow.#R##N##R##N#In this paper, we propose a different paradigm in tracking the large flows which overcomes this limit. We view the problem as that of managing a small flow cache with a finely tuned replacement policy that strives to avoid evicting the heavy-hitters. Our scheme starts from recorded traffic traces and uses Genetic Algorithms to evolve a replacement policy tailored for supporting seamless, stateful traffic-processing. We evaluate our scheme in terms of missed heavy-hitters: it performs close to the optimal, oracle-based policy, and when compared to other standard policies, it consistently outperforms them, even by a factor of two in most cases."
2577180,15258,369,Improvement for Rate-Based Protocols in Multihop Wireless Networks,2013,"Transport layer performance in IEEE 802.11 multihop wireless networks (MHWNs) has been greatly challenged by wireless medium characteristics and multihop nature which induce several types of packet loss including collision, random channel errors and route failures. In this paper, we propose a novel rate control scheme, called Bi-Metric Rate Control (BMRC), which regulates efficiently the source rate in MHWNs. BMRC's design is based on two MAC metrics: the Medium Access Delay used to detect the network contention level, and the Average Transmission Time used to estimate the effective packet sending rate by which the network will not be overloaded. The simulation results show that the adapted mechanism introduces significant performance improvement in terms of fairness, packet loss rate and delay in MHWNs."
1492689,15258,122,Expressing graph algorithms using generalized active messages,2013,"Recently, graph computation has emerged as an important class of high-performance computing application whose characteristics differ markedly from those of traditional, compute-bound, kernels. Libraries such as BLAS, LAPACK, and others have been successful in codifying best practices in numerical computing. The data-driven nature of graph applications necessitates a more complex application stack incorporating runtime optimization. In this paper, we present a method of phrasing graph algorithms as collections of asynchronous, concurrently executing, concise code fragments which may be invoked both locally and in remote address spaces. A runtime layer performs a number of dynamic optimizations, including message coalescing, message combining, and software routing. Practical implementations and performance results are provided for a number of representative algorithms."
1358388,15258,369,Optimized Dynamic Multicast Grouping for Content-Based Routing in Vehicular P2P Environments,2014,"Emerging vehicular applications and its efficient dissemination is still a research challenge due to highly dynamic nature of these networks. Nevertheless, asynchronous communication can support such unique characteristic. The proposed approach in this paper combines publish/subscribe semantics with multicast routing to develop a dissemination framework for vehicular networks. The method aggregates content-based subscriptions in the form of a compact data format using Binary Decision Diagram and extends Spatio-temporal Multicast Routing Protocol to create a dynamic dissemination mesh. It optimizes routing using advertisements semantic to enhance the scalability of the framework. Similar subscriptions are grouped using clustering to form multicast groups. The framework has been evaluated in terms of the delivery ratio and network overhead metrics in different networking conditions. The performance of the proposed approach is also compared with subscription semantics based routing. The results show that advertisement based optimization shows considerable increase in scalability when compared to the use of subscriptions semantics."
2515266,15258,11330,Expressing graph algorithms using generalized active messages,2013,"Recently, graph computation has emerged as an important class of high-performance computing application whose characteristics differ markedly from those of traditional, compute-bound kernels. Libraries such as BLAS, LAPACK, and others have been successful in codifying best practices in numerical computing. The data-driven nature of graph applications necessitates a more complex application stack incorporating runtime optimization. In this paper, we present a method of phrasing graph algorithms as collections of asynchronous, concurrently executing, concise code fragments which may be invoked both locally and in remote address spaces. A runtime layer performs a number of dynamic optimizations, including message coalescing, message combining, and software routing. We identify a number of common patterns in these algorithms, and explore how this programming model can express those patterns. Algorithmic transformations are discussed which expose asyn- chrony that can be leveraged by the runtime to improve performance and reduce resource utilization. Practical implementations and performance results are provided for a number of representative algorithms."
58585,15258,293,IPv6 alias resolution via induced fragmentation,2013,"Discovering router-level IPv6 topologies is important to understanding IPv6 growth, structure, and evolution and relation to IPv4. This work presents a fingerprint-based IPv6 alias resolution technique that induces fragmented responses from IPv6 router interfaces. We leverage the way in which IPv6 implements fragmentation to provide reliable inferences. We demonstrate perfect alias resolution accuracy in a controlled environment, and on a small subset of the production IPv6 Internet for which we have ground-truth. Internet-wide testing finds that over 70% of IPv6 interfaces probed respond to the test. Our promising results suggest a valuable technique to aid IPv6 topology discovery."
2069269,15258,339,"Rosemary: A Robust, Secure, and High-performance Network Operating System",2014,"Within the hierarchy of the Software Defined Network (SDN) network stack, the control layer operates as the critical middleware facilitator of interactions between the data plane and the network applications, which govern flow routing decisions. In the OpenFlow implementation of the SDN model, the control layer, commonly referred to as a network operating system (NOS), has been realized by a range of competing implementations that offer various performance and functionality advantages: Floodlight, POX, NOX, and ONIX. In this paper we focus on the question of control layer resilience, when rapidly developed prototype network applications go awry, or third-party network applications incorporate unexpected vulnerabilities, fatal instabilities, or even malicious logic. We demonstrate how simple and common failures in a network application may lead to loss of the control layer, and in effect, loss of network control. To address these concerns we present the ROSEMARY controller, which implements a network application containment and resilience strategy based around the notion of spawning applications independently within a micro-NOS. ROSEMARY distinguishes itself by its blend of process containment, resource utilization monitoring, and an application permission structure, all designed to prevent common failures of network applications from halting operation of the SDN Stack. We present our design and implementation of ROSEMARY, along with an extensive evaluation of its performance relative to several of the mostly well-known and widely used controllers. Rather than imposing significant performance costs, we find that with the integration of two optimization features, ROSEMARY offers a competitive performance advantage over the majority of other controllers."
1967183,15258,122,Wait-free queues with multiple enqueuers and dequeuers,2011,"The queue data structure is fundamental and ubiquitous. Lock-free versions of the queue are well known. However, an important open question is whether practical wait-free queues exist. Until now, only versions with limited concurrency were proposed. In this paper we provide a design for a practical wait-free queue. Our construction is based on the highly efficient lock-free queue of Michael and Scott. To achieve wait-freedom, we employ a priority-based helping scheme in which faster threads help the slower peers to complete their pending operations. We have implemented our scheme on multicore machines and present performance measurements comparing our implementation with that of Michael and Scott in several system configurations."
656787,15258,339,A Tale of Two Kernels: Towards Ending Kernel Hardening Wars with Split Kernel,2014,"Software security practitioners are often torn between choosing performance or security. In particular, OS kernels are sensitive to the smallest performance regressions. This makes it difficult to develop innovative kernel hardening mechanisms: they may inevitably incur some run-time performance overhead. Here, we propose building each kernel function with and without hardening, within a single split kernel. In particular, this allows trusted processes to be run under unmodified kernel code, while system calls of untrusted processes are directed to the hardened kernel code. We show such trusted processes run with no overhead when compared to an unmodified kernel. This allows deferring the decision of making use of hardening to the run-time. This means kernel distributors, system administrators and users can selectively enable hardening according to their needs: we give examples of such cases. Although this approach cannot be directly applied to arbitrary kernel hardening mechanisms, we show cases where it can. Finally, our implementation in the Linux kernel requires few changes to the kernel sources and no application source changes. Thus, it is both maintainable and easy to use."
79713,15258,293,"Behavior of DNS' top talkers, a .com/.net view",2012,"This paper provides the first systematic study of DNS data taken from one of the 13 servers for the .com/.net registry. DNS' generic Top Level Domains (gTLDs) such .com and .net serve resolvers from throughout the Internet and respond to billions of DNS queries every day. This study uses gTLD data to characterize the DNS resolver population and profile DNS query types. The results show a small and relatively stable set of resolvers (i.e. the top-talkers) constitute 90% of the overall traffic. The results provide a basis for understanding for this critical Internet service, insights on typical resolver behaviors and the use of IPv6 in DNS, and provides a foundation for further study of DNS behavior."
2118514,15258,369,An Indoor Probabilistic Localization Method Using Prior Information,2013,"In this paper, we propose a new probabilistic method for determining the position of an unknown node in an indoor environment. Our analysis shows that using a small subset of sensors reduces the error in comparison to larger sets. The best subset of sensors is determined by matching the power received by all of the sensors and comparing it to prior measurements. We present experimental measurements made that show the efficacy of this approach and compare this method to previously published techniques. Our analysis shows that the new method, Prior Measurement Comparison (PMC), yields greater estimation accuracy resulting in lower error."
1934944,15258,8228,Internet Flattening: Monitoring and Analysis of Inter-Domain Routing,2011,"The decrease of AS-level route length, called Internet flattening, has a significance impact on the the design of next generation global routing system. However, there is little quantitative assessment of its factors. We report our findings through monitoring and analysis of inter-domain routing. Using BGP routing table and update messages from RouteViews and RIPE RIS, we explore Internet flattening from a view of global inter-domain routing system. Our study shows that Internet flattening is from two dominating sources: (1) ASes close to Tier 1 contribute 36% of the total decrease in route length; and (2) Routes bypassing Tier 1 is responsible for 53% of the total decrease in route length. Our measurement results also indicate that multi-homing is not an important reason of Internet flattening. Besides, leading Content Providers contribute to Internet flattening ten times than that by Internet Service Providers. Base on our result, we propose mechanisms for the performance improvement for Content Providers."
1663873,15258,122,RaceFree: an efficient multi-threading model for determinism,2013,"Current deterministic systems generally incur large overhead due to the difficulty of detecting and eliminating data races. This paper presents RaceFree, a novel multi-threading runtime that adopts a  relaxed deterministic model  to provide a data-race-free environment for parallel programs. This model cuts off unnecessary shared-memory communication by isolating threads in separated memories, which eliminates direct data races. Meanwhile, we leverage the happen-before relation defined by applications themselves as one-way communication pipes to perform necessary thread communication. Shared-memory communication is transparently converted to message-passing style communication by our Memory Modification Propagation (MMP) mechanism, which propagates local memory modifications to other threads through the happen-before relation pipes. The overhead of RaceFree is 67.2% according to our tests on parallel benchmarks."
1419642,15258,8228,Study of visiting frequency in a delay tolerant network,2012,"In a disruption/delay tolerant network, message carriers are often used to act as relays between segregated nodes and gateways. In this paper, we study a special routing problem for message carriers in delay tolerant networks, the visiting frequency problem. Specifically, we present a detailed analysis on a near-optimal visiting frequency on the nodes in a subregion of the network, to ensure low average message delay, using a partitioning-based optimization approach. Then we propose a multiple visit algorithm and apply the above near-optimal visiting frequency to our multiple visit algorithm, to guarantee the low average message delay for the network. Simulation results demonstrate the superiority of our new algorithm comparing with the existing single visit algorithms."
1998962,15258,343,Deconstructing datacenter packet transport,2012,"We present, pFabric, a minimalistic datacenter fabric design that provides near-optimal performance in terms of completion time for high-priority flows and overall network utilization. pFabric's design eliminates nearly all buffering on switches (switches have only ~20KB of buffering per port), requires almost no congestion control and uses only simple mechanisms at each switch. Specifically, switches are only required to locally and greedily decide what packets to schedule and drop according to priorities in the packet header and do not maintain any flow state or rate estimates. Rate-control is almost unnecessary, all flows start at line-rate and only slow down in the extreme case of congestion collapse. We show via simulations using realistic workloads and topologies that this simple design achieves near optimal flow completion times and network utilization."
955130,15258,339,Efficient user-space information flow control,2013,"The model of Decentralized Information Flow Control (DIFC) is effective at improving application security and can support rich confidentiality and integrity policies. We describe the design and implementation of duPro, an efficient user-space information flow control framework. duPro adopts Software-based Fault Isolation (SFI) to isolate protection domains within the same process. It controls the end-to-end information flow at the granularity of SFI domains. Being a user-space framework, duPro does not require any OS changes. Since SFI is more lightweight than hardware-based isolation (e.g., OS processes), the inter-domain communication and scheduling in duPro are more efficient than process-level DIFC systems. Finally, duPro supports a novel checkpointing-restoration mechanism for efficiently reusing protection domains. Experiments demonstrate applications can be ported to duPro with negligible overhead, enhanced security, and with tight control over information flow."
475009,15258,293,On the potential of fixed-beam 60 GHz network interfaces in mobile devices,2011,"The small form-factor and significantly high bandwidth of 60 GHz wireless network interfaces make them an attractive technology for future bandwidth-hungry mobile devices. To overcome several challenges in making such 60 GHz communication practical, beamforming is widely accepted as an integral part of 60 GHz devices. In this paper, we perform a first-of-its-kind user study to answer a rather unconventional question: can users explicitly assist in aligning fixed-beam directional antennas on the transmit/receive side? Our measurements involving 30 users show significant promise, and lean us towards answering the question in the affirmative. The implication of these observations is in substantially simplifying the design of 60 GHz interfaces for mobile devices."
2349330,15258,122,FastLane: improving performance of software transactional memory for low thread counts,2013,"Software transactional memory (STM) can lead to scalable implementations of concurrent programs, as the  relative  performance of an application increases with the number of threads that support it. However, the  absolute  performance is typically impaired by the overheads of transaction management and instrumented accesses to shared memory. This often leads STM-based programs with low thread counts to perform worse than a sequential, non-instrumented version of the same application.   In this paper, we propose FastLane, a new STM algorithm that bridges the performance gap between sequential execution and classical STM algorithms when running on few cores. FastLane seeks to reduce instrumentation costs and thus performance degradation in its target operation range. We introduce a novel algorithm that differentiates between two types of threads: One thread (the master) executes transactions pessimistically without ever aborting, thus with minimal instrumentation and management costs, while other threads (the helpers) can commit speculative transactions only when they do not conflict with the master. Helpers thus contribute to the application progress without impairing on the performance of the master.   We implement FastLane as an extension of a state-of-the-art STM runtime system and compiler. Multiple code paths are produced for execution on a single, few, and many cores. The runtime system selects the code path providing the best throughput, depending on the number of cores available on the target machine. Evaluation results indicate that our approach provides promising performance at low thread counts: FastLane almost systematically wins over a classical STM in the 1-6 threads range, and often performs better than sequential execution of the non-instrumented version of the same application starting with 2 threads."
1218974,15258,507,The curriculum forecast for Portland: cloudy with a chance of data,2012,"With the advent of cloud computing, new data management technologies and systems have emerged that differ from existing databases in important ways. As a consequence, universities are currently facing the challenge of integrating these topics into their curriculum in order to prepare students for the changed IT landscape. In this report, we describe the approach we have taken at Portland State University to teach data management in the cloud. We also present our experiences with this effort and give an outlook on how it could be adapted to suit the requirements of other universities."
1264592,15258,369,Performance of Power Saving Modes in IEEE 802.16e System,2012,"To extend battery life, modern wireless systems implement Power Saving Mechanisms (PSMs). This work presents a performance evaluation of HTTP Web Browsing and Always-On traffic whithin joint IEEE 802.16e Sleep Mode and Idle Mode operation, on an accurate 802.16e PSM NS-2 simulation implementation. We first determine the most influencial PSM parameters in terms of power savings and performance degradation, for then determining optimal transition points between Sleep Mode and Idle Mode. Results show that although power savings can be achieved, performance degradation can be substantial for a wide range of PSM parameters, if (a) Sleep Mode Inactivity Timer are such that PSM is activated within TCP RTT, or (b) timers for PSM modes are such that there is a ``competition'' between which PSM mechanism should be activated. Also, under established conditions, we observe a significant power saving gains followed by a surprising system performance enhancement."
2152630,15258,8228,On the information propagation process in multi-lane vehicular ad-hoc networks,2012,"This paper studies the information propagation process in a 1D mobile ad-hoc network formed by vehicles traveling on a highway. We consider that vehicles can be divided into traffic streams; vehicles in the same traffic stream have the same speed distribution, while the speed distributions of vehicles in different traffic streams are different. Analytical formulas are derived for the fundamental properties of the information propagation process as well as the information propagation speed. Using the formulas, one can straightforwardly study the impact on the information propagation speed of various parameters such as radio range, vehicular traffic density, vehicular speed distribution and the time variation of vehicular speed."
2286486,15258,8228,XCP-Winf and RCP-Winf: Congestion Control Techniques for Wireless Mesh Networks,2011,"In wireless networks a packet can be lost due to numerous reasons, such as congestion, medium related errors, routing and mobility. In these scenarios, the real congestion status of the network is crucial to develop accurate and efficient congestion control protocols. Some of the most known and recent protocols developed to provide faster and lighter congestion control are the eXplicit Control Protocol (XCP) and the Rate Control Protocol (RCP). These protocols have been proposed essentially to work in wired networks and environments; however, there are already new versions of XCP for wireless networks. Moreover, although these protocols estimate the available bandwidth of the links, this estimation is not accurate for wireless networks. This paper proposes new flow control protocols for wireless mesh networks, based in XCP and RCP, which we have designated as XCPWinf and RCP-Winf. These congestion control mechanisms are supported on a new method to estimate the available bandwidth and the path capacity over a wireless network path, denoted as rt-Winf, through a cross-layer approach. The estimation is performed in real-time and without the need to intrusively inject packets in the network. This is accomplished by resorting to the CSMA-CA scheme with RTS/CTS packets to determine each node's channel allocation. The results obtained, through the simulation of these protocols in different scenarios, show that rt-Winf is able to significantly increase the efficiency of congestion control mechanisms."
633363,15258,293,Violation of Interdomain Routing Assumptions,2014,"We challenge a set of assumptions that are frequently used to model interdomain routing in the Internet by confronting them with routing decisions that are actually taken by ASes, as revealed through publicly available BGP feeds. Our results quantify for the first time the extent to which such assumptions are too simple to model real-world Internet routing policies. This should introduce a note of caution into future work that makes these assumptions and should prompt attempts to find more accurate models."
1686624,15258,343,Corybantic: towards the modular composition of SDN control programs,2013,"Software-Defined Networking (SDN) promises to enable vigorous innovation, through separation of the control plane from the data plane, and to enable novel forms of network management, through a controller that uses a global view to make globally-valid decisions. The design of SDN controllers creates novel challenges; much previous work has focused on making them scalable, reliable, and efficient.   However, prior work has ignored the problem that multiple controller functions may be competing for resources (e.g., link bandwidth or switch table slots). Our  Corybantic  design supports modular composition of independent controller modules, which manage different aspects of the network while competing for resources. Each module tries to optimize one or more objective functions; we address the challenge of how to coordinate between these modules to maximize the overall value delivered by the controllers' decisions, while still achieving modularity."
1867361,15258,122,A tool to analyze the performance of multithreaded programs on NUMA architectures,2014,"Almost all of today's microprocessors contain memory controllers and directly attach to memory. Modern multiprocessor systems support non-uniform memory access (NUMA): it is faster for a microprocessor to access memory that is directly attached than it is to access memory attached to another processor. Without careful distribution of computation and data, a multithreaded program running on such a system may have high average memory access latency. To use multiprocessor systems efficiently, programmers need performance tools to guide the design of NUMA-aware codes. To address this need, we enhanced the HPCToolkit performance tools to support measurement and analysis of performance problems on multiprocessor systems with multiple NUMA domains. With these extensions, HPCToolkit helps pinpoint, quantify, and analyze NUMA bottlenecks in executions of multithreaded programs. It computes derived metrics to assess the severity of bottlenecks, analyzes memory accesses, and provides a wealth of information to guide NUMA optimization, including information about how to distribute data to reduce access latency and minimize contention. This paper describes the design and implementation of our extensions to HPCToolkit. We demonstrate their utility by describing case studies in which we use these capabilities to diagnose NUMA bottlenecks in four multithreaded applications."
2400405,15258,122,Adoption protocols for fanout-optimal fault-tolerant termination detection,2013,"Termination detection is relevant for signaling completion (all processors are idle and no messages are in flight) of many operations in distributed systems, including work stealing algorithms, dynamic data exchange, and dynamically structured computations. In the face of growing supercomputers with increasing likelihood that each job may encounter faults, it is important for high-performance computing applications that rely on termination detection that such an algorithm be able to tolerate the inevitable faults. We provide a trio of new practical fault tolerance schemes for a standard approach to termination detection that are easy to implement, present low overhead in both theory and practice, and have scalable costs when recovering from faults. These schemes tolerate all single-process faults, and are probabilistically tolerant of faults affecting multiple processes. We combine the theoretical failure probabilities we can calculate for each algorithm with historical fault records from real machines to show that these algorithms have excellent overall survivability."
1312898,15258,122,Efficient SIMD code generation for irregular kernels,2012,"Array indirection causes several challenges for compilers to utilize single instruction, multiple data (SIMD) instructions. Disjoint memory references, arbitrarily misaligned memory references, and dependence cycles in loops are main challenges to handle for SIMD compilers. Due to those challenges, existing SIMD compilers have excluded loops with array indirection from their candidate loops for SIMD vectorization. However, addressing those challenges is inevitable, since many important compute-intensive applications extensively use array indirection to reduce memory and computation requirements. In this work, we propose a method to generate efficient SIMD code for loops containing indirected memory references. We extract both inter- and intra-iteration parallelism, taking data reorganization overhead into consideration. We also optimally place data reorganization code in order to amortize the reorganization overhead through the performance gain of SIMD vectorization. Experiments on four array indirection kernels, which are extracted from real-world scientific applications, show that our proposed method effectively generates SIMD code for irregular kernels with array indirection. Compared to the existing SIMD vectorization methods, our proposed method significantly improves the performance of irregular kernels by 91%, on average."
1391634,15258,8228,Energy-minimized design for IP over WDM networks under modular router line cards,2012,"On a router-port basis, our previous study [1] found that lightpath bypass strategy can significantly save power consumption over the lightpath non-bypass strategy. However, in real network systems, router ports are organized by network line cards or modules; on each line card there are multiple router ports. In this paper, we evaluate the energy consumption of an IP over WDM network in the context of modularized router ports. We develop mixed integer linear programming (MILP) model for power consumption minimization under the lightpath bypass strategy. We also compare the cases of lightpath bypass and nonbypass. It is found that for modularized route ports, the strategy of optical bypass can significantly outperform the strategy of non-bypass. Also, under different types of modular router line cards, a mixed deployment of different types of router line cards consumes the least energy compared to the deployment of a single type of line card."
2565937,15258,8228,On detecting abrupt changes in network entropy time series,2011,"In recent years, much research focused on entropy as a metric describing the chaos inherent to network traffic. In particular, network entropy time series turned out to be a scalable technique to detect unexpected behavior in network traffic.#R##N##R##N#In this paper, we propose an algorithm capable of detecting abrupt changes in network entropy time series. Abrupt changes indicate that the underlying frequency distribution of network traffic has changed significantly. Empirical evidence suggests that abrupt changes are often caused by malicious activity such as (D)DoS, network scans and worm activity, just to name a few.#R##N##R##N#Our experiments indicate that the proposed algorithm is able to reliably identify significant changes in network entropy time series. We believe that our approach helps operators of large-scale computer networks in identifying anomalies which are not visible in flow statistics."
696550,15258,293,A practical approach to portscan detection in very high-speed links,2011,"Port scans are continuously used by both worms and human attackers to probe for vulnerabilities in Internet facing systems. In this paper, we present a new method to efficiently detect TCP port scans in very high-speed links. The main idea behind our approach is to early discard those handshake packets that are not strictly needed to reliably detect port scans. We show that with just a couple of Bloom filters to track active servers and TCP handshakes we can easily discard about 85% of all handshake packets with negligible loss in accuracy. This significantly reduces both the memory requirements and CPU cost per packet. We evaluated our algorithm using packet traces and live traffic from 1 and 10 GigE academic networks. Our results show that our method requires less than 1 MB to accurately monitor a 10 Gb/s link, which perfectly fits in the cache memory of nowadays' general-purpose processors."
1069154,15258,122,Faster topology-aware collective algorithms through non-minimal communication,2012,"Known algorithms for two important collective communication operations, allgather and reduce-scatter, are minimal-communication algorithms; no process sends or receives more than the minimum amount of data. This, combined with the data-ordering semantics of the operations, limits the flexibility and performance of these algorithms. Our novel non-minimal, topology-aware algorithms deliver far better performance with the addition of a very small amount of redundant communication. We develop novel algorithms for Clos networks and single or multi-ported torus networks. Tests on a 32k-node BlueGene/P result in allgather speedups of up to 6x and reduce-scatter speedups of over 11x compared to the native IBM algorithm. Broadcast, reduce, and allreduce can be composed of allgather or reduce-scatter and other collective operations; our techniques also improve the performance of these algorithms."
1469028,15258,8228,A multi-criteria master nodes selection mechanism for knowledge dissemination in autonomic networks,2012,"Autonomic Networks represent a concept inspired by the biological world that aims at making a network independent of any human monitoring. To reach such autonomy, knowledge should be disseminated over the network, which remains an open problem. In fact, disseminating the knowledge over all nodes leads to a big overhead. That is why we need to select a subset of nodes in charge of knowledge management. A single criterion-based selection mechanism has been proposed in a previous work but such a mechanism seems to be very simplistic. In this paper, we present a new multi-criteria selection mechanism based on Pareto. The simulation results show that the proposed approach significantly improves performances compared to single criterion-based selection mechanism."
2334436,15258,8228,A Container-Based I/O for Virtual Routers: Experimental and Analytical Evaluations,2011,"Network virtualization is a promising technology that offers high levels of flexibility, isolation, extensibility and cost-effectiveness. In this paper, we focus on router virtualization. We evaluate the forwarding performance of virtual routers when the data plane runs in the guests. This scenario offers a high level of isolation and flexibility, however, it suffers from performance limitations due to the virtualization overhead. We show that the he I/O communication between the driver domain and the guests is the bottleneck. To overcome this limitation, we propose a new packets aggregation mechanism that transfers groups of packets between the driver domain and the guests. This enhancement makes the forwarding performance of one guest scale up to 1600 Kp/s. Furthermore, we propose a dimensioning tool in order to determine the maximum achievable throughput with regard to the container size."
2156541,15258,369,Energy Balancing in an OFDM-Based WSN,2011,"The energy balancing is one of the main concerns in wireless sensor networks (WSNs). Different from current methods, this paper attempts to solve the unbalanced energy consumption problem in the orthogonal frequency division multiplexing (OFDM) system for a WSN. The objective is to increase the sum throughput with almost equal energy consumption among the sensor nodes. Inspired by this goal, we formulated the optimization problem. Then a heuristic method is designed to solve this complex problem. The impact of number of subcarriers and sensor nodes on the fairness are studied in the numerical simulation. Comparisons with different common methods are made to show that the proposed method could achieve the excellent energy consumption fairness and better achievable throughput."
1338107,15258,369,Exploiting Additional Active Time of WiFi Interface to Reduce Power Consumption of Smartphones,2014,"Power saving mode mechanism in IEEE 802.11 is designed for reducing power consumption by switching WiFi interface of mobile device between active-state and sleep-state alternately. Since the power consumption in active-state is significantly higher than that in sleep-state, switching between both states should be done carefully; e.g., low priority packets such as delay tolerant packet should not trigger switching to active-state for increasing power saving effect. Delay tolerant traffic, however, also equally affects behaviors of the mechanism since the mechanism is operated within the MAC layer. To overcome this issue, we propose Scrooge which separates delay tolerant traffic from delay sensitive traffic to prevent delay tolerant traffic from impacting on behavior of power saving mechanism. Thus, delay tolerant packets never affect the behavior of power saving mode mechanism. Our prototype implementation improves power saving performance by up to 95% without significant transmission delay under common applications' traffic patterns."
1962109,15258,122,Accelerating CUDA graph algorithms at maximum warp,2011,"Graphs are powerful data representations favored in many computational domains. Modern GPUs have recently shown promising results in accelerating computationally challenging graph problems but their performance suffered heavily when the graph structure is highly irregular, as most real-world graphs tend to be. In this study, we first observe that the poor performance is caused by work imbalance and is an artifact of a discrepancy between the GPU programming model and the underlying GPU architecture.We then propose a novel virtual warp-centric programming method that exposes the traits of underlying GPU architectures to users. Our method significantly improves the performance of applications with heavily imbalanced workloads, and enables trade-offs between workload imbalance and ALU underutilization for fine-tuning the performance. Our evaluation reveals that our method exhibits up to 9x speedup over previous GPU algorithms and 12x over single thread CPU execution on irregular graphs. When properly configured, it also yields up to 30% improvement over previous GPU algorithms on regular graphs. In addition to performance gains on graph algorithms, our programming method achieves 1.3x to 15.1x speedup on a set of GPU benchmark applications. Our study also confirms that the performance gap between GPUs and other multi-threaded CPU graph implementations is primarily due to the large difference in memory bandwidth."
1654443,15258,8228,Saving energy and improving TCP throughput with rate adaptation in Ethernet,2012,"Reducing the power consumption of network interfaces contributes to lowering the overall power needs of the compute and communication infrastructure. Most modern Ethernet interfaces can operate at one of several data rates. In this paper, we present Queue Length Based Rate Adaptation (QLBRA), which can dynamically adapt the link rate for Ethernet interfaces at runtime using existing Ethernet standards. An implementation of the proposed rate adaptation functionality is demonstrated at runtime on a NetFPGA platform. Our results show that the rate adaptation approach can achieve significant energy savings and at the same time improve the throughput of TCP traffic due to the effect of packet pacing."
1964553,15258,122,Runtime elision of transactional barriers for captured memory,2013,"In this paper, we propose a new technique that can identify transaction-local memory (i.e.  captured memory ), in managed environments, while having a low runtime overhead. We implemented our proposal in a well known STM framework (Deuce) and we tested it in STMBench7 with two different STMs: TL2 and LSA. In both STMs the performance improved significantly (4 times and 2.6 times, respectively). Moreover, running the STAMP benchmarks with our approach shows improvements of 7 times in the best case for the Vacation application."
1687151,15258,8228,Energy efficient distributed router design,2013,"A multistage software router (MSSR) architecture is composed of several personal computers (PCs) to overcome single PC-based software router scalability issues. Although the architecture scales almost linearly with the number of internal elements, energy consumption could be a threat to its scalability features when building a core router with many internal components. Assuming a known 24 hour traffic load, this paper proposes energy efficient multistage software router design approaches, which enhance the performance of energy saving algorithms that minimize the energy consumption by tailoring the architecture to match the current input traffic demand. Simulation results show that a multistage software router architecture defined by the newly proposed design approaches saves roughly 10% of energy with respect to existing algorithms for similar cost. The energy saving may reach 20% depending on the initial admissible budget."
1761275,15258,8228,Accounting for load variation in energy-efficient data centers,2013,"The energy consumption in data centers is drastically increasing and becoming a significant portion in the data center operating expenses. Enabling a sleep mode in the idle computing servers and network hardware is the most efficient method to avoid unnecessary power consumption. However, changes in the power modes introduce considerable delays. Moreover, inability to wake up a sleeping server immediately requires an availability of a pool of idle servers able to accommodate incoming load in the short term to prevent QoS degradation. In this paper we investigate the amount of computing servers and network hardware needed to accommodate different incoming load patters in the data centers. Furthermore, we propose to build these servers on energy efficient hardware, which is costly but can scale its power consumption with the offered load levels. The evaluation results show that the proposed methodology can save up to $750 per server per year on average."
1877252,15258,507,A survey on energy-efficient data management,2011,"Energy management has now become a critical and urgent issue in green computing. A lot of efforts have been made on energy-efficiency computing at various levels from individual hardware components, system software, to applications. In this paper, we describe the energyefficiency computing problem, as well as possible strategies to tackle the problem. We survey some recently developed energy-saving data management techniques. Benchmarks and power models are described in the end for the evaluation of energy-efficiency solutions."
1950178,15258,8228,Nonparametric Bayesian identification of primary users' payloads in cognitive radio networks,2012,"In cognitive radio networks, a secondary user needs to estimate the primary users' traffic patterns so as to optimize its transmission strategy. In this paper, we propose a nonparametric Bayesian method for identifying traffic applications, since the traffic applications have their own distinctive patterns. In the proposed algorithm, the collapsed Gibbs sampler is applied to cluster the traffic applications using the infinite Gaussian mixture model over the feature space of the packet length, the packet inter-arrival time, and the variance of packet lengths. We analyze the effectiveness of our proposed technique by extensive simulation using the measured data obtained from the WiMax networks."
1726235,15258,8228,Live migration in green virtualized networks,2013,Network virtualization is a promising technology for the Internet of the Future. An open issue in virtualization is the management of network resources in a way that energy savings are achieved without compromising the Quality of Service (QoS) requirements of the virtual networks. The dynamic allocation and deallocation of virtual networks can lead the state of the substrate to a less than optimum energy consumption. This paper introduces two algorithms for the migration of virtual routers and/or links which aims to allocate resources so that energy consumption is minimized. The efficacy of the migration of virtual routers and/or links and its impact on energy consumption are analyzed based on results derived via simulations.
819515,15258,343,Managing the network with Merlin,2013,"This paper presents the Merlin network management framework. With Merlin, administrators express network policy using programs in a declarative language based on logical predicates and regular expressions. The Merlin compiler automatically partitions these programs into components that can be placed on a variety of devices including switches, middleboxes, and end hosts. It uses a constraint solver and parameterizable heuristics to allocate resources such as paths and bandwidth. To ease the administration of federated networks, Merlin provides mechanisms for delegating management of sub-policies to tenants, along with tools for verifying that delegated sub-policies do not violate global constraints. Overall, Merlin simplifies the task of network administration by providing high-level abstractions for directly specifying network policy."
2418554,15258,23749,Evaluation of the Feasibility of Making Large-Scale X-Ray Tomography Reconstructions on Clouds,2014,"Abstract —This work focuses on the evaluation of the suit-ability of Mangoose++, a medical image application for recon-struction of 3D volumes, by means of Cloud Computing. Dueto the increasing resolution of panel detectors in computedtomography and the need of lower execution times, the useof parallel implementations for clusters and accelerators havebeen generalized. Anyhow, the renewal and maintenance ofhardware is expensive which makes Cloud Computing avaluable alternative. In our evaluation, we analyze and discussthe costs and efﬁciency of the Mangosee++ application overAmazon EC2 platform, demonstrating that lower times canbe achieved in a reasonable price compared with ownedHPC-based hardware. We also provide a comparison betweendistinct hardware conﬁgurations so that we can infer theadvantages and disadvantages of each one. Keywords -Cloud Computing; HPC; Computed Tomography;Reconstruction; Amazon EC2; Elastic Compute Cloud; I. I NTRODUCTION Many small animal X-ray computed tomography (CT)scanners are based on cone-beam geometry with a ﬂat-panel detector orbiting in a circular trajectory [1], thanksto the advantages provided by this conﬁguration: reductionof acquisition time, large axial ﬁeld of view (FOV) withoutgeometrical distortions, and minimization of radiated dose[2]. With the evolution of technology, the acquisition timehas been reduced and the elements density of detector panelshas been increased. This last improvement produces a higheramount of data to process [3]. Together with this increaseof data, there is a need of faster reconstruction mechanismsto address the newest uses of CT: planning and monitoringin radiotherapy, image assisted surgery, and other clinicalapplications required the real time imaging [4]. Also, recentadvances in algorithms have not been exploited yet at thefull potential in high performance implementations, whichrepresents a barrier for extending the use of this technology[4]. All this motivates the need to look for optimizationsthat can handle the increasing complexity and demand ofthe reconstruction task.Approximated methods based on the algorithm proposedby Feldkamp, Davis and Kress [5] (namely FDK) arestill widely used for solving the 3D reconstruction task,despite the trend of CT towards statistical reconstructionalgorithms. The use of iterative reconstruction methods isstill popular thanks to their straightforward implementationand computational efﬁciency of them [1]. However, theyare slow compared to analytical reconstruction methodsmainly because of the computationally intensive forwardand backward projection operations. That motivates theneed of high-performance for tomography reconstruction.In [6], the authors show how to use a transputer networkto implement a real-time ultrasound process tomography, [7]presents a parallel image reconstruction technique on MIMDcomputers for three-dimensional cone-beam tomography,and [8] shows parallelization methods for implementationof a magnetic induction tomography forward model insymmetric multiprocessor systems. Nowadays, we can relyon modern accelerated computing systems such as GPGPUsor the recently introduced Intel Xeon Phi™ coprocessor, toalleviate these problems. Nevertheless, this is not the uniqueapproach to solve the problems related to computationalrequirements. New cloud computing platforms could be astraight-forward and cheap solution to the problems facedby this kind of applications if we take into account the on-demand/elastic advantages of them.Cloud computing platforms are, in most cases, organizedby resource providers in a cluster-like structure in orderto facilitate virtualization technologies. Usually, cloud plat-forms are provided through medium or large scale data andcomputing centers where all the systems have virtualizationfacilities installed [20] based on hypervisors such as Xen,Azure, and ESX. Virtualization is the heart of a cloudcomputing platform, as the services are provided by usingstandardized or tailored virtual machines to the differentcloud computing solutions presented in the previous section.The possibility of providing elastic computing and storagetransparently to the upper layers [19] motivates researchersand companies, as they can have low cost resources adaptedto their requirements to run varying size experiments or toallow the company grow with the clients demand. How-ever, harnessing virtualization is not a straightforward work.Along several years, hypervisors have been optimized toavoid performance looses. Novel middlewares have beenincluded to easily deploy both virtual machines and applica-tions, and new tools have been developed to cope with thecloud increasing complexity [23], [21].2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing"
2100647,15258,339,KoNKS: konsensus-style network koordinate system,2012,"A network coordinate system [7, 14, 15] assigns virtual coordinates (network positions) to every node in the network. These coordinates are assigned so that the coordinate distance between two nodes reflects the real network distance between those two nodes. This allows any peer in the sytem to accurately estimate the network distance between any pair of nodes, without having the pair of nodes contact each other. Network coordinate systems' ability to predict the network latency between arbitrary pairs of nodes can be used in many applications: finding the closest node to download content from in a content distribution network or route to in a peer-to-peer system [18], reducing inter-ISP communication [5, 13], reducing the amount of state stored in routers [1], performing byzantine leader elections [6], and detecting Sybil attackers [3, 8].   Current network coordinate systems have been shown to have good accuracy in predicting network distances, low processing and communication overhead, and fast convergence to stable positions. More recent papers have improved on the earlier designs by providing coordinate stability under churn and convergence under measurement uncertainty [2, 7, 11, 12].   However, it has also been shown [10] that those network coordinate systems are not secure, in the sense that a malicious peer in the network can report randomly chosen coordinates or maliciously delay responses to disrupt the network coordinate system. The fake reported coordinates or round-trip time (RTT) causes the nodes in the system to incorrectly update their coordinates. This renders the network latency prediction useless because the coordinate distance between two nodes will  not  reflect the real network distance between the two nodes. Moreover, the adversary could lie about its coordinates so that the coordinate distance between itself and a targeted node is smaller than the real network distance. In some applications, the adversary will then be more likely to be contacted or picked as a peer to download content from.   Several schemes [9, 16, 17, 19, 20] have been developed to protect network coordinate systems against the attacks in [10], where malicious peers report randomly chosen coordinates, report random but consistent coordinates, or add random delay in their messages to other peers. These schemes can be categorized into anomaly/outlier detection [9, 20], reputation system [16], and distributed reputation systems [17, 19]; all of them were shown to effectively mitigate the known attacks. Recently, however, a new type of attack [4] -- the frog-boiling attack -- was introduced, and it was shown that some of these schemes fail to protect against this attack. The frog-boiling attacker reports small but consistent lies that are not detected by any of the security mechanisms, but which cumulatively introduce unacceptable errors; for example, it was shown that this technique can randomly partition an overlay using a secure network coordinate system [20]. One of the issues is that the current secure schemes aimed only to patch against the known attacks. This could lead to an  arms race  where new attacks which they did not consider, bypass existing security mechanisms, resulting in new improved schemes to defend against the new attack, and so on.   To avoid this arms race, we evaluate a network coordinate system in terms of an explicit  security goal  -- an invariant that should hold despite the presence and actions of an attacker -- under a concrete threat model that states what resources the attacker can marshall. The two goals are 1) an attacker's influence on either the network distance or coordinate distance between two honest nodes is limited, and 2) the coordinate distance between a malicious peer and an honest peer cannot be smaller than the true network distance between these two nodes. The first goal limits an attacker's influence on honest nodes' coordinates while the second goal prevents an attacker from appearing closer than it actually is.   Our main contribution is describing a completely decentralized network coordinate system, KoNKS, which is secure under our stated security model. KoNKS -- consensus-style network coordinate system -- modifies the objective function that each peer follows to update its coordinates. In current network coordinate systems, a peer's goal is to minimize the sum of the prediction errors for all of its neighbors. In contrast, using KoNKS, a peer's goal is to minimize the number of neighbors whose individual relative error is unacceptable -- KoNKS puts an upper bound on each neighbor's relative error. The relative error determines how accurate the coordinate system is, thus when there are no attackers, minimizing the sum of errors should lead to more accurate distance predictions. However, minimizing the sum of prediction errors allows each neighbor to have a significant influence on the position of its peers. This is one of the reasons why the frog-boiling attack works. For example, a malicious neighbor could craft a lie so that its coordinate distance to the peer is much smaller than the measured network distance. In response, the peer would make a significant change to its coordinate because that update seemed to give the minimum total prediction error, even though it adds significant prediction error to every other neighbor.   This example cannot happen in KoNKS because every neighbor of a peer has the same amount of influence on that peer. In a way, KoNKS peers achieve consensus among their neighbors: each neighbor votes for a region in which the peer should reside, and the network position with the most votes from the neighbors is the one that KoNKS chooses. A malicious neighbor can still choose its reported coordinates and add delay to its RTT, but the push that lie has on the peer is limited, as the latter will have to satisfy its other neighbors as well. At every update, the peer takes into consideration each of its neighbors' relative error. We argue that KoNKS is secure because 1) a malicious node's influence on the coordinate distance between two honest nodes is limited, and 2) a malicious node cannot appear closer than it actually is because its relative error will be higher than the imposed threshold.   We show that KoNKS is as accurate as Vivaldi [7], one of the most popular decentralized network coordinate system (Vivaldi is implemented in Vuze [18] and is the basis for previous secure network coordinate systems [9, 16, 17, 20]), and is secure against all the current attacks, including the network-partition frog-boiling attack. More specifically, KoNKS puts an upper bound on the amount of influence an adversary can have on the honest nodes. For example, 10% of attackers can partition a network using KoNKS only so much before their lies do not have any effect anymore because they are outside of the threshold, or the other honest neighbors' influence equals the malicious neighbors' influence. KoNKS with no attack can achieve a median relative error as low as 12%, which is comparable to Vivaldi's median relative error of 10%. Moreover, KoNKS incurs a very low overhead, similar to Vivaldi as coordinates can be piggybacked on top of application messages. The processing overhead of each node updating its coordinates is also very small."
1621903,15258,11330,SRC: Damaris - using dedicated i/o cores for scalable post-petascale HPC simulations,2011,"As we enter the post-petascale era, scientific applications running on large-scale platforms generate increasingly larger amounts of data for checkpointing or offline visualization, which puts current storage systems under heavy pressure. Unfortunately, I/O scalability rapidly fades behind the increasing computation power available, and thereby reduced the overall application performance scalability. We consider the common case of large-scale simulations who alternate between computation phases and I/O phases. Two main approaches have been used to handle these I/O phases: 1) each process writes an individual file, leading to a very large number of files from which it is hard to retrieve scientific insights; 2) processes synchronize and use collective I/O to write to the same shared file. In both cases, because of mandatory communications betweens processes during the computation phase, all processes enter the I/O phase at the same time, which leads to huge access contention and extreme performance variability.   Previous research efforts have focused on improving each layer of the I/O stack separately: at the highest level scientific data formats like HDF5 allow to keep a high degree of semantics within files, while leveraging MPI-IO optimizations. Parallel file systems like GPFS or PVFS are also subject to optimization efforts, as they usually represent the main bottleneck of this I/O stack.   As a step forward, we introduce Damaris (Dedicated Adaptable Middleware for Application Resources Inline Steering), an approach targeting large-scale multicore SMP supercomputers. The main idea is to dedicate one or a few cores on each node to I/O and data processing to provide an efficient, scalable-by-design, in-compute-node data processing service. Damaris takes into account user-provided information related to the application, the file system and the intended use of the datasets to better schedule data transfers and processing. It may also respond to visualization tools to allow in-situ visualization without impacting the simulation.   We tested our implementation of Damaris as an I/O backend for the CM1 atmospheric model, one of the application intended to run on next generation supercomputer BlueWaters at NCSA. CM1 is a typical MPI application, originally writing one file per process at each checkpoint using HDF5. Deployed on 1024 cores on BluePrint, the BlueWater's interim system at NCSA with GPFS as underlying filesystem, this approach induces up to 10 seconds overhead in checkpointing phases every 2 minutes, with a high variability in the time spent by each process to write its data (from 1 to 10 seconds). Using one dedicated I/O core in each 16-cores SMP node, we completely remove this overhead. Moreover, the time spared by the I/O core enables a better compression level, thus reducing both the number of files produced (by a factor of 16) and the total data size. Experiments conducted on the French Grid5000 testbed with PVFS as underlying filesystem and a 24 cores/node cluster emphasized the benefit of our approach, which allows communication and computation to overlap, in a context involving high network contention at multiple levels."
1640515,15258,23749,V for Vicissitude: The Challenge of Scaling Complex Big Data Workflows,2014,"In this paper we present the scaling of BTWorld, our MapReduce-based approach to observing and analyzing the global BitTorrent network which we have been monitoring for the past 4 years. BTWorld currently provides a comprehensive and complex set of queries implemented in Pig Latin, with data dependencies between them, which translate to several MapReduce jobs that have a heavy-tailed distribution with respect to both execution time and input size characteristics. Processing BitTorrent data in excess of 1 TB with our BTWorld workflow required an in-depth analysis of the entire software stack and the design of a complete optimization cycle. We analyze our system from both theoretical and experimental perspectives and we show how we attained a 15 times larger scale of data processing than our previous results. I. INTRODUCTION the BitTorrent network (2), the vicissitude of processing our BitTorrent data, that is the combination between large volume of data and the complexity of the processing workflow, has prevented us until now to gather useful insights. To address this problem, in this work we demonstrate the scaling of the BTWorld workflow and process an order of magnitude more data than in our previous attempt (2). The contributions of this paper are conceptual, technical, and related to scale. In terms of conceptual contribution, we introduce a complex workflow for big data processing solving a real-world problem that is highly relevant for the evolution of the Internet, which is the analysis of the operation of the global BitTorrent file- sharing network. Popular yet simple benchmarks used in much of the big data research fail to stress the MapReduce software stack. In contrast, the level of complexity of our workflow drives the MapReduce platform to its limits which unexpectedly crashed multiple times. Thus, scaling it to very large data sets required several considerations, both in terms of tuning the platform configuration and workflow design. The BTWorld workflow currently includes 17 high-level SQL- like queries implemented in Pig Latin which translate to 35 MapReduce jobs. The complexity of the workflow turned out to be more important than the data volume. While trying to scale BTWorld to larger data sets, the vicissitude encountered determined us to analyze in-depth the entire software stack and understand the impact of each level on the actual performance of the workflow. Our technical contributions form a complete optimization cycle that includes modifications applied at all levels of the big data processing stack. At the storage level, we show the importance of input data organization and the influence of the replication factor on the execution time of complex workflows. At the level of MapReduce, we found that delaying the execution of reducers can alleviate memory pressure and that increasing default buffer allocations is essential. At the high-level programming level, Pig, we show that finding a balance between the number of tasks and memory allocation is crucial to avoid crashes. Finally, at the workflow level, it is important for the design to include inter-query data reuse. As to scale, we have processed 40 times more data com- pared to the biggest presentation at CCGrid SCALE 2013, MR-DBSCAN. At the same time, we surpass our own previous work by a factor of 15 (2). Most importantly though, the problem we are addressing in this paper concerns the global BitTorrent network, which is of an unprecedented scale in peer-to-peer research. The scientific community can greatly benefit from our analysis to improve the service level of the hundreds of millions of BitTorrent users (3), but also to alleviate the network issues that BitTorrent can cause because of its heavy use of upload bandwidth (4)."
2045211,15258,11330,Blue Gene/Q: design for sustained multi-petaflop computing,2012,"The Blue Gene/Q system represents the third generation of optimized high-performance computing Blue Gene solution servers and provides a platform for continued growth in HPC performance and capability. Blue Gene/Q started with a new design of the hardware platform, while retaining and significantly expanding an established, trusted and successful software environment.   To deliver a system that enables users to fully exploit the promise of high-performance computing for both traditional HPC applications and new commercial application areas, the Blue Gene/Q system architecture combines hardware and software innovations to overcome traditional bottlenecks, most famously the memory and power walls which have become emblematic of modern computing systems. At the same time, to deliver a platform for sustainable petascale computing, and beyond to exascale, we had to address a new set of walls with the many innovations described below: a scalability wall, a communication wall, and a reliability wall.   The new Blue Gene/Q system increases overall system performance with a new node architecture: Each node offers more thread-level-parallelism with a coherent SMP node consisting of eighteen 64-bit PowerPC cores with 4-way simultaneous multithreading. Each core provides for better exploitation of data-level parallelism with a new 4-way quad-vector processing unit (QPU). The memory subsystem integrates memory speculation support which can be used to implement both Transactional Memory and Speculative Execution programming models.   The compute nodes are connected in a five dimensional torus configuration using 10 point-to-point links, and a total network bandwidth of 44 GB/s per node. The on-chip messaging unit provides an optimized interface between the network routing logic and the memory subsystem, with enough bandwidth to keep all the links busy. It also offloads communication protocol processing by implementing collective broadcast and reduction operations, including integer and floating point sum, min and max.   Built on the Blue Gene hardware design is an efficient software stack that builds on several generations of Blue Gene software interfaces, while extending these capabilities and adding new functions to support new hardware capabilities. The hardware functions were designed with a focus on providing efficient primitives upon which to build the rich software environment.   To ensure reliable operation of a petascale system, reliability has to be a pervasive design consideration. At the architecture level, new QPX store-and-indicate instructions support the detection of programming errors. To ensure reliable operation in the presence of transient faults, we conducted exhaustive single event upset simulations based on fault injection into the simulated design. The operating system was structured to use firmware in a small on-chip boot eDRAM to avoid silent system hangs.   Together, the hardware and software innovations pioneered in Blue Gene/Q give application developers a platform and framework to develop and deploy sustained petascale computing applications. These petascale applications will allow its users to make new scientific discoveries and gain new business insights, which will be the true measure of the success of the new Blue Gene/Q systems."
2533974,15258,23497,The rise of the expert amateur: DIY culture and the evolution of computer science,2013,"We are at an important technological inflection point. Most of our computing systems have been designed and built by professionally trained experts (i.e. us -- computer scientists, engineers, and designers) for use in specific domains and to solve explicit prob-lems. Artifacts often called user manuals traditionally prescribed the appropriate usage of these tools and implied an acceptable etiquette for interaction and experience. A fringe group of individuals usually labeled hackers or amateurs or makers have challenged this producer-consumer model of technology by creating novel hardware and software features to improve our research and products while a similar creative group of technicians called artists have redirected the techniques, tools, and tenets of accepted technological usage away from their typical manifestations in practicality and product. Over time the technological artifacts of these fringe groups and the support for their rhetoric have gained them a foothold into computing culture and eroded the established power discontinuities within the practice of computing research. We now expect our computing tools to be driven by an architecture of open participation and democracy that encourages users to add value to their tools and applications as they use them. Similarly, the bar for enabling the design of novel, personal computing systems and hardware remixes has fallen to the point where many non-experts and novices are readily embracing and creating fascinating and ingenious computing artifacts outside of our official and traditionally sanctioned academic and industrial research communities.   But how have we as expert practitioners been influencing this discussion? By constructing a practice around the design and development of technology for task based and problem solving applications, we have unintentionally established such work as the status quo for the human computing experience. We have failed in our duty to open up alternate forums for technology to express itself and touch our lives beyond productivity and efficiency. Blinded by our quest for smart technologies we have forgotten to contemplate the design of technologies to inspire us to be smarter, more curious, and more inquisitive. We owe it to ourselves to rethink the impact we desire to have on this historic moment in computing culture. We must choose to participate in and perhaps lead a dialogue that heralds an expansive new acceptable practice of designing to enable participation by experts and non-experts alike. We are in the milieu of the rise of the expert amateur. We must change our mantra -- not just performance, completeness, and usability but openness, usefulness and relevancy to our world, its citizens, and our environment. This talk will explore elements of the DIY and maker culture and its relevancy to research questions across computational hardware, languages, and systems. Ultimately, this talk will outline and argue for expanding the design territory and potential opportunities for all of us to collaborate and benefit as a society from this cultural movement."
2444851,15258,122,Lifeline-based global load balancing,2011,"On shared-memory systems, Cilk-style work-stealing has been used to effectively parallelize irregular task-graph based applications such as Unbalanced Tree Search (UTS). There are two main difficulties in extending this approach to distributed memory. In the shared memory approach, thieves (nodes without work) constantly attempt to asynchronously steal work from randomly chosen victims until they find work. In distributed memory, thieves cannot autonomously steal work from a victim without disrupting its execution. When work is sparse, this results in performance degradation. In essence, a direct extension of traditional work-stealing to distributed memory violates the work-first principle underlying work-stealing. Further, thieves spend useless CPU cycles attacking victims that have no work, resulting in system inefficiencies in multi-programmed contexts. Second, it is non-trivial to detect active distributed termination (detect that programs at all nodes are looking for work, hence there is no work). This problem is well-studied and requires careful design for good performance. Unfortunately, in most existing languages/frameworks, application developers are forced to implement their own distributed termination detection.   In this paper, we develop a simple set of ideas that allow work-stealing to be efficiently extended to distributed memory. First, we introduce lifeline graphs: low-degree, low-diameter, fully connected directed graphs. Such graphs can be constructed from  k -dimensional hypercubes. When a node is unable to find work after w unsuccessful steals, it quiesces after informing the outgoing edges in its lifeline graph. Quiescent nodes do not disturb other nodes. A quiesced node is reactivated when work arrives from a lifeline and itself shares this work with those of its incoming lifelines that are activated. Termination occurs precisely when computation at all nodes has quiesced. In a language such as X10, such passive distributed termination can be detected automatically using the finish construct -- no application code is necessary.   Our design is implemented in a few hundred lines of X10. On the binomial tree described in olivier:08}, the program achieve 87% efficiency on an Infiniband cluster of 1024 Power7 cores, with a peak throughput of 2.37 GNodes/sec. It achieves 87% efficiency on a Blue Gene/P with 2048 processors, and a peak throughput of 0.966 GNodes/s. All numbers are relative to single core sequential performance. This implementation has been refactored into a reusable global load balancing framework. Applications can use this framework to obtain global load balance with minimal code changes.   In summary, we claim: (a) the first formulation of UTS that does not involve application level global termination detection, (b) the introduction of lifeline graphs to reduce failed steals (c) the demonstration of simple lifeline graphs based on k-hypercubes, (d) performance with superior efficiency (or the same efficiency but over a wider range) than published results on UTS. In particular, our framework can deliver the same or better performance as an unrestricted random work-stealing implementation, while reducing the number of attempted steals."
1494999,15258,11330,Imogen: a parallel 3D fluid and MHD code for GPUs,2013,"We present Imogen, a fully parallel code for simulating either the Euler or Ideal MHD equations, in two or three dimensions, on GPUs and GPU clusters. Fluid dynamic codes have historically been written entirely in either Fortran or C/C++. Imogen combines the power of GPU acceleration and compiled CUDA solver modules under the hood with the ease of development, ease of use, and ease of modification characteristic of interpreted languages as everything but the core numeric routines is written in Matlab.   Our basic goal of writing a highly parallel and fast fluid simulation code driven by Matlab which is GPU accelerated and fully parallel has been largely achieved at this time. We have tested simulations with up to 350 million cells using as many as 50 GPUs on the University of Oregon's ACISS supercomputer, and see no technical reason we could not use many more. Depending on the complexity of the physics used, a single C2070 device can handle as many as 25 million computation cells and still achieve simulation rates as high as a few seconds per timestep. Even though the code runs in an interpreted environment, we have found that interpretation overhead is quite small. Tests simulations with a resolution of 8 3  found roughly 80ms per complete iteration of overhead on a test workstation, which would be no more than a few percent of the time used by a large simulation.   We use a standard fluid scheme neatly summarized in [1] and the exactly ∇ • Β preserving magnetic update algorithm of [2]. Fluid and MHD problems are tested against Imogen and we find that its convergence is second order in both space and time. Because Imogen is a relatively new code, implementation and testing of support for extended physics is a continuous and ongoing process. The use of operator splitting means that new non-ideal effects can be implemented and tested without amending the fluid code.   The structures which kernels follow depending on the specifics of the finite differencing they will be undertaking is examined for patterns. Common errors encountered in the development process are explored.   In addition, work in progress on the application of Imogen to research into two astrophysical phenomenon, accretion shocks and the protostellar disks, is briefly presented. The linear instability of MHD shock waves for many/most possible parameters is established, and while there has been nonlinear work [3] it appears to largely be assumed that the distortion will keep growing and completely destroy the shock front in the nonlinear regime; We have observed severe distortion but have not seen a breakup. We also present early experiments in applying Imogen to differentially rotating disks."
1543081,15258,8806,Creating heterogeneity at run time by dynamic cache and bandwidth partitioning schemes,2014,"A heterogeneous chip multiprocessor (CMP) architecture consists of processor cores and caches of varying size and complexity. In a multi-programmed computing environment, threads of execution exhibit different run time characteristics and hardware resource requirements. So heterogeneous multiprocessor significantly out perform homogeneous multiprocessor system. Issues in designing and managing heterogeneity in multiprocessor have significant impact on overall system cost and performance. These issues are (a) replicating standard cores is an efficient strategy in homogeneous CMP design but in heterogeneous CMP architecture, particularly a fully custom heterogeneous processor not necessarily composed of pre-existing cores, incurs additional costs in design, verification, and testing, (b) in order to take advantage of a heterogeneous architecture, an appropriate policy to map running tasks to processor cores must be determined to maximize the performance of the whole system by accurately exploiting its resources, so a very good software scheduler require to take advantage of heterogeneity, and (c) processor speeds are improving at a much faster than the memories speed, as a result the data access time dominates the execution times of many programs. And in multiprocessor environment this gap increasing, as core count in chip multiprocessor increase, on-chip cache and also the off-chip memory bandwidth get scarcer to the cores.   In this paper, we propose a method of creating heterogeneity at run time by partitioning cache and memory bandwidth. In this case, we can take advantage of using pre-existing standard core in designing multiprocessor and a use of basic scheduler with out considering heterogeneity as heterogeneity is created at run time by partitioning cache and bandwidth. Also we have described a method of creating heterogeneity of system by coordinated partitioning of shared last level cache and off-chip memory bandwidth. We have proposed an efficient low overhead approach to partition the cache based on set wise partitioning by separating addressing part and data part, and along with graceful space acquirement policy. This approach quickly re-partitions the cache with minimum overhead and with smaller granularity. Also we have extended the bandwidth partition model which is based on CPI model to handle read/write access behavior of applications. Finally we have analyzed and experimentally evaluated six different cache partitioning schemes and concluded that partition based on available bandwidth partitioning and access frequency of L2 out perform others."
1742027,15258,22260,Combining Partial Redundancy and Checkpointing for HPC,2012,"Today's largest High Performance Computing (HPC) systems exceed one Petaflops (10^15) floating point operations per second) and exascale systems are projected within seven years. But reliability is becoming one of the major challenges faced by exascale computing. With billion-core parallelism, the mean time to failure is projected to be in the range of minutes or hours instead of days. Failures are becoming the norm rather than the exception during execution of HPC applications. Current fault tolerance techniques in HPC focus on reactive ways to mitigate faults, namely via checkpoint and restart (C/R). Apart from storage overheads, C/R-based fault recovery comes at an additional cost in terms of application performance because normal execution is disrupted when checkpoints are taken. Studies have shown that applications running at a large scale spend more than 50% of their total time saving checkpoints, restarting and redoing lost work. Redundancy is another fault tolerance technique, which employs redundant processes performing the same task. If a process fails, a replica of it can take over its execution. Thus, redundant copies can decrease the overall failure rate. The downside of redundancy is that extra resources are required and there is an additional overhead on communication and synchronization. This work contributes a model and analyzes the benefit of C/R in coordination with redundancy at different degrees to minimize the total wall clock time and resources utilization of HPC applications. We further conduct experiments with an implementation of redundancy within the MPI layer on a cluster. Our experimental results confirm the benefit of dual and triple redundancy -- but not for partial redundancy -- and show a close fit to the model. At ~80,000 processes, dual redundancy requires twice the number of processing resources for an application but allows two jobs of 128hours wall clock time to finish within the time of just one job without redundancy. For narrow ranges of processor counts, partial redundancy results in the lowest time. Once the count exceeds ~770,000, triple redundancy has the lowest overall cost. Thus, redundancy allows one to trade-off additional resource requirements against wall clock time, which provides a tuning knob for users to adapt to resource availabilities."
1500541,15258,11330,Author retrospective for optimizing matrix multiply using PHiPAC: a portable high-performance ANSI C coding methodology,2014,"PHiPAC was an early attempt to improve software performance by searching in a large design space of possible implementations to find the best one. At the time, in the early 1990s, the most efficient numerical linear algebra libraries were carefully hand tuned for specific microarchitectures and compilers, and were often written in assembly language. This allowed very precise tuning of an algorithm to the specifics of a current platform, and provided great opportunity for high efficiency. The prevailing thought at the time was that such an approach was necessary to produce near-peak performance. On the other hand, this approach was brittle, and required great human effort to try each code variant, and so only a tiny subset of the possible code design points could be explored. Worse, given the combined complexities of the compiler and microarchitecture, it was difficult to predict which code variants would be worth the implementation effort.   PHiPAC circumvented this effort by using code generators that could easily generate a vast assortment of very different points within a design space, and even across very different design spaces altogether. By following a set of carefully crafted coding guidelines, the generated code was reasonably efficient for any point in the design space. To search the design space, PHiPAC took a rather naive but effective approach. Due to the human-designed and deterministic nature of computing systems, one might reasonably think that smart modeling of the microprocessor and compiler would be sufficient to predict, without performing any timing, the optimal point for a given algorithm. But the combination of an optimizing compiler and a dynamically scheduled microarchitecture with multiple levels of cache and prefetching results in a very complex, highly non-linear system. Small changes in the code can cause large changes in performance, thwarting smart search algorithms that attempt to build models of the performance surface. PHiPAC instead used massive, diverse, offline, and only loosely informed grid or randomized search, where each point was evaluated by empirically measuring the code running on the machine, which succeeded due to its indifference to the shape of the performance surface."
2494836,15258,20774,Cache-conscious scheduling of streaming applications,2012,"This paper considers the problem of scheduling streaming applications on uniprocessors in order to minimize the number of cache-misses. Streaming applications are represented as a directed graph (or multigraph), where nodes are computation modules and edges are channels. When a module fires, it consumes some data-items from its input channels and produces some items on its output channels. In addition, each module may have some state (either code or data) which represents the memory locations that must be loaded into cache in order to execute the module. We consider synchronous dataflow graphs where the input and output rates of modules are known in advance and do not change during execution. We also assume that the state size of modules is known in advance.   Our main contribution is to show that for a large and important class of streaming computations, cache-efficient scheduling is essentially equivalent to solving a constrained graph partitioning problem. A streaming computation from this class has a cache-efficient schedule if and only if its graph has a low-bandwidth partition of the modules into components (subgraphs) whose total state fits within the cache, where the bandwidth of the partition is the number of data items that cross intercomponent channels per data item that enters the graph.   Given a good partition, we describe a runtime strategy for scheduling two classes of streaming graphs: pipelines, where the graph consists of a single directed chain, and a fairly general class of directed acyclic graphs (dags) with some additional restrictions. The runtime scheduling strategy consists of adding large external buffers at the input and output edges of each component, allowing each component to be executed many times. Partitioning enables a reduction in cache misses in two ways. First, any items that are generated on edges internal to subgraphs are never written out to memory, but remain in cache. Second, each subgraph is executed many times, allowing the state to be reused.   We prove the optimality of this runtime scheduling for all pipelines and for dags that meet certain conditions on buffer-size requirements. Specifically, we show that with constant-factor memory augmentation, partitioning on these graphs guarantees the optimal number of cache misses to within a constant factor. For the pipeline case, we also prove that such a partition can be found in polynomial time. For the dags we prove optimality if a good partition is provided; the partitioning problem itself is NP-complete."
941391,15258,23836,GPU-Based Steady-State Solution of the Chemical Master Equation,2013,"The Chemical Master Equation (CME) is a stochastic and discrete-state continuous-time model for macromolecular reaction networks inside the cell. Under this theoretical framework, the solution of a sparse linear system provides the steady-state probability landscape over the molecular microstates. The CME framework can in fact reveal important insights into basic principles on how biological networks function, having critical applications in stem cell study and cancer development. However, the exploratory nature of system biology research involves the solution of the same reaction network under different conditions. As a result, the application of the CME framework is feasible only if we are able to solve several large linear systems in a reasonable amount of time. In recent years, GPU has emerged as a cost-effective high performance architecture easily available to bioscientists around the world. In this paper, we propose an efficient GPUbased Jacobi iteration for steady-state probability calculation. We provide several optimization strategies based on the problem structure with the aim of outperforming the conventional multicore implementation while minimizing the GPU memory footprint. We combine an ELL+DIAG sparse matrix format with DFS ordering to leverage the diagonal density. Moreover, we devise an improved sliced ELL sparse matrix representation based on warp granularity and local rearrangement. Experimental results demonstrate an average double-precision performance of 14.212 GFLOPS in solving the CME (a speedup of 15.67x compared to the optimized Intel MKL library). Our implementation of the warp-grained sliced ELL format outperforms the state-of-the-art in terms of SpMV performance (a speedup of 1.24x over clSpMV). Moreover, it shows consistent improvements for a wider set of application domains and a good memory footprint reduction. The results achieved in this work provide the foundation for applying the CME framework to realistic biochemical systems. In addition, our GPU-based steady-state computation can be generalized to operation on stochastic matrices (Markov models), achieving good performance with matrix structures similar to biological reaction networks."
1424961,15258,11330,"Author retrospective for array expansion, array shrinking, or there and back again",2014,"In the late 1980's, I was recovering from a long stint as the manager of Paris University computing facility (yes, there were still computing facilities, and PCs were just coming of age) and I was teaching old fashioned automatic parallelization to postgraduate students. I had heard of scalar expansion and privatization, and it was a natural question whether it could be extended to arrays. I first concocted partial solutions - for instance, valid only for the innermost loop - and then decided to try for the general case: converting array accesses to single assignment form. I soon realized that this implied finding the source, or last write before a given read, and that the solution must be a function of the position of the read in the temporal execution of the program. It was obvious that this could not be done for arbitrary complex programs, hence I specified a set of restriction: the polyhedral model. I also introduced the execution order, now known as the 'happens-before' relation. Finding the last write then became an integer programming problem with some unfamiliar features: lexicographic order took the place of the economic function, the problem had to be solved exactly, and the coordinates of the read operation were acting as parameters. Hence, I had first to build PIP (a parametric integer programming tool [2]) before solving my problem. PIP was developed on a 80286 PC, using Borland TurboC and LeLisp.   It then took me about two years to have an improved form of the ICS paper published by a journal [3]. Here, the emphasis was more on single assignment conversion and its use for program comprehension. I also formalized a comparison algorithm, which is needed when there are several potential sources. But it was not until [4] that I managed to prove its termination.   Meanwhile, the ICS paper had attracted attention from the other side of the Atlantic. Most important was Bill Pugh's work [6], in which the problem was reformulated in term of affine relations, and solved by Bill's own linear programming tool, Omega. I remember that we exchanged our benchmarks, and found that our results were equivalent. An early example of reproducible research!!"
727427,15258,8306,The role of optics in future high radix switch design,2011,"For large-scale networks, high-radix switches reduce hop and switch count, which decreases latency and power. The ITRS projections for signal-pin count and per-pin bandwidth are nearly flat over the next decade, so increased radix in electronic switches will come at the cost of less per-port bandwidth. Silicon nanophotonic technology provides a long-term solution to this problem. We first compare the use of photonic I/O against an all-electrical, Cray YARC inspired baseline. We compare the power and performance of switches of radix 64, 100, and 144 in the 45, 32, and 22 nm technology steps. In addition with the greater off-chip bandwidth enabled by photonics, the high power of electrical components inside the switch becomes a problem beyond radix 64.   We propose an optical switch architecture that exploits highspeed optical interconnects to build a flat crossbar with multiplewriter, single-reader links. Unlike YARC, which uses small buffers at various stages, the proposed design buffers only at input and output ports. This simplifies the design and enables large buffers, capable of handling ethernet-size packets. To mitigate head-of-line blocking and maximize switch throughput, we use an arbitration scheme that allows each port to make eight requests and use two grants. The bandwidth of the optical crossbar is also doubled to to provide a 2x internal speedup. Since optical interconnects have high static power, we show that it is critical to balance the use of optical and electrical components to get the best energy efficiency. Overall, the adoption of photonic I/O allows 100,000 port networks to be constructed with less than one third the power of equivalent all-electronic networks. A further 50% reduction in power can be achieved by using photonics within the switch components. Our best optical design performs similarly to YARC for small packets while consuming less than half the power, and handles 80% more load for large message traffic."
2230875,15258,23836,Radio Astronomy Beam Forming on Many-Core Architectures,2012,"Traditional radio telescopes use large steel dishes to observe radio sources. The largest radio telescope in the world, LOFAR, uses tens of thousands of fixed, omni-directional antennas instead, a novel design that promises ground-breaking research in astronomy. Where traditional tele-scopes use custom-built hardware, LOFAR uses software to do signal processing in real time. This leads to an instrument that is inherently more flexible. However, the enormous data rates and processing requirements (tens to hundreds of teraflops) make this extremely challenging. The next-generation telescope, the SKA, will require exa flops. Unlike traditional instruments, LOFAR and SKA can observe in hundreds of directions simultaneously, using beam forming. This is useful, for example, to search the sky for pulsars (i.e. rapidly rotating highly magnetized neutron stars). Beam forming is an important technique in signal processing: it is also used in WIFI and 4G cellular networks, radar systems, and health-care microwave imaging instruments. We propose the use of many-core architectures, such as 48-core CPU systems and Graphics Processing Units (GPUs), to accelerate beam forming. We use two different frameworks for GPUs, CUDA and Open CL, and present results for hardware from different vendors (i.e. AMD and NVIDIA). Additionally, we implement the LOFAR beam former on multi-core CPUs, using Open MP with SSE vector instructions. We use auto-tuning to support different architectures and implementation frameworks, achieving both platform and performance portability. Finally, we compare our results with the production implementation, written in assembly and running on an IBM Blue Gene/P supercomputer. We compare both computational and power efficiency, since power usage is one of the fundamental challenges modern radio telescopes face. Compared to the production implementation, our auto-tuned beam former is 45 -- 50 times faster on GPUs, and 2 -- 8 times more power efficient. Our experimental results lead to the conclusion that GPUs are an attractive solution to accelerate beam forming."
1959513,15258,122,Efficient performance evaluation of memory hierarchy for highly multithreaded graphics processors,2012,"With the emergence of highly multithreaded architectures, performance monitoring techniques face new challenges in efficiently locating sources of performance discrepancies in the program source code. For example, the state-of-the-art performance counters in highly multithreaded graphics processing units (GPUs) report only the overall occurrences of microarchitecture events at the end of program execution. Furthermore, even if supported, any fine-grained sampling of performance counters will distort the actual program behavior and will make the sampled values inaccurate. On the other hand, it is difficult to achieve high resolution performance information at low sampling rates in the presence of thousands of concurrently running threads. In this paper, we present a novel software-based approach for monitoring the memory hierarchy performance in highly multithreaded general-purpose graphics processors. The proposed analysis is based on memory traces collected for snapshots of an application execution. A trace-based memory hierarchy model with a Monte Carlo experimental methodology generates statistical bounds of performance measures without being concerned about the exact inter-thread ordering of individual events but rather studying the behavior of the overall system. The statistical approach overcomes the classical problem of disturbed execution timing due to fine-grained instrumentation. The approach scales well as we deploy an efficient parallel trace collection technique to reduce the trace generation overhead and a simple memory hierarchy model to reduce the simulation time. The proposed scheme also keeps track of individual memory operations in the source code and can quantify their efficiency with respect to the memory system. A cross-validation of our results shows close agreement with the values read from the hardware performance counters on an NVIDIA Tesla C2050 GPU. Based on the high resolution profile data produced by our model we optimized memory accesses in the sparse matrix vector multiply kernel and achieved speedups ranging from 2.4 to 14.8 depending on the characteristics of the input matrices."
2328513,15258,9772,C-Hint: An Effective and Reliable Cache Management for RDMA-Accelerated Key-Value Stores,2014,"Recently, many in-memory key-value stores have started using a High-Performance network protocol, Remote Direct Memory Access (RDMA), to provision ultra-low latency access services. Among various solutions, previous studies have recognized that leveraging RDMA Read to optimize GET operations and continuing using message passing for other requests can offer tremendous performance improvement while avoiding read-write races. However, although such a design can utilize the power of RDMA when there is sufficient memory space, it has also raised new challenges on the cache management that do not exist in traditional key-value stores. First, RDMA Read deprives servers of the awareness of the read operations. Therefore, how to track popular items and make replacement decisions at the server side becomes a critical issue. Second, without the access knowledge from the clients, new approaches are needed for servers to efficiently and reliably reclaim the resources. Lastly, the remote pointers hold by clients to conduct RDMA are highly susceptible to the evictions made by remote servers. Thus, any replacement algorithm that solely considers the server-side hit ratio is insufficient and can cause severe underutilization of RDMA.   In this work, we present C-Hint, an efficient and reliable cache management system that is designed to address the above three challenges. Its basic mechanism relies on a holistic design of the servers and the clients to orchestrate the access history information. Specifically, it consists of several techniques, including lease-based key-value management, popularity differentiated lease assignment, as well as several optimizations to achieve efficient and reliable cache management. We have implemented and integrated C-Hint into an in-house memory-resident key-value store, named HydraDB, and systematically evaluated its performance on an InfiniBand cluster with different workloads. Our experiment results demonstrate that C-Hint can efficiently outperform several other alternate solutions and deliver both high hit rate and low latency performance."
2172797,15258,11157,Parabix: Boosting the efficiency of text processing on commodity processors,2012,"Modern applications employ text files widely for providing data storage in a readable format for applications ranging from database systems to mobile phones. Traditional text processing tools are built around a byte-at-a-time sequential processing model that introduces significant branch and cache miss penalties. Recent work has explored an alternative, transposed representation of text, Parabix (Parallel Bit Streams), to accelerate scanning and parsing using SIMD facilities. This paper advocates and develops Parabix as a general framework and toolkit, describing the software toolchain and run-time support that allows applications to exploit modern SIMD instructions for high performance text processing. The goal is to generalize the techniques to ensure that they apply across a wide variety of applications and architectures. The toolchain enables the application developer to write constructs assuming unbounded character streams and Parabix's code translator generates code based on machine specifics (e.g., SIMD register widths). The general argument in support of Parabix technology is made by a detailed performance and energy study of XML parsing across a range of processor architectures. Parabix exploits intra-core SIMD hardware and demonstrates 2×–7× speedup and 4× improvement in energy efficiency when compared with two widely used conventional software parsers, Expat and Apache-Xerces. SIMD implementations across three generations of x86 processors are studied including the new SandyBridge. The 256-bit AVX technology in Intel SandyBridge is compared with the well established 128-bit SSE technology to analyze the benefits and challenges of 3-operand instruction formats and wider SIMD hardware. Finally, the XML program is partitioned into pipeline stages to demonstrate that thread-level parallelism enables the application to exploit SIMD units scattered across the different cores, achieving improved performance (2× on 4 cores) while maintaining single-threaded energy levels."
837768,15258,23836,Acceleration of a Python-Based Tsunami Modelling Application via CUDA and OpenHMPP,2014,"Modern graphics processing units (GPUs) have became powerful and cost-effective computing platforms. Parallel programming standards (e.g. CUDA) and directive-based programming standards (like OpenHMPP and OpenACC) are available to harness this tremendous computing power to tackle largescale modelling and simulation in scientific areas. ANUGA is a tsunami modelling application which is based on unstructured triangular meshes and implemented in Python/C. This paper explores issues in porting and optimizing a Python/C-based unstructured mesh application to GPUs. Two paradigms are compared: CUDA via the PyCUDA API, involving writing GPU kernels, and OpenHMPP, involving adding directives to C code. In either case, the ‘naive’ approach of transferring unstructured mesh data to the GPU for each kernel resulted in an actual slowdown over single core performance on a CPU. Profiling results confirmed that this is due to data transfer times of the device to/from the host, even though all individual kernels achieved a good speedup. This necessitated an advanced approach, where all key data structures are mirrored on the host and the device. For both paradigms, this in turn involved converting all code updating these data structures to CUDA (or directive-augmented C, in the case of OpenHMPP). Furthermore, in the case of CUDA, the porting can no longer be done incrementally: all changes must be made in a single step. For debugging, this makes identifying which kernel(s) that have introduced bugs very difficult. To alleviate this, we adopted the relative debugging technique to the host-device context. Here, when in debugging mode, the mirrored data structures are updated upon each step on both the host (using the original serial code) and the device, with any discrepancy being immediately detected. We present a generic Python-based implementation of this technique. With this approach, the CUDA version achieved 2x speedup, and the OpenHMPP achieved 1.6x. The main optimization of unstructured mesh rearrangement to achieve coalesced memory access patterns contributed to 10% of the former. In terms of productivity, however, OpenHMPP achieved significantly better speedup per hour of programming effort."
2172371,15258,23836,A Novel Power Management for CMP Systems in Data-Intensive Environment,2011,"The emerging data-intensive applications of today are comprised of non-uniform CPU and I/O intensive workloads, thus imposing a requirement to consider both CPU and I/O effects in the power management strategies. Only scaling down the processor's frequency based on its busy/idle ratio cannot fully exploit opportunities of saving power. Our experiments show that besides the busy and idle status, each processor may also have I/O wait phases waiting for I/O operations to complete. During this period, the completion time is decided by the I/O subsystem rather than the CPU thus scaling the processor to a lower frequency will not affect the performance but save more power. In addition, the CPU's reaction to the I/O operations may be significantly affected by several factors, such as I/O type (sync or unsync), instruction/job level parallelism, it cannot be accurately modeled via physics laws like mechanical or chemical systems. In this paper, we propose a novel power management scheme called MAR (modeless, adaptive, rule-based) in multiprocessor systems to minimize the CPU power consumption under performance constraints. By using richer feedback factors, e.g. the I/O wait, MAR is able to accurately describe the relationships among core frequencies, performance and power consumption. We adopt a modeless control model to reduce the complexity of system modeling. MAR is designed for CMP (Chip Multi Processor) systems by employing multi-input/multi-output (MIMO) theory and per core level DVFS (Dynamic Voltage and Frequency Scaling). Our extensive experiments on a physical test bed demonstrate that, for the SPEC benchmark and data-intensive (TPC-C) benchmark, the efficiency of MAR is 93.6-96.2\% accurate to the ideal power saving strategy calculated off-line. Compared with baseline solutions, MAR could save 22.5-32.5\% more power while keeping the comparable performance loss of about 1.8-2.9\%. In addition, simulation results show the efficiency of our design for various CMP configurations."
856931,15258,9836,Efficient multiprogramming for multicores with SCAF,2013,"As hardware becomes increasingly parallel and the availability of scalable parallel software improves, the problem of managing multiple multithreaded applications (processes) becomes important.  Malleable  processes, which can vary the number of threads used as they run, enable sophisticated and flexible resource management. Although many existing applications parallelized for SMPs with parallel runtimes are in fact already malleable, deployed run-time environments provide no interface nor any strategy for intelligently allocating hardware threads or even preventing oversubscription. Work up until SCAF either depends upon profiling applications ahead of time in order to make good decisions about allocations, or does not account for process efficiency at all. This paper presents the  S cheduling and  A llocation with  F eedback (SCAF) system, a drop-in runtime solution which supports existing malleable applications in making intelligent allocation decisions based on observed efficiency without any paradigm change, changes to semantics, program modification, offline profiling, or even recompilation. Our existing implementation can control most unmodified OpenMP applications. Other malleable threading libraries can also easily be supported with small modifications, without requiring application modification.   In this work, we present the SCAF daemon and a SCAF-aware port of the GNU OpenMP runtime. We demonstrate that applications running on the SCAF runtime still perform well when executing on a quiescent system. We present a new technique for estimating process efficiency purely at runtime using available hardware counters, and demonstrate its effectiveness in aiding allocation decisions.   We evaluated SCAF using NAS NPB parallel benchmarks. When run concurrently pairwise, 70% of benchmark pairs on an 8-core Xeon processor saw improvements averaging 15% in sum of speedups compared to equipartitioning. For a 64-context Sparc T2 processor, 57% of pairs saw a similar 15% improvement. The improvement was 45% vs. equipartitioning when three selected benchmarks were concurrently run."
2474959,15258,9836,Efficient management of last-level caches in graphics processors for 3D scene rendering workloads,2013,"Three-dimensional (3D) scene rendering is implemented in the form of a pipeline in graphics processing units (GPUs). In different stages of the pipeline, different types of data get accessed. These include, for instance, vertex, depth, stencil, render target (same as pixel color), and texture sampler data. The GPUs traditionally include small caches for vertex, render target, depth, and stencil data as well as multi-level caches for the texture sampler units. Recent introduction of reasonably large last-level caches (LLCs) shared among these data streams in discrete as well as integrated graphics hardware architectures has opened up new opportunities for improving 3D rendering. The GPUs equipped with such large LLCs can enjoy far-flung intra- and inter-stream reuses. However, there is no comprehensive study that can help graphics cache architects understand how to effectively manage a large multi-megabyte LLC shared between different 3D graphics streams.   In this paper, we characterize the intra-stream and inter-stream reuses in 52 frames captured from eight DirectX game titles and four DirectX benchmark applications spanning three different frame resolutions. Based on this characterization, we propose graphics stream-aware probabilistic caching (GSPC) that dynamically learns the reuse probabilities and accordingly manages the LLC of the GPU. Our detailed trace-driven simulation of a typical GPU equipped with 768 shader thread contexts, twelve fixed-function texture samplers, and an 8 MB 16-way LLC shows that GSPC saves up to 29.6% and on average 13.1% LLC misses across 52 frames compared to the baseline state-of-the-art two-bit dynamic re-reference interval prediction (DRRIP) policy. These savings in the LLC misses result in a speedup of up to 18.2% and on average 8.0%. On a 16 MB LLC, the average speedup achieved by GSPC further improves to 11.8% compared to DRRIP."
2696329,15258,20358,Relevant change detection: a framework for the precise extraction of modified and novel web-based content as a filtering technique for analysis engines,2014,"Tracking the evolution of websites has become fundamental to the understanding of today's Internet. The automatic reasoning of how and why websites change has become essential to developers and businesses alike, in particular because the manual reasoning has become impractical due to the sheer number of modifications that websites undergo during their operational lifetime, including but not limited to rotating advertisements, personalized content, insertion of new content, or removal of old content. Prior work in the area of change detection, such as XyDiff, X-Diff or AT&T's internet difference engine, focused mainly on ``diffing'' XML-encoded literary documents or XML-encoded databases. Only some previous work investigated the differences that must be taken into account to accurately extract the difference between HTML documents for which the markup language does not necessarily describe the content but is used to describe how the content is displayed instead. Additionally, prior work identifies all changes to a website, even those that might not be relevant to the overall analysis goal, in turn, they unnecessarily burden the analysis engine with additional workload.   In this paper, we introduce a novel analysis framework, the Delta framework, that works by (i) extracting the modifications between two versions of the same website using a fuzzy tree difference algorithm, and (ii) using a machine-learning algorithm to derive a model of relevant website changes that can be used to cluster similar modifications to reduce the overall workload imposed on an analysis engine. Based on this model for example, the tracked content changes can be used to identify ongoing or even inactive web-based malware campaigns, or to automatically learn semantic translations of sentences or paragraphs by analyzing websites that are available in multiple languages.   In prior work, we showed the effectiveness of the Delta framework by applying it to the detection and automatic identification of web-based malware campaigns on a data set of over 26 million pairs of websites that were crawled over a time span of four months. During this time, the system based on our framework successfully identified previously unknown web-based malware campaigns, such as a targeted campaign infecting installations of the Discuz!X Internet forum software."
424186,15258,9748,HPC Performance and Energy-Efficiency of the OpenStack Cloud Middleware,2014,"Since its advent in the middle of the 2000's, the Cloud Computing (CC) paradigm is increasingly advertised as THE solution to most IT problems. While High Performance Computing (HPC) centers continuously evolve to provide more computing power to their users, several voices (most probably commercial ones) emit the wish that CC platforms could also serve HPC needs and eventually replace in-house HPC platforms. However, it is still unclear whether the overhead induced by the virtualization layer at the heart of every Cloud middleware suits an environment as high-demanding as an HPC platform. In parallel, with a growing concern for the considerable energy consumed by HPC platforms and data centers, research efforts are targeting green approaches with higher energy efficiency. At this level, virtualization is also emerging as the prominent approach to reduce the energy consumed by consolidating multiple running VM instances on a single server, thus giving credit towards a Cloud-based approach. In this paper, we analyze from an HPC perspective the performance and the energy efficiency of the leading open source Cloud middleware, OpenStack, when compared to a bare-metal (i.e. native) configuration. The conducted experiments were performed on top of the Grid'5000 platform with benchmarking tools that reflect regular HPC workloads, i.e. HPCC (which includes the reference HPL bench-mark) and Graph500. Power measurements were also performed in order to quantify the potential energy efficiency of the tested configurations, using the approaches proposed in the Green500 and GreenGraph500 projects. In order to abstract from the specifics of a single architecture, the benchmarks were run using two different hardware configurations, based on Intel and AMD processors. This work extends previous studies dedicated to the evaluation of hypervisors against HPC workloads. The results of this study pleads for in-house HPC platforms running without any virtualized frameworks, assessing that the current implementation of Cloud middleware is not well adapted to the execution of HPC applications."
814084,15258,22288,Optimizing Sequence Alignment in Cloud Using Hadoop and MPP Database,2012,"In bioinformatics, a sequence alignment is a way of arranging the sequences of DNA, RNA, or protein to identify regions of similarity that may be a consequence of functional, structural, or evolutionary relationships between the sequences. This information can effectively be used for medical and biological research only if one can extract functional insight from it. To obtain functional insight the factors to be considered while aligning sequences are: optimized querying of sequences, high speed matching and accuracy of alignment. The FAST-All (FASTA) for both proteins and nucleotides program considers all these factors and follows a largely heuristic method, which contributes to the high speed of its execution. The program initially observes the pattern of word hits, word-to-word matches of a given length, and marks potential matches rather than performing a more time-consuming, optimized search using a Smith-Waterman type of algorithm. In this paper, we propose an optimized approach to sequence alignment using FASTA algorithm, which incorporates high speed word-to-word matching. In the current scenario where data growth is in petabytes a day and processing requires state of the art technologies, Greenplum Massively Parallel Processing (MPP) database and Hadoop are emerging parallel technologies which form the backbone of this proposal. The complex nature of the algorithm, coupled with data and computational parallelism of Hadoop grid and Massively Parallel Processing database for querying from big datasets containing petabytes of sequences, improves the accuracy, speed of sequence alignment and optimizes querying from big datasets. Bioinformatics labs and centers across the globe today upload enormous amount of data and sequences in a central location for the scientific analysis. The transfer of such large datasets can also be simplified with Cloud approaches. So, Cloud Computing Technology is used in our implementation for the ease of gathering such sequences and data from various sources like medical research centers, scientists and biomedical labs around the globe. A plan for the final publicly consumable form of the program is to make it web-based and running on the Cloud."
1961600,15258,9748,Memcached Design on High Performance RDMA Capable Interconnects,2011,"Memcached is a key-value distributed memory object caching system. It is used widely in the data-center environment for caching results of database calls, API calls or any other data. Using Memcached, spare memory in data-center servers can be aggregated to speed up lookups of frequently accessed information. The performance of Memcached is directly related to the underlying networking technology, as workloads are often latency sensitive. The existing Memcached implementation is built upon BSD Sockets interface. Sockets offers byte-stream oriented semantics. Therefore, using Sockets, there is a conversion between Memcached's memory-object semantics and Socket's byte-stream semantics, imposing an overhead. This is in addition to any extra memory copies in the Sockets implementation within the OS. Over the past decade, high performance interconnects have employed Remote Direct Memory Access (RDMA) technology to provide excellent performance for the scientific computation domain. In addition to its high raw performance, the memory-based semantics of RDMA fits very well with Memcached's memory-object model. While the Sockets interface can be ported to use RDMA, it is not very efficient when compared with low-level RDMA APIs. In this paper, we describe a novel design of Memcached for RDMA capable networks. Our design extends the existing open-source Memcached software and makes it RDMA capable. We provide a detailed performance comparison of our Memcached design compared to unmodified Memcached using Sockets over RDMA and 10Gigabit Ethernet network with hardware-accelerated TCP/IP. Our performance evaluation reveals that latency of Memcached Get of 4KB size can be brought down to 12 µs using ConnectX InfiniBand QDR adapters. Latency of the same operation using older generation DDR adapters is about 20µs. These numbers are about a factor of four better than the performance obtained by using 10GigE with TCP Offload. In addition, these latencies of Get requests over a range of message sizes are better by a factor of five to ten compared to IP over InfiniBand and Sockets Direct Protocol over InfiniBand. Further, throughput of small Get operations can be improved by a factor of six when compared to Sockets over 10 Gigabit Ethernet network. Similar factor of six improvement in throughput is observed over Sockets Direct Protocol using ConnectX QDR adapters. To the best of our knowledge, this is the first such memcached design on high performance RDMA capable interconnects."
1942763,15258,23836,A Comprehensive Study of Task Coalescing for Selecting Parallelism Granularity in a Two-Stage Bidiagonal Reduction,2012,"We present new high performance numerical kernels combined with advanced optimization techniques that significantly increase the performance of parallel bidiagonal reduction. Our approach is based on developing efficient fine-grained computational tasks as well as reducing overheads associated with their high-level scheduling during the so-called bulge chasing procedure that is an essential phase of a scalable bidiagonalization procedure. In essence, we coalesce multiple tasks in a way that reduces the time needed to switch execution context between the scheduler and useful computational tasks. At the same time, we maintain the crucial information about the tasks and their data dependencies between the coalescing groups. This is the necessary condition to preserve numerical correctness of the computation. We show our annihilation strategy based on multiple applications of single orthogonal reflectors. Despite non-trivial characteristics in computational complexity and memory access patterns, our optimization approach smoothly applies to the annihilation scenario. The coalescing positively influences another equally important aspect of the bulge chasing stage: the memory reuse. For the tasks within the coalescing groups, the data is retained in high levels of the cache hierarchy and, as a consequence, operations that are normally memory-bound increase their ratio of computation to off-chip communication and become compute-bound which renders them amenable to efficient execution on multicore architectures. The performance for the new two-stage bidiagonal reduction is staggering. Our implementation results in up to 50-fold and 12-fold improvement (~130 Gflop/s) compared to the equivalent routines from LAPACK V3.2 and Intel MKL V10.3, respectively, on an eight socket hexa-core AMD Opteron multicore shared-memory system with a matrix size of 24000 &#x00D7; 24000. Last but not least, we provide a comprehensive study on the impact of the coalescing group size in terms of cache utilization and power consumption in the context of this new two-stage bidiagonal reduction."
1994973,15258,22288,MADMAC: Multiple Attribute Decision Methodology for Adoption of Clouds,2011,"Cloud Adoption decisions tend to involve multiple, conflicting criteria (attributes) with incommensurable units of measurements, which must be compared among multiple alternatives using imprecise and incomplete available information. Multi-attribute Decision Making (MADM) has been shown to provide a rational basis to aid decision making in such scenarios. We present a MADMAC framework for cloud adoption, consisting of 3 Decision Areas (DA) referred to as the Cloud Switch, Cloud Type and Vendor Choice. It requires the definition of Attributes, Alternatives and Attribute Weights, to construct a Decision Matrix and arrive at a relative ranking to identify the optimal alternative. We also present a taxonomy organized in a two level hierarchy: Server-centric clouds, Client-centric clouds and Mobile-centric clouds, which further map to detailed, specific applications or workloads. DSS presented showing algorithms derived from MADMAC can compute and optimize CA decisions separately for the three stages, where the attributes differently influence CA decisions. A modified Wide-band Delphi method is proposed for assessing the relative weights for each attribute, by workload. Relative ranks are calculated using these weights, and the Simple Additive Weighting (SAW) method is used to generate value functions for all the alternatives, and rank the alternatives by their value to finally choose the best alternative. Results from application of the method to four different types of workloads show that the method converges on reasonable cloud adoption decisions. MADMAC's key advantage is its fully quantitative and iterative convergence approach based on proven multi-attribute decision methods, which enables decision makers to comparatively assess the relative robustness of alternative cloud adoption decisions in a defensible manner. Being amenable to automation, it can respond well to even complex arrays of decision criteria inputs, unlike human decision makers. It can be implemented as a web-based DSS to readily support cloud decision making world-wide, and improved further using fuzzy TOPSIS methods, to address concerns about preferential inter-dependence of attributes, insufficient input data or judgment expertise."
2692814,15258,11058,Speculative linearizability,2012,"Linearizability is a key design methodology for reasoning about implementations of concurrent abstract data types in both shared memory and message passing systems. It provides the illusion that operations execute sequentially and fault-free, despite the asynchrony and faults inherent to a concurrent system, especially a distributed one. A key property of linearizability is inter-object composability: a system composed of linearizable objects is itself linearizable. However, devising linearizable objects is very difficult, requiring complex algorithms to work correctly under general circumstances, and often resulting in bad average-case behavior. Concurrent algorithm designers therefore resort to speculation: optimizing algorithms to handle common scenarios more efficiently. The outcome are even more complex protocols, for which it is no longer tractable to prove their correctness.   To simplify the design of efficient yet robust linearizable protocols, we propose a new notion:  speculative linearizability . This property is as general as linearizability, yet it allows intra-object composability: the correctness of independent protocol phases implies the correctness of their composition. In particular, it allows the designer to focus solely on the proof of an optimization and derive the correctness of the overall protocol from the correctness of the existing, non-optimized one.   Our notion of protocol phases allows processes to independently switch from one phase to another, without requiring them to reach agreement to determine the change of a phase. To illustrate the applicability of our methodology, we show how examples of speculative algorithms for shared memory and asynchronous message passing naturally fit into our framework.   We rigorously define speculative linearizability and prove our intra-object composition theorem in a trace-based as well as an automaton-based model. To obtain a further degree of confidence, we also formalize and mechanically check the theorem in the automaton-based model, using the I/O automata framework within the Isabelle interactive proof assistant. We expect our framework to enable, for the first time, scalable specifications and mechanical proofs of speculative implementations of linearizable objects."
2408552,15258,8306,EOLE: paving the way for an effective implementation of value prediction,2014,"Even in the multicore era, there is a continuous demand to increase the performance of single-threaded applications. However, the conventional path of increasing both issue width and instruction window size inevitably leads to the power wall. Value prediction (VP) was proposed in the mid 90's as an alternative path to further enhance the performance of wide-issue superscalar processors. Still, it was considered up to recently that a performance-effective implementation of Value Prediction would add tremendous complexity and power consumption in almost every stage of the pipeline   Nonetheless, recent work in the field of VP has shown that given an efficient confidence estimation mechanism, prediction validation could be removed from the out-of-order engine and delayed until commit time. As a result, recovering from mispredictions via selective replay can be avoided and a much simpler mechanism -- pipeline squashing -- can be used, while the out-of-order engine remains mostly unmodified.   Yet, VP and validation at commit time entails strong constraints on the Physical Register File. Write ports are needed to write predicted results and read ports are needed in order to validate them at commit time, potentially rendering the overall number of ports unbearable. Fortunately, VP also implies that many single-cycle ALU instructions have their operands predicted in the front-end and can be executed in-place, in-order. Similarly, the execution of single-cycle instructions whose result has been predicted can be delayed until commit time since predictions are validated at commit time   Consequently, a significant number of instructions -- 10% to 60% in our experiments -- can bypass the out-of-order engine, allowing the reduction of the issue width, which is a major contributor to both out-of-order engine complexity and register file port requirement. This reduction paves the way for a truly practical implementation of Value Prediction. Furthermore, since Value Prediction in itself usually increases performance, our resulting {Early | Out-of-Order | Late} Execution architecture, EOLE, is often more efficient than a baseline VP-augmented 6-issue superscalar while having a significantly narrower 4-issue out-of-order engine"
1045709,15258,11330,Optimizing throughput/power trade-offs in hardware transactional memory using DVFS and intelligent scheduling,2011,"Power has emerged as a first-order design constraint in modern processors and has energized microarchitecture researchers to produce a growing number of power optimization proposals. Almost in tandem with the move toward more energy-efficient designs, architects have been increasing the number of processing elements (PEs) on a single chip and promoting the concept of running multithreaded workloads. Nevertheless, software is still lagging behind and is often unable to exploit these additional resources -- giving rise to transactional memory. Transactional memory is a promising programming abstraction that makes it easier for programmers to exploit the resources available in many- core processor systems by removing some of the complexity associated with traditional lock-based programming. This paper proposes new techniques to merge the power and transactional memory domains.   An analysis of the per-core and chip-wide power consumption of hardware transactional memory systems (HTMs) pinpoints two areas ripe for power management policies: transactional stalls and aborts. The first proposed policy uses dynamic voltage and frequency scaling (DVFS) during transactional stall periods. By frequency scaling PEs based on their transactional state, DVFS can increase the throughput and energy efficiency of HTMs. The second method uses a transaction's conflict probability to reschedule transactions and clock gate aborted PEs to reduce overall contention and power consumption within the system. The proposed techniques are evaluated using three HTM configurations and are shown to reduce the energy delay squared product (ED2P) of the STAMP and SPLASH-2 benchmarks by an average of 18% when combined. Synthetic workloads are used to explore a wider range of program behaviors and the optimizations are shown to reduce the ED2P by an average of 29%. For a comparison, this work is shown reduce the ED2P by up to 30% relative to previous proposals for energy reduction in HTMs (e.g. transaction serialization)."
2009534,15258,23836,High-Performance Design of HBase with RDMA over InfiniBand,2012,"HBase is an open source distributed Key/Value store based on the idea of Big Table. It is being used in many data-center applications (e.g. Face book, Twitter, etc.) because of its portability and massive scalability. For this kind of system, low latency and high throughput is expected when supporting services for large scale concurrent accesses. However, the existing HBase implementation is built upon Java Sockets Interface that provides sub-optimal performance due to the overhead to provide cross-platform portability. The byte-stream oriented Java sockets semantics confine the possibility to leverage new generations of network technologies. This makes it hard to provide high performance services for data-intensive applications. High Performance Computing (HPC) domain has exploited high performance and low latency networks such as Infini Band for many years. These interconnects provide advanced network features, such as Remote Direct Memory Access (RDMA), to achieve high throughput and low latency along with low CPU utilization. RDMA follows memory-block semantics, which can be adopted efficiently to satisfy the object transmission primitives used in HBase. In this paper, we present a novel design of HBase for RDMA capable networks via Java Native Interface (JNI). Our design extends the existing open-source HBase software and makes it RDMA capable. Our performance evaluation reveals that latency of HBase Get operations of 1KB message size can be reduced to 43.7µs with the new design on QDR platform (32 Gbps). This is about a factor of 3.5 improvement over 10 Gigabit Ethernet (10 GigE) network with TCP Offload. Throughput evaluations using four HBase region servers and 64 clients indicate that the new design boosts up throughput by 3 X times over 1 GigE and 10 GigE networks. To the best of our knowledge, this is first HBase design utilizing high performance RDMA capable interconnects."
2516228,15258,8306,Staged memory scheduling: achieving high performance and scalability in heterogeneous systems,2012,"When multiple processor (CPU) cores and a GPU integrated together on the same chip share the off-chip main memory, requests from the GPU can heavily interfere with requests from the CPU cores, leading to low system performance and starvation of CPU cores. Unfortunately, state-of-the-art application-aware memory scheduling algorithms are ineffective at solving this problem at low complexity due to the large amount of GPU traffic. A large and costly request buffer is needed to provide these algorithms with enough visibility across the global request stream, requiring relatively complex hardware implementations.   This paper proposes a fundamentally new approach that decouples the memory controller's three primary tasks into three significantly simpler structures that together improve system performance and fairness, especially in integrated CPU-GPU systems. Our three-stage memory controller first groups requests based on row-buffer locality. This grouping allows the second stage to focus only on inter-application request scheduling. These two stages enforce high-level policies regarding performance and fairness, and therefore the last stage consists of simple per-bank FIFO queues (no further command reordering within each bank) and straightforward logic that deals only with low-level DRAM commands and timing.   We evaluate the design trade-offs involved in our Staged Memory Scheduler (SMS) and compare it against three state-of-the-art memory controller designs. Our evaluations show that SMS improves CPU performance without degrading GPU frame rate beyond a generally acceptable level, while being significantly less complex to implement than previous application-aware schedulers. Furthermore, SMS can be configured by the system software to prioritize the CPU or the GPU at varying levels to address different performance needs."
2194488,15258,23836,QR Factorization on a Multicore Node Enhanced with Multiple GPU Accelerators,2011,"One of the major trends in the design of exascale architectures is the use of multicore nodes enhanced with GPU accelerators. Exploiting all resources of a hybrid accelerators-based node at their maximum potential is thus a fundamental step towards exascale computing. In this article, we present the design of a highly efficient QR factorization for such a node. Our method is in three steps. The first step consists of expressing the QR factorization as a sequence of tasks of well chosen granularity that will aim at being executed on a CPU core or a GPU. We show that we can efficiently adapt high-level algorithms from the literature that were initially designed for homogeneous multicore architectures. The second step consists of designing the kernels that implement each individual task. We use CPU kernels from previous work and present new kernels for GPUs that complement kernels already available in the MAGMA library. We show the impact on performance of these GPU kernels. In particular, we present the benefits of new hybrid CPU/GPU kernels. The last step consists of scheduling these tasks on the computational units. We present two alternative approaches, respectively based on static and dynamic scheduling. In the case of static scheduling, we exploit the a priori knowledge of the schedule to perform successive optimizations leading to very high performance. We, however, highlight the lack of portability of this approach and its limitations to relatively simple algorithms on relatively homogeneous nodes. Alternatively, by relying on an efficient runtime system, Star PU, in charge of ensuring data availability and coherency, we can schedule more complex algorithms on complex heterogeneous nodes with much higher productivity. In this latter case, we show that we can achieve high performance in a portable way thanks to a fine interaction between the application and the runtime system. We demonstrate that the obtained performance is very close to the theoretical upper bounds that we obtained using Linear Programming."
932312,15258,8912,Invited talk: Challenges in Medical Cyber-Physical Systems,2012,"As computers and communication bandwidth become ever faster and cheaper, computing and communication capabilities are embedded in all types of objects and structures in the physical environment. Harnessing these capabilities to bridge the cyber-world with the physical world will allow the development of applications with great societal impact and economic benefit. At the heart of these applications are cyber-physical systems consisting of integrated computational and communication cores that interact with the physical world, with intelligence provided by embedded software. Cyber Physical Systems (CPS) are engineered systems that provide tight integration of and coordination between the cyber world of computing and communications and the physical world. CPS are to meet the needs of the new generation of engineered systems that are highly dependable, efficiently produced and certified, and capable of advanced performance in computation, communication, and control. CPS will transform how we interact with and control the physical world around us, as the Internet transformed how we interact and communicate with one another and revolutionized how and where we access information. One application domain of CPS is Medical Cyber-Physical Systems (MCPS), which are life-critical, context-aware, networked systems of medical devices. Medical device industry is undergoing a transformation, embracing the potential of embedded software and network connectivity. Instead of stand-alone devices that can be designed, certified, and used to treat patients independent of each other, distributed systems that simultaneously control multiple aspects of the patient's physiology are increasingly used in hospitals to provide high-quality continuous care for patients. The combination of embedded software controlling medical devices, networking capabilities, and complicated physiological dynamics of patient bodies makes MCPS complex. The need to design complex MCPS that are both safe and effective presents numerous challenges, including achieving high assurance in system software, interoperability, context-aware intelligence, autonomy, security and privacy, and device certification. In this talk, I will discuss these challenges in developing MCPS and present some of our work in addressing them, and several open research and development issues."
1369738,15258,9748,On-the-Fly Adaptive Routing in High-Radix Hierarchical Networks,2012,"Dragonfly networks have been recently proposed for the interconnection network of forthcoming exascale supercomputers. Relying on large-radix routers, they build a topology with low diameter and high throughput, divided into multiple groups of routers. While minimal routing is appropriate for uniform traffic patterns, adversarial traffic patterns can saturate inter-group links and degrade the obtained performance. Such traffic patterns occur in typical communication patterns used by many HPC applications, such as neighbor data exchanges in multi-dimensional space decompositions. Non-minimal traffic routing is employed to handle such cases. Adaptive policies have been designed to select between minimal and nonminimal routing to handle variable traffic patterns. However, previous papers have not taken into account the effect of saturation of intra-group (local) links. This paper studies how local link saturation can be common in these networks, and shows that it can largely reduce the performance. The solution to this problem is to use nonminimal paths that avoid those saturated local links. However, this extends the maximum path length, and since all previous routing proposals prevent deadlock by relying on an ascending order of virtual channels, it would imply unaffordable cost and complexity in the network routers. In this paper we introduce a novel routing/flow-control scheme that decouples the routing and the deadlock avoidance mechanisms. Our model does not impose any dependencies between virtual channels, allowing for on-the-fly (in-transit) adaptive routing of packets. To prevent deadlock we employ a deadlock-free escape sub network based on injection restriction. Simulations show that our model obtains lower latency, higher throughput, and faster adaptation to transient traffic, because it dynamically exploits a higher path diversity to avoid saturated links. Notably, our proposal consumes traffic bursts 43% faster than previous ones."
2372624,15258,8306,STAG: spintronic-tape architecture for GPGPU cache hierarchies,2014,"General-purpose Graphics Processing Units (GPGPUs) are widely used for executing massively parallel workloads from various application domains. Feeding data to the hundreds to thousands of cores that current GPGPUs integrate places great demands on the memory hierarchy, fueling an ever-increasing demand for on-chip memory.   In this work, we propose STAG, a high density, energy-efficient GPGPU cache hierarchy design using a new spintronic memory technology called Domain Wall Memory (DWM). DWMs inherently offer unprecedented benefits in density by storing multiple bits in the domains of a ferromagnetic nanowire, which logically resembles a bit-serial tape. However, this structure also leads to a unique challenge that the bits must be sequentially accessed by performing shift operations, resulting in variable and potentially higher access latencies. To address this challenge, STAG utilizes a number of architectural techniques : (i) a hybrid cache organization that employs different DWM bit-cells to realize the different memory arrays within the GPGPU cache hierarchy, (ii) a clustered, bit-interleaved organization, in which the bits in a cache block are spread across a cluster of DWM tapes, allowing parallel access, (iii) tape head management policies that predictively configure DWM arrays to reduce the expected number of shift operations for subsequent accesses, and (iv) a shift aware pro- motion buffer (SaPB), in which accesses to the DWM cache are predicted based on intra-warp locality, and locations that would incur a large shift penalty are promoted to a smaller buffer. Over a wide range of benchmarks from the Rodinia, IS- PASS and Parboil suites, STAG achieves significant benefits in performance (12.1% over SRAM and 5.8% over STT-MRAM) and energy (3.3X over SRAM and 2.6X over STT-MRAM)"
1125542,15258,22260,Will They Blend?: Exploring Big Data Computation Atop Traditional HPC NAS Storage,2014,"The Apache Hadoop framework has rung in a new era in how data-rich organizations can process, store, and analyze large amounts of data. This has resulted in increased potential for an infrastructure exodus from the traditional solution of commercial database ad-hoc analytics on network-attached storage (NAS). While many data-rich organizations can afford to either move entirely to Hadoop for their Big Data analytics, or to maintain their existing traditional infrastructures and acquire a new set of infrastructure solely for Hadoop jobs, most supercomputing centers do not enjoy either of those possibilities. Too much of the existing scientific code is tailored to work on massively parallel file systems unlike the Hadoop Distributed File System (HDFS), and their datasets are too large to reasonably maintain and/or ferry between two distinct storage systems. Nevertheless, as scientists search for easier-to-program frameworks with a lower time-to-science to post-process their huge datasets after execution, there is increasing pressure to enable use of MapReduce within these traditional High Performance Computing (HPC) architectures. Therefore, in this work we explore potential means to enable use of the easy-to-program Hadoop MapReduce framework without requiring a complete infrastructure overhaul from existing HPC NAS solutions. We demonstrate that retaining function-dedicated resources like NAS is not only possible, but can even be effected efficiently with MapReduce. In our exploration, we unearth subtle pitfalls resultant from this mash-up of new-era Big Data computation on conventional HPC storage and share the clever architectural configurations that allow us to avoid them. Last, we design and present a novel Hadoop File System, the Reliable Array of Independent NAS File System (RainFS), and experimentally demonstrate its improvements in performance and reliability over the previous architectures we have investigated."
250006,15258,9748,Consistency and Fault Tolerance Considerations for the Next Iteration of the DOE Fast Forward Storage and IO Project,2014,"The DOE Extreme-Scale Technology Acceleration Fast Forward Storage and IO Stack project is going to have significant impact on storage systems design within and beyond the HPC community. With phase 1 of the project complete, it is an excellent opportunity to evaluate many of the decisions made to feed into the phase 2 effort. With this paper we not only provide a timely summary of important aspects of the design specifications but also capture the underlying reasoning that is not available elsewhere.The initial effort to define a next generation storage system has made admirable contributions in architecture and design. Formalizing the general idea of data staging into burst buffers for the storage system will help manage the performance variability and offer additional data processing opportunities outside the main compute and storage system. Adding a transactional mechanism to manage faults and data visibility helps enable effective analytics without having to work around the IO stack semantics. While these and other contributions are valuable, similar efforts made elsewhere may offer attractive alternatives or differing semantics that could yield a more feature rich environment with little to no additional overhead. For example, the Doubly Distributed Transactions (D2T) protocol offers an alternative approach for incorporating transactional semantics into the data path. Another project, PreDatA, examined how to get the best throughput for data operators and may offer additional insights into further refinements of the Burst Buffer concept. This paper examines some of the choices made by the Fast Forward team and compares them with other options and offers observations and suggestions based on these other efforts. This will include some non-core contributions of other projects, such as some of the demonstration metadata and data storage components generated while implementing D2T, to make suggestions that may help the next generation design for how the IO stack works as a whole."
1942280,15258,23836,Joint Host-Network Optimization for Energy-Efficient Data Center Networking,2013,"Data centers consume significant amounts of energy. As severs become more energy efficient with various energy saving techniques, the data center network (DCN) has been accounting for 20% or more of the energy consumed by the entire data center. While DCNs are typically provisioned with full bisection bandwidth, DCN traffic demonstrates fluctuating patterns. The objective of this work is to improve the energy efficiency of DCNs during off-peak traffic time by powering off idle devices. Although there exist a number of energy optimization solutions for DCNs, they consider only either the hosts or network, but not both. In this paper, we propose a joint optimization scheme that simultaneously optimizes virtual machine (VM) placement and network flow routing to maximize energy savings, and we also build an OpenFlow based prototype to experimentally demonstrate the effectiveness of our design. First, we formulate the joint optimization problem as an integer linear program, but it is not a practical solution due to high complexity. To practically and effectively combine host and network based optimization, we present a unified representation method that converts the VM placement problem to a routing problem. In addition, to accelerate processing the large number of servers and an even larger number of VMs, we describe a parallelization approach that divides the DCN into clusters for parallel processing. Further, to quickly find efficient paths for flows, we propose a fast topology oriented multipath routing algorithm that uses depth-first search to quickly traverse between hierarchical switch layers and uses the best-fit criterion to maximize flow consolidation. Finally, we have conducted extensive simulations and experiments to compare our design with existing ones. The simulation and experiment results fully demonstrate that our design outperforms existing hostor network-only optimization solutions, and well approximates the ideal linear program."
1977085,15258,11330,HiRe: using hint & release to improve synchronization of speculative threads,2012,"Thread-Level Speculation (TLS) is a promising technique for improving performance of serial codes on multi-cores by automatically extracting threads and running them in parallel. However, the speculation efficiency as well as the performance gain of TLS systems are reduced by cross-thread data dependence violations. Reducing the cost and frequency of violations are key to improving the efficiency of TLS. One method to keep a dependence from violating is to predict it and communicate the value via synchronization. However, prior work in this field still cannot handle enough violating dependences, especially hard-to-predict ones and those in non-loop TLS tasks. Also, they suffer from over-synchronization and/or introduce complicated hardware. The major reason is that these techniques are highly sensitive to the accuracy of the dependence prediction, which is hard to improve in the face of irregular dependence and task patterns.   In this paper, we propose a novel synchronization technique that avoids over synchronization and works for irregularly occurring dependences. We use a profiler to find and mark store-load pairs that generate data dependences. Then, the compiler schedules a hint instruction in advance of the store to inform successor threads of a possible pending write to a specific address; in this way, later loads only wait for a store if the loading location has been hinted. The compiler also schedules a release instruction that notifies the load when it should proceed. It places the release both after the store and on every path leading away from the hint that does not pass through the store. By placing it on all such paths, we limit the cost due to over synchronization. Together, the hint and release form our proposal, called HiRe. We implemented the HiRe scheme on a well-tuned TLS system and evaluated it on a set of SPEC CPU 2000 applications; we find that HiRe suffers only 22% of the violations that occur in our base TLS system, and it cuts the instruction waste rate of TLS in half. Furthermore, it outperforms prior approaches we studied by 3%."
1430657,15258,20338,DNS to the rescue: discerning content and services in a tangled web,2012,"A careful perusal of the Internet evolution reveals two major trends - explosion of cloud-based services and video streaming applications. In both of the above cases, the owner (e.g., CNN, YouTube, or Zynga) of the content and the organization serving it (e.g., Akamai, Limelight, or Amazon EC2) are decoupled, thus making it harder to understand the association between the content, owner, and the host where the content resides. This has created a tangled world wide web that is very hard to unwind, impairing ISPs' and network administrators' capabilities to control the traffic flowing in their networks.   In this paper, we present DN-Hunter, a system that leverages the information provided by DNS traffic to discern the tangle. Parsing through DNS queries, DN-Hunter tags traffic flows with the associated domain name. This association has several applications and reveals a large amount of useful information: (i) Provides a fine-grained traffic visibility even when the traffic is encrypted (i.e., TLS/SSL flows), thus enabling more effective policy controls,(ii) Identifies flows even before the flows begin, thus providing superior network management capabilities to administrators, $(iii)$ Understand and track (over time) different CDNs and cloud providers that host content for a particular resource, (iv) Discern all the services/content hosted by a given CDN or cloud provider in a particular geography and time interval, and (v) Provides insights into all applications/services running on any given layer-4 port number.   We conduct extensive experimental analysis and show results from real traffic traces (including FTTH and 4G ISPs) that support our hypothesis. Simply put, the information provided by DNS traffic is one of the key components required for understanding the tangled web, and bringing the ability to effectively manage network traffic back to the operators."
2273147,15258,9836,Use it or lose it: wear-out and lifetime in future chip multiprocessors,2013,"Moore's Law scaling is continuing to yield even higher transistor density with each succeeding process generation, leading to today's multi-core Chip Multi-Processors (CMPs) with tens or even hundreds of interconnected cores or tiles. Unfortunately, deep sub-micron CMOS process technology is marred by increasing susceptibility to wearout. Prolonged operational stress gives rise to accelerated wearout and failure, due to several physical failure mechanisms, including Hot Carrier Injection (HCI) and Negative Bias Temperature Instability (NBTI). Each failure mechanism correlates with different usage-based stresses, all of which can eventually generate permanent faults. While the wearout of an individual core in many-core CMPs may not necessarily be catastrophic for the system, a single fault in the inter-processor Network-on-Chip (NoC) fabric could render the entire chip useless, as it could lead to protocol-level deadlocks, or even partition away vital components such as the memory controller or other critical I/O. In this paper, we develop critical path models for HCI- and NBTI-induced wear due to the actual stresses caused by real workloads, applied onto the interconnect micro-architecture. A key finding from this modeling being that, counter to prevailing wisdom, wearout in the CMP on-chip interconnect is correlated with lack of load observed in the NoC routers, rather than high load. We then develop a novel wearout-decelerating scheme in which routers under low load have their wearout-sensitive components exercised, without significantly impacting cycle time, pipeline depth, area or power consumption of the overall router. We subsequently show that the proposed design yields a 13.8×-65× increase in CMP lifetime."
1700285,15258,23836,Shedding Light on Lithium/Air Batteries Using Millions of Threads on the BG/Q Supercomputer,2014,"In this work, we present a novel parallelization scheme for a highly efficient evaluation of the Hartree-Fock exact exchange (HFX) in ab initio molecular dynamics simulations, specifically tailored for condensed phase simulations. Our developments allow one to achieve the necessary accuracy for the evaluation of the HFX in a highly controllable manner. We show here that our solutions can take great advantage of the latest trends in HPC platforms, such as extreme threading, short vector instructions and highly dimensional interconnection networks. Indeed, all these trends are evident in the IBM Blue Gene/Q supercomputer. We demonstrate an unprecedented scalability up to 6,291,456 threads (96 BG/Q racks) with a near perfect parallel efficiency, which represents a more than 20-fold improvement as compared to the current state of the art. In terms of reduction of time to solution, we achieved an improvement that can surpass a 10-fold decrease in runtime with respect to directly comparable approaches. We exploit this development to enhance the accuracy of DFT based molecular dynamics by using the PBE0 hybrid functional. This approach allowed us to investigate the chemical behavior of organic solvents in one of the most challenging research topics in energy storage, lithium/air batteries, and to propose alternative solvents with enhanced stability to ensure an appropriate reversible electrochemical reaction. This step is key for the development of a viable lithium/air storage technology, which would have been a daunting computational task using standard methods. Recent research has shown that the electrolyte plays a key role in non-aqueous lithium/air batteries in producing the appropriate reversible electrochemical reduction. In particular, the chemical degradation of propylene carbonate, the typical electrolyte used, by lithium peroxide has been demonstrated by molecular dynamics simulations of highly realistic models. Reaching the necessary high accuracy in these simulations is a daunting computational task using standard methods."
2547010,15258,23497,Chameleon: operating system support for dynamic processors,2012,"The rise of multi-core processors has shifted performance efforts towards parallel programs. However, single-threaded code, whether from legacy programs or ones difficult to parallelize, remains important. Proposed asymmetric multicore processors statically dedicate hardware to improve sequential performance, but at the cost of reduced parallel performance. However, several proposed mechanisms provide the best-of-both-worlds by combining multiple cores into a single, more powerful processor for sequential code. For example, Core Fusion merges multiple cores to pool caches and functional units, and Intel's Turbo Boost raises the clock speed of a core if the other cores on a chip are powered down.   These reconfiguration mechanisms have two important properties. First the set of available cores and their capabilities can vary over short time scales. Current operating systems are not designed for rapidly changing hardware: the existing hotplug mechanisms for reconfiguring processors require global operations and hundreds of milliseconds to complete. Second, configurations may be mutually exclusive: using power to speed one core means it cannot be used to speed another. Current schedulers cannot manage this requirement.   We present Chameleon, an extension to Linux to support dynamic processors that can reconfigure their cores at runtime. Chameleon provides processor proxies to enable rapid reconfiguration, execution objects to abstract the processing capabilities of physical CPUs, and a cluster scheduler to balance the needs of sequential and parallel programs. In experiments that emulate a dynamic processor, we find that Chameleon can reconfigure processors 100,000 times faster than Linux and allows applications full access to hardware capabilities: sequential code runs at full speed on a powerful execution context, while parallel code runs on as many cores as possible."
1778143,15258,20774,Experimental analysis of space-bounded schedulers,2014,"The running time of nested parallel programs on shared memory machines depends in significant part on how well the scheduler mapping the program to the machine is optimized for the organization of caches and processors on the machine. Recent work proposed ``space-bounded schedulers'' for scheduling such programs on the multi-level cache hierarchies of current machines. The main benefit of this class of schedulers is that they provably preserve locality of the program at every level in the hierarchy, resulting (in theory) in fewer cache misses and better use of bandwidth than the popular work-stealing scheduler. On the other hand, compared to work-stealing, space-bounded schedulers are inferior at load balancing and may have greater scheduling overheads, raising the question as to the relative effectiveness of the two schedulers in practice.   In this paper, we provide the first experimental study aimed at addressing this question. To facilitate this study, we built a flexible experimental framework with separate interfaces for programs and schedulers. This enables a head-to-head comparison of the relative strengths of schedulers in terms of running times and cache miss counts across a range of benchmarks. (The framework is validated by comparisons with the Intel\textregistered{} Cilk\texttrademark{} Plus work-stealing scheduler.) We present experimental results on a 32-core Xeon\textregistered{} 7560 comparing work-stealing, hierarchy-minded work-stealing, and two variants of space-bounded schedulers on both divide-and-conquer micro-benchmarks and some popular algorithmic kernels. Our results indicate that space-bounded schedulers reduce the number of L3 cache misses compared to work-stealing schedulers by 25--65\% for most of the benchmarks, but incur up to 7\% additional scheduler and load-imbalance overhead. Only for memory-intensive benchmarks can the reduction in cache misses overcome the added overhead, resulting in up to a 25\% improvement in running time for synthetic benchmarks and about 20\% improvement for algorithmic kernels. We also quantify runtime improvements varying the available bandwidth per core (the ``bandwidth gap''), and show up to 50\% improvements in the running times of kernels as this gap increases 4-fold. As part of our study, we generalize prior definitions of space-bounded schedulers to allow for more practical variants (while still preserving their guarantees), and explore implementation tradeoffs."
758401,15258,23836,CoAdELL: Adaptivity and Compression for Improving Sparse Matrix-Vector Multiplication on GPUs,2014,"Numerous applications in science and engineering rely on sparse linear algebra. The efficiency of a fundamental kernel such as the Sparse Matrix-Vector multiplication (SpMV) is crucial for solving increasingly complex computational problems. However, the SpMV is notorious for its extremely low arithmetic intensity and irregular memory patterns, posing a challenge for optimization. Over the last few years, an extensive amount of literature has been devoted to implementing SpMV on Graphic Processing Units (GPUs), with the aim of exploiting the available fine-grain parallelism and memory bandwidth. In this paper, we propose to efficiently combine adaptivity and compression into an ELL-based sparse format in order to improve the state-of-the-art of the SpMV on Graphic Processing Units (GPUs). The foundation of our work is AdELL, an efficient sparse data structure based on the idea of distributing working threads to rows according to their computational load, creating balanced hardware-level blocks (warps) while coping with the irregular matrix structure. We designed a lightweight index compression scheme based on delta encoding and warp granularity that can be transparently embedded into AdELL, leading to an immediate performance benefit associated with the bandwidth-limited nature of the SpMV. The proposed integration provides a highly-optimized novel sparse matrix format known as Compressed Adaptive ELL (CoAdELL). We evaluated the effectiveness of our approach on a large set of benchmarks from heterogenous application domains. The results show consistent improvements for double-precision SpMV calculations over the AdELL baseline. Moreover, we assessed the general relevance of CoAdELL with respect to other optimized GPU-based sparse matrix formats. We drew a direct comparison with clSpMV and BRO-HYB, obtaining sufficient experimental evidence (33% geometric average improvement over clSpMV and 43% over BRO-HYB) to propose our research work as the novel state-of-the-art."
1843655,15258,23836,Highly Efficient Performance Portable Tracking of Evolving Surfaces,2012,"In this paper we present a framework to obtain highly efficient implementations for the narrow band level set method on commercial off-the-shelf (COTS) multicore CPU systems with a cache-based memory hierarchy such as Intel Xeon and Atom processors. The narrow-band level set algorithm tracks wave-fronts in discretized volumes (for instance, explosion shock waves), and is computationally very demanding. At the core of our optimization framework is a novel projection-based approach to enhance data locality and enable reuse for sparse surfaces in dense discretized volumes. The method reduces stencil operations on sparse and changing sets of pixels belonging to an evolving surface into dense stencil operations on meta-pixels in a lower-dimensional projection of the pixel space. These meta-pixels are then amenable to standard techniques like time tiling. However, the complexity introduced by ever-changing meta-pixels requires us to revisit and adapt all other necessary optimizations. We apply adapted versions of SIMDization, multi-threading, DAG scheduling for basic tiles, and specialization through code generation to extract maximum performance. The system is implemented as highly parameterized code skeleton that is auto-tuned and uses program generation. We evaluated our framework on a dual-socket 2.8 GHz Xeon 5560 and a 1.6 GHz Atom N270. Our single-core performance reaches 26\% -- 35\% of the machine peak on the Xeon, and 12\% -- 20\% on the Atom across a range of image sizes. We see up to 6.5x speedup on 8 cores of the dual-socket Xeon. For cache-resident sizes our code outperforms the best available third-party code (C pre-compiled into a DLL) by about 10x and for the largest out-of-cache sizes the speedup approaches around 200x. Experiments fully explain the high speedup numbers."
1232164,15258,23836,GPU Accelerated Nature Inspired Methods for Modelling Large Scale Bi-directional Pedestrian Movement,2014,"Pedestrian movement, although ubiquitous and well-studied, is still not that well understood due to the complicating nature of the embedded social dynamics. Interest among researchers in simulating pedestrian movement and interactions has grown significantly in part due to increased computational and visualization capabilities afforded by high power computing. Different approaches have been adopted to simulate pedestrian movement under various circumstances and interactions. In the present work, bi-directional crowd movement is simulated where an equal numbers of individuals try to reach the opposite sides of an environment. Two movement methods are considered. First a Least Effort Model (LEM) is investigated where agents try to take an optimal path with as minimal changes from their intended path as possible. Following this, a modified form of Ant Colony Optimization (ACO) is proposed, where individuals are guided by a goal of reaching the other side in a least effort mode as well as a pheromone trail left by predecessors. The basic idea is to increase agent interaction, thereby more closely reflecting a real world scenario. The methodology utilizes Graphics Processing Units (GPUs) for general purpose computing using the CUDA platform. Because of the inherent parallel properties associated with pedestrian movement such as proximate interactions of individuals on a 2D grid, GPUs are well suited. The main feature of the implementation undertaken here is that the parallelism is data driven. The data driven implementation leads to a speedup up to 18x compared to its sequential counterpart running on a single threaded CPU. The numbers of pedestrians considered in the model ranged from 2K to 100K representing numbers typical of mass gathering events. A detailed discussion addresses implementation challenges faced and averted. Detailed analysis is also provided on the throughput of pedestrians across the environment."
2005100,15258,23836,Advancing Large Scale Many-Body QMC Simulations on GPU Accelerated Multicore Systems,2012,"The Determinant Quantum Monte Carlo (DQMC) method is one of the most powerful approaches for understanding properties of an important class of materials with strongly interacting electrons, including magnets and superconductors. It treats these interactions exactly, but the solution of a system of $N$ electrons must be extrapolated to bulk values. Currently $N \approx 500$ is state-of-the-art. Increasing $N$ is required before DQMC can be used to model newly synthesized materials like functional multilayers. DQMC requires millions of linear algebra computations of order $N$ matrices and scales as $N^3$. DQMC cannot exploit parallel distributed memory computers efficiently due to limited scalability with the small matrix sizes and stringent procedures for numerical stability. Today, the combination of multisocket multicore processors and GPUs provides widely available platforms with new opportunities for DQMC parallelization. The kernel of DQMC, the calculation of the Green's function, involves long products of matrices. For numerical stability, these products must be computed using graded decompositions generated by the QR decomposition with column pivoting. The high communication overhead of pivoting limits parallel efficiency. In this paper, we propose a novel approach that exploits the progressive graded structure to reduce the communication costs of pivoting. We show that this method preserves the same numerical stability and achieves 70\% performance of highly optimized {\tt DGEMM} on a two-socket six-core Intel processor. We have integrated this new method and other parallelization techniques into QUEST, a modern DQMC simulation package. Using 36 hours on this Intel processor, we are able to compute accurately the magnetic properties and Fermi surface of a system of $N=1024$ electrons. This simulation is almost an order of magnitude more difficult than $N \approx 500$, owing to the $N^3$ scaling. This increase in system size will allow, for the first time, the computation of the magnetic and transport properties of layered materials with DQMC. In addition, we show preliminary results which further accelerate DQMC simulations by using GPU processors."
2019418,15258,23836,Address Translation Optimization for Unified Parallel C Multi-dimensional Arrays,2011,"Partitioned Global Address Space (PGAS) languages offer significant programmability advantages with its global memory view abstraction, one-sided communication constructs and data locality awareness. These attributes place PGAS languages at the forefront of possible solutions to the exploding programming complexity in the many-core architectures. To enable the shared address space abstraction, PGAS languages use an address translation mechanism while accessing shared memory to convert shared addresses to physical addresses. This mechanism is already expensive in terms of performance in distributed memory environments, but it becomes a major bottleneck in machines with shared memory support where the access latencies are significantly lower. Multi- and many-core processors exhibit even lower latencies for shared data due to on-chip cache space utilization. Thus, efficient handling of address translation becomes even more crucial as this overhead may easily become the dominant factor in the overall data access time for such architectures. To alleviate address translation overhead, this paper introduces a new mechanism targeting multi-dimensional arrays used in most scientific and image processing applications. Relative costs and the implementation details for UPC are evaluated with different workloads (matrix multiplication, Random Access benchmark and Sobel edge detection) on two different platforms: a many-core system, the TILE64 (a 64 core processor) and a dual-socket, quad-core Intel Nehalem system (up to 16 threads). Our optimization provides substantial performance improvements, up to 40x. In addition, the proposed mechanism can easily be integrated into compilers abstracting it from the programmers. Accordingly, this improves UPC productivity as it will reduce manual optimization efforts required to minimize the address translation overhead."
2131823,15258,23497,DreamWeaver: architectural support for deep sleep,2012,"Numerous data center services exhibit low average utilization leading to poor energy efficiency. Although CPU voltage and frequency scaling historically has been an effective means to scale down power with utilization, transistor scaling trends are limiting its effectiveness and the CPU is accounting for a shrinking fraction of system power. Recent research advocates the use of full-system idle low-power modes to combat energy losses, as such modes provide the deepest power savings with bounded response time impact. However, the trend towards increasing cores per die is undermining the effectiveness of these sleep modes, particularly for request-parallel data center applications, because the independent idle periods across individual cores are unlikely to align by happenstance.   We propose DreamWeaver, architectural support to facilitate deep sleep for request-parallel applications on multicore servers. DreamWeaver comprises two elements: Weave Scheduling, a scheduling policy to coalesce idle and busy periods across cores to create opportunities for system-wide deep sleep; and the Dream Processor, a light-weight co-processor that monitors incoming network traffic and suspended work during sleep to determine when the system must wake. DreamWeaver is based on two key concepts: (1) stall execution and sleep anytime any core is unoccupied, but (2) constrain the maximum time any request may be stalled. Unlike prior scheduling approaches, DreamWeaver will preempt execution to sleep, maximizing time spent at the systems' most efficient operating point. We demonstrate that DreamWeaver can smoothly trade-off bounded, predictable increases in 99th-percentile response time for increasing power savings, and strictly dominates the savings available with voltage and frequency scaling and timeout-based request batching schemes."
2288522,15258,8306,Optimizing virtual machine consolidation performance on NUMA server architecture for cloud workloads,2014,"Server virtualization and workload consolidation enable multiple workloads to share a single physical server, resulting in significant energy savings and utilization improvements. The shift of physical server architectures to NUMA and the increasing popularity of scale-out cloud applications undermine workload consolidation efficiency and result in overall system degradation. In this work, we characterize the consolidation of cloud workloads on NUMA virtualized systems, estimate four different sources of architecture overhead, and explore optimization opportunities beyond the default NUMA-aware hypervisor memory management   Motivated by the observed architectural impact on cloud workload consolidation performance, we propose three optimization techniques incorporating NUMA access overhead into the hypervisor's virtual machine memory allocation and page fault handling routines. Among these, estimation of the memory zone access overhead serves as a foundation for the other two techniques: a NUMA overhead aware buddy allocator and a P2M swap FIFO. Cache hit rate, cycle loss due to cache miss, and IPC serve as indicators to estimate the access cost of each memory node. Our optimized buddy allocator dynamically selects low-overhead memory zones and proportionally distributes memory pages across target nodes. The P2M swap FIFO records recently unused PFN, MFN lists for mapping exchanges to rebalance memory access pressure within one domain. Our real system based evaluations show a 41.1% performance improvement when consolidating 16-VMs on a 4- socket server (the proposed allocator contributes 22.8% of the performance gain and the P2M swap FIFO accounts for the rest). Furthermore, our techniques can cooperate well with other methods (i.e. vCPU migration) and scale well when varying VM memory size and the number of sockets in a physical host"
752510,15258,20774,Brief announcement: a game-theoretic model motivated by the darpa network challenge,2013,"In this paper we propose a game-theoretic model to analyze events similar to the 2009  DARPA Network Challenge , which was organized by the Defense Advanced Research Projects Agency (DARPA) for exploring the roles that the Internet and social networks play in incentivizing wide-area collaborations. The challenge was to form a group that would be the first to find the locations of ten moored weather balloons across the United States. We consider a model in which  N  people (who can form groups) are located in some topology with a fixed coverage volume around each person's geographical location. We consider various topologies where the players can be located such as the Euclidean  d -dimension space and the vertices of a graph. A balloon is placed in the space and a group wins if it is the first one to report the location of the balloon. A larger team has a higher probability of finding the balloon, but we assume that the prize money is divided equally among the team members. Hence there is a competing tension to keep teams as small as possible.    Risk aversion  is the reluctance of a person to accept a bargain with an uncertain payoff rather than another bargain with a more certain, but possibly lower, expected payoff. In our model we consider the  isoelastic  utility function derived from the Arrow-Pratt measure of relative risk aversion. The main aim is to analyze the structures of the groups in Nash equilibria for our model. For the  d -dimensional Euclidean space ( d  ≥ 1) and the class of bounded degree regular graphs we show that in any Nash Equilibrium the  richest group (having maximum expected utility per person) covers a constant fraction of the total volume. The objective of events like the DARPA Network Challenge is to mobilize a large number of people quickly so that they can cover a big fraction of the total area. Our results suggest that this objective can be met under certain conditions."
769863,15258,122,Morph algorithms on GPUs,2013,"There is growing interest in using GPUs to accelerate graph algorithms such as breadth-first search, computing page-ranks, and finding shortest paths. However, these algorithms do not modify the graph structure, so their implementation is relatively easy compared to general graph algorithms like mesh generation and refinement, which  morph  the underlying graph in non-trivial ways by adding and removing nodes and edges. We know relatively little about how to implement morph algorithms efficiently on GPUs.   In this paper, we present and study four morph algorithms: (i) a computational geometry algorithm called Delaunay Mesh Refinement (DMR), (ii) an approximate SAT solver called Survey Propagation (SP), (iii) a compiler analysis called Points-To Analysis (PTA), and (iv) Boruvka's Minimum Spanning Tree algorithm (MST). Each of these algorithms modifies the graph data structure in different ways and thus poses interesting challenges.   We overcome these challenges using algorithmic and GPU-specific optimizations. We propose efficient techniques to perform concurrent subgraph addition, subgraph deletion, conflict detection and several optimizations to improve the scalability of morph algorithms. For an input mesh with 10 million triangles, our DMR code achieves an 80x speedup over the highly optimized serial  Triangle  program and a 2.3x speedup over a multicore implementation running with 48 threads. Our SP code is 3x faster than a multicore implementation with 48 threads on an input with 1 million literals. The PTA implementation is able to analyze six SPEC 2000 benchmark programs in just 74 milliseconds, achieving a geometric mean speedup of 9.3x over a 48-thread multicore version. Our MST code is slower than a multicore version with 48 threads for sparse graphs but significantly faster for denser graphs.   This work provides several insights into how other morph algorithms can be efficiently implemented on GPUs."
856039,15258,9748,AdELL: An Adaptive Warp-Balancing ELL Format for Efficient Sparse Matrix-Vector Multiplication on GPUs,2013,"The sparse matrix-vector multiplication (SpMV) is a fundamental computational kernel used in science and engineering. As a result, the performance of a large number of applications depends on the efficiency of the SpMV. This kernel is, in fact, a bandwidth-limited operation and poses a challenge for optimization when the matrix has an irregular structure. The literature on implementing SpMV on throughput-oriented many core processors is extensive and mostly focuses on matrix formats, proposing different ideas to adapt matrix sparsity to the underlying architecture. In this paper, we propose a novel ELL-based matrix format called Adaptive ELL (AdELL) to improve the state-of-the-art of the SpMV on Graphic Processing Units (GPUs). The AdELL format is based on the idea of distributing working threads to rows according to their computational load, creating balanced hardware-level blocks (warps) that take full advantage of the vectorized execution on Streaming Multiprocessors (SMs). The AdELL data structure is created using a novel warp-balancing heuristic designed to smooth the workload among warps without the need of tuning any parameters. AdELL provides an efficient warp-level synchronization (as opposed to block-level) but can also use atomic operations to distribute very skewed rows over multiple warps. Moreover, we introduce a loop unrolling heuristic that optimizes the SpMV performance by selecting the best unrolling factor based on the warp workload. We tested the proposed AdELL sparse format on a set of conventional benchmarks from heterogeneous application domains. The results show substantial and consistent performance improvements for double-precision calculations, outperforming the state-of-the-art ensemble framework clSpMV. We could observe speedup peaks up to 1.94 and a 25% (geometric) average improvement, which can be potentially increased to 43% introducing a simple 1x2 blocking strategy."
1238326,15258,9836,Formally enhanced runtime verification to ensure NoC functional correctness,2011,"As silicon technology scales, modern processors and embedded systems are rapidly shifting towards complex chip multi-processor (CMP) and system-on-chip (SoC) designs, comprising several processor cores and IP components communicating via a network-on-chip (NoC). As a side-effect of this trend, ensuring their correctness has become increasingly problematic. In particular, the network-on-chip often includes complex features and components to support the required communication bandwidth among the nodes in the system. In this landscape, it is no wonder that design errors in the NoC may go undetected and escape into the final silicon, with potential detrimental impact on the overall system.   In this work, we propose ForEVeR, a solution that complements the use of formal methods and runtime verification to ensure functional correctness in NoCs. Formal verification, due to its scalability limitations, is used to verify the smaller modules, such as individual router components. We complete the protection against escaped design errors with a runtime technique, a network-level error detection and recovery solution, which monitors the traffic in the NoC and protects it against escaped functional bugs that affect the communication paths in the network. To this end, ForEVeR augments the baseline NoC with a lightweight checker network that alerts destination nodes of incoming packets ahead of time. If a bug is detected, flagged by missed packet arrivals, a recovery mechanism delivers the in-flight data safely to the intended destination via the checker network. ForEVeR's experimental evaluation shows that it can recover from NoC design errors at only 4.8% area cost for an 8x8 mesh interconnect, with a recovery performance cost of less than 30K cycles per functional bug manifestation. Additionally, it incurs no performance overhead in the absence of errors."
1024135,15258,9772,Vanguard: Increasing Server Efficiency via Workload Isolation in the Storage I/O Path,2014,"Server consolidation via virtualization is an essential technique for improving infrastructure cost in modern datacenters. From the viewpoint of datacenter operators, consolidation offers compelling advantages by reducing the number of physical servers, and reducing operational costs such as energy consumption. However, performance interference between co-located workloads can be crippling. Conservatively, and at significant cost, datacenter operators are forced to keep physical servers at low utilization levels (typically below 20%), to minimize adverse performance interactions.   In this paper, we focus on addressing the issue of performance interference on a virtualized server operating at high utilization levels. In our work, we find that eliminating interference in the I/O path is critical for achieving good performance on consolidated servers. We present Vanguard, a device driver stack that implements a full I/O path in the Linux kernel that provisions competing workloads with dedicated resources. We focus on two key resources: in-memory buffers for the filesystem, and space on SSD devices that serve as a transparent cache for block devices. Our approach effectively mitigates performance interference, for several mixes of transactional, streaming, and analytical processing workloads. We find that with our approach a server can run more workloads close to their nominal performance level as compared to the unmodified Linux I/O path, by careful allocation of I/O path resources to each workload. At excessive load levels, i.e. when the aggregate load exceeds the capabilities of the server, our approach can still provide isolated slices of the I/O path for a subset of the co-located workloads yielding at least 50% of their nominal performance. In addition, Vanguard is shown to be 2.5x more efficient in terms of service resource usage for a 4-workload mix, taking into account utilization and power consumption. With an I/O-heavy mix 6-workload mix, Vanguard is 8x more efficient than the unmodified baseline Linux system."
2064354,15258,22288,Certicloud: A Novel TPM-based Approach to Ensure Cloud IaaS Security,2011,"The security issues raised by the Cloud paradigm are not always tackled from the user point of view. For instance, considering an Infrastructure-as-a-Service (IaaS) Cloud, it is currently impossible for a user to certify in a reliable and secure way that the environment he deployed (typically a Virtual Machine(VM)) has not been corrupted, whether by malicious acts or not. Yet having this functionality would enhance the confidence on the IaaS provider and therefore attract new customers. This paper fills this need by proposing CERTICLOUD, a novel approach for the protection of IaaS platforms that relies on the concepts developed in the Trusted Computing Group (TCG) together with hardware elements, i.e., Trusted Platform Module (TPM) to offer a secured and reassuring environment. Those aspects are guaranteed by two protocols: TCRR and Verify MyVM. When the first one asserts the integrity of a remote resource and permits to exchange a private symmetric key, the second authorizes the user to detect trustfully and on demand any tampering attempt on its running VM. These protocols being key components in the proposed framework, we take very seriously their analysis against known cryptanalytic attacks. This is testified by their successful validation by AVISPA and Scyther, two reference tools for the automatic verification of security protocols. The CERTICLOUD proposal is then detailed: relying on the above protocols, this platform provides the secure storage of users environments and their safe deployment onto a virtualization framework. While the physical resources are checked by TCRR, the user can execute on demand the Verify MyVM protocol to certify the integrity of its deployed environment. Experimental results operated on a first prototype of CERTICLOUD demonstrate the feasibility and the low overhead of the approach, together with its easy implementation on recent commodity machines."
2003492,15258,23836,Automated Architecture-Aware Mapping of Streaming Applications Onto GPUs,2011,"Graphic Processing Units (GPUs) are made up of many streaming multiprocessors, each consisting of processing cores that interleave the execution of a large number of threads. Groups of threads - called {\em warps} and {\em wave fronts}, respectively, in nVidia and AMD literature - are selected by the hardware scheduler and executed in lockstep on the available cores. If threads in such a group access the slow off-chip global memory, the entire group has to be stalled, and another group is scheduled instead. The utilization of a given multiprocessor will remain high if there is a sufficient number of alternative thread groups to select from. Many parallel general purpose applications have been efficiently mapped to GPUs. Unfortunately, many stream processing applications exhibit unfavorable data movement patterns and low computation-to-communication ratio that may lead to poor performance. In this paper, we describe an automated compilation flow that maps most stream processing applications onto GPUs by taking into consideration two important architectural features of nVidia GPUs, namely interleaved execution as well as the small amount of shared memory available in each streaming multiprocessors. In particular, we show that using a small number of compute threads such that the memory footprint is reduced, we can achieve high utilization of the GPU cores. Our scheme goes against the conventional wisdom of GPU programming which is to use a large number of homogeneous threads. Instead, it uses a mix of {\em compute} and {\em memory access} threads, together with a carefully crafted schedule that exploits parallelism in the streaming application, while maximizing the effectiveness of the unique memory hierarchy. \% small on-chip memory located within each streaming multiprocessor. We have implemented our scheme in the compiler of the Stream It programming language, and our results show a significant speedup compared to the state-of-the-art solutions."
1888576,15258,22260,HybridMR: A Hierarchical MapReduce Scheduler for Hybrid Data Centers,2013,"Virtualized environments are attractive because they simplify cluster management, while facilitating cost-effective workload consolidation. As a result, virtual machines in public clouds or private data centers, have become the norm for running transactional applications like web services and virtual desktops. On the other hand, batch workloads like MapReduce, are typically deployed in a native cluster to avoid the performance overheads of virtualization. While both these virtual and native environments have their own strengths and weaknesses, we demonstrate in this work that it is feasible to provide the best of these two computing paradigms in a hybrid platform. In this paper, we make a case for a hybrid data center consisting of native and virtual environments, and propose a 2-phase hierarchical scheduler, called HybridMR, for the effective resource management of interactive and batch workloads. In the first phase, HybridMR classifies incoming MapReduce jobs based on the expected virtualization overheads, and uses this information to automatically guide placement between physical and virtual machines. In the second phase, HybridMR manages the run-time performance of MapReduce jobs collocated with interactive applications in order to provide best effort delivery to batch jobs, while complying with the Service Level Agreements (SLAs) of interactive applications. By consolidating batch jobs with over-provisioned foreground applications, the available unused resources are better utilized, resulting in improved application performance and energy efficiency. Evaluations on a hybrid cluster consisting of 24 physical servers and 48 virtual machines, with diverse workload mix of interactive and batch MapReduce applications, demonstrate that HybridMR can achieve up to 40% improvement in the completion times of MapReduce jobs, over the virtual-only case, while complying with the SLAs of interactive applications. Compared to the native-only cluster, at the cost of minimal performance penalty, HybridMR boosts resource utilization by 45%, and achieves up to 43% energy savings. These results indicate that a hybrid data center with an efficient scheduling mechanism can provide a cost-effective solution for hosting both batch and interactive workloads."
1262464,15258,23836,Auto-Tuning Dedispersion for Many-Core Accelerators,2014,"Dedispersion is a basic algorithm to reconstruct impulsive astrophysical signals. It is used in high sampling-rate radio astronomy to counteract temporal smearing by intervening interstellar medium. To counteract this smearing, the received signal train must be dedispersed for thousands of trial distances, after which the transformed signals are further analyzed. This process is expensive on both computing and data handling. This challenge is exacerbated in future, and even some current, radio telescopes which routinely produce hundreds of such data streams in parallel. There, the compute requirements for dedispersion are high (petascale), while the data intensity is extreme. Yet, the dedispersion algorithm remains a basic component of every radio telescope, and a fundamental step in searching the sky for radio pulsars and other transient astrophysical objects. In this paper, we study the parallelization of the dedispersion algorithm on many-core accelerators, including GPUs from AMD and NVIDIA, and the Intel Xeon Phi. An important contribution is the computational analysis of the algorithm, from which we conclude that dedispersion is inherently memory-bound in any realistic scenario, in contrast to earlier reports. We also provide empirical proof that, even in unrealistic scenarios, hardware limitations keep the arithmetic intensity low, thus limiting performance. We exploit auto-tuning to adapt the algorithm, not only to different accelerators, but also to different observations, and even telescopes. Our experiments show how the algorithm is tuned automatically for different scenarios and how it exploits and highlights the underlying specificities of the hardware: in some observations, the tuner automatically optimizes device occupancy, while in others it optimizes memory bandwidth. We quantitatively analyze the problem space, and by comparing the results of optimal auto-tuned versions against the best performing fixed codes, we show the impact that auto-tuning has on performance, and conclude that it is statistically relevant."
1663964,15258,9748,GPU Powered ROSA Analyzer,2013,"In this work we present the first version of ROSAA, Rosa Analyzer, using a GPU architecture. ROSA is a Markovian Process Algebra able to capture pure non-determinism, probabilities and timed actions, Over it, a tool has been developed for getting closer to a fully automatic process of analyzing the behaviour of a system specified as a process of ROSA, so that, ROSAA is able to automatically generate the part of the Labeled Transition System (occasionally the whole one), LTS in the sequel, in which we could be interested, but, since this is a very computationally expensive task, a GPU powered version of ROSAA which includes parallel processing capabilities, has been created to better deal with such generating process. As the conventional GPU processing loads are mainly focused on data parallelization over quite similar types of data, this work means a quite novel use of these kind of architectures, moreover the authors do not know any other formal model tool running over GPUs. ROSAA running starts with the Syntactic analysis so generating a layered structure suitable to, afterwards, apply the Operational Semantics transition rules in the easiest way. Since from each specification/state more than one rule could be applied, this is the key point at which GPU should provide its benefits, i.e., allowing to generate all the new states reachable in a single-semantics-step from a given one, at the same time through a simultaneous launching of a set of threads over the GPU platform. Although this establishes a step forward to the practical usefulness of such type of tools, the state-explosion problem arises indeed, so we are aware that reducing the size of the LTS will be sooner or later required, in this line the authors are working on an heuristics to properly prune an enough number of branches of the LTS, so making the task of generating it, more tractable."
1842293,15258,11375,An aggressive worn-out flash block management scheme to alleviate SSD performance degradation,2014,"Since NAND flash cannot be updated in place, SSDs must perform all writes in pre-erased pages. Consequently, pages containing superseded data must be invalidated and garbage collected. This garbage collection adds significant cost in terms of the extra writes necessary to relocate valid pages from erasure candidates to clean blocks, causing the well-known write amplification problem. SSDs reserve a certain amount of flash space which is invisible to users, called over-provisioning space, to alleviate the write amplification problem. However, NAND blocks can support only a limited number of program/erase cycles. As blocks are retired due to exceeding the limit, the reduced size of the over-provisioning pool leads to degraded SSD performance.   In this work, we propose a novel system design that we call the Smart Retirement FTL (SR-FTL) to reuse the flash blocks which have been cycled to the maximum specified P/E endurance. We take advantage of the fact that the specified P/E limit guarantees data retention time of at least one year while most active data becomes stale in a period much shorter than one year, as observed in a variety of disk workloads. Our approach aggressively manages worn blocks to store data that requires only short retention time. In the meantime, the data reliability on worn blocks is carefully guaranteed. We evaluate the SR-FTL by both simulation on an SSD simulator and prototype implementation on an OpenSSD platform. Experimental results show that the SR-FTL successfully maintains consistent over-provisioning space levels as blocks wear and thus the degree of SSD performance degradation near end-of-life. In addition, we show that our scheme reduces block wear near end-of-life by as much as 84% in some scenarios."
1887353,15258,23836,cuBLASTP: Fine-Grained Parallelization of Protein Sequence Search on a GPU,2014,"BLAST, short for Basic Local Alignment Search Tool, is a fundamental algorithm in the life sciences that compares biological sequences. However, with the advent of next-generation sequencing (NGS) and increase in sequence read-lengths, whether at the outset or downstream from NGS, the exponential growth of sequence databases is arguably outstripping our ability to analyze the data. Though several recent studies have utilized the graphics processing unit (GPU) to speedup the BLAST algorithm for searching protein sequences (i.e., BLASTP), these studies used coarse-grained parallel approaches, where one sequence alignment is mapped to only one thread. Moreover, due to the irregular memory access patterns in BLASTP, there remain significant challenges to map the most time-consuming phases (i.e., hit detection and ungapped extension) to the GPU using a fine-grained multithreaded approach. To address the above issues, we propose cuBLASTP, an efficient fine-grained BLASTP implementation for the GPU using CUDA. Our cuBLASTP realization encompasses many research contributions, including (1) memory-access reordering to reorder hits from column-major order to diagonal-major order, (2) position-based indexing to map a hit with a packed data structure to a bin, (3) aggressive hit filtering to eliminate hits beyond the threshold distance along the diagonal, (4) diagonal-based parallelism and hit-based parallelism for ungapped extension to extend sequences with different lengths in databases, and (5) hierarchical buffering to reduce memory-access overhead for the core data structures. The experimental results show that on a NVIDIA Kepler GPU, cuBLASTP delivers up to a 5.0-fold speedup over sequential FSA-BLAST and a 3.7-fold speedup over multithreaded NCBI-BLAST for the overall program execution. In addition, compared with GPU-BLASTP (the fastest GPU implementation of BLASTP to date), cuBLASTP achieves up to a 2.8-fold speedup for the kernel execution on the GPU and a 1.8-fold speedup for the overall program execution."
2507391,15258,9244,Six degrees of scientific data: reading patterns for extreme scale science IO,2011,"Petascale science simulations generate 10s of TBs of application data per day, much of it devoted to their checkpoint/restart fault tolerance mechanisms. Previous work demonstrated the importance of carefully managing such output to prevent application slowdown due to IO blocking, resource contention negatively impacting simulation performance and to fully exploit the IO bandwidth available to the petascale machine. This paper takes a further step in understanding and managing extreme-scale IO. Specifically, its evaluations seek to understand how to efficiently read data for subsequent data analysis, visualization, checkpoint restart after a failure, and other read-intensive operations. In their entirety, these actions support the 'end-to-end' needs of scientists enabling the scientific processes being undertaken. Contributions include the following. First, working with application scientists, we define 'read' benchmarks that capture the common read patterns used by analysis codes. Second, these read patterns are used to evaluate different IO techniques at scale to understand the effects of alternative data sizes and organizations in relation to the performance seen by end users. Third, defining the novel notion of a 'data district' to characterize how data is organized for reads, we experimentally compare the read performance seen with the ADIOS middleware's log-based BP format to that seen by the logically contiguous NetCDF or HDF5 formats commonly used by analysis tools. Measurements assess the performance seen across patterns and with different data sizes, organizations, and read process counts. Outcomes demonstrate that high end-to-end IO performance requires data organizations that offer flexibility in data layout and placement on parallel storage targets, including in ways that can make tradeoffs in the performance of data writes vs. reads."
1010653,15258,23836,Designing Network Failover and Recovery in MPI for Multi-Rail InfiniBand Clusters,2012,"The emerging trends of designing commodity based supercomputing systems have a severe detrimental impact on the Mean-Time-Between-Failures (MTBF). The MTBF for typical HEC installations is currently estimated to be between eight hours and fifteen days. Failures in the interconnect fabric account for a fair share of the total failures occurring in such systems. This will continue to degrade as system sizes become larger. Thus, it is highly desirable that next generation system architectures and software environments provide sophisticated network level fault-tolerance and fault resilient solutions. In the past few years, the number of cores on processors has increased dramatically. To make efficient use of these machines it is necessary to provide the required bandwidth to all the cores. To keep up with the multi-core trend, current generation supercomputers and clusters are designed with multiple network cards (rails) to provide enhanced data transfer capabilities. Besides providing enhanced performance, such multi-rail networks can also be leveraged to provide network level fault resilience. This paper presents a design for a failover mechanism in a multi-rail scenario, for handling network failures and their recovery without compromising on performance. In a general message passing scenario, whenever there is a network failure, the entire job aborts. Our design allows the job to continue even when a network failure occurs, by using the remaining rails for communication. Once the rail recovers from the failure, we also propose a protocol to re-establish connections on that rail and resume normal operations. We experimentally demonstrate that our implementation adds very little overhead and is able to deliver good performance which is comparable to that of the other rails running in isolation. We also show that the recovery is immediate and is associated with no additional overhead. We also depict sustenance and reliability of the design by running application benchmarks with permanent failures."
1228453,15258,20774,Efficient online scheduling for deadline-sensitive jobs: extended abstract,2013,"We consider mechanisms for online deadline-aware scheduling in large computing clusters. Batch jobs that run on such clusters often require guarantees on their completion time (i.e., deadlines). However, most existing scheduling systems implement fair-share resource allocation between users, an approach that ignores heterogeneity in job requirements and may cause deadlines to be missed.   In our framework, jobs arrive dynamically and are characterized by their value and total resource demand (or estimation thereof), along with their reported deadlines. The scheduler's objective is to maximize the aggregate value of jobs completed by their deadlines. We circumvent known lower bounds for this problem by assuming that the input has  slack , meaning that any job could be delayed and still finish by its deadline. Under the slackness assumption, we design a preemptive scheduler with a constant-factor worst-case performance guarantee. Along the way, we pay close attention to practical aspects, such as runtime efficiency, data locality and demand uncertainty. We evaluate the algorithm via simulations over real job traces taken from a large production cluster, and show that its actual performance is significantly better than other heuristics used in practice.   We then extend our framework to handle provider commitments: the requirement that jobs admitted to service must be executed until completion. We prove that no algorithm can obtain worst-case guarantees when enforcing the commitment decision to the job arrival time. Nevertheless, we design efficient heuristics that commit on job admission, in the spirit of our basic algorithm. We show empirically that these heuristics perform just as well as (or better than) the original algorithm. Finally, we discuss how our scheduling framework can be used to design  truthful  scheduling mechanisms, motivated by applications to commercial public cloud offerings."
2178452,15258,23836,Power Token Balancing: Adapting CMPs to Power Constraints for Parallel Multithreaded Workloads,2011,"In the recent years virtually all processor architectures employ multiple cores per chip (CMPs). It is possible to use legacy (i.e., single-core) power saving techniques in CMPs which run either sequential applications or independent multithreaded workloads. However, new challenges arise when running parallel shared-memory applications. In the later case, sacrificing some performance in a single core (thread) in order to be more energy-efficient might unintentionally delay the rest of cores (threads) due to synchronization points (locks/barriers), therefore, harming the performance of the whole application. CMPs increasingly face thermal and power-related problems during their typical use. Such problems can be solved by setting a power budget to the processor/core. This paper initially studies the behavior of different techniques to match a predefined power budget in a CMP processor. While legacy techniques properly work for thread independent/multi-programmed workloads, parallel workloads exhibit the problem of independently adapting the power of each core in a thread dependent scenario. In order to solve this problem we propose a novel mechanism, Power Token Balancing (PTB), aimed at accurately matching an external power constraint by balancing the power consumed among the different cores using a power token-based approach while optimizing the energy efficiency. We can use power (seen as tokens or coupons) from non-critical threads for the benefit of critical threads. PTB runs transparent for thread independent / multiprogrammed workloads and can be also used as a spin lock detector based on power patterns. Results show that PTB matches more accurately a predefined power budget (total energy consumed over the budget is reduced to 8\% for a 16-core CMP) than DVFS with only a 3\% energy increase. Finally, we can trade accuracy on matching the power budget for energy-efficiency reducing the energy a 4% with a 20% of accuracy."
2030330,15258,23836,Extending OpenSHMEM for GPU Computing,2013,"Graphics Processing Units (GPUs) are becoming an integral part of modern supercomputer architectures due to their high compute density and performance per watt. In order to maximize utilization, it is imperative that applications running on these clusters have low synchronization and communication overheads. Partitioned Global Address Space (PGAS) models provide an attractive approach for developing parallel scientific applications. Such models simplify programming through the abstraction of a shared memory address space while their one-sided communication primitives allow for efficient implementation of applications with minimum synchronization. OpenSHMEM is a library-based programming model that is gaining popularity. However, the current OpenSHMEM standard does not support direct communication from GPU device buffers. It requires data to be copied to the host memory before OpenSHMEM calls can be made. Similarly, data has to moved to the GPU explicitly by remote processes. This severely limits the programmability and performance of GPU applications. In this paper we provide extensions to the OpenSHMEM model which allow communication calls to be made directly on the GPU memory. The proposed extensions are interoperable with the two most popular GPU programming frameworks: CUDA and OpenCL. We present designs for an efficient OpenSHMEM runtime which transparently provide high-performance communication between GPUs in different inter-node and intra-node configurations. To the best of our knowledge this is the first work that enables GPU-GPU communication using the OpenSHMEM model for both CUDA and OpenCL computing frameworks. The proposed extensions to OpenSHMEM, coupled with the high-performance runtime, improve the latency of GPU-GPU shmem getmem operation by 90%, 40% and 17%, for intra-IOH (I/O Hub), inter-IOH and inter-node configurations. It improves the performance of OpenSHMEM atomics by up to 55% and 52%, for intra-IOH and inter-node GPU configurations respectively. The proposed enhancements improve the performance of Stencil2D kernel by 65% on a cluster of 192 GPUs and the performance of BFS kernel by 12% on a cluster of 96 GPUs."
1571467,15258,9772,Untangling cluster management with Helix,2012,"Distributed data systems systems are used in a variety of settings like online serving, offline analytics, data transport, and search, among other use cases. They let organizations scale out their workloads using cost-effective commodity hardware, while retaining key properties like fault tolerance and scalability. At LinkedIn we have built a number of such systems. A key pattern we observe is that even though they may serve different purposes, they tend to have a lot of common functionality, and tend to use common building blocks in their architectures. One such building block that is just beginning to receive attention is cluster management, which addresses the complexity of handling a dynamic, large-scale system with many servers. Such systems must handle software and hardware failures, setup tasks such as bootstrapping data, and operational issues such as data placement, load balancing, planned upgrades, and cluster expansion.   All of this shared complexity, which we see in all of our systems, motivates us to build a cluster management framework, Helix, to solve these problems once in a general way.   Helix provides an abstraction for a system developer to separate coordination and management tasks from component functional tasks of a distributed system. The developer defines the system behavior via a state model that enumerates the possible states of each component, the transitions between those states, and constraints that govern the system's valid settings. Helix does the heavy lifting of ensuring the system satisfies that state model in the distributed setting, while also meeting the system's goals on load balancing and throttling state changes. We detail several Helix-managed production distributed systems at LinkedIn and how Helix has helped them avoid building custom management components. We describe the Helix design and implementation and present an experimental study that demonstrates its performance and functionality."
2266871,15258,23836,Monitoring and Predicting Hardware Failures in HPC Clusters with FTB-IPMI,2012,"Fault-detection and prediction in HPC clusters and Cloud-computing systems are increasingly challenging issues. Several system middleware such as job schedulers and MPI implementations provide support for both reactive and proactive mechanisms to tolerate faults. These techniques rely on external components such as system logs and infrastructure monitors to provide information about hardware/software failure either through detection, or as a prediction. However, these middleware work in isolation, without disseminating the knowledge of faults encountered. In this context, we propose a light-weight multi-threaded service, namely FTB-IPMI, which provides distributed fault-monitoring using the Intelligent Platform Management Interface (IPMI) and coordinated propagation of fault information using the Fault-Tolerance Backplane (FTB). In essence, it serves as a middleman between system hardware and the software stack by translating raw hardware events to structured software events and delivering it to any interested component using a publish-subscribe framework. Fault-predictors and other decision-making engines that rely on distributed failure information can benefit from FTB-IPMI to facilitate proactive fault-tolerance mechanisms such as preemptive job migration. We have developed a fault-prediction engine within MVAPICH2, an RDMA-based MPI implementation, to demonstrate this capability. Failure predictions made by this engine are used to trigger migration of processes from failing nodes to healthy spare nodes, thereby providing resilience to the MPI application. Experimental evaluation clearly indicates that a single instance of FTB-IPMI can scale to several hundreds of nodes with a remarkably low resource-utilization footprint. A deployment of FTB-IPMI that services a cluster with 128 compute-nodes, sweeps the entire cluster and collects IPMI sensor information on CPU temperature, system voltages and fan speeds in about 0.75 seconds. The average CPU utilization of this service running on a single node is 0.35%."
1669012,15258,23836,A Framework for Lattice QCD Calculations on GPUs,2014,"Computing platforms equipped with accelerators like GPUs have proven to provide great computational power. However, exploiting such platforms for existing scientific applications is not a trivial task. Current GPU programming frameworks such as CUDA C/C++ require low-level programming from the developer in order to achieve high performance code. As a result porting of applications to GPUs is typically limited to time-dominant algorithms and routines, leaving the remainder not accelerated which can open a serious Amdahl's law issue. The Lattice QCD application Chroma allows us to explore a different porting strategy. The layered structure of the software architecture logically separates the data-parallel from the application layer. The QCD Data-Parallel software layer provides data types and expressions with stencil-like operations suitable for lattice field theory. Chroma implements algorithms in terms of this high-level interface. Thus by porting the low-level layer one effectively ports the whole application layer in one swing. The QDP-JIT/PTX library, our reimplementation of the low-level layer, provides a framework for Lattice QCD calculations for the CUDA architecture. The complete software interface is supported and thus applications can be run unaltered on GPU-based parallel computers. This reimplementation was possible due to the availability of a JIT compiler which translates an assembly language (PTX) to GPU code. The existing expression templates enabled us to employ compile-time computations in order to build code generators and to automate the memory management for CUDA. Our implementation has allowed us to deploy the full Chroma gauge-generation program on large scale GPU-based machines such as Titan and Blue Waters and accelerate the calculation by more than an order of magnitude."
652710,15258,9748,Dynamic distributed scheduling algorithm for state space search,2012,"Petascale computing requires complex runtime systems that need to consider load balancing along with low time and message complexity for scheduling massive scale parallel computations. Simultaneous consideration of these objectives makes online distributed scheduling a very challenging problem. For state space search applications such as UTS, NQueens, Balanced Tree Search, SAT and others, the computations are highly irregular and data dependent. Here, prior scheduling approaches such as [16], [14], [7], HotSLAW [10], which are dominantly locality-aware work-stealing driven, could lead to low parallel efficiency and scalability along with potentially high stack memory usage.#R##N##R##N#In this paper we present a novel distributed scheduling algorithm (LDSS) for multi-place parallel computations, that uses an unique combination of d-choice randomized remote (inter-place) spawns and topology-aware randomized remote work steals to reduce the overheads in the scheduler and dynamically maintain load balance across the compute nodes of the system. Our design was implemented using GASNet API and POSIX threads. For the UTS (Unbalanced Tree Search) benchmark (using upto 4096 nodes of Blue Gene/P), we deliver the best parallel efficiency (92%) for 295B node binomial tree, better than [16] (87%) and demonstrate super-linear speedup on 1 Trillion node (largest studied so far) geometric tree along with higher tree node processing rate. We also deliver upto 40% better performance than Charm++. Further, our memory utilization is lower compared to HotSLAW. Moreover, for NQueens (N=18), we demonstrate superior parallel efficiency (92%) as compared Charm++ (85%)."
1647611,15258,23836,Dataflow-like Synchronization in a PGAS Programming Model,2012,"It is expected that the first exascale supercomputer will be deployed within the next 10 years, but which programming model will allow easy development and yet scalable and efficient programs is still not known. One of the programming models considered to be feasible is the so-called partitioned global address space~(PGAS) model, which allows easy development by providing one common memory address space across all cluster nodes. In this paper we compare remote memory access and memory consistency of current PGAS programming languages and describe how synchronization can generated unneeded network transfers. We furthermore introduce our variation of the PGAS model that allows for implicit fine-grained pair-wise synchronization among the nodes. Efficient and easy to use synchronization is necessary to keep all the processors of upcoming supercomputers busy. We furthermore offer easy deployment of RDMA transfers and use communication algorithms commonly used in MPI collective operations, but lift the requirement of the operations to be collective. Our model is based on single assignment variables and uses a data-flow like synchronization mechanism. Reading uninitialized variables results in the reading thread to be blocked until data are made available by another thread. That way synchronization is done implicitly when data are read. Broadcast, scatter and gather are modeled based on data distribution among the nodes, whereas for reduction and scan we follow a combining PRAM approach of having multiple threads write to the same memory location. We discuss both a Gaus-Seidel stencil and bitonic sort in our model. We implemented a proof-of-concept library showing the usability and scalability of the model. With this library the Gaus-Seidel stencil scaled well in initial experiments on an 8-node machine."
684216,15258,11330,Characterizing the impact of soft errors on iterative methods in scientific computing,2011,"The increase in on-chip transistor count facilitates achieving higher performance, but at the expense of higher susceptibility to soft errors. In this paper, we characterize the challenges posed by soft errors for large-scale applications representative of workloads on supercomputing systems. Such applications are typically based on the computational solution of partial differential equation models using either explicit or implicit methods. In both cases, the execution time of such applications is typically dominated by the time spent in their underlying sparse matrix vector multiplication kernel (SpMV,  t  ←  A  •  y ). We provide a theoretical analysis of the impact of a single soft error through its propagation by a sequence of sparse matrix vector multiplication operations. Our analysis indicates that a single soft error in some  i th   component of the vector  y  can corrupt the entire resultant vector in a relatively short sequence of SpMV operations. Additionally, the propagation pattern corresponds to the sparsity structure of the coefficient matrix  A  and the magnitude of the error grows non-linearly as(|| A  i || 2∗ ) k , after  k  SpMV operations, where, || A  i∗ || 2  is the 2-norm of the  i th   row of  A . We corroborate this analysis with empirical observations on a model heat equation using explicit method and well known sparse matrix systems (matrices from a test suite) for the implicit method using iterative solvers such as CG, PCG and SOR. Our results indicate that explicit schemes will suffer from soft error induced numerical instabilities, thus exacerbating intrinsic stability issues for such methods, that impose constraints on relative time and space step sizes. For implicit schemes, linear solver performance through widely used CG and PCG schemes, degrades by a factor as high as 200x, whereas, a stationary scheme such as SOR is inherently soft error resilient. Our results thus indicate the need for new approaches to achieve soft error resiliency in such methods and a critical evaluation of the tradeoffs among multiple metrics, including, performance, reliability and energy."
1876230,15258,9836,Hardware transactional memory for GPU architectures,2011,"Graphics processor units (GPUs) are designed to efficiently exploit thread level parallelism (TLP), multiplexing execution of 1000s of concurrent threads on a relatively smaller set of single-instruction, multiple-thread (SIMT) cores to hide various long latency operations. While threads within a CUDA block/OpenCL workgroup can communicate efficiently through an intra-core scratchpad memory, threads in different blocks can only communicate via global memory accesses. Programmers wishing to exploit such communication have to consider data-races that may occur when multiple threads modify the same memory location. Recent GPUs provide a form of inter-block communication through atomic operations for single 32-bit/64-bit words. Although fine-grained locks can be constructed from these atomic operations, synchronization using locks is prone to deadlock. In this paper, we propose to solve these problems by extending GPUs to support transactional memory (TM). Major challenges include supporting 1000s of concurrent transactions and committing non-conflicting transactions in parallel. We propose KILO TM, a novel hardware TM design for GPUs that scales to 1000s of concurrent transactions. Without cache coherency hardware to depend on, it uses word-level, value-based conflict detection to avoid broadcast communication and reduce on-chip storage overhead. It employs speculative validation using a novel bloom filter organization to increase transaction commit parallelism. For a set of TM-enhanced GPU applications, KILO TM captures 59% of the performance of fine-grained locking, and is on average 128x faster than executing all transactions serially, for an estimated hardware area overhead of 0.5% of a commercial GPU."
775518,15258,9244,COSMIC: middleware for high performance and reliable multiprocessing on xeon phi coprocessors,2013,"It is remarkably easy to offload processing to Intel's newest manycore coprocessor, the Xeon-Phi: it supports a popular ISA (x86-based), a popular OS (Linux) and a popular programming model (OpenMP). Unfortunately, easy portability does not automatically ensure high performance. Additional programmer effort is necessary to leverage the new performance-oriented hardware features. But programmer optimizations alone are insufficient. Multiprocessing is also necessary to improve hardware utilization, and Linux makes it easy for processes to share the manycore coprocessor. However multiprocessing inefficiencies can easily offset gains made by the programmer. Our experiments on a production, high-performance Xeon server with multiple Xeon Phi coprocessors show that multiprocessing on coprocessors not only slows down the processes but also introduces unreliability (some processes crash unexpectedly). We propose a new, user-level middleware called COSMIC that improves performance and reliability of multiprocessing on coprocessors like the Xeon Phi. COSMIC seamlessly fits in the existing Xeon Phi software stack and is transparent to programmers. It manages Xeon Phi processes that execute parallel regions offloaded to the coprocessors. Offloads typically have programmer-driven performance directives like thread and affinity requirements. Unlike the existing Xeon Phi software stack, COSMIC does fair scheduling of both processes and offloads, and takes into account conflicting requirements of offloads belonging to different processes. By doing so, COSMIC has two clear benefits. First, it improves multiprocessing performance by preventing thread and memory oversubscription, by avoiding inter-offload interference and by reducing load imbalance on coprocessors and cores. Second, it increases multiprocessing reliability by exploiting programmer-specified per-process coprocessor memory requirements to completely avoid memory oversubscription and crashes. Our experiments on several representative Xeon Phi workloads show that, in a multiprocessing environment, COSMIC improves average core utilization by up to 3 times, reduces make-span by up to 52%, reduces average process latency (turn-around-time) by 70%, and completely eliminates process crashes."
1811920,15258,8306,Can traditional programming bridge the Ninja performance gap for parallel computing applications,2012,"Current processor trends of integrating more cores with wider SIMD units, along with a deeper and complex memory hierarchy, have made it increasingly more challenging to extract performance from applications. It is believed by some that traditional approaches to programming do not apply to these modern processors and hence radical new languages must be discovered. In this paper, we question this thinking and offer evidence in support of traditional programming methods and the performance-vs-programming effort effectiveness of common multi-core processors and upcoming many-core architectures in delivering significant speedup, and close-to-optimal performance for commonly used parallel computing workloads.   We first quantify the extent of the  Ninja gap , which is the performance gap between naively written C/C++ code that is parallelism unaware (often serial) and best-optimized code on modern multi-/many-core processors. Using a set of representative throughput computing benchmarks, we show that  there is an average   Ninja gap   of 24X (up to 53X ) for a recent 6-core Intel® Core™ i7 X980 Westmere CPU, and that this gap if left unaddressed will inevitably increase. We show how a set of well-known algorithmic changes coupled with advancements in modern compiler technology can bring down the Ninja gap to an average of  just 1.3X . These changes typically require low programming effort, as compared to the very high effort in producing Ninja code. We also discuss hardware support for programmability that can reduce the impact of these changes and even further increase programmer productivity. We show equally encouraging results for the upcoming Intel® Many Integrated Core architecture (Intel® MIC) which has more cores and wider SIMD. We thus demonstrate that we can contain the otherwise uncontrolled growth of the Ninja gap and offer  a more stable and predictable performance growth  over future architectures, offering strong evidence that radical language changes are not required."
937559,15258,20649,Reliability challenges for electric vehicles: from devices to architecture and systems software,2013,"Today, modern high-end cars have close to 100 electronic control units (ECUs) that are used to implement a variety of applications ranging from safety-critical control to driver assistance and comfort-related functionalities. The total sum of these applications is several million lines of software code. The ECUs are connected to different sensors and actuators and communicate via a variety of communication buses like CAN, FlexRay and now also Ethernet. In the case of electric vehicles, both the amount and the importance of such electronics and software are even higher. Here, a number of hydraulic or pneumatic controls are replaced by corresponding software-implemented controllers in order to reduce the overall weight of the car and hence to improve its driving range. Until recently, most of the software and system design in the automotive domain -- as in many other domains -- relied on an always correctly functioning or a  zero-defect  hardware implementation platform. However, as the device geometries of integrated circuits continue to shrink, this assumption is increasingly not true. Incorporating large safety margins in the design process results in very pessimistic design and expensive processors. Further, the processors in cars -- in contrast to those in many consumer electronics devices like mobile phones -- are exposed to harsh environments, extreme temperature variations, and often, strong electromagnetic fields. Hence, their reliability is even more questionable and must be explicitly accounted for in all layers of design abstraction -- starting from circuit design to architecture design, to software design and runtime management and monitoring. In this paper we outline some of these issues, currently followed practices, and the challenges that lie ahead of us in the automotive and electric vehicles domain."
2194545,15258,22260,Deterministic Blind Rendezvous in Cognitive Radio Networks,2014,"Blind rendezvous is a fundamental problem in cognitive radio networks. The problem involves a collection of agents (radios) that wish to discover each other (i.e., rendezvous) in the blind setting where there is no shared infrastructure and they initially have no knowledge of each other. Time is divided into discrete slots and spectrum is divided into discrete channels, [n] = 1, 2, ..., n. Each agent may access (or hop on) a single channel in a single time slot and two agents rendezvous when they hop on the same channel in the same time slot. The goal is to design deterministic channel hopping schedules for each agent so as to guarantee rendezvous between any pair of agents with access to overlapping sets of channels. The problem has three complicating considerations: first, the agents are asymmetric, i.e., each agent Ai only has access to a particular subset Si C [n] of the channels and different agents may have access to different subsets of channels (clearly, two agents can rendezvous only if their channel subsets overlap), second, the agents are synchronous, i.e., they do not possess a common sense of absolute time, so different agents may commence their channel schedules at different times (they do have a common sense of slot duration), lastly, agents are anonymous i.e., they do not possess an identity, and hence the schedule for Ai must depend only on Si. Whether guaranteed blind rendezvous in the asynchronous model was even achievable was an open problem. In a recent breakthrough, two independent sets of authors, Shin et al. (Communications Letters, 2010) and Lin et al. (INFOCOM, 2011), gave the first constructions guaranteeing asynchronous blind rendezvous in O (n^2) and O (n^3) time, respectively. We present a substantially improved and conceptually simpler construction guaranteeing that any two agents, Ai, Aj, will rendezvous in O (|Si| |Sj| log log n) time. Our results are the first that achieve nontrivial dependence on |Si|, the sizes of the sets of available channels. This allows us, for example, to save roughly a quadratic factor over the best previous results in the important case when channel subsets have constant size. We also achieve the best possible bound of O (1) rendezvous time for the symmetric situation, previous works could do no better than O (n). Using techniques from the probabilistic method and Ramsey theory we establish that our construction is nearly optimal: we show both an ω (|Si| |Sj|) lower bound and an ω (log log n) lower bound when |Si|, |Sj| &2264; n/2."
1681800,15258,23836,Optimizing Collective Communication in UPC,2014,"Message Passing Interface (MPI) has been the defacto programming model for scientific parallel applications. However, data driven applications with irregular communication patterns are harder to implement using MPI. The Partitioned Global Address Space (PGAS) programming models present an alternative approach to improve programmability. PGAS languages like UPC are growing in popularity because of their ability to provide shared-memory programming model over distributed memory machines. However, since UPC is an emerging standard, it is unlikely that entire applications will be re-written with it. Instead, unified communication runtimes have paved the way for a new class of hybrid applications that can leverage the benefits of both MPI and PGAS models. Such unified runtimes need to be designed in a high performance, scalable manner to improve the performance of emerging hybrid applications. Collective communication primitives offer a flexible, portable way to implement group communication operations and are supported in both MPI and PGAS programming models. Owing to their advantages, they are also widely used across various scientific parallel applications. Over the years, MPI libraries have relied upon aggressive software- /hardware-based and kernel-assisted optimizations to deliver low communication latency for various collective operations. However, there is much room for improvement for collective operations in state-of-the-art, open-source implementations of UPC. In this paper, we address the challenges associated with improving the performance of collective primitives in UPC. Further, we also explore design alternatives to enable collective primitives in UPC to directly leverage the designs available in the MVAPICH2 MPI library. Our experimental evaluations show that our designs improve the performance of the UPC broadcast and all-gather operations, by 25X and 18X respectively for 128KB message at 2,048 processes. Our designs improve the performance of the UPC 2D-Heat kernel by up to 2X times at 2,048 processes, and NAS-FT benchmark by 12% at 256 processes."
1231025,15258,23836,High Performance Alltoall and Allgather Designs for InfiniBand MIC Clusters,2014,"Intel's Many-Integrated-Core (MIC) architecture aims to provide Teraflop throughput (through high degrees of parallelism) with a high FLOP/Watt ratio and x86 compatibility. However, this two-fold approach to solving power and programmability challenges for Exascale computing is constrained by certain architectural idiosyncrasies. MIC coprocessors have a memory constrained environment and its processors operate at slower clock rates. Also, being PCI devices, the communication characteristics of MIC co-processors are different compared to communication behavior seen in homogeneous environments. For instance, the performance of sending data from the MIC memory to a remote node's memory through message passing routines has 3x-6x higher latency than sending from the host processor memory. Hence communication libraries that do not consider these architectural subtleties are likely to nullify performance benefits or even cause degradation in applications that intend to use MICs and rely heavily on communication routines. The performance of Message Passing Interface (MPI) operations, especially dense collective operations like All-to-all and All gather, strongly affect the performance of many distributed parallel applications. In this paper, we revisit state-of-the-art algorithms commonly used to implement All-to-all collectives and propose adaptations and optimizations to alleviate architectural bottlenecks on MIC clusters. We also propose a few novel designs to improve the communication latency of these operations. Through micro-benchmarks and applications, we substantiate the benefits of incorporating the proposed adaptations to the All-to-All collective operations. At the micro-benchmark level, the proposed designs show as much as 79% improvement for All gather operation and up to 70% improvement for All-to-all and with the P3DFFT application, an improvement of 38% is seen in overall execution time."
971866,15258,23836,Application Level Fault Recovery: Using Fault-Tolerant Open MPI in a PDE Solver,2014,"A fault-tolerant version of Open Message Passing Interface (Open MPI), based on the draft User Level Failure Mitigation (ULFM) proposal of the MPI Forum's Fault Tolerance Working Group, is used to create fault-tolerant applications. This allows applications and libraries to design their own recovery methods and control them at the user level. However, only a limited amount of research work on user level failure recovery (including the implementation and performance evaluation of this prototype) has been carried out. This paper contributes a fault-tolerant implementation of an application solving 2D partial differential equations (PDEs) by means of a sparse grid combination technique which is capable of surviving multiple process failures caused by the faults. Our fault recovery involves reconstructing the faulty communicators without shrinking the global size by re-spawning failed MPI processes on the same physical processors where they were before the failure (for load balancing). It also involves restoring lost data from either exact check pointed data on disk, approximated data in memory (via an alternate sparse grid combination technique) or a near-exact copy of replicated data in memory. The experimental results show that the faulty communicator reconstruction time is currently large in the draft ULFM, especially for multiple process failures. They also show that the alternate combination technique has the lowest data recovery overhead, except on a system with very low disk write latency for which checkpointing has the lowest overhead. Furthermore, the errors due to the recovery of approximated data are within a factor of 10 in all cases, with the surprising result that the alternate combination technique being more accurate than the near-exact replication method. The contributed implementation details, including the analysis of the experimental results, of this paper will help application developers to resolve different issues of design and implementation of fault-tolerant applications by means of the Open MPI ULFM standard."
2506091,15258,23749,Mining Concept Drifting Network Traffic in Cloud Computing Environments,2012,"Anomaly-based network Intrusion Detection Systems (IDS)model patterns of normal activity and detect novel network attacks. However, these systems depend on the availability of the systems normal traffic pattern profile. But the statistical fingerprint of the normal traffic pattern can change and shift over a period of time due to changes in operational or user activity at the networked site or even system updates. The changes in normal traffic patterns over time lead to concept drift. Some changes can be temporal, cyclical and can be short-lived or they can last for longer periods of time. Depending on a number of factors the speed at which the change in traffic patterns occurs can also be variable, ranging from near instantaneous to the change occurring over the span of numerous months. These changes in traffic patterns are a cause of concern for IDSs as they can lead to a significant increase in false positive rates, thereby reducing the overall system performance. In order to improve the reliability of the IDS, there is a need for an automated mechanism to detect valid traffic changes and avoid inappropriate ad hoc responses. ROC curves have historically been used to evaluate the accuracy of IDSs. ROC curves generated using fixed, time-invariant classification thresholds do not characterize the best accuracy that an IDS can achieve in presence of concept-drifting network traffic. In this paper, we present integrated supervised machine learning and control theoretic model (especially for clouds) for detecting concept drift in network traffic patterns. The model comprises of an online support vector machine based classifier (incremental anomaly based detection), a Kullback-Leiblerdivergence based relative entropy measurement scheme (quantifying concept drift) and feedback control engine (adapting ROC thresholding). In our proposed system, any intrusion activity will cause significant variations, thereby causing a large error, while a minor aberration in the variations(concept drift) will not be immediately reported as alert."
1343818,15258,23836,Power-Efficient Multiple Producer-Consumer,2014,"Power efficiency has been one of the main objectives of hardware design in the last two decades. However, with the recent explosion of mobile computing and the increasing demand for green data centers, software power efficiency has also risen to be an equally important factor. We argue that most classic concurrency control algorithms were designed in an era when power efficiency was not an important dimension in algorithm design. Such algorithms are applied to solve a wide range of problems from kernel-level primitives in operating systems to networking devices and web services. These primitives and services are constantly and heavily invoked in any computer system and by larger scale in networking devices and data centers. Thus, even a small change in their power spectrum can make a huge impact on overall power consumption in long periods of time. This paper focuses on the classic producer-consumer problem. First, we study the power efficiency of different existing implementations of the producer-consumer problem. In particular, we present evidence that these implementations behave drastically differently with respect to power consumption. Secondly, we present a dynamic algorithm for the multiple producer-consumer problem, where consumers in a multicore system use learning mechanisms to predict the rate of production, and effectively utilize this prediction to attempt to latch onto previously scheduled CPU wake-ups. Such group latching results in minimizing the overall number of CPU wakeups and in effect, power consumption. We enable consumers to dynamically reserve more pre-allocated memory in cases where the production rate is too high. Consumers may compete for the extra space and dynamically release it when it is no longer needed. Our experiments show that our algorithm provides up to 40% decrease in the number of CPU wakeups, and 30% decrease in power consumption. We validate the scalability of our algorithm with an increasing number of consumers."
2377837,15258,23836,"On Graphs, GPUs, and Blind Dating: A Workload to Processor Matchmaking Quest",2013,"Graph processing has gained renewed attention. The increasing large scale and wealth of connected data, such as those accrued by social network applications, demand the design of new techniques and platforms to efficiently derive actionable information from large scale graphs. Hybrid systems that host processing units optimized for both fast sequential processing and bulk processing (e.g., GPUaccelerated systems) have the potential to cope with the heterogeneous structure of real graphs and enable high performance graph processing. Reaching this point, however, poses multiple challenges. The heterogeneity of the processing elements (e.g., GPUs implement a different parallel processing model than CPUs and have much less memory) and the inherent irregularity of graph workloads require careful graph partitioning and load assignment. In particular, the workload generated by a partitioning scheme should match the strength of the processing element the partition is allocated to. This work explores the feasibility and quantifies the performance gains of such low-cost partitioning schemes. We propose to partition the workload between the two types of processing elements based on vertex connectivity. We show that such partitioning schemes offer a simple, yet efficient way to boost the overall performance of the hybrid system. Our evaluation illustrates that processing a 4-billion edges graph on a system with one CPU socket and one GPU, while offloading as little as 25% of the edges to the GPU, achieves 2x performance improvement over state-of-the-art implementations running on a dual-socket symmetric system. Moreover, for the same graph, a hybrid system with dualsocket and dual-GPU is capable of 1.13 Billion breadth-first search traversed edge per second, a performance rate that is competitive with the latest entries in the Graph500 list, yet at a much lower price point."
1956840,15258,23836,Hierarchical QR Factorization Algorithms for Multi-core Cluster Systems,2012,"This paper describes a new QR factorization algorithm which is especially designed for massively parallel platforms combining parallel distributed multi-core nodes. %equipped with accelerators. These platforms make the present and the foreseeable future of high-performance computing. Our new QR factorization algorithm falls in the category of the tile algorithms which naturally enables good data locality for the sequential kernels executed by the cores (high sequential performance), low number of messages in a parallel distributed setting (small latency term), and fine granularity (high parallelism). Each tile algorithm is uniquely characterized by its sequence of reduction trees. In the context of a cluster of multicores, in order to minimize the number of inter-processor communications (aka, ``communication-avoiding'' algorithm), it is natural to consider two-level hierarchical trees composed of an ``inter-node'' tree which acts on top of ``intra-node'' trees. At the intra-node level, we propose a hierarchical tree made of three levels: (0) ``TS level'' for cache-friendliness, (1) ``low level'' for decoupled highly parallel inter-node reductions, (2) ``coupling level'' to efficiently resolve interactions between local reductions and global reductions. Our hierarchical algorithm and its implementation are flexible and modular, and can accommodate several kernel types, different distribution layouts, and a variety of reduction trees at all levels, both inter-cluster and intra-cluster. Numerical experiments on a cluster of multicore nodes (1) confirm that each of the four levels of our hierarchical tree contributes to build up performance and (2) build insights on how these levels influence performance and interact within each other. Our implementation of the new algorithm with the \Dague scheduling tool significantly outperforms currently available QR factorization softwares for all matrix shapes, thereby bringing a new advance in numerical linear algebra for petascale and exascale platforms."
1369547,15258,122,Revisiting the combining synchronization technique,2012,"Fine-grain thread synchronization has been proved, in several cases, to be outperformed by efficient implementations of the combining technique where a single thread, called the  combiner , holding a coarse-grain lock, serves, in addition to its own synchronization request, active requests announced by other threads while they are waiting by performing some form of spinning. Efficient implementations of this technique significantly reduce the cost of synchronization, so in many cases they exhibit much better performance than the most efficient finely synchronized algorithms.   In this paper, we revisit the combining technique with the goal to discover where its real performance power resides and whether or how ensuring some desired properties (e.g., fairness in serving requests) would impact performance. We do so by presenting two new implementations of this technique; the first (CC-Synch) addresses systems that support coherent caches, whereas the second (DSM-Synch) works better in cacheless NUMA machines. In comparison to previous such implementations, the new implementations (1) provide bounds on the number of remote memory references (RMRs) that they perform, (2) support a stronger notion of fairness, and (3) use simpler and less basic primitives than previous approaches. In all our experiments, the new implementations outperform by far all previous state-of-the-art combining-based and fine-grain synchronization algorithms. Our experimental analysis sheds light to the questions we aimed to answer.   Several modern multi-core systems organize the cores into clusters and provide fast communication within the same cluster and much slower communication across clusters. We present an hierarchical version of CC-Synch, called H-Synch which exploits the hierarchical communication nature of such systems to achieve better performance. Experiments show that H-Synch significantly outper forms previous state-of-the-art hierarchical approaches.   We provide new implementations of common shared data structures (like stacks and queues) based on CC-Synch, DSM-Synch and H-Synch. Our experiments show that these implementations outperform by far all previous (fine-grain or combined-based) implementations of shared stacks and queues."
1021261,15258,23836,An Agent-Based Approach to Reconciling Data Heterogeneity in Cyber-Physical Systems,2011,"Computing and communication devices in any cyber-physical system (CPS) of non-trivial scale exhibit significant heterogeneity. Critical infrastructure systems, which are prime examples of CPSs, are no exception. The extent of networking capability, decentralized control, and more generally, integration between the cyber and physical infrastructures can vary greatly within a large-scale CPS. Other manifestations of heterogeneity in CPSs are in the resolution, syntax, and semantics of data collected by sensors from the physical infrastructure. Similar challenges complicate the use of databases that maintain past sensor data, device settings, or information about the physical infrastructure. The work presented in this paper aims to address these challenges by using the summary schemas model (SSM), which enables heterogeneous data sources to be queried with an unrestricted view and/or terminology. This support for imprecise queries significantly broadens the scope of data that can be used for intelligent decision support and carries the promise of increased reliability and performance for the CPS. We seek to ensure that ambiguity and imprecision do not accompany this expanded scope. %a.r.(note imprecise query also may bring ambiguity and not exact answer into the picture) The ultimate goal of a CPS is to fortify and streamline the operation of its physical infrastructure. The success of this task is contingent upon correct and efficient interpretation of data describing the state of the physical components, and the constraints to which it is subject. To this end, we propose agent-based semantic interpretation services that extract meaningful and useful information from raw data from heterogeneous sources, aided by the SSM. The proposed approach is described in the context of intelligent water distribution networks, which are cyber-physical critical infrastructure systems responsible for reliable delivery of potable water. The methodology is general, and can be extended to a broad range of CPSs, including smart power grids and intelligent transportation systems."
1418485,15258,11058,Dynamic trace-based analysis of vectorization potential of applications,2012,"Recent hardware trends with GPUs and the increasing vector lengths of SSE-like ISA extensions for multicore CPUs imply that effective exploitation of SIMD parallelism is critical for achieving high performance on emerging and future architectures. A vast majority of existing applications were developed without any attention by their developers towards effective vectorizability of the codes. While developers of production compilers such as GNU gcc, Intel icc, PGI pgcc, and IBM xlc have invested considerable effort and made significant advances in enhancing automatic vectorization capabilities, these compilers still cannot effectively vectorize many existing scientific and engineering codes. It is therefore of considerable interest to analyze existing applications to assess the inherent latent potential for SIMD parallelism, exploitable through further compiler advances and/or via manual code changes.   In this paper we develop an approach to infer a program's SIMD parallelization potential by analyzing the dynamic data-dependence graph derived from a sequential execution trace. By considering only the observed run-time data dependences for the trace, and by relaxing the execution order of operations to allow any dependence-preserving reordering, we can detect potential SIMD parallelism that may otherwise be missed by more conservative compile-time analyses. We show that for several benchmarks our tool discovers regions of code within computationally-intensive loops that exhibit high potential for SIMD parallelism but are not vectorized by state-of-the-art compilers. We present several case studies of the use of the tool, both in identifying opportunities to enhance the transformation capabilities of vectorizing compilers, as well as in pointing to code regions to manually modify in order to enable auto-vectorization and performance improvement by existing compilers."
1393804,15258,22260,G-COPSS: A Content Centric Communication Infrastructure for Gaming Applications,2012,"Information-Centric Networking provides substantial flexibility for users to obtain information without knowing the source of information or its current location. With users increasingly focused on an online world, an emerging challenge for the network infrastructure is to support Massively Multiplayer Online Role Playing Game (MMORPG). Currently, MMORPG is built on IP infrastructure with the primary responsibility resting on servers for disseminating control messages and predicting/retrieving objects belonging to each player's view. Scale and timeliness are major challenges of such a server-oriented gaming architecture. Limited server resources significantly impair the user's interactive experience, requiring game implementations to limit the number of players in a single game instance. We propose Gaming over COPSS (G-COPSS), a distributed communication infrastructure using a Content-Oriented Pub/Sub System (COPSS) to enable efficient decentralized information dissemination in MMORPG, jointly exploiting the network and end-systems for player management and information dissemination. G-COPSS aims to scale well in the number of players in a single game, while still meeting users' response time requirements. We have implemented G-COPSS on top of the open-source CCNx implementation. We use a simple game with a hierarchical map to carefully micro benchmark the implementation and the processing involved in managing game dynamics. We have also micro benchmarked the game based on NDN and a server with an IP infrastructure. We emulate an application that is particularly emblematic of MMORPG -- Counter-Strike -- but one in which all players share a hierarchical structured map. Using trace-driven simulation, we demonstrate that G-COPSS can achieve high scalability and tight timeliness requirements of MMORPG. The simulator is parameterized based on micro benchmarks of our implementation. Our evaluations show that G-COPSS provides orders of magnitude improvement in update latency and a factor of two reduction in aggregate network load compared to a server-based implementation."
2099549,15258,11330,Rethinking shared-memory languages and hardware,2011,"The era of parallel computing for the masses is here, but writing correct parallel programs remains difficult. For many domains, shared-memory remains an attractive programming model. The memory model, which specifies the meaning of shared variables, is at the heart of this programming model. Unfortunately, it has involved a tradeoff between programmability and performance, and has arguably been one of the most challenging and contentious areas in both hardware architecture and programming language specification. Recent broad community-scale efforts have finally led to a convergence in this debate, with popular languages such as Java and C++ and most hardware vendors publishing compatible memory model specifications. Although this convergence is a dramatic improvement, it has exposed fundamental shortcomings in current popular languages and systems that thwart safe and efficient parallel computing.   I will discuss the path to the above convergence, the hard lessons learned, and their implications. A cornerstone of this convergence has been the view that the memory model should be a contract between the programmer and the system - if the programmer writes disciplined (data-race-free) programs, the system will provide high programmability (sequential consistency) and performance. I will discuss why this view is the best we can do with current popular languages, and why it is inadequate moving forward, requiring rethinking popular parallel languages and hardware. In particular, I will argue that (1) parallel languages should not only promote high-level disciplined models, but they should also enforce the discipline, and (2) for scalable and efficient performance, hardware should be co-designed to take advantage of and support such disciplined models. I will describe the Deterministic Parallel Java (DPJ) language and DeNovo hardware projects at Illinois as examples of such an approach.   This talk draws on collaborations with many colleagues over the last two decades on memory models (in particular, a CACM'10 paper with Hans-J. Boehm) and with faculty, researchers, and students from the DPJ and DeNovo projects."
916265,15258,22288,WinWizard: Expanding Xen with a LibVMI Intrusion Detection Tool,2014,"Virtual machine introspection (VMI) has grown into a number of novel security measures in recent years. Virtualized environments provide isolation, which gives way to better security. This paper presents an extension, WinWizard, of LibVMI that creates a VMI-based intrusion detection system (IDS) with emphasis on memory introspection. WinWizard is able to detect rootkits that attempts to hide processes from the administrator. Rootkits are able to subvert traditional virus scanning services because they are able to run at the kernel level. Rootkit detection becomes difficult because if the operating system has been subverted, especially at the kernel level, then it is difficult to find unauthorized changes to itself or its components. Most anti-viruses and other rootkit detectors that work on infected systems are usually only effective against rookits that have a defect in their hiding techniques. Rootkit detection through VMI is one way to effectively detect rookits. VMI detection tools will also be useful in industry. Industry is beginning to advance in its usage of cloud based workspaces. Examples of companies include Amazons Workspaces and Citrix XenDesktop. They offer remote desktops for small and medium sized businesses. These workspaces offer a fully managed cloud-based desktop experience where users can access their work resources from a variety of devices. Many universities and small businesses use services like these to reduce the number of IT staff and ease administration of a large number of desktops. As this field becomes more accessible, rootkits are going to drastically affect the performance and security of not only one users desktop, but on entire cloud infrastructures. The main way to detect a rootkit inside of these workspaces would be through virtual machine introspection. WinWinzard has demonstrated to be successful in detecting these types of rootkits, while causing little additional overhead to other virtual machines being hosted on the same hypervisor."
1655477,15258,11330,Multiple sub-row buffers in DRAM: unlocking performance and energy improvement opportunities,2012,"The twin demands of energy-efficiency and higher performance on DRAM are highly emphasized in multicore architectures. A variety of schemes have been proposed to address either the latency or the energy consumption of DRAMs. These schemes typically require non-trivial hardware changes and end up improving latency at the cost of energy or vice-versa.   One specific DRAM performance problem in multicores is that interleaved accesses from different cores can potentially degrade row-buffer locality. In this paper, based on the temporal and spatial locality characteristics of memory accesses, we propose a reorganization of the existing single large row-buffer in a DRAM bank into multiple sub-row buffers (MSRB). This re-organization not only improves row hit rates, and hence the average memory latency, but also brings down the energy consumed by the DRAM. The first major contribution of this work is proposing such a reorganization without requiring any significant changes to the existing widely accepted DRAM specifications. Our proposed reorganization improves weighted speedup by 35.8%, 14.5% and 21.6% in quad, eight and sixteen core workloads along with a 42%, 28% and 31% reduction in DRAM energy.   The proposed MSRB organization enables opportunities for the management of multiple row-buffers at the memory controller level. As the memory controller is aware of the behaviour of individual cores it allows us to implement coordinated buffer allocation schemes for different cores that take into account program behaviour. We demonstrate two such schemes, namely Fairness Oriented Allocation and Performance Oriented Allocation, which show the flexibility that memory controllers can now exploit in our MSRB organization to improve overall performance and/or fairness. Further, the MSRB organization enables additional opportunities for DRAM intra-bank parallelism and selective early precharging of the LRU row-buffer to further improve memory access latencies. These two optimizations together provide an additional 5.9% performance improvement."
715645,15258,20774,A scalable framework for heterogeneous GPU-based clusters,2012,"GPU-based heterogeneous clusters continue to draw attention from vendors and HPC users due to their high energy efficiency and much improved single-node computational performance, however, there is little parallel software available that can utilize all CPU cores and all GPUs on the heterogeneous system efficiently. On a heterogeneous cluster, the performance of a GPU (or a compute node) increases in a much faster rate than the performance of the PCI-Express connection (or the interconnection network) such that communication eventually becomes the bottleneck of the entire system. To overcome the bottleneck, we developed a multi-level partitioning and distribution method that guarantees a near-optimal communication volume. We have also extended heterogeneous tile algorithms to work on distributed memory GPU clusters. Our main idea is to execute a serial program and generate hybrid-size tasks, and follow a dataflow programming model to fire the tasks on different compute nodes. We then devised a distributed dynamic scheduling runtime system to schedule tasks, and transfer data between hybrid CPU-GPU compute nodes transparently. The runtime system employs a novel distributed task-assignment protocol to solve data dependencies between tasks without coordination between processing units. The runtime system on each node consists of a number of CPU compute threads, a number of GPU compute threads, a task generation thread, an MPI communication thread, and a CUDA communication thread. By overlapping computation and communication through dynamic scheduling, we are able to attain a high performance of 75 TFlops for Cholesky factorization on the heterogeneous Keeneland system using 100 nodes, each with twelve CPU cores and three GPUs. Moreover, our framework is able to attain high performance on distributed-memory clusters without GPUs, and shared-system multiGPUs."
2649849,15258,23593,Elastic CGRAs,2013,"Vital technology trends such as voltage scaling and homogeneous multicore scaling have reached their limits and architects turn to alternate computing paradigms, such as heterogeneous and domain-specialized solutions. Coarse-Grain Reconfigurable Arrays (CGRAs) promise the performance of massively spatial computing while offering interesting trade-offs of flexibility versus energy efficiency. Yet, configuring and scheduling execution for CGRAs generally runs into the classic difficulties that have hampered Very-Long Instruction Word (VLIW) architectures: efficient schedules are difficult to generate, especially for applications with complex control flow and data structures, and they are inherently static - thus, in adapted to variable-latency components (such as the read ports of caches). Over the years, VLIWs have been relegated to important but specific application domains where such issues are more under the control of the designers; similarly, statically-scheduled CGRAs may prove inadequate for future general-purpose computing systems. In this paper, we introduce Elastic CGRAs, the superscalar processors of computing fabrics: no complex schedule needs to be computed at configuration time, and the operations execute dynamically in the CGRA when data are ready, thus exploiting the data parallelism that an application offers. We designed, down to a manufacturable layout, a simple CGRA where we demonstrated and optimized our elastic control circuitry. We also built a complete compilation toolchain that transforms arbitrary C code in a configuration for the array. The area overhead (26.2%), critical path overhead (8.2%) and energy overhead (53.6%) of Elastic CGRAs over non-elastic CGRAs are significantly lower than the overhead of superscalar processors over VLIWs, while providing the same benefits. At such moderate costs, elasticity may prove to be one of the key enablers to make the adoption of CGRAs widespread."
1045966,15258,23836,F2C2-STM: Flux-Based Feedback-Driven Concurrency Control for STMs,2014,"Software Transactional Memory (STM) systems provide an easy to use programming model for concurrent code and have been found suitable for parallelizing many applications providing performance gains with minimal programmer effort. With increasing core counts on modern processors one would expect increasing benefits. However, we observe that running STM applications on higher core counts is sometimes, in fact, detrimental to performance. This is due to the larger number of conflicts that arise with a larger number of parallel cores. As the number of cores available on processors steadily rise, a larger number of applications are beginning to exhibit these characteristics. In this paper we propose a novel dynamic concurrency control technique which can significantly improve performance (up to 50%) as well as resource utilization (up to 85%) for these applications at higher core counts. Our technique uses ideas borrowed from TCP's network congestion control algorithm and uses self-induced concurrency fluctuations to dynamically monitor and match varying concurrency levels in applications while minimizing global synchronization. Our flux-based feedback-driven concurrency control technique is capable of fully recovering the performance of the best statically chosen concurrency specification (as chosen by an oracle) regardless of the initial specification for several real world applications. Further, our technique can actually improve upon the performance of the oracle chosen specification by more than 10% for certain applications through dynamic adaptation to available parallelism. We demonstrate our approach on the STAMP benchmark suite while reporting significant performance and resource utilization benefits. We also demonstrate significantly better performance when comparing against state of the art concurrency control and scheduling techniques. Further, our technique is programmer friendly as it requires no changes to application code and no offline phases."
1931940,15258,11330,Automatic generation of executable communication specifications from parallel applications,2011,"Portable parallel benchmarks are widely used and highly effective for (a) the evaluation, analysis and procurement of high-performance computing (HPC) systems and (b) quantifying the potential benefits of porting applications for new hardware platforms. Yet, past techniques to synthetically parametrized hand-coded HPC benchmarks prove insufficient for today's rapidly-evolving scientific codes particularly when subject to multi-scale science modeling or when utilizing domain-specific libraries.   To address these problems, this work contributes novel methods to automatically generate highly portable and customizable communication benchmarks from HPC applications. We utilize ScalaTrace, a lossless, yet scalable, parallel application tracing framework to collect selected aspects of the run-time  behavior  of HPC applications, including communication operations and execution time, while abstracting away the  details  of the computation proper. We subsequently generate benchmarks with identical run-time behavior from the collected traces. A unique feature of our approach is that we generate benchmarks in CONCEPTUAL, a domain-specific language that enables the expression of sophisticated communication patterns using a rich and easily understandable grammar yet compiles to ordinary C+MPI. Experimental results demonstrate that the generated benchmarks are able to preserve the run-time behavior--including both the communication pattern and the execution time---of the original applications. Such automated benchmark generation is particularly valuable for proprietary, export-controlled, or classified application codes: when supplied to a third party, our auto-generated benchmarks ensure performance fidelity but without the risks associated with releasing the original code. This ability to automatically generate performance-accurate benchmarks from parallel applications is novel and without any precedence, to our knowledge."
1222767,15258,23836,Optimizing MPI Communication on Multi-GPU Systems Using CUDA Inter-Process Communication,2012,"Many modern clusters are being equipped with multiple GPUs per node to achieve better compute density and power efficiency. However, moving data in/out of GPUs continues to remain a major performance bottleneck. With CUDA 4.1, NVIDIA has introduced Inter-Process Communication (IPC) to address data movement overheads between processes using different GPUs connected to the same node. State-of-the-art MPI libraries like MVAPICH2 are being modified to allow application developers to use MPI calls directly over GPU device memory. This improves the programmability for application developers by removing the burden of dealing with complex data movement optimizations. In this paper, we propose efficient designs for intra-node MPI communication on multi-GPU nodes, taking advantage of IPC capabilities provided in CUDA. We also demonstrate how MPI one-sided communication semantics can provide better performance and overlap by taking advantage of IPC and the Direct Memory Access (DMA) engine on a GPU. We demonstrate the effectiveness of our designs using micro-benchmarks and an application. The proposed designs improve GPU-to-GPU MPI Send/Receive latency for 4MByte messages by 79% and achieve 4 times the bandwidth for the same message size. One-sided communication using Put and Active synchronization shows 74% improvement in latency for 4MByte message, compared to the existing Send/Receive based implementation. Our benchmark using Get and Passive Synchronization demonstrates that true asynchronous progress can be achieved using IPC and the GPU DMA engine. Our designs for two-sided and one-sided communication improve the performance of GPULBM, a CUDA implementation of Lattice Boltzmann Method for multiphase flows, by 16%, compared to the performance using existing designs in MVAPICH2. To the best of our knowledge, this is the first paper to provide a comprehensive solution for MPI two-sided and one-sided GPU-to-GPU communication within a node, using CUDA IPC."
1917629,15258,23497,ReQoS: reactive static/dynamic compilation for QoS in warehouse scale computers,2013,"As multicore processors with expanding core counts continue to dominate the server market, the overall utilization of the class of datacenters known as  warehouse scale computers  (WSCs) depends heavily on colocation of multiple workloads on each server to take advantage of the computational power provided by modern processors. However, many of the applications running in WSCs, such as websearch, are user-facing and have quality of service (QoS) requirements. When multiple applications are co-located on a multicore machine, contention for shared memory resources threatens application QoS as severe cross-core performance interference may occur. WSC operators are left with two options: either disregard QoS to maximize WSC utilization, or disallow the co-location of high-priority user-facing applications with other applications, resulting in low machine utilization and millions of dollars wasted.   This paper presents ReQoS, a static/dynamic compilation approach that enables low-priority applications to adaptively manipulate their own contentiousness to ensure the QoS of high-priority co-runners. ReQoS is composed of a profile guided compilation technique that identifies and inserts markers in contentious code regions in low-priority applications, and a lightweight runtime that monitors the QoS of high-priority applications and reactively reduces the pressure low-priority applications generate to the memory subsystem when cross-core interference is detected. In this work, we show that ReQoS can accurately diagnose contention and significantly reduce performance interference to ensure application QoS. Applying ReQoS to SPEC2006 and SmashBench workloads on real multicore machines, we are able to improve machine utilization by more than 70% in many cases, and more than 50% on average, while enforcing a 90% QoS threshold. We are also able to improve the energy efficiency of modern multicore machines by 47% on average over a policy of disallowing co-locations."
903638,15258,9836,Protean Code: Achieving Near-Free Online Code Transformations for Warehouse Scale Computers,2014,"Rampant dynamism due to load fluctuations, co runner changes, and varying levels of interference poses a threat to application quality of service (QoS) and has limited our ability to allow co-locations in modern warehouse scale computers (WSCs). Instruction set features such as the non-temporal memory access hints found in modern ISAs (both ARM and x86) may be useful in mitigating these effects. However, despite the challenge of this dynamism and the availability of an instruction set mechanism that might help address the problem, a key capability missing in the system software stack in modern WSCs is the ability to dynamically transform (and re-transform) the executing application code to apply these instruction set features when necessary. In this work we introduce protean code, a novel approach for enacting arbitrary compiler transformations at runtime for native programs running on commodity hardware with negligible (<1%) overhead. The fundamental insight behind the underlying mechanism of protean code is that, instead of maintaining full control throughout the program's execution as with traditional dynamic optimizers, protean code allows the original binary to execute continuously and diverts control flow only at a set of virtualized points, allowing rapid and seamless rerouting to the new code variants. In addition, the protean code compiler embeds IR with high-level semantic information into the program, empowering the dynamic compiler to perform rich analysis and transformations online with little overhead. Using a fully functional protean code compiler and runtime built on LLVM, we design PC3D, Protean Code for Cache Contention in Datacenters. PC3D dynamically employs non-temporal access hints to achieve utilization improvements of up to 2.8x (1.5x on average) higher than state-of-the-art contention mitigation runtime techniques at a QoS target of 98%."
1636882,15258,23836,Prototyping the MBTAC Processor for the REPLICA CMP,2014,"Current chip multiprocessors (CMP) have mostly been designed by replicating sequential/single core processors and providing some support for operating them with a shared memory. As a result of this, they define asynchronous computational model of threads, often require maximizing the locality of memory references to get decent performance, and feature high intercommunication overheads, that make parallel programming tedious for general purpose functionalities. Most of these problems can be eliminated by designing the processors architecture for scalable general purpose computing from the very beginning like done in processors for configurable emulated shared memory (CESM) CMPs. They provide support for machine instruction-level synchronization, make use of multithreading to support latency-insensitive computation, and promote the concept of uniform synchronous shared memory for easy variable allocation and convenient data exchange. In our earlier work we have proposed the first CESM architecture TOTAL ECLIPSE composed of early MBTAC processors making use of very low-overhead multithreading, parallel computing savvy functional unit organization, support for fast synchronization between the instructions and threads, and highly efficient multioperations. Unfortunately, certain key parts of these processors turned out to be hardly implementable and overall they lacked support for ordered multiprefix operations and full configurability of the CESM scheme. In this paper we introduce a new fully configurable version of the MBTAC-processor for our new REPLICA CESM architecture and the first FPGA implementations of it. To evaluate it, we execute short test programs on it and compare it preliminary against Intel Core i7 and DLX processors. Our FPGA design flow and testing approach are described."
782098,15258,11330,Channel borrowing: an energy-efficient nanophotonic crossbar architecture with light-weight arbitration,2012,"The emerging on-chip optical interconnection has become a promising candidate for future network design because of its advantages in high bandwidth density, low propagation delay and dynamic power consumption. However, a key challenge of on-chip optics is the high static power consumption which dominates the total network power. Hence, it is imperative to design an energy-efficient optical network architecture with high throughput while consuming low static power. In conventional optical crossbars, static channel allocation results in low channel utilization and network throughput, while full channel sharing requires a significant number of microrings, which incurs high static power.   To obtain high network throughput with low power consumption, this paper proposes a nanophotonic crossbar architecture with light-weight distributed arbitration. Network channels are allocated to an owner node, but can also be used by a few other nodes during idle time. The number of microring resonators is greatly reduced compared to the full channel sharing architecture. The arbitration is also simplified due to the small number of nodes sharing a channel. Every node can use the statically assigned channel to avoid starvation and borrow an additional idle channel to improve the utilization of the network. We intelligently select the network nodes that should share a channel to increase the chance of successful borrowing with low probability of conflict. The energy efficiency of the proposed network architecture is evaluated in terms of energy efficiency (throughput/watt) and Energy-delay 2 (ED 2 ) using synthetic traces and traffic traces from PARSEC benchmarks. The simulation results show that our design can improve energy efficiency by 34% and 26% and improve ED^2 by 73% and 45% compared to Single-write-multi-read (SWMR) crossbars and Multi-write-multi-read (MWMR) crossbars respectively."
1975419,15258,23497,A case for neuromorphic ISAs,2011,"The desire to create novel computing systems, paired with recent advances in neuroscientific understanding of the brain, has led researchers to develop neuromorphic architectures that emulate the brain. To date, such models are developed, trained, and deployed on the same substrate. However, excessive co-dependence between the substrate and the algorithm prevents portability, or at the very least requires reconstructing and retraining the model whenever the substrate changes. This paper proposes a well-defined abstraction layer -- the Neuromorphic instruction set architecture, or NISA -- that separates a neural application's algorithmic specification from the underlying execution substrate, and describes the Aivo framework, which demonstrates the concrete advantages of such an abstraction layer. Aivo consists of a NISA implementation for a rate-encoded neuromorphic system based on the cortical column abstraction, a state-of-the-art integrated development and runtime environment (IDE), and various profile-based optimization tools. Aivo's IDE generates code for emulating cortical networks on the host CPU, multiple GPGPUs, or as boolean functions. Its runtime system can deploy and adaptively optimize cortical networks in a manner similar to conventional just-in-time compilers in managed runtime systems (e.g. Java, C#).   We demonstrate the abilities of the NISA abstraction by constructing a cortical network model of the mammalian visual cortex, deploying on multiple execution substrates, and utilizing the various optimization tools we have created. For this hierarchical configuration, Aivo's profiling based network optimization tools reduce the memory footprint by 50% and improve the execution time by a factor of 3x on the host CPU. Deploying the same network on a single GPGPU results in a 30x speedup. We further demonstrate that a speedup of 480x can be achieved by deploying a massively scaled cortical network across three GPGPUs. Finally, converting a trained hierarchical network to C/C++ boolean constructs on the host CPU results in 44x speedup."
927237,15258,9836,MLP-aware dynamic instruction window resizing for adaptively exploiting both ILP and MLP,2013,"It is difficult to improve the single-thread performance of a processor in memory-intensive programs because processors have hit the memory wall, i.e., the large speed discrepancy between the processors and the main memory. Exploiting memory-level parallelism (MLP) is an effective way to overcome this problem. One scheme for exploiting MLP is aggressive out-of-order execution. To achieve this, large instruction window resources (i.e., the reorder buffer, the issue queue, and the load/store queue) are required; however, simply enlarging these resources degrades the clock cycle time. While pipelining these resources can solve this problem, this leads to instruction issue delays, which prevents instruction-level parallelism (ILP) from being exploited effectively. As a result, the performance of compute-intensive programs is degraded dramatically.   This paper proposes an adaptive dynamic instruction window resizing scheme that enlarges and pipelines the window resources only when MLP is exploitable, and shrinks and de-pipelines the resources when ILP is exploitable. Our scheme changes the size of the window resources by predicting whether MLP is exploitable based on the occurrence of last-level cache misses. Our scheme is very simple and hardware change is accommodated within the existing processor organization, it is thus very practical. Evaluation results using the SPEC2006 benchmark programs show that, for all programs, our dynamic instruction window resizing scheme achieves performance levels similar to the best performance achieved with fixed-size resources. On average, our scheme produces a performance improvement of 21% in comparison with that of a conventional processor, with an additional cost of only 6% of the conventional processor core or 3% of the entire processor chip, thus achieving a significantly better cost/performance ratio that is far beyond the level that can be achieved based on Pollack's law. The evaluation results also show an 8% better energy efficiency in terms of 1/EDP (energy-delay product)."
1855317,15258,23497,Paragon: collaborative speculative loop execution on GPU and CPU,2012,"The rise of graphics engines as one of the main parallel platforms for general purpose computing has ignited a wide search for better programming support for GPUs. Due to their non-traditional execution model, developing applications for GPUs is usually very challenging, and as a result, these devices are left under-utilized in many commodity systems. Several languages, such as CUDA, have emerged to solve this challenge, but past research has shown that developing applications in these languages is a daunting task because of the tedious performance optimization cycle or inherent algorithmic characteristics of an application, which could make it unsuitable for GPUs. Also, previous approaches of automatically generating optimized parallel code in CUDA for GPUs using complex compilation techniques have failed to utilize GPUs that are present in everyday computing devices such as laptops and mobile systems.   In this work, we take a different approach. Although it is hard to generate optimized code for GPU, it is beneficial to utilize them speculatively rather than leaving them running idle due to their high raw performance capabilities compared to CPUs. To achieve this goal, we propose Paragon: a collaborative static/dynamic compiler platform to speculatively run possibly-data-parallel pieces of sequential applications on GPUs. Paragon utilizes the GPU in an opportunistic way for loops that are categorized as possibly-data-parallel by its loop classification phase. While running the loop speculatively, Paragon monitors the dependencies using a light-weight kernel management unit, and transfers the execution to the CPU in case a conflict is detected. Paragon resumes the execution on the GPU after the dependency is executed sequentially on the CPU. Our experiments show that Paragon achieves up to 12x speedup compared to unsafe CPU execution with 4 threads."
2459016,15258,9748,Eager Meets Lazy: The Impact of Write-Buffering on Hardware Transactional Memory,2011,"Hardware transactional memory (HTM) systems have been studied extensively along the dimensions of speculative versioning and contention management policies. The relative performance of several designs policies has been discussed at length in prior work within the framework of scalable chip-multiprocessing systems. Yet, the impact of simple structural optimizations like write-buffering has not been investigated and performance deviations due to the presence or absence of these optimizations remains unclear. This lack of insight into the effective use and impact of these interfacial structures between the processor core and the coherent memory hierarchy forms the crux of the problem we study in this paper. Through detailed modeling of various write-buffering configurations we show that they play a major role in determining the overall performance of a practical HTM system. Our study of both eager and lazy conflict resolution mechanisms in a scalable parallel architecture notes a remarkable convergence of the performance of these two diametrically opposite design points when write buffers are introduced and used well to support the common case. Mitigation of redundant actions, fewer invalidations on abort, latency-hiding and prefetch effects contribute towards reducing execution times for transactions. Shorter transaction durations also imply a lower contention probability, thereby amplifying gains even further. The insights, related to the interplay between buffering mechanisms, system policies and workload characteristics, contained in this paper clearly distinguish gains in performance to be had from write-buffering from those that can be ascribed to HTM policy. We believe that this information would facilitate sound design decisions when incorporating HTMs into parallel architectures."
245728,15258,8967,Horus: fine-grained encryption-based security for large-scale storage,2013,"With the growing use of large-scale distributed systems, the likelihood that at least one node is compromised is increasing. Large-scale systems that process sensitive data such as geographic data with defense implications, drug modeling, nuclear explosion modeling, and private genomic data would benefit greatly from strong security for their storage. Nevertheless, many high performance computing (HPC), cloud, or secure content delivery network (SCDN) systems that handle such data still store them unencrypted or use simple encryption schemes, relying heavily on physical isolation to ensure confidentiality, providing little protection against compromised computers or malicious insiders. Moreover, current encryption solutions cannot efficiently provide fine-grained encryption for large datasets.#R##N##R##N#Our approach, Horus, encrypts large datasets using keyed hash trees (KHTs) to generate different keys for each region of the dataset, providing fine-grained security: the key for one region cannot be used to access another region. Horus also reduces key management and distribution overhead while providing end-to-end data encryption and reducing the need to trust system operators or cloud service providers. Horus requires little modification to existing systems and user applications. Performance evaluation shows that our prototype's key distribution is highly scalable and robust: a single key server can provide 140,000 keys per second, theoretically enough to sustain more than 100 GB/s I/O throughput, and multiple key servers can efficiently operate in parallel to support load balancing and reliability."
1221872,15258,23497,GPUDet: a deterministic GPU architecture,2013,"Nondeterminism is a key challenge in developing multithreaded applications. Even with the same input, each execution of a multithreaded program may produce a different output. This behavior complicates debugging and limits one's ability to test for correctness. This non-reproducibility situation is aggravated on massively parallel architectures like graphics processing units (GPUs) with thousands of concurrent threads. We believe providing a deterministic environment to ease debugging and testing of GPU applications is essential to enable a broader class of software to use GPUs.   Many hardware and software techniques have been proposed for providing determinism on general-purpose multi-core processors. However, these techniques are designed for small numbers of threads. Scaling them to thousands of threads on a GPU is a major challenge. This paper proposes a scalable hardware mechanism, GPUDet, to provide determinism in GPU architectures. In this paper we characterize the existing deterministic and nondeterministic aspects of current GPU execution models, and we use these observations to inform GPUDet's design. For example, GPUDet leverages the inherent determinism of the SIMD hardware in GPUs to provide determinism within a wavefront at no cost. GPUDet also exploits the Z-Buffer Unit, an existing GPU hardware unit for graphics rendering, to allow parallel out-of-order memory writes to produce a deterministic output. Other optimizations in GPUDet include deterministic parallel execution of atomic operations and a workgroup-aware algorithm that eliminates unnecessary global synchronizations.   Our simulation results indicate that GPUDet incurs only 2X slowdown on average over a baseline nondeterministic architecture, with runtime overheads as low as 4% for compute-bound applications, despite running GPU kernels with thousands of threads. We also characterize the sources of overhead for deterministic execution on GPUs to provide insights for further optimizations."
1147851,15258,9244,kMemvisor: flexible system wide memory mirroring in virtual environments,2013,"Today's commercial cloud service providers require the availability with an annual uptime percentage at least 99.95\%. While memory errors become norms instead of exceptions with the increasing memory's density and capacity in cloud applications. Thus, uncorrected errors from DRAM can be a significant source of system downtime. To address this increasingly important concern, both hardware and software memory mirroring technologies are studied nowadays to provide memory high availability. However, hardware solutions like mirror memory, which uses doubled chip, need dedicated and costly peripheral hardware. While existing software approaches, i.e., virtual machine's checkpoint technology, reduce the expense but incur the high overhead in practical usage. In this paper, we present a novel system called \emph{k}Memvisor to provide system-wide high availability memory mirroring. It is a software approach achieving flexible multi-granularity memory mirroring via virtualization and binary translation technology. Specifically, kMemvisor first creates backup space of the same size of the specified memory for applications or virtual machines. We can flexibly set memory areas to be mirrored or not mirrored from application level to system-wide. Then, all memory write instructions in the native memory space are captured and instrumented by mirror memory write instructions to synchronize the data in backup space. Furthermore, this instruction level memory synchronization reduces backup overhead and lowers the probability of data loss compared with traditional software approaches. So kMemvisor could use data from the backup space to recover when memory failures happen. The results show that kMemvisor causes 55% overhead in the worst case of system-wide high availability and 30% average for the real world applications, which outperforms the state-of-the-art software approaches even in the worst case."
2413906,15258,9244,On the efficacy of GPU-integrated MPI for scientific applications,2013,"Scientific computing applications are quickly adapting to leverage the massive parallelism of GPUs in large-scale clusters. However, the current hybrid programming models require application developers to explicitly manage the disjointed host and GPU memories, thus reducing both efficiency and productivity. Consequently, GPU-integrated MPI solutions, such as MPI-ACC and MVAPICH2-GPU, have been developed that provide unified programming interfaces and optimized implementations for end-to-end data communication among CPUs and GPUs. To date, however, there lacks an in-depth performance characterization of the new optimization spaces or the productivity impact of such GPU-integrated communication systems for scientific applications.   In this paper, we study the efficacy of GPU-integrated MPI on scientific applications from domains such as epidemiology simulation and seismology modeling, and we discuss the lessons learned. We use MPI-ACC as an example implementation and demonstrate how the programmer can seamlessly choose between either the CPU or the GPU as the logical communication end point, depending on the application's computational requirements. MPI-ACC also encourages programmers to explore novel application-specific optimizations, such as internode CPU-GPU communication with concurrent CPU-GPU computations, which can improve the overall cluster utilization. Furthermore, MPI-ACC internally implements scalable memory management techniques, thereby decoupling the low-level memory optimizations from the applications and making them scalable and portable across several architectures. Experimental results from a state-of-the-art cluster with hundreds of GPUs show that the MPI-ACC--driven new application-specific optimizations can improve the performance of an epidemiology simulation by up to 61.6% and the performance of a seismology modeling application by up to 44%, when compared with traditional hybrid MPI+GPU implementations. We conclude that GPU-integrated MPI significantly enhances programmer productivity and has the potential to improve the performance and portability of scientific applications, thus making a significant step toward GPUs being 'first-class citizens' of hybrid CPU-GPU clusters."
2199044,15258,8306,Scalable power control for many-core architectures running multi-threaded applications,2011,"Optimizing the performance of a multi-core microprocessor within a power budget has recently received a lot of attention. However, most existing solutions are centralized and cannot scale well with the rapidly increasing level of core integration. While a few recent studies propose power control algorithms for many-core architectures, those solutions assume that the workload of every core is independent and therefore cannot effectively allocate power based on thread criticality to accelerate multi-threaded parallel applications, which are expected to be the primary workloads of many-core architectures. This paper presents a scalable power control solution for many-core microprocessors that is specifically designed to handle realistic workloads, i.e., a mixed group of single-threaded and multi-threaded applications. Our solution features a three-layer design. First, we adopt control theory to precisely control the power of the entire chip to its chip-level budget by adjusting the aggregated frequency of all the cores on the chip. Second, we dynamically group cores running the same applications and then partition the chip-level aggregated frequency quota among different groups for optimized overall microprocessor performance. Finally, we partition the group-level frequency quota among the cores in each group based on the measured thread criticality for shorter application completion time. As a result, our solution can optimize the microprocessor performance while precisely limiting the chip-level power consumption below the desired budget. Empirical results on a 12-core hardware testbed show that our control solution can provide precise power control, as well as 17% and 11% better application performance than two state-of-the-art solutions, on average, for mixed PARSEC and SPEC benchmarks. Furthermore, our extensive simulation results for 32, 64, and 128 cores, as well as overhead analysis for up to 4,096 cores, demonstrate that our solution is highly scalable to many-core architectures."
1145763,15258,9836,Quantifying the relationship between the power delivery network and architectural policies in a 3D-stacked memory device,2013,"Many of the pins on a modern chip are used for power delivery. If fewer pins were used to supply the same current, the wires and pins used for power delivery would have to carry larger currents over longer distances. This results in an IR-drop problem, where some of the voltage is dropped across the long resistive wires making up the power delivery network, and the eventual circuits experience fluctuations in their supplied voltage. The same problem also manifests if the pin count is the same, but the current draw is higher. IR-drop can be especially problematic in 3D DRAM devices because (i) low cost (few pins and TSVs) is a high priority, (ii) 3D-stacking increases current draw within the package without providing proportionate room for more pins, and (iii) TSVs add to the resistance of the power delivery network.   This paper is the first to characterize the relationship between the power delivery network and the maximum supported activity in a 3D-stacked DRAM memory device. The design of the power delivery network determines if some banks can handle less activity than others. It also determines the combinations of bank activities that are permissible. Both of these attributes can feed into architectural policies. For example, if some banks can handle more activities than others, the architecture benefits by placing data from high-priority threads or data from frequently accessed pages into those banks. The memory controller can also derive higher performance if it schedules requests to specific combinations of banks that do not violate the IR-drop constraint.   We first define an IR-drop-aware scheduler that encodes a number of activity constraints. This scheduler, however, falls short of the performance of an unrealistic ideal PDN that imposes no scheduling constraints by 4.6x. By addressing starvation phenomena in the scheduler, the gap is reduced to only 1.47x. Finally, by adding a dynamic page placement policy, performance is within 1.2x of the unrealistic ideal PDN. We thus show that architectural polices can help mitigate the limitations imposed by a cost constrained design."
2600884,15258,22288,Assessing the Readiness to Move into the Cloud,2012,"The race to keep software compatible and optimal with respect to the latest trends is hard. 90% of software cost can be due to maintenance, and 75% on developing new features to stay competitive and relevant. The industry progresses through periods of incremental development interspersed with true paradigm shifts. Legacy software must keep up the pace. At present we are experiencing one of these paradigm shifts, as remarked by the EC (1) The speed of change in Internet technologies continues to be impressive. Software is becoming more and more pervasive: it runs on the devices that we use every day ... (opening) a new world of possible applications. Today, technological and business model innovation generates large demand for the transition of legacy software towards modernization. However, software modernization is not a trivial issue and if improperly done, it dangers the business continuity and sustainability. This means that for any company meditating about the transition to the new paradigm of cloud computing, there is a need to have at its disposal an innovative and combined technical and business analysis on the maturity and prospect of the legacy application. The major target of this process is to identify in advance the perspectives of the migration and pre-evaluate the performance and business benefits with relation to the cost of the process. For the first time, the business value will be directly attached to the technical performance. This paper presents this aforementioned approach, being currently developed and tested, in order to assess the maturity of an application and the convenience of migrating to the new cloud computing paradigm or not, based on quantitative indicators while always ensuring the company's business continuity. Following this approach, questions such as cost and effort of the migration, impact of new business models in the company or return of the investment will be provided in advance of tackling the actual modernization."
918336,15258,11157,Staged Reads: Mitigating the impact of DRAM writes on DRAM reads,2012,"Main memory latencies have always been a concern for system performance. Given that reads are on the critical path for CPU progress, reads must be prioritized over writes. However, writes must be eventually processed and they often delay pending reads. In fact, a single channel in the main memory system offers almost no parallelism between reads and writes. This is because a single off-chip memory bus is shared by reads and writes and the direction of the bus has to be explicitly turned around when switching from writes to reads. This is an expensive operation and its cost is amortized by carrying out a burst of writes or reads every time the bus direction is switched. As a result, no reads can be processed while a memory channel is busy servicing writes. This paper proposes a novel mechanism to boost read-write parallelism and perform useful components of read operations even when the memory system is busy performing writes. If some of the banks are busy servicing writes, we start issuing reads to the other idle banks. The results of these reads are stored in a few registers near the memory chip's I/O pads. These results are quickly returned immediately following the bus turnaround. The process is referred to as a Staged Read because it decouples a single read operation into two stages, with the first step being performed in parallel with writes. This innovation can also be viewed as a form of prefetch that is internal to a memory chip. The proposed technique works best when there is bank imbalance in the write stream. We also introduce a write scheduling algorithm that artificially creates bank imbalance and allows useful read operations to be performed during the write drain. Across a suite of memory-intensive workloads, we show that Staged Reads can boost throughput by up to 33% (average 7%) with an average DRAM access latency improvement of 17%, while incurring a very small cost (0.25%) in terms of memory chip area. The throughput improvements are even greater when considering write-intensive workloads (average 11%) or future systems (average 12%)."
1587810,15258,22260,Mining Web Technical Discussions to Identify Malware Capabilities,2013,"The exponential growth of unique malware binary artifacts has led researchers to explore automated techniques for characterizing unknown malware binaries' capabilities. Thus far, automatic malware analysis systems have relied on labeled training data and analyst defined rules to identify malware samples' software features and functional categories. Such approaches require substantial expert analyst effort to maintain, as malware authors change programming languages, APIs, malicious tactics, and operating system targets. In this paper we present preliminary results demonstrating the viability of a new research direction for malware capability identification that addresses these issues, the concept of mining web technical documentation to automatically identify malware capabilities. This approach does not require expert generation of rules or training labels and automatically stays up to date with the latest software engineering trends. We make two contributions aimed at demonstrating the value of this research direction: first, with a corpus of 6 million web technical postings from the programming question and answer website StackOverflow.com, we show that symbols found in a corpus of malicious executable files, such as registry keys, file names, and API call names, also occur frequently in the StackOverflow data, suggesting that applying natural language processing to the StackOverflow posts (and other technical documents) may help us automatically generate characterizations of technical symbols, and, thereby, capabilities, found in malware. Our second contribution is to show that by analyzing function call symbol co-occurrence within StackOverflow posts, as well as the semantic tags associated with these posts, we can create function relationship graphs over the symbols which show promise in helping to identifying malware software capabilities. We argue that these early findings demonstrate the promise of a web technical document based approach to automating malware capability identification."
2668975,15258,11330,Evaluation of the Impact of Direct Warm-Water Cooling of the HPC Servers on the Data Center Ecosystem,2014,"The last 10 years we have witnessed a rapid growth of the computational performance of servers used by the scientific community. This trend was especially visible in the HPC scene, where the price per FLOPS decreased, while the packing density and power consumption of the servers increased. This, in turn changed significantly challenges and costs of keeping the environmental conditions. Currently operational costs, mainly the power bill, over the lifetime of a computing system overshadow the acquisition costs. In addition, the overheads on the consumed power introduced by the need of cooling the systems may be as big as 40%. This is a huge portion of the costs, therefore, optimizations in this area should be beneficial in terms of both economy and efficiency. There are many approaches for optimizations of the costs, mainly focusing on the air cooling. Contrary to these have we decided to scrutinize a different approach. We planned to use warm up to 45 i¾?C inlet temperature as the cooling medium for computing cluster and check if using this way of cooling can introduce significant savings and, at the same time, we can simplify the cooling infrastructure making it more robust and energy efficient. Additionally, in our approach we tried to use variable coolant temperature and flow to take maximum advantage of so called free cooling, minimizing the power consumption of the server-cooling loop pair.#R##N##R##N#To validate the hypothesis PSNC Poznan Supercomputing and Networking Center built a customized prototype system which consists of hybrid CPU and GPU computing cluster, provided by the company Iceotope, along with a customized, highly manageable and instrumented cooling loop.#R##N##R##N#In the paper we analyze the results of using our warm-water liquid cooled system to see if and, if it is the case, what are the positive and negative consequences for the data center ecosystem."
1713408,15258,23836,Hybrid BFS Approach Using Semi-external Memory,2014,"NVM devices will greatly expand the possibility of processing extremely large-scale graphs that exceed the DRAM capacity of the nodes, however, efficient implementation based on detailed performance analysis of access patterns of unstructured graph kernel on systems that utilize a mixture of DRAM and NVM devices has not been well investigated. We introduce a graph data offloading technique using NVMs that augment the hybrid BFS (Breadth-first search) algorithm widely used in the Graph500 benchmark, and conduct performance analysis to demonstrate the utility of NVMs for unstructured data. Experimental results of a Scale27 problem of a Kronecker graph compliant to the Graph500 benchmark show that our approach maximally sustains 4.22 Giga TEPS (Traversed Edges Per Second), reducing DRAM size by half with only 19.18% performance degradation on a 4-way AMD Opteron 6172 machine heavily equipped with NVM devices. Although direct comparison is difficult, this is significantly greater than the result of 0.05 GTEPS for a SCALE 36 problem by using 1TB of DRAM and 12 TB of NVM as reported by Pearce et al. Although our approach uses higher DRAM to NVM ratio, we show that a good compromise is achievable between performance vs. capacity ratio for processing large-scale graphs. This result as well as detailed performance analysis of the proposed technique suggests that we can process extremely large-scale graphs per node with minimum performance degradation by carefully considering the data structures of a given graph and the access patterns to both DRAM and NVM devices. As a result, our implementation has achieved 4.35 MTEPS/W(Mega TEPS per Watt) and ranked 4th on November 2013 edition of the Green Graph500 list in the Big Data category by using only a single fat server heavily equipped with NVMs."
1632616,15258,8306,Thin servers with smart pipes: designing SoC accelerators for memcached,2013,"Distributed in-memory key-value stores, such as memcached, are central to the scalability of modern internet services. Current deployments use commodity servers with high-end processors. However, given the cost-sensitivity of internet services and the recent proliferation of volume low-power System-on-Chip (SoC) designs, we see an opportunity for alternative architectures. We undertake a detailed characterization of memcached to reveal performance and power inefficiencies. Our study considers both high-performance and low-power CPUs and NICs across a variety of carefully-designed benchmarks that exercise the range of memcached behavior. We discover that, regardless of CPU microarchitecture, memcached execution is remarkably inefficient, saturating neither network links nor available memory bandwidth. Instead, we find performance is typically limited by the per-packet processing overheads in the NIC and OS kernel---long code paths limit CPU performance due to poor branch predictability and instruction fetch bottlenecks.   Our insights suggest that neither high-performance nor low-power cores provide a satisfactory power-performance trade-off, and point to a need for tighter integration of the network interface. Hence, we argue for an alternate architecture---Thin Servers with Smart Pipes (TSSP)---for cost-effective high-performance memcached deployment. TSSP couples an embedded-class low-power core to a memcached accelerator that can process GET requests entirely in hardware, offloading both network handling and data look up. We demonstrate the potential benefits of our TSSP architecture through an FPGA prototyping platform, and show the potential for a 6X-16X power-performance improvement over conventional server baselines."
1461690,15258,11330,HOMR: a hybrid approach to exploit maximum overlapping in MapReduce over high performance interconnects,2014,"Hadoop MapReduce is the most popular open-source parallel programming model extensively used in Big Data analytics. Although fault tolerance and platform independence make Hadoop MapReduce the most popular choice for many users, it still has huge performance improvement potentials. Recently, RDMA-based design of Hadoop MapReduce has alleviated major performance bottlenecks with the implementation of many novel design features such as in-memory merge, prefetching and caching of map outputs, and overlapping of merge and reduce phases. Although these features reduce the overall execution time for MapReduce jobs compared to the default framework, further improvement is possible if shuffle and merge phases can also be overlapped with the map phase during job execution. In this paper, we propose HOMR (a Hybrid approach to exploit maximum Overlapping in MapReduce), that incorporates not only the features implemented in RDMA-based design, but also exploits maximum possible overlapping among all different phases compared to current best approaches. Our solution introduces two key concepts: Greedy Shuffle Algorithm and On-demand Shuffle Adjustment, both of which are essential to achieve significant performance benefits over the default MapReduce framework. Architecture of HOMR is generalized enough to provide performance efficiency both over different Sockets interface as well as previous RDMA-based designs over InfiniBand. Performance evaluations show that HOMR with RDMA over InfiniBand can achieve performance benefits of 54% and 56% compared to default Hadoop over IPoIB (IP over InfiniBand) and 10GigE, respectively. Compared to the previous best RDMA-based designs, this benefit is 29%. HOMR over Sockets also achieves a maximum of 38-40% benefit compared to default Hadoop over Sockets interface. We also evaluate our design with real-world workloads like SWIM and PUMA, and observe benefits of up to 16% and 18%, respectively, over the previous best-case RDMA-based design. To the best of our knowledge, this is the first approach to achieve maximum possible overlapping for MapReduce framework."
2990121,15258,9748,Delivering Parallel Programmability to the Masses via the Intel MIC Ecosystem: A Case Study,2014,"Moore's Law effectively doubles the compute power of a microprocessor every 24 months. Over the past decade, however, this doubling in performance has been due to the doubling of the number of cores in a microprocessor rather than clock speed increases. Perhaps nowhere is this more evident than with the Intel Xeon Phi coprocessor. This many core architecture exhibits not only massive inter-core parallelism but also intra-core parallelism via a wider SIMD width. However, for data-intensive applications, the bandwidth constraint of MIChinders the full utilization of computational resources, especiallywhen massive parallelism is required to process big data sets. Furthermore, the process of optimizing the performance on suchplatforms is complex and requires architectural expertise. To evaluate the efficacy of the Intel MIC ecosystem for big data applications, we use the Floyd-Warshall algorithmas a representative case study for graph applications. Ourstudy offers evidence that traditional compiler optimizations candeliver parallel programmability to the masses on the Intel XeonPhi platform. That is, developers can straightforwardly createmanycore codes in the Intel Xeon Phi ecosystem that deliversignificant speedup. The optimizations include reordering data-access patterns, adjusting loop structures, vectorizing branches, and using OpenMP directives. We start from the default serialalgorithm and apply the above optimizations one by one. Overall, we achieve a 281.7-fold speedup over the default serial version. When compared with the default OpenMP Floyd-Warshall parallel implementation, we still achieve a 6.4-fold speedup. We also observe that the identically optimized code on MIC can outperform its CPU counterpart by up to 3.2-fold."
2189252,15258,23836,MATE-CG: A Map Reduce-Like Framework for Accelerating Data-Intensive Computations on Heterogeneous Clusters,2012,"Clusters of GPUs have rapidly emerged as the means for achieving extreme-scale, cost-effective, and powerefficient high performance computing. At the same time, high level APIs like map-reduce are being used for developing several types of high-end and/or data-intensive applications. Map-reduce, originally developed for data processing applications, has been successfully used for many classes of applications that involve a significant amount of computations, such as machine learning, image processing, and data mining applications. Because such applications can be accelerated using GPUs (and other accelerators), there has been interest in supporting map-reduce-like APIs on GPUs. However, while the use of map-reduce for a single GPU has been studied, developing map-reduce-like models for programming a heterogeneous CPU-GPU cluster remains an open challenge. This paper presents the MATE-CG system, which is a map reduce-like framework based on the generalized reduction API. We develop support for enabling scalable and efficient implementation of data-intensive applications in a heterogeneous cluster of multi-core CPUs and many-core GPUs. Our contributions are three folds: 1) we port the generalized reduction model on clusters of modern GPUs with a map-reduce-like API, dealing with very large datasets, 2) we further propose three schemes to better utilize the computing power of CPUs and/or GPUs and develop an auto-tuning strategy to achieve the best-possible heterogeneous configuration for iterative applications, 3) we show how analytical models can be used to optimize important parameters in our system. We evaluate our system using three representative data intensive applications and report results on a heterogeneous cluster of 128 CPU cores and 16 GPUs (7168 GPU cores). We show an average speedup of 87× on this cluster over execution with 2 CPU-cores. Our applications also achieve an average improvement of 25% by using CPU cores and GPUs simultaneously, over the best performance achieved from using only one of the types of resources in the cluster."
896730,15258,9748,An Execution Environment for Robust Parallel Computing on Volunteer PC Grids,2012,"A pool of distributed volunteer PCs presents an extremely hostile environment for execution of communicating parallel codes due to system and network heterogeneity, varying availability, and frequent failures. Well known methods for fault tolerance, specifically replication and check pointing, are challenging to deploy and not sufficient individually to provide continuous forward application progress. As the failure of a single logical process leads to application failure, the degree of redundancy needed for long running applications is too large to be practical. Check pointing and rollback does not provide protection against slow and variable speed nodes and is impractical when system wide MTBF is in minutes or less, common for a moderate size volunteer computing pool. The approach taken in this research is to exploit both, but that presents formidable challenges, efficient check pointing of distributed replicated processes, dynamic management of redundancy, quick restart in a distributed environment, and others. Proposed solution also leverages node selection based on availability prediction. The integrated runtime system is shown to effectively execute moderate size, coarse grain, communicating codes on a worldwide distributed volunteer environment, a new milestone in volunteer computing. The results provide new insight into how multiple techniques interact and contribute to robustness. The programming model is based on one-sided Put/Get calls to an abstract global shared space that works seamlessly with replicated processes. A Replica Exchange Molecular Dynamics code is employed to drive evaluation. The execution environment includes hosts on a University campus as well as hosts distributed around the world."
2112925,15258,23836,Exploiting Data Similarity to Reduce Memory Footprints,2011,"Memory size has long limited large-scale applications on high-performance computing (HPC) systems. Since compute nodes frequently do not have swap space, physical memory often limits problem sizes. Increasing core counts per chip and power density constraints, which limit the number of DIMMs per node, have exacerbated this problem. Further, DRAM constitutes a significant portion of overall HPC system cost. Therefore, instead of adding more DRAM to the nodes, mechanisms to manage memory usage more efficiently -- preferably transparently -- could increase effective DRAM capacity and thus the benefit of multicore nodes for HPC systems. MPI application processes often exhibit significant data similarity. These data regions occupy multiple physical locations across the individual rank processes within a multicore node and thus offer a potential savings in memory capacity. These regions, primarily residing in heap, are dynamic, which makes them difficult to manage statically. Our novel memory allocation library, {\it SBLLmallocShort}, automatically identifies identical memory blocks and merges them into a single copy. Our implementation is transparent to the application and does not require any kernel modifications. Overall, we demonstrate that {\it SBLLmalloc} reduces the memory footprint of a range of MPI applications by $32.03\%$ on average and up to $60.87\%$. Further, {\it SBLLmalloc} supports problem sizes for IRS over $21.36\%$ larger than using standard memory management techniques, thus significantly increasing effective system size. Similarly, {\it SBLLmalloc} requires $43.75\%$ fewer nodes than standard memory management techniques to solve an AMG problem."
2181130,15258,23836,NVMalloc: Exposing an Aggregate SSD Store as a Memory Partition in Extreme-Scale Machines,2012,"DRAM is a precious resource in extreme-scale machines and is increasingly becoming scarce, mainly due to the growing number of cores per node. On future multi-peta flop and exa flop machines, the memory pressure is likely to be so severe that we need to rethink our memory usage models. Fortunately, the advent of non-volatile memory (NVM) offers a unique opportunity in this space. Current NVM offerings possess several desirable properties, such as low cost and power efficiency, but suffer from high latency and lifetime issues. We need rich techniques to be able to use them alongside DRAM. In this paper, we propose a novel approach for exploiting NVM as a secondary memory partition so that applications can explicitly allocate and manipulate memory regions therein. More specifically, we propose an NVMalloc library with a suite of services that enables applications to access a distributed NVM storage system. We have devised ways within NVMalloc so that the storage system, built from compute node-local NVM devices, can be accessed in a byte-addressable fashion using the memory mapped I/O interface. Our approach has the potential to re-energize out-of-core computations on large-scale machines by having applications allocate certain variables through NVMalloc, thereby increasing the overall memory capacity available. Our evaluation on a 128-core cluster shows that NVMalloc enables applications to compute problem sizes larger than the physical memory in a cost-effective manner. It can bring more performance/efficiency gain with increased computation time between NVM memory accesses or increased data access locality. In addition, our results suggest that while NVMalloc enables transparent access to NVM-resident variables, the explicit control it provides is crucial to optimize application performance."
1453596,15258,23836,A Dependable Coarse-Grain Reconfigurable Multicore Array,2014,"Recent trends in semiconductor technology have dictated the constant reduction of device size. One negative effect stemming from the reduction in size and increased complexity is the reduced device reliability. This paper is centered around the matter of permanent fault tolerance and graceful system degradation in the presence of permanent faults. We take advantage of the natural redundancy of homogeneous multicores following a sparing strategy to reuse functional pipeline stages of faulty cores. This is done by incorporating reconfigurable interconnects next to which the cores of the system are placed, providing the flexibility to redirect the data-flow from the faulty pipeline stages of damaged cores to spare (still) functional ones. Several micro-architectural changes are introduced to decouple the processor stages and allow them to be interchangeable. The proposed approach is a clear departure from previous ones by offering full flexibility as well as highly graceful performance degradation at reasonable costs. More specifically, our coarsegrain faulttolerant multicore array provides up to ×4 better availability compared to a conventional multicore and up to ×2 higher probability to deliver at least one functioning core in high fault densities. For our benchmarks, our design (synthesized for STM 65nm SP technology) incurs a total execution-time overhead for the complete system ranging from ×1.37 to ×3.3 compared to a (baseline) non-fault-tolerant system, depending on the permanent-fault density. The area overhead is 19.5% and the energy consumption, without incorporating any power/energy- saving technique, is estimated on average to be 20.9% higher compared to the baseline, unprotected design."
740125,15258,8912,Towards secure monitoring and control systems: Diversify!,2013,"Cyber attacks have become surprisingly sophisticated over the past fifteen years. While early infections mostly targeted individual machines, recent threats leverage the widespread network connectivity to develop complex and highly coordinated attacks involving several distributed nodes [1]. Attackers are currently targeting very diverse domains, e.g., e-commerce systems, corporate networks, datacenter facilities and industrial systems, to achieve a variety of objectives, which range from credentials compromise to sabotage of physical devices, by means of smarter and smarter worms and rootkits. Stuxnet is a recent worm that well emphasizes the strong technical advances achieved by the attackers' community. It was discovered in July 2010 and firstly affected Iranian nuclear plants [2]. Stuxnet compromises the regular behavior of the supervisory control and data acquisition (SCADA) system by reprogramming the code of programmable logic controllers (PLC). Once compromised, PLCs can progressively destroy a device (e.g., components of a centrifuge, such as the case of the Iranian plant) by sending malicious control signals. Stuxnet combines a relevant number of challenging features: it exploits zero-days vulnerabilities of the Windows OS to affect the nodes connected to the PLC; it propagates either locally (e.g., by means of USB sticks) or remotely (e.g., via shared folders or the print spooler vulnerability); it is able to modify its behavior during the progression of the attack, and communicates with a remote command and control server. More importantly, Stuxnet can remain undetected for many months [3] because it is able to fool the SCADA system by emulating regular monitoring signals."
2117857,15258,23836,A Fault-Tolerant High Performance Cloud Strategy for Scientific Computing,2011,"Scientific computing often requires the availability of a massive number of computers for performing large scale experiments. Traditionally, high-performance computing solutions and installed facilities such as clusters and super computers have been employed to address these needs. Cloud computing provides scientists with a completely new model of utilizing the computing infrastructure with the ability to perform parallel computations using large pools of virtual machines (VMs). The infrastructure services (Infrastructure-as-a-service), provided by these cloud vendors, allow any user to provision a large number of compute instances. However, scientific computing is typically characterized by complex communication patterns and requires optimized runtimes. Today, VMs are manually instantiated, configured and maintained by cloud users. These coupled with the latency, crash and omission failures in service providers, results in an inefficient use of VMs, increased complexity in VM-management tasks, a reduction in the overall computation power and increased time for task completion. In this paper, a high performance cloud computing strategy is proposed that combines the adaptation of a parallel processing framework, such as the Message Passing Interface (MPI) and an efficient checkpoint infrastructure for VMs, enabling its effective use for scientific computing. By developing such a mechanism, we can achieve optimized runtimes comparable to native clusters, improve checkpoints with low interference on task execution and provide efficient task recovery. In addition, check pointing is used to minimize the cost and volatility of resource provisioning, while improving overall reliability. Analysis and simulations show that the proposed approach compares favorably with the native cluster MPI implementations."
1056314,15258,9244,Scalable in situ scientific data encoding for analytical query processing,2013,"The process of scientific data analysis in high-performance computing environments has been evolving along with the advancement of computing capabilities. With the onset of exascale computing, the increasing gap between compute performance and I/O bandwidth has rendered the traditional method of post-simulation processing a tedious process. Despite the challenges due to increased data production, there exists an opportunity to benefit from cheap computing power to perform query-driven exploration and visualization during simulation time. To accelerate such analyses, applications traditionally augment raw data with large indexes, post-simulation, which are then repeatedly utilized for data exploration. However, the generation of current state-of-the-art indexes involve a compute- and memory-intensive processing, thus rendering them inapplicable in an in situ context. In this paper we propose DIRAQ, a parallel in situ, in network data encoding and reorganization technique that enables the transformation of simulation output into a query-efficient form, with negligible runtime overhead to the simulation run. DIRAQ begins with an effective core-local, precision-based encoding approach, which incorporates an embedded compressed index that is 3 -- 6x smaller than current state-of-the-art indexing schemes. DIRAQ then applies an in network index merging strategy, enabling the creation of aggregated indexes ideally suited for spatial-context querying that speed up query responses by up to 10x versus alternative techniques. We also employ a novel aggregation strategy that is topology-, data-, and memory-aware, resulting in efficient I/O and yielding overall end-to-end encoding and I/O time that is less than that required to write the raw data with MPI collective I/O."
1363351,15258,9836,Crank it up or dial it down: coordinated multiprocessor frequency and folding control,2013,"Dynamic power management features are now an integral part of processor chip and system design. Dynamic voltage and frequency scaling (DVFS), core folding and per-core power gating (PCPG) are power control actuators (or knobs) that are available in modern multi-core systems. However, figuring out the actuation protocol for such knobs in order to achieve maximum efficiency has so far remained an open research problem. In the context of specific system utilization dynamics, the desirable order of applying these knobs is not easy to determine.   For complexity-effective algorithm development, DVFS, core folding and PCPG control methods have evolved in a somewhat decoupled manner. However, as we show in this paper, independent actuation of these techniques can lead to conflicting decisions that jeopardize the system in terms of power-performance efficiency. Therefore, a more robust coordination protocol is necessary in orchestrating the power management functions. Heuristics for achieving such coordinated control are already becoming available in server systems. It remains an open research problem to optimally adjust power and performance management options at run-time for a wide range of time-varying workload applications, environmental conditions, and power constraints.   This research paper contributes a novel approach for a systematically architected, robust, multi-knob power management protocol, which we empirically analyze on live server systems. We use a latest generation POWER7+ multi-core system to demonstrate the benefits of our proposed new  coordinated  power management algorithm (called PAMPA). We report measurement-based analysis to show that PAMPA achieves comparable power-performance efficiencies (relative to a baseline decoupled control system) while achieving conflict-free actuation and robust operation."
807519,15258,9836,A Mostly-Clean DRAM Cache for Effective Hit Speculation and Self-Balancing Dispatch,2012,"Die-stacking technology allows conventional DRAM to be integrated with processors. While numerous opportunities to make use of such stacked DRAM exist, one promising way is to use it as a large cache. Although previous studies show that DRAM caches can deliver performance benefits, there remain inefficiencies as well as significant hardware costs for auxiliary structures. This paper presents two innovations that exploit the bursty nature of memory requests to streamline the DRAM cache. The first is a low-cost Hit-Miss Predictor (HMP) that virtually eliminates the hardware overhead of the previously proposed multi-megabyte Miss Map structure. The second is a Self-Balancing Dispatch (SBD) mechanism that dynamically sends some requests to the off-chip memory even though the request may have hit in the die-stacked DRAM cache. This makes effective use of otherwise idle off-chip bandwidth when the DRAM cache is servicing a burst of cache hits. These techniques, however, are hampered by dirty (modified) data in the DRAM cache. To ensure correctness in the presence of dirty data in the cache, the HMP must verify that a block predicted as a miss is not actually present, otherwise the dirty block must be provided. This verification process can add latency, especially when DRAM cache banks are busy. In a similar vein, SBD cannot redirect requests to off-chip memory when a dirty copy of the block exists in the DRAM cache. To relax these constraints, we introduce a hybrid write policy for the cache that simultaneously supports write-through and write-back policies for different pages. Only a limited number of pages are permitted to operate in a write-back mode at one time, thereby bounding the amount of dirty data in the DRAM cache. By keeping the majority of the DRAM cache clean, most HMP predictions do not need to be verified, and the self balancing dispatch has more opportunities to redistribute requests (i.e., only requests to the limited number of dirty pages must go to the DRAM cache to maintain correctness). Our proposed techniques improve performance compared to the Miss Map-based DRAM cache approach while simultaneously eliminating the costly Miss Map structure."
1117157,15258,9836,B-Fetch: Branch Prediction Directed Prefetching for Chip-Multiprocessors,2014,"For decades, the primary tools in alleviating the Memory Wall have been large cache hierarchies and data prefetchers. Both approaches, become more challenging in modern, Chip-multiprocessor (CMP) design. Increasing the last-level cache (LLC) size yields diminishing returns in terms of performance per Watt; given VLSI power scaling trends, this approach becomes hard to justify. These trends also impact hardware budgets for prefetchers. Moreover, in the context of CMPs running multiple concurrent processes, prefetching accuracy is critical to prevent cache pollution effects. These concerns point to the need for a light-weight prefetcher with high accuracy. Existing data prefetchers may generally be classified as low-overhead and low accuracy (Next-n, Stride, etc.) or high-overhead and high accuracy (STeMS, ISB). We propose B-Fetch: a data prefetcher driven by branch prediction and effective address value speculation. B-Fetch leverages control flow prediction to generate an expected future path of the executing application. It then speculatively computes the effective address of the load instructions along that path based upon a history of past register transformations. Detailed simulation using a cycle accurate simulator shows a geometric mean speedup of 23.4% for single-threaded workloads, improving to 28.6% for multi-application workloads over a baseline system without prefetching. We find that B-Fetch outperforms an existing best-of-class light-weight prefetcher under single-threaded and multi programmed workloads by 9% on average, with 65% less storage overhead."
2018065,15258,23836,Power-Aware Replica Placement and Update Strategies in Tree Networks,2011,"This paper deals with optimal strategies to place replicas in tree networks, with the double objective to minimize the total cost of the servers, and/or to optimize power consumption. The client requests are known beforehand, and some servers are assumed to pre-exist in the tree. Without power consumption constraints, the total cost is an arbitrary function of the number of existing servers that are reused, and of the number of new servers. Whenever creating and operating a new server has higher cost than reusing an existing one (which is a very natural assumption), cost optimal strategies have to trade-off between reusing resources and load-balancing requests on new servers. We provide an optimal dynamic programming algorithm that returns the optimal cost, thereby extending known results without pre-existing servers. With power consumption constraints, we assume that servers operate under a set of $M$ different modes depending upon the number of requests that they have to process. In practice $M$ is a small number, typically $2$ or $3$, depending upon the number of allowed voltages. Power consumption includes a static part, proportional to the total number of servers, and a dynamic part, proportional to a constant exponent of the server mode, which depends upon the model for power. The cost function becomes a more complicated function that takes into account reuse and creation as before, but also upgrading or downgrading an existing server from one mode to another. We show that with an arbitrary number of modes, the power minimization problem is NP-complete, even without cost constraint, and without static power. Still, we provide an optimal dynamic programming algorithm that returns the minimal power, given a threshold value on the total cost, it has exponential complexity in the number of modes $M$, and its practical usefulness is limited to small values of~$M$. Still, experiments conducted with this algorithm show that it can process large trees in reasonable time, despite its worst-case complexity."
1859902,15258,9836,BuMP: Bulk Memory Access Prediction and Streaming,2014,"With the end of Den nard scaling, server power has emerged as the limiting factor in the quest for more capable data enters. Without the benefit of supply voltage scaling, it is essential to lower the energy per operation to improve server efficiency. As the industry moves to lean-core server processors, the energy bottleneck is shifting toward main memory as a chief source of server energy consumption in modern data enters. Maximizing the energy efficiency of today's DRAM chips and interfaces requires amortizing the costly DRAM page activations over multiple row buffer accesses. This work introduces Bulk Memory Access Prediction and Streaming, or BuMP. We make the observation that a significant fraction (59-79%) of all memory accesses fall into DRAM pages with high access density, meaning that the majority of their cache blocks will be accessed within a modest time frame of the first access. Accesses to high-density DRAM pages include not only memory reads in response to load instructions, but also reads stemming from store instructions as well as memory writes upon a dirty LLC eviction. The remaining accesses go to low-density pages and virtually unpredictable reference patterns (e.g., Hashed key lookups). BuMP employs a low-cost predictor to identify high-density pages and triggers bulk transfer operations upon the first read or write to the page. In doing so, BuMP enforces high row buffer locality where it is profitable, thereby reducing DRAM energy per access by 23%, and improves server throughput by 11% across a wide range of server applications."
1106589,15258,9836,SMiTe: Precise QoS Prediction on Real-System SMT Processors to Improve Utilization in Warehouse Scale Computers,2014,"One of the key challenges for improving efficiency in warehouse scale computers (WSCs) is to improve server utilization while guaranteeing the quality of service (QoS) of latency-sensitive applications. To this end, prior work has proposed techniques to precisely predict performance and QoS interference to identify 'safe' application co-locations. However, such techniques are only applicable to resources shared across cores. Achieving such precise interference prediction on real-system simultaneous multithreading (SMT) architectures has been a significantly challenging open problem due to the complexity introduced by sharing resources within a core.   In this paper, we demonstrate through a real-system investigation that the fundamental difference between resource sharing behaviors on CMP and SMT architectures calls for a redesign of the way we model interference. For SMT servers, the interference on different shared resources, including private caches, memory ports, as well as integer and floating-point functional units, do not correlate with each other. This insight suggests the necessity of decoupling interference into multiple resource sharing dimensions. In this work, we propose SMiTe, a methodology that enables precise performance prediction for SMT co-location on real-system commodity processors. With a set of Rulers, which are carefully designed software stressors that apply pressure to a multidimensional space of shared resources, we quantify application sensitivity and contentiousness in a decoupled manner. We then establish a regression model to combine the sensitivity and contentiousness in different dimensions to predict performance interference. Using this methodology, we are able to precisely predict the performance interference in SMT co-location with an average error of 2.80% on SPEC CPU2006 and 1.79% on Cloud Suite. Our evaluation shows that SMiTe allows us to improve the utilization of WSCs by up to 42.57% while enforcing an application's QoS requirements."
1715245,15258,9748,A Hybrid CPU-GPU System for Stitching Large Scale Optical Microscopy Images,2014,"Researchers in various fields are using optical microscopy to acquire very large images, 10000 -- 200000 of pixels per side. Optical microscopes acquire these images as grids of overlapping partial images (thousands of pixels per side) that are then stitched together via software. Composing such large images is a compute and data intensive task even for modern machines. Researchers compound this difficulty further by obtaining time-series, volumetric, or multiple channel images with the resulting data sets now having or approaching terabyte sizes. We present a scalable hybrid CPU-GPU implementation of image stitching that processes large image sets at near interactive rates. Our implementation scales well with both image sizes and the number of CPU cores and GPU cards in a machine. It processes a grid of 42×59 tiles into a 17k × 22k pixels image in 43 s (end-to-end execution times) when using one NVIDIA Tesla C2070 card and two Intel Xeon E-5620 quad-core CPUs, and in 29 s when using two Tesla C2070 cards and the same two CPUs. It also composes and renders the composite image without saving it in 15 s. In comparison, ImageJ/Fiji, which is widely used by biologists, has an image stitching plugin that takes > 3.6 h for the same workload despite being multithreaded and executing the same mathematical operators, it composes and saves the large image in an additional 1.5 h. This implementation takes advantage of coarse-grain parallelism. It organizes the computation into a pipeline architecture that spans CPU and GPU resources and overlaps computation with data motion. The implementation achieves a nearly 10x performance improvement over our optimized non-pipeline GPU implementation and demonstrates near-linear speedup when increasing CPU thread count and increasing number of GPUs."
2276265,15258,11058,Using managed runtime systems to tolerate holes in wearable memories,2013,"New memory technologies, such as phase-change memory (PCM), promise denser and cheaper main memory, and are expected to displace DRAM. However, many of them experience permanent failures far more quickly than DRAM. DRAM mechanisms that handle permanent failures rely on very low failure rates and, if directly applied to PCM, are extremely inefficient: Discarding a page when the first line fails wastes 98% of the memory.   This paper proposes low complexity cooperative software and hardware that handle failure rates as high as 50%. Our approach makes error handling transparent to the application by using the memory abstraction offered by managed languages. Once hardware error correction for a memory line is exhausted, rather than discarding the entire page, the hardware communicates the failed line to a failure-aware OS and runtime. The runtime ensures memory allocations never use failed lines and moves data when lines fail during program execution. This paper describes minimal extensions to an Immix mark-region garbage collector, which correctly utilizes pages with failed physical lines by skipping over failures. This paper also proposes hardware support that clusters failed lines at one end of a memory region to reduce fragmentation and improve performance under failures. Contrary to accepted hardware wisdom that advocates for wear-leveling, we show that with software support non-uniform failures delay the impact of memory failure. Together, these mechanisms incur no performance overhead when there are no failures and at failure levels of 10% to 50% suffer only an average overhead of 4% and 12%}, respectively. These results indicate that hardware and software cooperation can greatly extend the life of wearable memories."
1938879,15258,23836,Energy-Efficient and Fault-Tolerant Unified Buffer and Bufferless Crossbar Architecture for NoCs,2012,"Network-on-Chip (NoC) architecture is considered to be an attractive solution to overcome the combined problems of limited bandwidth and scalability in multicores. Input buffering at the router allows the network to sustain the accepted throughput without performance degradation. However, the input buffers consume a substantial portion of the total power budget, and there have been proposals to reduce the size of these buffers. Eliminating buffers altogether can also reduce the power consumption at low network loads, however at higher loads when conflicts are frequent, deflecting or dropping packets can lead to higher power. In this paper, with both enhancing performance and decreasing power consumption as our goals, we propose a dual-input crossbar design called DXbar, which combines the advantages of buffer less networks to enable low-latency routing at low network load and limited buffering capability to handle excessive packets at high network load. Moreover, we also propose a unified dual-input crossbar that combines the buffer less and buffered approach in one integrated architecture. The dual crossbar network naturally provides fault tolerance and improves the reliability of the network. Dual-input crossbar architecture improves the area overhead, while providing similar performance as dual crossbar architecture. DXbar design not only has superior performance compared to the state-of-the-art designs based on similar motivation, but also achieves significant power savings. The simulation results of the proposed methodology show that DXbar achieves over 15-20% performance improvement and saves at least 15% power over the baseline design for synthetic and Splash-2 benchmarks. We further evaluated the performance by injecting varying percentage of faults into the network for both DOR and WF adaptive routing algorithms. Our results indicate that DOR outperforms WF adaptive routing algorithm at high network loads with increasing percentage of faults."
1424389,15258,23749,hatS: A Heterogeneity-Aware Tiered Storage for Hadoop,2014,"Hadoop has become the de-facto large-scale data processing framework for modern analytics applications. A major obstacle for sustaining high performance and scalability in Hadoop is managing the data growth while meeting the ever higher I/O demand. To this end, a promising trend in storage systems is to utilize hybrid and heterogeneous devices - Solid State Disks (SSD), ram disks and Network Attached Storage (NAS), which can help achieve very high I/O rates at acceptable cost. However, the Hadoop Distributed File System (HDFS) that is unable to exploit such heterogeneous storage. This is because HDFS works on the assumption that the underlying devices are homogeneous storage blocks, disregarding their individual I/O characteristics, which leads to performance degradation. In this paper, we present hatS, a Heterogeneity-Aware Tiered Storage, which is a novel redesign of HDFS into a multi-tiered storage system that seamlessly integrates heterogeneous storage technologies into the Hadoop ecosystem. hatS also proposes data placement and retrieval policies, which improve the utilization of the storage devices based on their characteristics such as I/O throughput and capacity. We evaluate hatS using an actual implementation on a medium-sized cluster consisting of HDDs and two types of SSDs (i.e., SATA SSD and PCIe SSD). Experiments show that hatS achieves 32.6% higher read bandwidth, on average, than HDFS for the test Hadoop jobs (such as Grep and Test DFSIO) by directing 64% of the I/O accesses to the SSD tiers. We also evaluate our approach with trace-driven simulations using synthetic Facebook workloads, and show that compared to the standard setup, hatS improves the average I/O rate by 36%, which results in 26% improvement in the job completion time."
2288946,15258,23836,High-throughput Analysis of Large Microscopy Image Datasets on CPU-GPU Cluster Platforms,2013,"Analysis of large pathology image datasets offers significant opportunities for the investigation of disease morphology, but the resource requirements of analysis pipelines limit the scale of such studies. Motivated by a brain cancer study, we propose and evaluate a parallel image analysis application pipeline for high throughput computation of large datasets of high resolution pathology tissue images on distributed CPU-GPU platforms. To achieve efficient execution on these hybrid systems, we have built runtime support that allows us to express the cancer image analysis application as a hierarchical data processing pipeline. The application is implemented as a coarse-grain pipeline of stages, where each stage may be further partitioned into another pipeline of fine-grain operations. The fine-grain operations are efficiently managed and scheduled for computation on CPUs and GPUs using performance aware scheduling techniques along with several optimizations, including architecture aware process placement, data locality conscious task assignment, data prefetching, and asynchronous data copy. These optimizations are employed to maximize the utilization of the aggregate computing power of CPUs and GPUs and minimize data copy overheads. Our experimental evaluation shows that the cooperative use of CPUs and GPUs achieves significant improvements on top of GPU-only versions (up to 1.6×) and that the execution of the application as a set of fine-grain operations provides more opportunities for runtime optimizations and attains better performance than coarser-grain, monolithic implementations used in other works. An implementation of the cancer image analysis pipeline using the runtime support was able to process an image dataset consisting of 36,848 4K×4K-pixel image tiles (about 1.8TB uncompressed) in less than 4 minutes (150 tiles/second) on 100 nodes of a state-of-the-art hybrid cluster system."
2539537,15258,20876,FlexECC: partially relaxing ECC of MLC SSD for better cache performance,2014,"The ever-growing capacity and continuously-dropping price have enabled flash-based MLC SSDs to be widely deployed as large non-volatile cache for storage systems. As MLC SSDs become increasingly denser and larger-capacity, more complex and complicated Error Correction Code (ECC) schemes are required to fight against the decreasing raw reliability associated with shrinking cells. However, sophisticated ECCs could impose excessive overhead on page decoding latency and thus hurt performance. In fact, we could avoid employing expensive ECC schemes inside SSDs which are utilized at the cache layer. We propose FlexECC, a specifically designed MLC SSD architecture for the purpose of better cache performance without compromising system reliability and consistency. With the help of an upper-layer cache manager classifying and passing down block access hints, FlexECC chooses to apply either regular ECC or lightweight Error Detection Code (EDC) for blocks. To reduce performance penalty caused by retrieving backend copies for corrupted blocks from the next-level store, FlexECC periodically schedules a scrubbing process to verify the integrity of blocks protected by EDC and replenish corrupted ones into the cache in advance. Experimental results of a proof-of-concept FlexECC implementation show that compared to SSDs armed with regular ECC schemes, FlexECC improves cache performance by up to 30.8% for representative workloads and 63.5% for read-intensive workloads due to reduced read latency and garbage collection overhead. In addition, FlexECC also retains its performance advantages even under various faulty conditions without sacrificing system resiliency."
1081597,15258,23836,A Utility Based Power-Aware Autonomic Approach for Running Scientific Applications,2012,"Traditionally, computational power and performance of the high performance computing (HPC) systems are assumed to depend upon the number of processors and speed of supercomputers. Supercomputers run at their peak performance to efficiently execute scientific applications. Therefore, these supercomputers consume enormous amount of power that results in increased operational cost. The high power consumption translates into high temperature of the physical HPC systems, which in turn results in high failure rate and decreased reliability. Employing an aggressive cooling system does not improve the situation, because it involves an additional operational and infrastructure cost. Slowing down these HPC systems results in loss of performance that is also not recommended. Moreover, the execution of scientific applications is affected adversely through the variation in available computational resources. This variation is due to the computational resource utilization by other applications running at the computing nodes. Therefore, the execution of a scientific application should be monitored with respect to its performance objectives (deadline etc.). Failure in meeting the deadlines may result in high cost in terms of revenue loss to the service providers. These issues raise the motivation towards the designing of an autonomic approach for managing power consumption in HPC systems without adversely affecting to the performance of the system. In this paper, we present a utility based power-aware approach that uses a model-based control theoretic framework for executing scientific applications. The approach and related simulations indicate that the performance and the power requirements of the system can dynamically be adjusted, while maintaining the predefined quality of service (QoS) goals in terms of deadline of execution and power consumption of the HPC system, even in the presence of computational resource related perturbations. This approach is autonomic, performance directed, dynamically controlled, and independent of the execution of the application."
1449798,15258,22288,MuSIC: Mobility-Aware Optimal Service Allocation in Mobile Cloud Computing,2013,"This paper exploits the observation that using tiered clouds, i.e. clouds at multiple levels (local and public) can increase the performance and scalability of mobile applications. User Mobility introduces new complexities in enabling an optimal decomposition of tasks that can execute cooperatively on mobile clients and the tiered cloud architecture while considering multiple QoS goals such application delay, device power consumption and user cost/price. In this paper, we propose a novel framework to model mobile applications as a location-time workflows (LTW) of tasks, here user mobility patterns are translated to a mobile service usage patterns. We show that an optimal mapping of LTWs to tiered mobile cloud resources is an NP-hard problem. We propose an efficient heuristic algorithm called MuSIC that is able to perform well (78% of optimal, 30% better than simple strategies), and scale well to a large number of users while ensuring high application QoS. We evaluate MuSIC and the 2-tier mobile cloud approach via implementation (on real world clouds) and extensive simulations using rich mobile applications like intensive signal processing and video streaming applications. Our experimental and simulation results indicate that MuSIC supports scalable operation (100+ concurrent users executing complex workflows) while improving QoS. We observe about 25% lower delays and power (under fixed price constraints) and about 35% decrease in price (considering fixed delay) in comparison to only using the public cloud. Our studies also show that MuSIC performs quite well under different mobility patterns, e.g. random waypoint, Manhattan models and is resilient to errors/uncertainty in prediction of mobile user location-time workflows."
921780,15258,9244,"Experiences with self-organizing, decentralized grids using the grid appliance",2011,"Give a man a fish, feed him for a day. Teach a man to fish, feed him for a lifetime -- Lau Tzu Large-scale grid computing projects such as TeraGrid and Open Science Grid provide researchers vast amounts of compute resources but with requirements that could limit access, results delayed due to potentially long job queues, and environments and policies that might affect a user's work flow. In many scenarios and in particular with the advent of Infrastructure-as-a-Service (IaaS) cloud computing, individual users and communities can benefit from less restrictive, dynamic systems that include a combination of local resources and on-demand resources provisioned by one or more IaaS provider. These types of scenarios benefit from flexibility in deploying resources, remote access, and environment configuration.   In this paper, we address how small groups can dynamically create, join, and manage grid infrastructures with low administrative overhead. Our work distinguishes itself from other projects with similar objects by enabling a combination of decentralized system organization and user access for job submission in addition to a web 2.0 interfaces for managing grid membership and automate certificate management. These components contribute to the design of the Grid Appliance, an implementation of a wide area overlay network of virtual workstations (WOW), which has developed over the past six years into a mature system with several deployments and many users. In addition to an architectural description, this paper contains lessons learned during the development and deployment of Grid Appliance systems and a case study backed by quantitative analysis that verifies the utility of our approach."
941619,15258,11330,CRQ-based fair scheduling on composable multicore architectures,2012,"As different workloads require different processor resources for better execution efficiency, recent work has proposed composable chip multiprocessors (CCMPs), which provide the capability to configure different number and types of processing cores at system runtime. However, such composable architecture poses a new significant challenge to system scheduler, that is, how to ensure priority-based performance for each task (i.e. fairness), while exploiting the benefits of composability by dynamically changing the hardware configurations to match the parallelism requirements in running tasks (i.e. resource allocation). Current multicore schedulers fail to address this problem, as they traditionally assume fixed number and types of cores.   In this work, we introduce centralized run queue (CRQ) and propose an efficiency-based algorithm to address the fair scheduling problem on CCMP. Firstly, instead of using distributed per-core run queues, this paper employs CRQ to simplify the scheduling and resource allocation decisions on CCMP, and proposes a pipeline-like scheduling mechanism to hide the large scheduling decision overhead on the centralized queue. Secondly, an efficiency-based dynamic priority (EDP) algorithm is proposed to keep fair scheduling on CCMP, which can not only provide homogenous tasks with performance proportional to their priorities, but also ensure equal-priority heterogeneous tasks to get equivalent performance slowdowns when running simultaneously. To evaluate our design, experimental studies are carried out to compare EDP on CCMP with several state-of-art fair schedulers on symmetric and asymmetric CMPs. Our simulation results demonstrate that, while providing good fairness, EDP on CCMP outperforms the best performing fair scheduler on fixed symmetric and asymmetric CMPs by as much as 11.8% in user-oriented performance, and by 12.5% in system throughput."
2317131,15258,20774,Locality-aware task management for unstructured parallelism: a quantitative limit study,2013,"As we increase the number of cores on a processor die, the on-chip cache hierarchies that support these cores are getting larger, deeper, and more complex. As a result, non-uniform memory access effects are now prevalent even on a single chip. To reduce execution time and energy consumption, data access locality should be exploited. This is especially important for task-based programming systems, where a scheduler decides when and where on the chip the code segments, i.e., tasks, should execute. Capturing locality for structured task parallelism has been done effectively, but the more difficult case, unstructured parallelism, remains largely unsolved - little quantitative analysis exists to demonstrate the potential of locality-aware scheduling, and to guide future scheduler implementations in the most fruitful direction.   This paper quantifies the potential of locality-aware scheduling for unstructured parallelism on three different many-core processors. Our simulation results of 32-core systems show that locality-aware scheduling can bring up to 2.39x speedup over a randomized schedule, and 2.05x speedup over a state-of-the-art baseline scheduling scheme. At the same time, a locality-aware schedule reduces average energy consumption by 55% and 47%, relative to the random and the baseline schedule, respectively. In addition, our 1024-core simulation results project that these benefits will only increase: Compared to 32-core executions, we see up to 1.83x additional locality benefits. To capture such potentials in a practical setting, we also perform a detailed scheduler design space exploration to quantify the impact of different scheduling decisions. We also highlight the importance of locality-aware stealing, and demonstrate that a stealing scheme can exploit significant locality while performing load balancing. Over randomized stealing, our proposed scheme shows up to 2.0x speedup for stolen tasks."
1543425,15258,23836,Experiences in Teaching a Specialty Multicore Computing Course,2012,"We detail the design and experiences in delivering a specialty multicore computing course whose materials are openly available. The course ambitiously covers three multicore programming paradigms: shared memory (OpenMP), device (CUDA) and message passing (RCCE), and involves significant practical work on their respective platforms: an UltraSPARC T2, Fermi GPU and the Intel Single-Chip Cloud Computer. Specialized multicore architecture topics include chip multiprocessing, virtualization support, on-chip accelerators and networks, transactional memory and speculative execution. The mode of delivery emphasizes the relationship between programming performance and the underlying computer architecture, necessitating the need to provide suitable infrastructure in the form of instrumented test programs and the use of performance evaluation tools. Further infrastructure had to be created to facilitate the safe, convenient and efficient use by students on the GPU and Single-Chip Cloud Computer. The programming assignments, based on the theme of the LINPACK benchmark, also required significant infrastructure for reliably determining correctness and assisting debugging. While the course assumed as background knowledge an introductory computer systems and concurrency course, we found that students could learn device programming in a short time, by building on their knowledge of shared memory programming. However, we found that more time is needed for learning message passing. We also found that, provided students had a suitably strong computer systems background, they could successfully meet the course's learning objectives, although the skill of correctly interpreting performance data remains difficult to learn when suitable performance analysis tools are not available."
1321256,15258,9244,CAM: a topology aware minimum cost flow based resource manager for MapReduce applications in the cloud,2012,"MapReduce has emerged as a prevailing distributed computation paradigm for enterprise and large-scale data-intensive computing. The model is also increasingly used in the massively-parallel cloud environment, where MapReduce jobs are run on a set of virtual machines (VMs) on pay-as-needed basis. However, MapReduce jobs suffer from performance degradation when running in the cloud due to inefficient resource allocation. In particular, the MapReduce model is designed for and leverages information from the native clusters to operate efficiently, whereas the cloud presents a virtual cluster topology overlying or hiding actual network information. This results in two  placement anomalies : loss of  data locality  and loss of  job locality , where jobs are placed physically away from their data or other associated jobs, adversely affecting their performance.   In this paper we propose, CAM, a cloud platform that provides an innovative resource scheduler particularly designed for hosting MapReduce applications in the cloud. CAM reconciles both data and VM resource allocation with a variety of competing constraints, such as storage utilization, changing CPU load and network link capacities. CAM uses a flow-network-based algorithm that is able to optimize MapReduce performance under the specified constraints -- not only by initial placement, but by readjusting through VM and data migration as well. Additionally, our platform exposes, otherwise hidden, lower-level topology information to the MapReduce job scheduler so that it makes optimal task assignments. Evaluation of CAM using both micro-benchmarks and simulations on a 23 VM cluster shows that compared to a state-of-the-art resource allocator, our system reduces network traffic and average MapReduce job execution time by a factor of 3 and 8.6, respectively."
1432558,15258,11330,Exploiting domain knowledge to optimize parallel computational mechanics codes,2013,"An important emerging problem domain in computational science and engineering is the development of  multi-scale computational methods  for complex problems in mechanics that span multiple spatial and temporal scales. An attractive approach to solving these problems is  recursive decomposition:  the problem is broken up into a tree of loosely coupled sub-problems which can be solved independently and then coupled back together to obtain the desired solution. However, a particular problem can be solved in myriad ways by coupling the sub-problems together in different tree orders. As we argue in this paper, the space of possible orders is vast, the performance gap between an arbitrary order and the best order is potentially quite large, and the likelihood that a domain scientist can find the best order to solve a problem on a particular machine is vanishingly small. In this paper, we present a system that uses domain-specific knowledge captured in computational libraries to optimize code written in a conventional language (C). The system generates efficient coupling orders to solve computational mechanics problems using recursive decomposition. Our system adopts the inspector-executor paradigm, where the problem is inspected and a novel heuristic finds an effective implementation based on domain properties evaluated by a cost model. The derived implementation is then executed by a parallel run-time system (Cilk) which achieves optimal parallel performance. We demonstrate that our cost model is highly correlated with actual application runtime, that our proposed technique outperforms non-decomposed and non-multiscale methods. The code generated by the heuristic also outperforms alternate scheduling strategies, as well as over 99% of randomly-generated recursive decompositions sampled from the space of possible solutions."
1106017,15258,23620,Plan B: a buffered memory model for Java,2013,"Recent advances in verification have made it possible to envision trusted implementations of real-world languages. Java with its type-safety and fully specified semantics would appear to be an ideal candidate; yet, the complexity of the translation steps used in production virtual machines have made it a challenging target for verifying compiler technology. One of Java's key innovations, its memory model, poses significant obstacles to such an endeavor. The Java Memory Model is an ambitious attempt at specifying the behavior of multithreaded programs in a portable, hardware agnostic, way. While experts have an intuitive grasp of the properties that the model should enjoy, the specification is complex and not well-suited for integration within a verifying compiler infrastructure. Moreover, the specification is given in an axiomatic style that is distant from the intuitive reordering-based reasonings traditionally used to justify or rule out behaviors, and ill suited to the kind of operational reasoning one would expect to employ in a compiler. This paper takes a step back, and introduces a Buffered Memory Model (BMM) for Java. We choose a pragmatic point in the design space sacrificing generality in favor of a model that is fully characterized in terms of the reorderings it allows, amenable to formal reasoning, and which can be efficiently applied to a specific hardware family, namely x86 multiprocessors. Although the BMM restricts the reorderings compilers are allowed to perform, it serves as the key enabling device to achieving a verification pathway from bytecode to machine instructions. Despite its restrictions, we show that it is backwards compatible with the Java Memory Model and that it does not cripple performance on TSO architectures."
2058807,15258,9836,NOC-Out: Microarchitecting a Scale-Out Processor,2012,"Scale-out server workloads benefit from many-core processor organizations that enable high throughput thanks to abundant request-level parallelism. A key characteristic of these workloads is the large instruction footprint that exceeds the capacity of private caches. While a shared last-level cache (LLC) can capture the instruction working set, it necessitates a low-latency interconnect fabric to minimize the core stall time on instruction fetches serviced by the LLC. Many-core processors with a mesh interconnect sacrifice performance on scale-out workloads due to NOC-induced delays. Low-diameter topologies can overcome the performance limitations of meshes through rich inter-node connectivity, but at a high area expense. To address the drawbacks of existing designs, this work introduces NOC-Out -- a many-core processor organization that affords low LLC access delays at a small area cost. NOC-Out is tuned to accommodate the bilateral core-to-cache access pattern, characterized by minimal coherence activity and lack of inter-core communication, that is dominant in scale-out workloads. Optimizing for the bilateral access pattern, NOC-Out segregates cores and LLC banks into distinct network regions and reduces costly network connectivity by eliminating the majority of inter-core links. NOC-Out further simplifies the interconnect through the use of low-complexity tree-based topologies. A detailed evaluation targeting a 64-core CMP and a set of scale-out workloads reveals that NOC-Out improves system performance by 17% and reduces network area by 28% over a tiled mesh-based design. Compared to a design with a richly-connected flattened butterfly topology, NOC-Out reduces network area by 9x while matching the performance."
1295773,15258,20774,Non-monetary fair scheduling: a cooperative game theory approach,2013,"We consider a multi-organizational system in which each organization contributes processors to the global pool but also jobs to be processed on the common resources. The fairness of the scheduling algorithm is essential for the stability and even for the existence of such systems (as organizations may refuse to join an unfair system).   We consider on-line, non-clairvoyant scheduling of sequential jobs. The started jobs cannot be stopped, canceled, preempted, or moved to other processors. We consider identical processors, but most of our results can be extended to related or unrelated processors.   We model the fair scheduling problem as a cooperative game and we use the Shapley value to determine the ideal fair schedule. In contrast to the current literature, we do not use money to assess the relative utilities of jobs. Instead, to calculate the contribution of an organization, we determine how the presence of this organization influences the performance of other organizations. Our approach can be used with arbitrary utility function (e.g., flow time, tardiness, resource utilization), but we argue that the utility function should be strategy resilient. The organizations should be discouraged from splitting, merging or delaying their jobs. We present the unique (to within a multiplicative and additive constants) strategy resilient utility function.   We show that the problem of fair scheduling is NP-hard and hard to approximate. However, for unit-size jobs, we present a fully polynomial-time randomized approximation scheme (FPRAS). We also show that the problem parametrized with the number of organizations is fixed parameter tractable (FPT). In cooperative game theory, the Shapley value is considered in many contexts as the fair solution. Our results show that, although the problem for the large number of organizations is computationally hard, this solution concept can be used in scheduling (for instance, as a benchmark for measuring fairness of heuristic algorithms)."
1736714,15258,22288,On the Interplay between Network Traffic and Energy Consumption in Virtualized Environment: An Empirical Study,2014,"Networking and virtualization are two key building blocks of modern cloud computing. The energy consumption of physical machines has been carefully examined in the past research, including the impact of network traffic. When it comes with virtual machines, the inter-play between energy consumption and network traffic however becomes much more complicated. The traffic are now generated by and exchanged between virtual machines (VMs), which could reside in different physical machines with their respective network interface cards (NICs), or share the same physical machine. When multiple VMs share a physical NIC, their traffic can interfere with each other, causing extra overhead. Yet the VM's allocation can be dynamic and they can even migrated across physical machines, thereby changing the traffic pattern. These factors combined make the network traffic highly diverse and dynamic, so is the corresponding energy consumption. A close examination on the network traffic and energy consumption in virtualized environments is thus of need. In this paper, we present an initial measurement study on the interplay between energy consumption and network traffic in representative virtualization environments. Our study reveals a series of unique energy consumption patterns of the network traffic in this context. We show that state-of-the-art virtualization designs noticeably increase the demand of CPU resources when handling networked transactions, generating excessive interrupt requests with ceaselessly context switching, which in turn increases energy consumption. Even when the physical machine is in an idle state, the VM network transactions will will incur remarkable energy consumption. Furthermore, even with identical number of VMs and amount of traffic on a physical machine, the energy consumptions vary significantly with different VM allocation strategies. Our close examination pinpoints the root cause, and offers new angles to revisit the existing resource usage and energy consumption models, so as to optimize the service provisioning as well as virtual machine placement and migration."
1015129,15258,9748,MLOC: Multi-level Layout Optimization Framework for Compressed Scientific Data Exploration with Heterogeneous Access Patterns,2012,"The size and scope of cutting-edge scientific simulations are growing much faster than the I/O and storage capabilities of their runtime environments. The growing gap gets exacerbated by exploratory data&#x00E2;intensive analytics, such as querying simulation data for regions of interest with multivariate, spatio-temporal constraints. Query-driven data exploration induces heterogeneous access patterns that further stress the performance of the underlying storage system. To partially alleviate the problem, data reduction via compression and multi-resolution data extraction are becoming an integral part of I/O systems. While addressing the data size issue, these techniques introduce yet another mix of access patterns to a heterogeneous set of possibilities. Moreover, how extreme-scale datasets are partitioned into multiple files and organized on a parallel file systems augments to an already combinatorial space of possible access patterns. To address this challenge, we present MLOC, a parallel Multilevel Layout Optimization framework for Compressed scientific spatio-temporal data at extreme scale. MLOC proposes multiple fine-grained data layout optimization kernels that form a generic core from which a broader constellation of such kernels can be organically consolidated to enable an effective data exploration with various combinations of access patterns. Specifically, the kernels are optimized for access patterns induced by (a) query&#x00E2;driven multivariate, spatio-temporal constraints, (b) precision&#x00E2;driven data analytics, (c) compression&#x00E2;driven data reduction, (d) multi-resolution data sampling, and (e) multi&#x00E2;file data partitioning and organization on a parallel file system. MLOC organizes these optimization kernels within a multi&#x00E2;level architecture, on which all the levels can be flexibly re-ordered by user&#x00E2;defined priorities. When tested on query&#x00E2;driven exploration of compressed data, MLOC demonstrates a superior performance compared to any state-of-the-art scientific database management technologies."
1868621,15258,23836,TM-dietlibc: A TM-aware Real-World System Library,2013,"The simplicity of concurrent programming with Transactional Memory (TM) and its recent implementation in mainstream processors greatly motivates researchers and industry to investigate this field and propose new implementations and optimizations. However, there is still no standard C system library which a wide range of TM developers can adopt. TM application developers have been forced to avoid library calls inside of transactions or to execute them irrevocably (i.e. in serial order). In this paper, we present the first TM-aware system library, a complex software implementation integrated with TM principles and suited for software (STM), hardware (HTM) and hybrid TM (HyTM). The library we propose is derived from a modified lock-based implementation and can be used with the existing standard C API. In our work, we describe design challenges and code optimizations that would be specific to any TMbased system library or application. We argue about system call execution within transactions, highlighting the possibility of unexpected results from threads. For this reason we propose: (1) a mechanism for detecting conflicts over kernel data in user space, and (2) a new barrier to allow hybrid TM to be used effectively with system libraries. Our evaluation includes different TM implementations and the focus is on memory management and file operations since they are widely used in applications and require additional mechanisms for concurrent execution. We show the benefit we gain with our libc modifications providing parallel execution as much as possible. The library we propose shows high scalability when linked with STM and HTM. For file operations it shows on average a 1.1, 2.6 and 3.7x performance speedup for 8 cores using HyTM, STM and HTM, respectively (over a lock-based single-threaded execution). For a red-black tree it shows on average 3.14x performance speedup for 8 cores using STM (over a multi-read single-threaded execution)."
1348868,15258,8912,PHYS: Profiled-HYbrid Sampling for soft error reliability benchmarking,2013,"In this paper, we introduce PHYS (Profiled-HYbrid Sampling), a sampling framework for soft-error benchmarking of caches. Reliability simulations of caches are much more complex than performance simulations and therefore exhibit large simulation slowdowns (two orders of magnitude) over performance simulations. The major problem is that the reliability lifetime of every accessed block must be tracked from beginning to end, on top of simulating the benchmark, in order to track the total number of vulnerability cycles (VCs) between two accesses to the block. Because of the need to track SDCs (silent error corruption) and to distinguish between true and false DUEs (detected but unrecoverable errors) vulnerability cycles cannot be truncated when data is written back from cache to main memory. Vulnerability cycles must be maintained even during a block's sojourn in main memory to track whether corrupted values in a block are used by the processor, until program termination. PHYS solves this problem by sampling intervals between accesses to each memory block, instead of sampling the execution of the processor in a time interval as is classically done in performance simulations. At first a statistical profiling phase captures the distribution of VCs for every block. This profiling step provides a statistical guarantee of the minimum sampling rate of access intervals needed to meet a desired FIT error target with a given confidence interval. Then, per cacheset sampling rates are dynamically adjusted to sample VCs with higher merit. We compare PHYS with many other possible sampling methods, some of which are widely used to accelerate performance-centric simulations but have also been applied in the past to track reliability lifetime. We demonstrate the superiority of PHYS in the context of reliability benchmarking through exhaustive evaluations of various sampling techniques."
2343210,15258,20338,Crossroads: A Practical Data Sketching Solution for Mining Intersection of Streams,2014,"The explosive increase in cellular network traffic, users, and applications, as well as the corresponding shifts in user expectations, has created heavy needs and demands on cellular data providers. In this paper we address one such need: mining the logs of cellular voice and data traffic to rapidly detect network performance anomalies and other events of interest. The core challenge in solving this problem is the issue that it is impossible to predict beforehand where in the traffic the event may appear, requiring us to be able to query arbitrary subsets of the network traffic (e.g., longer than usual round-trip times for users in a specific urban area to connect to FunContent.com using a particular model of phone). Since it is infeasible to store all combinations of such data, especially when it is collected in real-time, we need to be able to summarize the traffic data using succinct sketch data structures to answer these queries.   The major contribution of this paper is the introduction of a scheme, called Crossroads, that can be used to compute the intersection of the measurements between two overlapping streams. For instance, in the above example, it is possible to compute the intersection of all the data going between the downtown area and FunContent.com with all the data generated by the model of phone to detect anomalous RTT behavior. In effect, this gives us a way to essentially square root the number of sketches that we need to maintain, transforming a prohibitively expensive problem to one that is tractable in practice. We provide rigorous analysis of our sketch and the trade-offs between memory footprint and accuracy. We also demonstrate the efficacy of our solution via simulation on data collected at a major cellular service carrier in the US."
1011641,15258,23836,Scaling Irregular Applications through Data Aggregation and Software Multithreading,2014,"Emerging applications in areas such as bioinformatics, data analytics, semantic databases and knowledge discovery employ datasets from tens to hundreds of terabytes. Currently, only distributed memory clusters have enough aggregate space to enable in-memory processing of datasets of this size. However, in addition to large sizes, the data structures used by these new application classes are usually characterized by unpredictable and fine-grained accesses: i.e., they present an irregular behavior. Traditional commodity clusters, instead, exploit cache-based processor and high-bandwidth networks optimized for locality, regular computation and bulk communication. For these reasons, irregular applications are inefficient on these systems, and require custom, hand-coded optimizations to provide scaling in both performance and size. Lightweight software multithreading, which enables tolerating data access latencies by overlapping network communication with computation, and aggregation, which allows reducing overheads and increasing bandwidth utilization by coalescing fine-grained network messages, are key techniques that can speed up the performance of large scale irregular applications on commodity clusters. In this paper we describe GMT (Global Memory and Threading), a runtime system library that couples software multithreading and message aggregation together with a Partitioned Global Address Space (PGAS) data model to enable higher performance and scaling of irregular applications on multi-node systems. We present the architecture of the runtime, explaining how it is designed around these two critical techniques. We show that irregular applications written using our runtime can outperform, even by orders of magnitude, the corresponding applications written using other programming models that do not exploit these techniques."
1344564,15258,9748,"Predicting Execution Readiness of MPI Binaries with FEAM, a Framework for Efficient Application Migration",2013,"As computing resources have become ubiquitous, computational research initiatives have spread into a wider variety of disciplines. With the variety of computing environments dramatically expanded, using available compute resources can be a much more complicated proposition. Additionally, users in disciplines that are not traditionally compute-heavy may not have experience with migrating an application from one computing environment to another. Thus, while more and faster resources should allow for more and better research to be carried out, the increase in resources can just as easily stymie progress. An ideal solution would enable computations to run on any available compute resource with minimal interaction from the user and would run a version of the application tuned for that particular site. In this work, we focus on the first goal. This step alone dramatically improves the ability of researchers to take advantage of the variety of computing resources available to them and, as a result, carry out more and better research. The work presented in this paper specifically focuses on increasing the ease-of-use of high performance computing clusters for running parallel computations coded using the MPI standard. We present methods that determine whether an HPC site is a good fit for running an MPI binary. We present a Linux-based implementation of our methods called FEAM (a Framework for Efficient Application Migration). FEAM predicts execution readiness, resolves missing shared libraries, and composes site-specific configurations. We show that FEAM is more than 90% accurate at predicting execution readiness of MPI application binaries from the NAS Parallel and SPEC MPI2007 benchmark suites. We also show that by automatically resolving shared libraries requirements, FEAM is able to increase the number of successful executions by 41%."
2114159,15258,23836,Kernel Specialization for Improved Adaptability and Performance on Graphics Processing Units (GPUs),2013,"Graphics processing units (GPUs) offer significant speedups over CPUs for certain classes of applications. However, programming for GPUs is challenging. There are many parameters that affect performance and their values may change depending on both problem instance and GPU hardware specifics. In addition, most GPU kernels are compiled once; performance optimizations are applied at application compile time. As a result, many GPU libraries and programs have limited adaptability to variations among problem instances and hardware configurations. These factors limit code reuse and the applicability of GPU computing to a wider variety of problems. This paper introduces GPGPU kernel specialization, a technique used to describe highly adaptable kernels that exhibit high performance across a wide range of programmer variables as well as different generations of GPUs. We also introduce our GPU Prototyping Framework (GPU-PF) for dynamic runtime generation of customized GPU kernels incorporating both problem and implementation-specific parameters. GPU-PF fully separates the GPU and CPU code so the GPU code can be compiled during program execution once all the parameters are known. This work explores the implementation and parameterization of two real world applications targeting two generations of NVIDIA CUDA-enabled GPUs using kernel specialization and GPU-PF: large template matching and cone-beam image reconstruction via backprojection. Starting with high performance GPU kernels that compare favorably to multi-threaded reference implementations, kernel specialization is shown to increase adaptability while providing performance improvements including improved run time and reduction in resource usage. Kernel specialization offers productivity benefits, improved library code, and a means to increase the parameterizability of GPGPU implementations."
1801318,15258,23836,Low-Cost Parallel Algorithms for 2:1 Octree Balance,2012,"The logical structure of a forest of octrees can be used to create scalable algorithms for parallel adaptive mesh refinement (AMR), which has recently been demonstrated for several petascale applications. Among various frequently used octree-based mesh operations, including refinement, coarsening, partitioning, and enumerating nodes, ensuring a 2:1 size balance between neighboring elements has historically been the most expensive in terms of CPU time and communication volume. The 2:1 balance operation is thus a primary target to optimize. One important component of a parallel balance algorithm is the ability to determine whether any two given octants have a consistent distance/size relation. Based on new logical concepts we propose fast algorithms for making this decision for all types of 2:1 balance conditions in 2D and 3D. Since we are able to achieve this without constructing any parent nodes in the tree that would otherwise need to be sorted and communicated, we can significantly reduce the required memory and communication volume. In addition, we propose a lightweight collective algorithm for reversing the asymmetric communication pattern induced by non-local octant interactions. We have implemented our improvements as part of the open-source ``p4est''software. Benchmarking this code with both synthetic and simulation-driven adapted meshes we are able to demonstrate much reduced runtime and excellent weak and strong scalability. On our largest benchmark problem with$5.13 \times 10^{11}$ octants the new 2:1 balance algorithm executes in less than 8 seconds on 112,128 CPU cores of the Jaguar Cray XT5 supercomputer."
1966100,15258,9748,Symbiotic Scheduling for Shared Caches in Multi-core Systems Using Memory Footprint Signature,2011,"As the trend of more cores sharing common resources on a single die and more systems crammed into enterprise computing space continue, optimizing the economies of scale for a given compute capacity is becoming more critical. One major challenge in performance scalability is the growing L2 cache contention caused by multiple contexts running on a multi-core processor either natively or under a virtual machine environment. Currently, an OS, at best, relies on history based affinity information to dispatch a process or thread onto a particular processor core. Unfortunately, this simple method can easily lead to destructive performance effect due to conflicts in common resources, thereby slowing down all processes. To ameliorate the allocation/management policy of a shared cache on a multi-core, in this paper, we propose Bloom filter signatures, a low-complexity architectural support to allow an OS or a Virtual Machine Monitor to infer cache footprint characteristics and interference of applications, and then perform job scheduling based on symbiosis. Our scheme integrates hardware-level counting Bloom filters in caches to efficiently summarize cache usage behavior on a per-core, per-process or per-VM basis. We then proposed and studied three resource allocation algorithms to determine the optimal process-to-core mapping to minimize interference in the L2. We executed applications using allocation generated by our new process to-core mapping algorithms on an Intel Core 2 Duo machine and showed an averaged 22% (up to 54%) improvement when applications run natively, and an averaged 9.5% improvement (up to 26%)when running inside VMs."
1633769,15258,23836,PAGE: A Framework for Easy PArallelization of GEnomic Applications,2014,"With the availability of high-throughput and low-cost sequencing technologies, an increasing amount of genetic data is becoming available to researchers. There is clearly a potential for significant new scientific and medical advances by analysis of such data, however, it is imperative to exploit parallelism and achieve effective utilization of the computing resources to be able to handle massive datasets. Thus, frameworks that can help researchers develop parallel applications without dealing with low-level details of parallel coding are very important for advances in genetic research. In this study, we develop a middleware, PAGE, which supports 'map reduce-like' processing, but with significant differences from a system like Hadoop, to be useful and effective for parallelizing analysis of genomic data. Particularly, it can work with map functions written in any language, thus allowing utilization of existing serial tools (even those for which only an executable is available) as map functions. Thus, it can greatly simplify parallel application development for scenarios where complex data formats and/or nuanced serial algorithms are involved, as is often the case for genomic data. It allows parallelization by partitioning by-locus or partitioning by-chromosome, provides different scheduling schemes, and execution models, to match the nature of algorithms common in genetic research. We have evaluated the middleware system using four popular genomic applications, including VarScan, Unified Genotyper, Realigner Target Creator, and Indel Realigner, and compared the achieved performance against with two popular frameworks (Hadoop and GATK). We show that our middleware outperforms GATK and Hadoop and it is able to achieve high parallel efficiency and scalability."
1282191,15258,8912,"Design and Evaluation of FA-MPI, a Transactional Resilience Scheme for Non-blocking MPI",2014,"With the rapid scale out of supercomputers comes a corresponding higher failure frequency. Fault-tolerant methods have evolved to adapt to high rates of failure, but the behavior of MPI, the most widely used scalable programming middleware, is insufficient when confronting such failures. We present FA-MPI (Fault-Aware MPI), a set of extensions to the MPI standard designed to enable applications to implement a wide range of fault-tolerant methods. FA-MPI introduces transactional concepts to the MPI programming model for the first time to address failure detection, isolation, mitigation, and recovery via application-driven policies. To reach the maximum achievable performance of these scalable machines, overlapping communication and I/O with computation through non-blocking operations (while reducing jitter) are design themes of growing importance. Therefore, we emphasize fault tolerant, non-blocking communication operations combined with a set of nest able lightweight transactional Try Block API extensions architected to exploit system and application hierarchy both for failure detection and recovery. This is to enable applications to run to completion with higher probability than otherwise. Scaling up and out and fault-free overhead are key concerns that can be managed by tuning transaction granularity, we provide a simulation of FA-MPI in a stencil 3D program to illustrate this. Supported failure models include but are not limited to process failures, a key difference from other proposed fault-tolerant extensions to MPI. Restriction to non-blocking operations is a current limitation as compared to other proposed approaches insofar as legacy applications are concerned, but FA-MPI aligns well with future-looking applications emphasizing Exascale. And, tools to evolve legacy MPI programs to this fault-aware paradigm will soon bridge that portability gap."
845106,15258,9836,Enabling datacenter servers to scale out economically and sustainably,2013,"As cloud applications proliferate and data-processing demands increase, server resources must grow to unleash the performance of emerging workloads that scale well with large number of compute nodes. Nevertheless, power has become a crucial bottleneck that restricts horizontal scaling (scale out) of server systems, especially in datacenters that employ power over-subscription. When a datacenter hits the maximum capacity of its power provisioning equipment, the owner has to either build another facility or upgrade existing utility power infrastructure -- both approaches add huge capital expenditure, require significant construction lead time, and can further increase the owner's carbon footprint.   This paper proposes  Oasis , a power provisioning scheme for enabling power-/carbon- constrained datacenter servers to scale out economically and sustainably.  Oasis  naturally supports incremental power capacity expansion with near-zero environmental impact as it takes advantages of modular renewable energy system and emerging distributed battery architecture. It allows scale-out datacenter to double its capacity using 100% green energy with up to 25% less overhead cost. This paper also describes our implementation of  Oasis  prototype and introduces our multi-source driven power management scheme  Ozone. Ozone  allows  Oasis  to identify the most suitable power supply control strategies and adjust server load cooperatively to maximize overall system efficiency and reliability. Our results show that  Ozone  could reduce the performance degradation of  Oasis  to 1%, extend  Oasis  battery lifetime by over 50%, and almost triple the average battery backup capacity which is crucial for mission-critical systems."
2062445,15258,22260,Understanding Vicious Cycles in Server Clusters,2011,"In this paper, we present an automated on-line service for troubleshooting performance problems in server clusters caused by unintended vicious cycles. The tool complements a large volume of prior performance troubleshooting and diagnostic literature for server farms that identifies problems arising due to resource bottlenecks or failed components. We show that unintended interactions between components in large-scale systems can cause performance problems even in the absence of bottlenecks or failures. Our tool leverages discriminative sequence mining to identify anomalous sequences of events that are candidates for blame for the performance problem. The tool looks for patterns consistent with vicious cycles or unstable behavior, as such patterns, when present, are most likely to be problematic. It highlights candidates that are semantically conflicting, such as those arising when different performance management mechanisms make adjustments in conflicting directions. Our approach offers two key advantages in performance troubleshooting. First, it does not require detailed prior knowledge of the underlying system to diagnose the problem. Second, contrary to simple statistical techniques, such as correlation analysis, that work well for continuous variables, our scheme can also identify chains of events (labels) that may explain the root cause of a problem. Our service is deployed on a web server testbed of 17 machines. To make the comparison of our scheme to prior work more concrete, we first reproduce two real-life problem scenarios reported in earlier literature, then explore a third, new case study. In all cases, our tool reports the patterns that explain the cause of the problem without requiring detailed a priori knowledge."
145582,15258,20349,Expanding rural cellular networks with virtual coverage,2013,"The cellular system is the world's largest network, providing service to over five billion people. Operators of these networks face fundamental trade-offs in coverage, capacity and operating power. These trade-offs, when coupled with the reality of infrastructure in poorer areas, mean that upwards of a billion people lack access to this fundamental service. Limited power infrastructure, in particular, hampers the economic viability of wide-area rural coverage.#R##N##R##N#In this work, we present an alternative system for implementing large-scale rural cellular networks. Rather than providing constant coverage, we instead provide virtual coverage: coverage that is only present when requested. Virtual coverage powers the network on-demand, which reduces overall power draw, lowers the cost of rural connectivity, and enables new markets.#R##N##R##N#We built a prototype cellular system utilizing virtual coverage by modifying a GSM base station and a set of Motorola phones to support making and receiving calls under virtual coverage. To support the billions of already-deployed devices, we also implemented a small radio capable of adding backwards-compatible support for virtual coverage to existing GSM handsets. We demonstrate a maximum of 84% power and cost savings from using virtual coverage. We also evaluated virtual coverage by simulating the potential power savings on real-world cellular networks in two representative developing counties: one in sub-Saharan Africa and one in South Asia. Simulating power use based on realworld call records obtained from local mobile operators, we find our system saves 21-34% of power draw at night, and 7-21% during the day. We expect even more savings in areas currently off the grid. These results demonstrate the feasibility of implementing such a system, particularly in areas with solar or otherwise-intermittent power sources."
2460608,15258,23836,Acceleration of an Asynchronous Message Driven Programming Paradigm on IBM Blue Gene/Q,2013,"IBM Blue Gene/Q is the next generation Blue Gene machine that can scale to tens of Peta Flops with 16 cores and 64 hardware threads per node. However, significant efforts are required to fully exploit its capacity on various applications, spanning multiple programming models. In this paper, we focus on the asynchronous message driven parallel programming model - Charm++. Since its behavior (asynchronous) is substantially different from MPI, that presents a challenge in porting it efficiently to BG/Q. On the other hand, the significant synergy between BG/Q software and Charm++ creates opportunities for effective utilization of BG/Q resources. We describe various novel fine-grained threading techniques in Charm++ to exploit the hardware features of the BG/Q compute chip. These include the use of L2 atomics to implement lockless producer-consumer queues to accelerate communication between threads, fast memory allocators, hardware communication threads that are awakened via low overhead interrupts from the BG/Q wakeup unit. Burst of short messages is processed by using the ManytoMany interface to reduce runtime overhead. We also present techniques to optimize NAMD computation via Quad Processing Unit (QPX) vector instructions and the acceleration of message rate via communication threads to optimize the Particle Mesh Ewald (PME) computation. We demonstrate the benefits of our techniques via two benchmarks, 3D Fast Fourier Transform, and the molecular dynamics application NAMD. For the 92,000-atom ApoA1 molecule, we achieved 683μs/step with PME every 4 steps and 782μs/step with PME every step."
2196333,15258,11330,Implementing a classic: zero-copy all-to-all communication with mpi datatypes,2014,"We investigate the use of the derived datatype mechanism of MPI (the Message-Passing Interface) in the implementation of the classic all-to-all communication algorithm of Bruck et al.\ (1997). Through a series of improvements to the canonical implementation of the algorithm we gradually eliminate initial and final processor-local data reorganizations, culminating in a \emph{zero-copy} version that contains no explicit, process-local data movement or copy operations: all necessary data movements are implied by MPI derived datatypes, and carried out as part of the communication operations. We furthermore show how the improved algorithm can be used to solve irregular all-to-all communication problems (that are not too irregular). The Bruck algorithm serves as a vehicle to demonstrate descriptive and performance advantages with MPI datatypes in the implementation of complex algorithms, and discuss shortcomings and inconveniences in the current MPI datatype mechanism. In particular, we use and implement three new derived datatypes (bounded vector, circular vector, and bucket) not in MPI that might be useful in other contexts. We also discuss the role of persistent collectives which are currently not found in MPI for amortizing type creation (and other) overheads, and implement a persistent variant of the \texttt{MPI\_Alltoall} collective.   On two small systems we experimentally compare the algorithmic improvements to the Bruck et al.\ algorithm when implemented on top of MPI, showing the zero-copy version to perform significantly better than the initial, straight-forward implementation. One of our variants has also been implemented inside \texttt{mvapich}, and we show it to perform better than the \texttt{mvapich} implementation of the Bruck et al.\ algorithm for the range of processes and problem sizes where it is enabled. The persistent version of \texttt{MPI\_Alltoall} has no overhead and outperforms all other variants, and in particular improves upon the standard implementation by 50\% to 15\% across the full range of problem sizes considered."
895863,15258,9836,Systematic Energy Characterization of CMP/SMT Processor Systems via Automated Micro-Benchmarks,2012,"Microprocessor-based systems today are composed of multi-core, multi-threaded processors with complex cache hierarchies and gigabytes of main memory. Accurate characterization of such a system, through predictive pre-silicon modeling and/or diagnostic post silicon measurement based analysis are increasingly cumbersome and error prone. This is especially true of energy-related characterization studies. In this paper, we take the position that automated micro-benchmarks generated with particular objectives in mind hold the key to obtaining accurate energy-related characterization. As such, we first present a flexible micro-benchmark generation framework (MicroProbe) that is used to probe complex multi-core/multithreaded systems with a variety and range of energy-related queries in mind. We then present experimental results centered around an IBM POWER7 CMP/SMT system to demonstrate how the systematically generated micro-benchmarks can be used to answer three specific queries: (a) How to project application-specific (and if needed, phase-specific) power consumption with component-wise breakdowns? (b) How to measure energy-per-instruction (EPI) values for the target machine? (c) How to bound the worst-case (maximum) power consumption in order to determine safe, but practical (i.e. affordable) packaging or cooling solutions? The solution approaches to the above problems are all new. Hardware measurement based analysis shows superior power projection accuracy (with error margins of less than 2.3% across SPEC CPU2006) as well as maxpower stressing capability (with 10.7% increase in processor power over the very worst-case power seen during the execution of SPEC CPU2006 applications)."
2535910,15258,23497,"Providing safe, user space access to fast, solid state disks",2012,"Emerging fast, non-volatile memories (e.g., phase change memories, spin-torque MRAMs, and the memristor) reduce storage access latencies by an order of magnitude compared to state-of-the-art flash-based SSDs. This improved performance means that software overheads that had little impact on the performance of flash-based systems can present serious bottlenecks in systems that incorporate these new technologies. We describe a novel storage hardware and software architecture that nearly eliminates two sources of this overhead: Entering the kernel and performing file system permission checks. The new architecture provides a private, virtualized interface for each process and moves file system protection checks into hardware. As a result, applications can access file data without operating system intervention, eliminating OS and file system costs entirely for most accesses. We describe the support the system provides for fast permission checks in hardware, our approach to notifying applications when requests complete, and the small, easily portable changes required in the file system to support the new access model. Existing applications require no modification to use the new interface. We evaluate the performance of the system using a suite of microbenchmarks and database workloads and show that the new interface improves latency and bandwidth for 4 KB writes by 60% and 7.2x, respectively, OLTP database transaction throughput by up to 2.0x, and Berkeley-DB throughput by up to 5.7x. A streamlined asynchronous file IO interface built to fully utilize the new interface enables an additional 5.5x increase in throughput with 1 thread and 2.8x increase in efficiency for 512 B transfers."
1134499,15258,9589,SoftMoW: Recursive and Reconfigurable Cellular WAN Architecture,2014,"The current LTE network architecture is organized into very large regions, each having a core network and a radio access network. The core network contains an Internet edge comprised of packet data network gateways (PGWs). The radio network consists of only base stations. There are minimal interactions among regions other than interference management at the edge. The current architecture has several problems. First, mobile application performance is seriously impacted by the lack of Internet egress points per region. Second, the continued exponential growth of mobile traffic puts tremendous pressure on the scalability of PGWs. Third, the fast growth of signaling traffic known as the signaling storm problem poses a major challenge to the scalability of the control plane. To address these problems, we present SoftMoW, a recursive and reconfigurable cellular WAN architecture that supports seamlessly inter-connected core networks, reconfigurable control plane, and global optimization.   To scale the control plane nation-wide, SoftMoW recursively builds up the hierarchical control plane with novel abstractions of both control plane and data plane entities. To enable scalable end-to-end path setup, SoftMoW presents a novel label swapping mechanism such that each controller only operates on its logical topology and each switch along the path only sees at most one label. SoftMoW supports new network-wide optimization functions such as optimal routing and inter-region handover minimization. We demonstrate that SoftMoW improves the performance, flexibility and scalability of cellular WAN using real LTE network traces with thousands of base stations and millions of subscribers. Our evaluation shows that path inflation and inter-region handovers can be reduced by up to 60% and 44% respectively."
1318097,15258,122,A peta-scalable CPU-GPU algorithm for global atmospheric simulations,2013,"Developing highly scalable algorithms for global atmospheric modeling is becoming increasingly important as scientists inquire to understand behaviors of the global atmosphere at extreme scales. Nowadays, heterogeneous architecture based on both processors and accelerators is becoming an important solution for large-scale computing. However, large-scale simulation of the global atmosphere brings a severe challenge to the development of highly scalable algorithms that fit well into state-of-the-art heterogeneous systems. Although successes have been made on GPU-accelerated computing in some top-level applications, studies on fully exploiting heterogeneous architectures in global atmospheric modeling are still very less to be seen, due in large part to both the computational difficulties of the mathematical models and the requirement of high accuracy for long term simulations.   In this paper, we propose a peta-scalable hybrid algorithm that is successfully applied in a cubed-sphere shallow-water model in global atmospheric simulations. We employ an adjustable partition between CPUs and GPUs to achieve a balanced utilization of the entire hybrid system, and present a pipe-flow scheme to conduct conflict-free inter-node communication on the cubed-sphere geometry and to maximize communication-computation overlap. Systematic optimizations for multithreading on both GPU and CPU sides are performed to enhance computing throughput and improve memory efficiency. Our experiments demonstrate nearly ideal strong and weak scalabilities on up to 3,750 nodes of the Tianhe-1A. The largest run sustains a performance of 0.8 Pflops in double precision (32% of the peak performance), using 45,000 CPU cores and 3,750 GPUs."
1777172,15258,8306,Power management of online data-intensive services,2011,"Much of the success of the Internet services model can be attributed to the popularity of a class of workloads that we call Online Data-Intensive (OLDI) services. These workloads perform significant computing over massive data sets per user request but, unlike their offline counterparts (such as MapReduce computations), they require responsiveness in the sub-second time scale at high request rates. Large search products, online advertising, and machine translation are examples of workloads in this class. Although the load in OLDI services can vary widely during the day, their energy consumption sees little variance due to the lack of energy proportionality of the underlying machinery. The scale and latency sensitivity of OLDI workloads also make them a challenging target for power management techniques.   We investigate what, if anything, can be done to make OLDI systems more energy-proportional. Specifically, we evaluate the applicability of active and idle low-power modes to reduce the power consumed by the primary server components (processor, memory, and disk), while maintaining tight response time constraints, particularly on 95th-percentile latency. Using Web search as a representative example of this workload class, we first characterize a production Web search workload at cluster-wide scale. We provide a fine-grain characterization and expose the opportunity for power savings using low-power modes of each primary server component. Second, we develop and validate a performance model to evaluate the impact of processor- and memory-based low-power modes on the search latency distribution and consider the benefit of current and foreseeable low-power modes. Our results highlight the challenges of power management for this class of workloads. In contrast to other server workloads, for which idle low-power modes have shown great promise, for OLDI workloads we find that energy-proportionality with acceptable query latency can only be achieved using coordinated, full-system active low-power modes."
1109201,15258,122,Scheduling parallel programs by work stealing with private deques,2013,"Work stealing has proven to be an effective method for scheduling parallel programs on multicore computers. To achieve high performance, work stealing distributes tasks between concurrent queues, called deques, which are assigned to each processor. Each processor operates on its deque locally except when performing load balancing via steals. Unfortunately, concurrent deques suffer from two limitations: 1) local deque operations require expensive memory fences in modern weak-memory architectures, 2) they can be very difficult to extend to support various optimizations and flexible forms of task distribution strategies needed many applications, e.g., those that do not fit nicely into the divide-and-conquer, nested data parallel paradigm.   For these reasons, there has been a lot recent interest in implementations of work stealing with non-concurrent deques, where deques remain entirely private to each processor and load balancing is performed via message passing. Private deques eliminate the need for memory fences from local operations and enable the design and implementation of efficient techniques for reducing task-creation overheads and improving task distribution. These advantages, however, come at the cost of communication. It is not known whether work stealing with private deques enjoys the theoretical guarantees of concurrent deques and whether they can be effective in practice.   In this paper, we propose two work-stealing algorithms with private deques and prove that the algorithms guarantee similar theoretical bounds as work stealing with concurrent deques. For the analysis, we use a probabilistic model and consider a new parameter, the branching depth of the computation. We present an implementation of the algorithm as a C++ library and show that it compares well to Cilk on a range of benchmarks. Since our approach relies on private deques, it enables implementing flexible task creation and distribution strategies. As a specific example, we show how to implement task coalescing and steal-half strategies, which can be important in fine-grain, non-divide-and-conquer algorithms such as graph algorithms, and apply them to the depth-first-search problem."
2290248,15258,22288,Cost-Effective Partial Migration of VoD Services to Content Clouds,2011,"Since user demand for a Video-on-demand (VoD) service varies with time in one-day period, provisioning self-owned servers for the peak load it must sustain a few hours per day leads to bandwidth underutilization at other times. Content clouds, e.g. Amazon Cloud Front and Azure CDN, let VoD providers pay by bytes for bandwidth resources, potentially leading to cost savings even if the unit rate to rent a machine from a cloud provider is higher than the rate to own one. In this paper, based on long-term traces from two large-scale VoD systems and temporal development model of content clouds, we tackle challenges, design and potential benefits in migrating VoD services into the hybrid cloud-assisted deployment, where the user requests are partly served by the self-owned servers and partly served by the cloud. Our measurements show that the popularity of the most popular videos decays so quickly, for example, by 11% after one hour that it poses large challenges on updating videos in the cloud. However, the trace-driven evaluations show that our proposed migration strategies (active, reactive and smart strategies), although simply based on the current information, can make the hybrid cloud-assisted VoD deployment save up to 30% bandwidth expense compared with the Clients/Server mode. They can also handle unpredicted the flash crowd traffic with little cost. It also shows that the cloud price and server bandwidth chosen play the most important roles in saving cost, while the cloud storage size and cloud content update strategy play the key roles in the user experience improvement."
2378212,15258,20774,Ephemeral networks with random availability of links: diameter and connectivity,2014,"In this work we consider temporal networks, the links of which are available only at random times  (randomly available temporal networks) . Our networks are {\em ephemeral}: their links appear sporadically, only at certain times, within a given maximum time ( lifetime  of the net). More specifically, our temporal networks notion concerns networks, whose edges (arcs) are assigned one or more random discrete-time labels drawn from a set of natural numbers. The labels of an edge indicate the discrete moments in time at which the edge is available. In such networks, information (e.g., messages) have to follow  temporal paths , i.e., paths, the edges of which are assigned a strictly increasing sequence of labels. We first examine a very hostile network: a clique, each edge of which is known to be available  only one random time  in the time period {1,2, ...,  n } ( n  is the number of vertices). How fast can a vertex send a message to all other vertices in such a network? To answer this, we define the notion of the Temporal Diameter for the random temporal clique and prove that it is Θ(log  n ) with high probability and in expectation. In fact, we show that information dissemination is very fast with high probability even in this hostile network with regard to availability. This result is similar to the results for the random phone-call model. Our model, though, is weaker. Our availability assumptions are different and randomness is provided only by the input. We show here that the temporal diameter of the clique is crucially affected by the clique's lifetime,  a , e.g., when  a  is asymptotically larger than the number of vertices,  n , then the temporal diameter must be Ω(  a  /  n  log  n  ). We, then, consider the least number,  r , of  random points in time  at which an edge is available, in order to guarantee at least a temporal path between any pair of vertices of the network (notice that the clique is the only network for which just one instance of availability per edge, even non-random, suffices for this). We show that  r  is Ω(log  n ) even for some networks of diameter 2. Finally, we compare this cost to an (optimal) deterministic allocation of labels of availability that guarantees a temporal path between any pair of vertices. For this reason, we introduce the notion of the  Price of Randomness  and we show an upper bound for general networks."
779059,15258,9772,Using batteries to reduce the power costs of internet-scale distributed networks,2012,"Modern Internet-scale distributed networks have hundreds of thousands of servers deployed in hundreds of locations and networks around the world. Canonical examples of such networks are content delivery networks (called CDNs) that we study in this paper. The operating expenses of large distributed networks are increasingly driven by the cost of supplying power to their servers. Typically, CDNs procure power through long-term contracts from co-location providers and pay on the basis of the power (KWs) provisioned for them, rather than on the basis of the energy (KWHs) actually consumed. We propose the use of batteries to reduce both the required power supply and the incurred power cost of a CDN. We provide a theoretical model and an algorithmic framework for provisioning batteries to minimize the total power supply and the total power costs of a CDN. We evaluate our battery provisioning algorithms using extensive load traces derived from Akamai's CDN to empirically study the achievable benefits. We show that batteries can provide up to 14% power savings, that would increase to 22% for more power-proportional next-generation servers, and would increase even more to 35.3% for perfectly power-proportional servers. Likewise, the cost savings, inclusive of the additional battery costs, range from 13.26% to 33.8% as servers become more power-proportional. Further, much of these savings can be achieved with a small cycle rate of one full discharge/charge cycle every three days that is conducive to satisfactory battery lifetimes. In summary, we show that a CDN can utilize batteries to significantly reduce both the total supplied power and the total power costs, thereby establishing batteries as a key element in future distributed network architecture. While we use the canonical example of a CDN, our results also apply to other similar Internet-scale distributed networks."
2292966,15258,122,Towards fair and efficient SMP virtual machine scheduling,2014,"As multicore processors become prevalent in modern computer systems, there is a growing need for increasing hardware utilization and exploiting the parallelism of such platforms. With virtualization technology, hardware utilization is improved by encapsulating independent workloads into virtual machines (VMs) and consolidating them onto the same machine. SMP virtual machines have been widely adopted to exploit parallelism. For virtualized systems, such as a public cloud, fairness between tenants and the efficiency of running their applications are keys to success. However, we find that existing virtualization platforms fail to enforce fairness between VMs with different number of virtual CPUs (vCPU) that run on multiple CPUs. We attribute the unfairness to the use of per-CPU schedulers and the load imbalance on these CPUs that incur inaccurate CPU allocations. Unfortunately, existing approaches to reduce unfairness, e.g., dynamic load balancing and CPU capping, introduce significant inefficiencies to parallel workloads.   In this paper, we present Flex, a vCPU scheduling scheme that enforces fairness at VM-level and improves the efficiency of hosted parallel applications. Flex centers on two key designs: (1) dynamically adjusting vCPU weights (FlexW) on multiple CPUs to achieve VM-level fairness and (2) flexibly scheduling vCPUs (FlexS) to minimize wasted busy-waiting time. We have implemented Flex in Xen and performed comprehensive evaluations with various parallel workloads. Results show that Flex is able to achieve CPU allocations with on average no more than 5% error compared to the ideal fair allocation. Further, Flex outperforms Xen's credit scheduler and two representative co-scheduling approaches by as much as 10X for parallel applications using busy-waiting or blocking synchronization methods."
2097765,15258,23836,HierKNEM: An Adaptive Framework for Kernel-Assisted and Topology-Aware Collective Communications on Many-core Clusters,2012,"Multicore Clusters, which have become the most prominent form of High Performance Computing (HPC) systems, challenge the performance of MPI applications with non uniform memory accesses and shared cache hierarchies. Recent advances in MPI collective communications have alleviated the performance issue exposed by deep memory hierarchies by carefully considering the mapping between the collective topology and the core distance, as well as the use of single-copy kernel assisted mechanisms. However, on distributed environments, a single level approach cannot encompass the extreme variations not only in bandwidth and latency capabilities, but also in the aptitude to support duplex communications or operate multiple concurrent copies simultaneously. This calls for a collaborative approach between multiple layers of collective algorithms, dedicating to extracting the maximum degree of parallelism from the collective algorithm by consolidating the intra- and inter-node communications. In this work, we present Hier KNEM a kernel-assisted topology-aware collective framework, and how this framework orchestrates the collaboration between multiple layers of collective algorithms. The resulting scheme enables perfect overlap of intra- and inter-node communications. We demonstrated experimentally, by considering three of the most used collective operations (Broadcast, All gather and Reduction), that 1) this approach is immune to modifications of the underlying process-core binding, 2) it outperforms state-of-art MPI libraries (Open MPI, MPICH2 and MVAPICH2) demonstrating up to a 30x speedup for synthetic benchmarks, and up to a 3x acceleration for a parallel graph application (ASP), 3) it furthermore demonstrates a linear speedup with the increase of the number of cores per node, a paramount requirement for scalability on future many-core hardware."
945123,15258,11330,Multi-stage coordinated prefetching for present-day processors,2014,"Data prefetching is an important technique for hiding memory latency. Latest microarchitectures provide support for both hardware and software prefetching. However, the architectural features supporting either are different. In addition, these features can vary from one architecture to another. As a result, the choice of the right prefetching strategy is non-trivial for both the programmers and compiler-writers.   In this paper, we study different prefetching techniques in the context of different architectural features that support prefetching on existing hardware platforms. These features include, the size of the line fill buffer or the Miss Status Handling Registers servicing prefetch requests at each level of cache, the aggressiveness and effectiveness of the hardware prefetchers, interaction between software prefetch requests and the hardware prefetcher, the nature of the instruction pipeline (in-order/out-of-order execution), etc. Our experiments with two widely different processors, a latest multi-core (SandyBridge) and a many-core (Xeon Phi) processor, show that these architectural features have a significant bearing on the prefetching choice in a given source program, so much so that the best prefetching technique on SandyBridge performs worst on Xeon Phi and vice-versa. Based on our study of the interaction between the host architecture and prefetching, we find that coordinated multi-stage prefetching that brings data closer to the core in stages, yields best performance. On SandyBridge, the mid-level cache hardware prefetcher and L1 software prefetching coordinate to achieve this end, whereas on Xeon Phi, pure software prefetching proves adequate. We implement our algorithm in the ROSE source-to-source compiler framework. Experimental results demonstrate that coordinated prefetching achieves a speed-up (geometric mean over benchmarks from the SPEC suite) of 1.55X and 1.3X against the hardware prefetcher and the Intel compiler, respectively, on Xeon Phi. On SandyBridge, a speed-up of 1.08X is obtained over its effective hardware prefetcher."
2088884,15258,22288,Prototyping Efficient Desktop-as-a-Service for FPGA Based Cloud Computing Architecture,2012,"Cloud computing, a delivery of computing as a service mainly implying how to use utilities in our context, can be provided either at infrastructure, platform or software levels. The Desktop-as-a-Service (DaaS) paradigm, derives from the software level Software-as-a-Service (SaaS) paradigm, is drawing increasing interest because of its transformation from desktops into a cost-efficient, scalable and comfortable subscription service. Unlike most existing solutions delivering service with various protocols based on image transmitting in PC dominating environment, we present a DaaS with cloud server technologies on FPGA to address the problem of high power consumption and heavy network traffic. With the booming of mobile cloud computing, users can access the service on demand with smart phones or other portable devices like iPad or Amazon kindle as well as PC. Our system provides virtual desktop web pages written in HTML/JavaScript to avoid frequent image transmissions and reduce network traffic. To build the cloud prototype system, we combine Lightweight TCP/IP stack (LwIP) and Java Optimized Processor (JOP) to build a web server enabling dynamic web page interactions. Our system significantly saves volumes of data in transmission and network bandwidth. Analytical performance evaluation shows that on average, our system suffers only 25% transmitting latency and saves 46% of energy efficiency in comparison to other solutions. Our efficient DaaS based on FPGA explores new application of embedded web server in green cloud computing as well as new service paradigm of mobile cloud computing."
259909,15258,11223,The mystery machine: end-to-end performance analysis of large-scale internet services,2014,"Current debugging and optimization methods scale poorly to deal with the complexity of modern Internet services, in which a single request triggers parallel execution of numerous heterogeneous software components over a distributed set of computers. The Achilles' heel of current methods is the need for a complete and accurate model of the system under observation: producing such a model is challenging because it requires either assimilating the collective knowledge of hundreds of programmers responsible for the individual components or restricting the ways in which components interact.#R##N##R##N#Fortunately, the scale of modern Internet services offers a compensating benefit: the sheer volume of requests serviced means that, even at low sampling rates, one can gather a tremendous amount of empirical performance observations and apply big data techniques to analyze those observations. In this paper, we show how one can automatically construct a model of request execution from pre-existing component logs by generating a large number of potential hypotheses about program behavior and rejecting hypotheses contradicted by the empirical observations. We also show how one can validate potential performance improvements without costly implementation effort by leveraging the variation in component behavior that arises naturally over large numbers of requests to measure the impact of optimizing individual components or changing scheduling behavior.#R##N##R##N#We validate our methodology by analyzing performance traces of over 1.3 million requests to Facebook servers. We present a detailed study of the factors that affect the end-to-end latency of such requests. We also use our methodology to suggest and validate a scheduling optimization for improving Facebook request latency."
1333150,15258,21022,Do not blame users for misconfigurations,2013,"Similar to software bugs, configuration errors are also one of the major causes of today's system failures. Many configuration issues manifest themselves in ways similar to software bugs such as crashes, hangs, silent failures. It leaves users clueless and forced to report to developers for technical support, wasting not only users' but also developers' precious time and effort. Unfortunately, unlike software bugs, many software developers take a much less active, responsible role in handling configuration errors because they are users' faults.   This paper advocates the importance for software developers to take an active role in handling misconfigurations. It also makes a concrete first step towards this goal by providing tooling support to help developers improve their configuration design, and harden their systems against configuration errors. Specifically, we build a tool, called Spex, to automatically infer configuration requirements (referred to as  constraints ) from software source code, and then use the inferred constraints to: (1) expose  misconfiguration vulnerabilities  (i.e., bad system reactions to configuration errors such as crashes, hangs, silent failures); and (2) detect certain types of error-prone configuration design and handling.   We evaluate Spex with one commercial storage system and six open-source server applications. Spex automatically infers a total of 3800 constraints for more than 2500 configuration parameters. Based on these constraints, Spex further detects 743 various misconfiguration vulnerabilities and at least 112 error-prone constraints in the latest versions of the evaluated systems. To this day, 364 vulnerabilities and 80 inconsistent constraints have been confirmed or fixed by developers after we reported them. Our results have influenced the Squid Web proxy project to improve its configuration parsing library towards a more user-friendly design."
1407535,15258,23836,OpenMP Task Scheduling Analysis via OpenMP Runtime API and Tool Visualization,2014,"OpenMP tasks propose a new dimension of concurrency to cap irregular parallelism within applications. The addition of OpenMP tasks allows programmers to express concurrency at a high level of abstraction and makes the OpenMP runtime responsible about the burden of scheduling parallel execution. The ability to observe the performance of OpenMP task scheduling strategies portably across shared memory platforms has been a challenge due to the lack of performance interface standards in the runtime layer. In this paper, we exploit our proposed tasking extensions to the OpenMP Runtime API (ORA), Known as Collector APIs, for profiling task level parallelism. We describe the integration of these Collector APIs, implemented in the OpenUH compiler, into the TAU performance system. Our proposed task extensions are in line with the new interface specification called OMPT, which is currently under evaluation by the OpenMP community. We use this integration to analyze various OpenMP task scheduling strategies implemented in OpenUH. The capabilities of these scheduling strategies are evaluated with respect to exploiting data locality, maintaining load balance, and minimizing overhead costs. We present a comprehensive performance study of diverse OpenMP benchmarks, from the Barcelona OpenMP Test Suite, comparing different task pools (DEFAULT, SIMPLE, SIMPLE_2LEVEL, PUBLIC PRIVATE), task queues (DEQUE, FIFO, CFIFO, LIFO, INV_DEQUE), and task queue storages (ARRAY, DYN_ARRAY, LIST, LOCKLESS) on an AMD Opteron multicore system (48 cores total). Our results show that the benchmarks with similar characteristics exhibit the same behavior in terms of the performance of the applied scheduling strategies. Moreover, the task pool configuration, which controls the organization of task queues, was found to have the highest impact on performance."
1662603,15258,20338,On the benefits of using a large IXP as an internet vantage point,2013,"In the context of measuring the Internet, a long-standing question has been whether there exist well-localized physical entities in today's network where traffic from a representative cross-section of the constituents of the Internet can be observed at a fine-enough granularity to paint an accurate and informative picture of how these constituents shape and impact much of the structure and evolution of today's Internet and the actual traffic it carries. In this paper, we first answer this question in the affirmative by mining 17 weeks of continuous sFlow data from one of the largest European IXPs. Examining these weekly snapshots, we discover a vantage point with excellent visibility into the Internet, seeing week-in and week-out traffic from all 42K+ routed ASes, almost all 450K+ routed prefixes, from close to 1.5M servers, and around a quarter billion IPs from all around the globe. Second, to show the potential of such vantage points, we analyze the server-related portion of the traffic at this IXP, identify the server IPs and cluster them according to the organizations responsible for delivering the content. In the process, we observe a clear trend among many of the critical Internet players towards network heterogenization; that is, either hosting servers of third-party networks in their own infrastructures or pursuing massive deployments of their own servers in strategically chosen third-party networks. While the latter is a well-known business strategy of companies such as Akamai, Google, and Netflix, we show in this paper the extent of network heterogenization in today's Internet and illustrate how it enriches the traditional, largely traffic-agnostic AS-level view of the Internet."
2827513,15258,11330,Computationally Limited Randomness.,2011,"The starting point of this work is the basic question of whether there exists a formal and meaningful way to limit the computational power that a time bounded randomized Turing Machine can employ on its randomness. We attack this question using a fascinating connection between space and time bounded machines given by Cook (4): a Turing Machine S running in space s with access to an unbounded stack is equivalent to a Turing Machine T running in time 2 O(s) . We extend S with access to a read-only tape containing 2 O(s) uniform random bits, and a usual error regime: one-sided or two-sided, and bounded or unbounded. We study the efiect of placing a bound p on the number of passes S is allowed on its random tape. It follows from Cook's results that: † If p = 1 (one-way access) and the error is one-sided unbounded, S is equivalent to deterministic T. † If p = 1 (unrestricted access), S is equivalent to randomized T (with the same error). As our flrst two contributions, we completely resolve the case of unbounded error. We show that we cannot meaningfully interpolate between deterministic and randomized T by increasing p: † If p = 1 and the error is two-sided unbounded, S is still equivalent to deterministic T. † If p = 2 and the error is unbounded, S is already equivalent to randomized T (with the same error). In the bounded error case, we consider a logarithmic space Stack Machine S that is allowed p passes over its randomness. Of particular interest is the case p = 2 (log n) i , where n is the input length, and i is a positive integer. Intuitively, we show that S performs polynomial time computation on its input and parallel (preprocessing plus NC i ) computation on its randomness. Formally, we introduce Randomness Compilers. In this model, a polynomial time Turing Machine gets an input x and outputs a (polynomial size, bounded fan-in) circuit Cx that takes random inputs. Acceptance of x is determined by the acceptance probability of Cx. We say that the randomness compiler has depth d if Cx has depth d(jxj). As our third contribution, we show that: † S simulates, and is in turn simulated by, a randomness compiler with depth O i (logn) i ¢ , and O i (logn) i+1 ¢ , respectively. Randomness Compilers are a formal reflnement of polynomial time randomized Turing Machines that might elicit independent interest."
1562174,15258,9748,Modeling and Practical Evaluation of a Service Location Problem in Large Scale Networks,2011,"We consider a generalization of a classical optimization problem related to server and replica location problems in networks. More precisely, we suppose that a set of users distributed over a network wish to have access to a particular service proposed by a set of providers. The aim is then to distinguish a set of service providers able to offer a sufficient amount of resources in order to satisfy the requests of the clients. Moreover, a quality of service following some requirements in terms of latencies is desirable. A smart repartition of the servers in the network may also ensure good fault tolerance properties. We model this problem as a variant of Bin Packing, namely Bin Packing under Distance Constraint(BPDC) where the goal is to build a minimal number of bins(i.e. to choose a minimal number of servers) so that (i) each client is associated to exactly one server, (ii) the capacity of the server is large enough to satisfy the requests of its clients and (iii) the distance between two clients associated to the same server is minimized. We prove that this problem is hard to approximate even when using resource augmentation techniques : we compare the number of obtained bins when using polynomial time algorithms allowed to build bins of diameter at most beta.dmax, for beta > 1, to the optimal number of bins of diameter at most dmax. On the one hand, we prove that (i) if _ = (2â'epsilon), BPDC is hard to approximate within any constant approximation ratio, for any epsilon > 0, and that (ii) BPDC is hard to approximate at a ratio lower than 3/2 even if resource augmentation is used. On the other hand, if beta = 2, we propose a polynomial time approximation algorithm for BPDC with approximation ratio 7/3 in the general case. We show how to turn an approximation algorithm for BPDC into an approximation algorithm for the non-uniform capacitated K-center problem and vice-versa. Then, we present a comparison of the quality of results for BPDC in the context of several Internet latency embedding tools such as Sequoia and Vivaldi, using datasets based on Planet Lab latency measurements."
2331611,15258,507,SkimpyStash: RAM space skimpy key-value store on flash-based storage,2011,"We present SkimpyStash, a RAM space skimpy key-value store on flash-based storage, designed for high throughput, low latency server applications. The distinguishing feature of SkimpyStash is the design goal of extremely low RAM footprint at about 1 (± 0.5) byte per key-value pair, which is more aggressive than earlier designs. SkimpyStash uses a hash table directory in RAM to index key-value pairs stored in a log-structured manner on flash. To break the barrier of a flash pointer (say, 4 bytes) worth of RAM overhead per key, it moves most of the pointers that locate each key-value pair from RAM to flash itself. This is realized by (i) resolving hash table collisions using linear chaining, where multiple keys that resolve (collide) to the same hash table bucket are chained in a linked list, and (ii) storing the linked lists on flash itself with a pointer in each hash table bucket in RAM pointing to the beginning record of the chain on flash, hence incurring multiple flash reads per lookup. Two further techniques are used to improve performance: (iii) two-choice based load balancing to reduce wide variation in bucket sizes (hence, chain lengths and associated lookup times), and a bloom filter in each hash table directory slot in RAM to disambiguate the choice during lookup, and (iv) compaction procedure to pack bucket chain records contiguously onto flash pages so as to reduce flash reads during lookup. The average bucket size is the critical design parameter that serves as a powerful knob for making a continuum of tradeoffs between low RAM usage and low lookup latencies. Our evaluations on commodity server platforms with real-world data center applications show that SkimpyStash provides throughputs from few 10,000s to upwards of 100,000 get-set operations/sec."
1490005,15258,9772,Probabilistic deduplication for cluster-based storage systems,2012,"The need to backup huge quantities of data has led to the development of a number of distributed deduplication techniques that aim to reproduce the operation of centralized, single-node backup systems in a cluster-based environment. At one extreme, stateful solutions rely on indexing mechanisms to maximize deduplication. However the cost of these strategies in terms of computation and memory resources makes them unsuitable for large-scale storage systems. At the other extreme, stateless strategies store data blocks based only on their content, without taking into account previous placement decisions, thus reducing the cost but also the effectiveness of deduplication.   In this work, we propose, Produck, a stateful, yet light-weight cluster-based backup system that provides deduplication rates close to those of a single-node system at a very low computational cost and with minimal memory overhead. In doing so, we provide two main contributions: a lightweight probabilistic node-assignment mechanism and a new bucket-based load-balancing strategy. The former allows Produck to quickly identify the servers that can provide the highest deduplication rates for a given data block. The latter efficiently spreads the load equally among the nodes. Our experiments compare Produck against state-of-the-art alternatives over a publicly available dataset consisting of 16 full  Wikipedia  backups, as well as over a private one consisting of images of the environments available for deployment on the Grid5000 experimental platform. Our results show that, on average, Produck provides (i) up to 18% better deduplication compared to a stateless  minhash -based technique, and (ii) an 18-fold reduction in computational cost with respect to a stateful Bloom-filter-based solution."
841122,15258,8306,STREX: boosting instruction cache reuse in OLTP workloads through stratified transaction execution,2013,"Online transaction processing (OLTP) workload performance suffers from instruction stalls; the instruction footprint of a typical transaction exceeds by far the capacity of an L1 cache, leading to ongoing cache thrashing. Several proposed techniques remove some instruction stalls in exchange for error-prone instrumentation to the code base, or a sharp increase in the L1-I cache unit area and power. Others reduce instruction miss latency by better utilizing a shared L2 cache. SLICC [2], a recently proposed thread migration technique that exploits transaction instruction locality, is promising for high core counts but performs sub-optimally or may hurt performance when running on few cores.   This paper corroborates that OLTP transactions exhibit significant intra- and inter-thread overlap in their instruction footprint, and analyzes the instruction stall reduction benefits. This paper presents STREX, a hardware, programmer-transparent technique that exploits typical transaction behavior to improve instruction reuse in first level caches. STREX time-multiplexes the execution of similar transactions dynamically on a single core so that instructions fetched by one transaction are reused by all other transactions executing in the system as much as possible. STREX dynamically slices the execution of each transaction into cache-sized segments simply by observing when blocks are brought in the cache and when they are evicted. Experiments show that, when compared to baseline execution on 2--16 cores, STREX consistently improves performance while reducing the number of L1 instruction and data misses by 37% and 14% on average, respectively. Finally, this paper proposes a practical hybrid technique that combines STREX and SLICC, thereby guaranteeing performance benefits regardless of the number of available cores and the workload's footprint."
2358302,15258,8306,ArchRanker: a ranking approach to design space exploration,2014,"Architectural Design Space Exploration (DSE) is a notoriously difficult problem due to the exponentially large size of the design space and long simulation times. Previously, many studies proposed to formulate DSE as a regression problem which predicts architecture responses (e.g., time, power) of a given architectural configuration. Several of these techniques achieve high accuracy, though often at the cost of significant simulation time for training the regression models.   We argue that the information the architect mostly needs during the DSE process is whether a given configuration will perform better than another one in the presences of design constraints, or better than any other one seen so far, rather than precisely estimating the performance of that configuration.   Based on this observation, we propose a novel rankingbased approach to DSE where we train a model to predict which of two architecture configurations will perform best. We show that, not only this ranking model more accurately predicts the relative merit of two architecture configurations than an ANN-based state-of-the-art regression model, but also that it requires much fewer training simulations to achieve the same accuracy, or that it can be used for and is even better at quantifying the performance gap between two configurations   We implement the framework for training and using this model, called ArchRanker, and we evaluate it on several DSE scenarios (unicore/multicore design spaces, and both time and power performance metrics). We try to emulate as closely as possible the DSE process by creating constraint-based scenarios, or an iterative DSE process. We find that ArchRanker makes 29:68% to 54:43% fewer incorrect predictions on pairwise relative merit of configurations (tested with 79,800 configuration pairs) than an ANN-based regression model across all DSE scenarios considered (values averaged over all benchmarks for each scenario). We also find that, to achieve the same accuracy as ArchRanker, the ANN often requires three times more training simulations"
2456062,15258,8306,LOT-ECC: localized and tiered reliability mechanisms for commodity memory systems,2012,"Memory system reliability is a serious and growing concern in modern servers. Existing chipkill-level memory protection mechanisms suffer from several drawbacks. They activate a large number of chips on every memory access -- this increases energy consumption, and reduces performance due to the reduction in rank-level parallelism. Additionally, they increase access granularity, resulting in wasted bandwidth in the absence of sufficient access locality. They also restrict systems to use narrow-I/O x4 devices, which are known to be less energy-efficient than the wider x8 DRAM devices. In this paper, we present LOT-ECC, a localized and multi-tiered protection scheme that attempts to solve these problems. We separate error detection and error correction functionality, and employ simple checksum and parity codes effectively to provide strong fault-tolerance, while simultaneously simplifying implementation. Data and codes are localized to the same DRAM row to improve access efficiency. We use system firmware to store correction codes in DRAM data memory and modify the memory controller to handle data mapping. We thus build an effective fault-tolerance mechanism that provides strong reliability guarantees, activates as few chips as possible (reducing power consumption by up to 44.8% and reducing latency by up to 46.9%), and reduces circuit complexity, all while working with commodity DRAMs and operating systems. Finally, we propose the novel concept of a heterogeneous DIMM that enables the extension of LOT-ECC to x16 and wider DRAM parts."
721008,15258,22260,CLUE: Achieving Fast Update over Compressed Table for Parallel Lookup with Reduced Dynamic Redundancy,2012,"The sizes of routing table in backbone routers continue to keep a rapid growth and some of them currently increase up to 400K entries [1]. An effective solution to deflate the large table is the routing table compression. Meanwhile, there is an increasingly urgent demand for fast routing update mainly due to the change of network topology and new emerging Internet functionalities. Furthermore, the Internet link transmission speed has scaled up to 100Gbps commercially and towards 400Gbps Ethernet for laboratory experiments, resulting in a raring need of ultra-fast routing lookup. To achieve high performance, backbone routers must gracefully handle the three issues simultaneously: routing table Compression, fast routing Lookup, and fast incremental Update (CLUE), while previous works often only concentrate on one of the three dimensions. To address these issues, we propose a complete set of solutions-CLUE, by improving previous works and adding a novel incremental update mechanism. CLUE consists of three parts: a routing table compression algorithm, an improved parallel lookup mechanism, and a new fast incremental update mechanism. The routing table compression algorithm is based on ONRTC algorithm [2], a base for fast TCAM parallel lookup and fast update of TCAM. The second part is the improvement of the logical caching scheme for dynamic load balancing parallel lookup mechanism [3]. The third one is the conjunction of the trie, TCAM and redundant prefixes update algorithm. We analyze the performance of CLUE by mathematical proof, and draw the conclusion that speedup factor is proportional to the hit rate of redundant prefixes in the worst case, which is also confirmed by experimental results. Large-scale experimental results show that, compared with the mechanism in [3], CLUE only needs about 71% TCAM entries, 4.29% update time, and 3/4 dynamic redundant prefixes for the same throughput when using four TCAMs. In addition, CLUE has another advantage over the mechanism in [3] -- the frequent interactions between control plane and data plane caused by redundant prefixes update can be avoided."
1445762,15258,23836,Provisioning Policies for Elastic Computing Environments,2012,"Resources experience dynamic load as demand fluctuates. Therefore, resource providers must estimate the appropriate amount of resources to purchase in order to meet variable user demand. With the relatively recent introduction of infrastructure-as-a-service (IaaS) clouds (e.g. Amazon EC2) resource providers may choose to outsource demand as needed. As a result, a resource provider may decide to decrease his initial capital outlay and purchase a smaller resource that meets the needs of his users the majority of the time while budgeting for future outsourcing costs. When bursts in demand exceed the capacity of the resource, a resource provider can use elastic computing to outsource excess demand to IaaS clouds based on a defined budget. To create efficient elastic environments, existing services must be extended with elastic computing functionality and resource provisioning policies that match resource deployments with demand must be developed. In this paper we consider an elastic environment that extends a local cluster resource with IaaS resources. We present resource provisioning policies to dynamically match resource supply with demand. Our policies balance the requirements of users and administrators, such as minimizing the monetary cost of the IaaS deployment and reducing job queued time. We develop a discrete event simulator, the elastic cloud simulator (ECS), to evaluate our policies using scientific workloads. Our results demonstrate that by outsourcing on a flexible basis instead of simply provisioning the maximum number of instances preemptively, we reduce the average queued time by up to 58% and cost by 38%. Our results also demonstrate that our multi-variable policies provide more flexibility in balancing budget and time requirements than typical single-variable reference policies, giving resource providers controls to manage their elastic environments."
2151991,15258,8306,Row-buffer decoupling: a case for low-latency DRAM microarchitecture,2014,"Modern DRAM devices for the main memory are structured to have multiple banks to satisfy ever-increasing throughput, energy-efficiency, and capacity demands. Due to tight cost constraints, only one row can be buffered (opened) per bank and actively service requests at a time, while the row must be deactivated (closed) before a new row is stored into the row buffers. Hasty deactivation unnecessarily re-opens rows for otherwise row-buffer hits while hindsight accompanies the deactivation process on the critical path of accessing data for row-buffer misses. The time to (de)activate a row is comparable to the time to read an open row while applications are often sensitive to DRAM latency. Hence, it is critical to make the right decision on when to close a row. However, the increasing number of banks per DRAM device over generations reduces the number of requests per bank. This forces a memory controller to frequently predict when to close a row due to a lack of information on future requests, while the dynamic nature of memory access patterns limits the prediction accuracy   In this paper, we propose a novel DRAM microarchitecture that can eliminate the need for any prediction. First, we identify that precharging the bitlines dominates the deactivate time, while sense amplifiers that work as a row buffer are physically coupled with the bitlines such that a single command precharges both bitlines and sense amplifiers simultaneously. By decoupling the bitlines from the row buffers using isolation transistors, the bitlines can be precharged right after a row becomes activated. Therefore, only the sense amplifiers need to be precharged for a miss in most cases, taking an order of magnitude shorter time than the conventional deactivation process. Second, we show that this row-buffer decoupling enables internal DRAM ?-operations to be separated and recombined, which can be exploited by memory controllers to make the main memory system more energy efficient. Our experiments demonstrate that row-buffer decoupling improves the geometric mean of the instructions per cycle and MIPS2/W by 14% and 29%, respectively, for memory-intensive SPEC CPU2006 applications"
2298381,15258,22260,PARSE 2.0: A Tool for Parallel Application Run Time Behavior Evaluation,2011,"Run time variability of parallel applications continues to be a significant challenge in high performance computing (HPC) systems. We are currently studying run time variability in the context of both systemic performance and energy management. Our perspective is from that of the application, focusing on the interactions of the inter-process communication system on the set of concurrently executing parallel applications. In such a scenario, application run time can be extended and become highly variable. While some applications may be more sensitive to these interactions, others may in fact be generating the interactions that cause inconsistent run time, thus forming the notion of application-level behavioral attributes. To gain insight into this problem, our earlier work developed a framework that emulates parallel applications, called PACE. We also introduced a Parallel Application Run time Sensitivity Evaluation (PARSE) function that uses the PACE framework to study the run time effects of controlled network performance degradation on applications. Inter-process communication has evolved over the last decade from network communication between single-processor, single-core nodes to hybrid systems whose compute nodes contain several multi-core processor units. Motivated by the evolution of compute hardware and systems software, this work introduces PARSE 2.0, which is a nearly complete re-write that extends PARSE capabilities to include fully automating the processes of evaluating and quantifying run time critical parallel application-level behavioral attributes. We present an overview of the tool and the attributes being evaluated, and present experimental results from tests conducted on several widely used parallel benchmarks and application code fragments. The results re-enforce our earlier work, demonstrating that parallel applications can be classified according to their behavioral attributes, in the context of communication system resources."
1797675,15258,23836,"VisIO: Enabling Interactive Visualization of Ultra-Scale, Time Series Data via High-Bandwidth Distributed I/O Systems",2011,"Petascale simulations compute at resolutions ranging into billions of cells and write terabytes of data for visualization and analysis. Interactive visualization of this time series is a desired step before starting a new run. The I/O subsystem and associated network often are a significant impediment to interactive visualization of time-varying data, as they are not configured or provisioned to provide necessary I/O read rates. In this paper, we propose a new I/O library for visualization applications: VisIO. Visualization applications commonly use N-to-N reads within their parallel enabled readers which provides an incentive for a shared-nothing approach to I/O, similar to other data-intensive approaches such as Hadoop. However, unlike other data-intensive applications, visualization requires: (1) interactive performance for large data volumes, (2) compatibility with MPI and POSIX file system semantics for compatibility with existing infrastructure, and (3) use of existing file formats and their stipulated data partitioning rules. VisIO, provides a mechanism for using a non-POSIX distributed file system to provide linear scaling of I/O bandwidth. In addition, we introduce a novel scheduling algorithm that helps to co-locate visualization processes on nodes with the requested data. Testing using VisIO integrated into Para View was conducted using the Hadoop Distributed File System (HDFS) on TACC's Longhorn cluster. A representative dataset, VPIC, across 128 nodes showed a 64.4\% read performance improvement compared to the provided Lustre installation. Also tested, was a dataset representing a global ocean salinity simulation that showed a 51.4\% improvement in read performance over Lustre when using our VisIO system. VisIO, provides powerful high-performance I/O services to visualization applications, allowing for interactive performance with ultra-scale, time-series data."
1569966,15258,23836,Comparison of Multi-objective Optimization Algorithms for the JShadObf JavaScript Obfuscator,2014,"With the advent of the Cloud Computing (CC) paradigm and the explosion of new Web Services proposed over the Internet (such as Google Office Apps, Dropbox or Doodle), the protection of the programs at the heart of these services becomes more and more crucial, especially for the companies making business on top of these services. The majority of these services are now using the JavaScript programming language to interact with the user as all modern web browsers--either on desktops, game consoles, tablets or smart phones--include JavaScript interpreters making it the most ubiquitous programming language in history. This context renew the interest of obfuscation techniques, i.e. to render a program unintelligible without altering its functionality. The objective is to prevent the reverse-engineering on the program for a certain period of time – an absolute protection by this way being unrealistic since stand-alone obfuscation for arbitrary programs has been proven impossible in 2001. In [11], we have presented JSHADOBF, an obfuscation framework based on evolutionary heuristics designed to optimize for a given input JavaScript program, the sequence of transformations that should be applied to the source code to improve its obfuscation capacity. Measuring this capacity is based on the combination of several metrics optimized simultaneously with Multi-Objective Evolutionary Algorithms (MOEAs). In this paper, we extend and complete the experiments made around JSHADOBF to analyze the impact of the underlying Multi-Objective Evolutionary Algorithms (MOEAs) algorithm onto the obfuscation process. In particular, we compare the performances of NSGA-II and MOEAD (two reference algorithms in the optimization domain) on top of JSHADOBF to first obfuscate a pedagogical program inherited from linear algebra, then one of the most popular and widely used JavaScript library: JQuery."
1251974,15258,422,Scalable near real-time failure localization of data center networks,2014,"Large-scale data center networks are complex---comprising several thousand network devices and several hundred thousand links---and form the critical infrastructure upon which all higher-level services depend on. Despite the built-in redundancy in data center networks, performance issues and device or link failures in the network can lead to user-perceived service interruptions. Therefore, determining and localizing user-impacting availability and performance issues in the network in near real time is crucial. Traditionally, both passive and active monitoring approaches have been used for failure localization. However, data from passive monitoring is often too noisy and does not effectively capture silent or gray failures, whereas active monitoring is potent in detecting faults but limited in its ability to isolate the exact fault location depending on its scale and granularity.   Our key idea is to use statistical data mining techniques on large-scale active monitoring data to determine a ranked list of suspect causes, which we refine with passive monitoring signals. In particular, we compute a failure probability for devices and links in near real time using data from active monitoring, and look for statistically significant increases in the failure probability. We also correlate the probabilistic output with other failure signals from passive monitoring to increase the confidence of the probabilistic analysis. We have implemented our approach in the Windows Azure production environment and have validated its effectiveness in terms of localization accuracy, precision, and time to localization using known network incidents over the past three months. The correlated ranked list of devices and links is surfaced as a report that is used by network operators to investigate current issues and identify probable root causes."
2125530,15258,20774,Storage and search in dynamic peer-to-peer networks,2013,"We study robust and efficient distributed algorithms for searching, storing, and maintaining data in dynamic Peer-to-Peer (P2P) networks. P2P networks are highly dynamic networks that experience heavy node  churn  (i.e., nodes join and leave the network continuously over time). Our goal is to guarantee, despite high node churn rate, that a large number of nodes in the network can store, retrieve, and maintain a large number of data items. Our main contributions are fast randomized distributed algorithms that guarantee the above with high probability even under high  adversarial  churn. In particular, we present the following main results:   1. A randomized distributed search algorithm that with high probability guarantees that searches from as many as  n - o(n)  nodes ( n  is the stable network size) succeed in  O (log  n  )-rounds despite  O ( n /log 1+δ  n ) churn, for any small constant δ > 0,  per round . We assume that the churn is controlled by an oblivious adversary (that has complete knowledge and control of what nodes join and leave and at what time and has unlimited computational power, but is oblivious to the random choices made by the algorithm).   2. A storage and maintenance algorithm that guarantees, with high probability, data items can be efficiently stored (with only θ(log  n ) copies of each data item) and maintained in a dynamic P2P network with churn rate up to  O ( n /log 1+δ  n ) per round. Our search algorithm together with our storage and maintenance algorithm guarantees that as many as  n - o(n)  nodes can efficiently store, maintain, and search even under  O ( n /log 1+δ  n ) churn  per round . Our algorithms require only polylogarithmic in  n  bits to be processed and sent (per round) by each node.   To the best of our knowledge, our algorithms are the first-known, fully-distributed storage and search algorithms that provably work under highly dynamic settings (i.e., high churn rates per step). Furthermore, they are localized (i.e., do not require any global topological knowledge) and scalable. A technical contribution of this paper, which may be of independent interest, is showing how random walks can be provably used to derive scalable distributed algorithms in dynamic networks with adversarial node churn."
2288576,15258,11058,VeriCon: towards verifying controller programs in software-defined networks,2014,"Software-defined networking (SDN) is a new paradigm for operating and managing computer networks. SDN enables logically-centralized control over network devices through a controller software that operates independently from the network hardware, and can be viewed as the network operating system. Network operators can run both inhouse and third-party SDN programs (often called applications) on top of the controller, e.g., to specify routing and access control policies. SDN opens up the possibility of applying formal methods to prove the correctness of computer networks. Indeed, recently much effort has been invested in applying finite state model checking to check that SDN programs behave correctly. However, in general, scaling these methods to large networks is challenging and, moreover, they cannot guarantee the absence of errors.   We present VeriCon, the first system for verifying that an SDN program is correct on  all  admissible topologies and for  all  possible (infinite) sequences of network events. VeriCon either confirms the correctness of the controller program on  all  admissible network topologies or outputs a concrete counterexample. VeriCon uses first-order logic to specify admissible network topologies and desired network-wide invariants, and then implements classical Floyd-Hoare-Dijkstra deductive verification using Z3. Our preliminary experience indicates that VeriCon is able to rapidly verify correctness, or identify bugs, for a large repertoire of simple core SDN programs. VeriCon is compositional, in the sense that it verifies the correctness of execution of any single network event w.r.t. the specified invariant, and can thus scale to handle large programs. To relieve the burden of specifying inductive invariants from the programmer, VeriCon includes a separate procedure for inferring invariants, which is shown to be effective on simple controller programs. We view VeriCon as a first step en route to practical mechanisms for verifying network-wide invariants of SDN programs."
2529586,15258,23836,High-Productivity and High-Performance Analysis of Filtered Semantic Graphs,2013,"High performance is a crucial consideration when executing a complex analytic query on a massive semantic graph. In a semantic graph, vertices and edges carry attributes of various types. Analytic queries on semantic graphs typically depend on the values of these attributes; thus, the computation must view the graph through a filter that passes only those individual vertices and edges of interest. Knowledge Discovery Toolbox (KDT), a Python library for parallel graph computations, is customizable in two ways. First, the user can write custom graph algorithms by specifying operations between edges and vertices. These programmer-specified operations are called semiring operations due to KDT's underlying linear-algebraic abstractions. Second, the user can customize existing graph algorithms by writing filters that return true for those vertices and edges the user wants to retain during algorithm execution. For high productivity, both semiring operations and filters are written in a high-level language, resulting in relatively low performance due to the bottleneck of having to call into the Python virtual machine for each vertex and edge. In this work, we use the Selective Embedded JIT Specialization (SEJITS) approach to automatically translate semiring operations and filters defined by programmers into a lower-level efficiency language, bypassing the upcall into Python. We evaluate our approach by comparing it with the high-performance Combinatorial BLAS engine, and show our approach enables users to write in high-level languages and still obtain the high performance of low-level code. We also present a new roofline model for graph traversals, and show that our high-performance implementations do not significantly deviate from the roofline. Overall, we demonstrate the first known solution to the problem of obtaining high performance from a productivity language when applying graph algorithms selectively on semantic graphs."
1303208,15258,9836,Control-Flow Decoupling,2012,"Mobile and PC/server class processor companies continue to roll out flagship core micro architectures that are faster than their predecessors. Meanwhile placing more cores on a chip coupled with constant supply voltage puts per-core energy consumption at a premium. Hence, the challenge is to find future micro architecture optimizations that not only increase performance but also conserve energy. Eliminating branch mispredictions -- which waste both time and energy -- is valuable in this respect. We first explore the control-flow landscape by characterizing mispredictions in four benchmark suites. We find that a third of mispredictions-per-1K-instructions (MPKI) come from what we call separable branches: branches with large control-dependent regions (not suitable for if-conversion), whose backward slices do not depend on their control-dependent instructions or have only a short dependence. We propose control-flow decoupling (CFD) to eradicate mispredictions of separable branches. The idea is to separate the loop containing the branch into two loops: the first contains only the branch's predicate computation and the second contains the branch and its control-dependent instructions. The first loop communicates branch outcomes to the second loop through an architectural queue. Micro architecturally, the queue resides in the fetch unit to drive timely, non-speculative fetching or skipping of successive dynamic instances of the control-dependent region. Either the programmer or compiler can transform a loop for CFD, and we evaluate both. On a micro architecture configured similar to Intel's Sandy Bridge core, CFD increases performance by up to 43%, and reduces energy consumption by up to 41%. Moreover, for some applications, CFD is a necessary catalyst for future complexity-effective large-window architectures to tolerate memory latency."
1640870,15258,10228,A novel paradigm for context-aware content pre-fetching in mobile networks,2013,"The current content provision methods and associated pricing and business models are challenged by the traffic requirements anticipated for future “data intensive” services. In order to deliver substantially higher peak rates operators will need to deploy a much denser infrastructure and/or acquire more spectrum, thus significantly increasing their CAPEX and OPEX and reducing revenues. To improve the utilization of available network resources this paper presents ActiveCast, a disruptive content delivery paradigm that supports opportunistic content pre-fetching by introducing semantic and context awareness in the currently “agnostic” networking paradigm. The experimental investigations presented in the paper focus on mobile video provision and a content provider, integrated with Facebook and YouTube, has been developed and used to identify socially relevant content for a set of test users. Part of the studies presented in the paper aim at experimentally understanding the structure of the energy costs associated with pre-fetching and on defining a delivery strategy that allows controlling the amount of energy invested. A comparison between a centralized implementation, in which pre-fetching is coordinated by the mobile operators, and an Over-The-Top (OTT) implementation of ActiveCast are also presented. The results show that complementing the context information available at individual user terminals with traffic information, shared by mobile operators through the ActiveCast API, can substantially reduce the energy costs of content delivery, as compared with “on demand” video streaming. Additionally, opportunistically exploiting connections with WiFi APs can amplify the gains already achievable by prefetching on wide area networks."
777715,15258,21056,Impact of flash memory on video-on-demand storage: analysis of tradeoffs,2011,"There is no doubt that video-on-demand (VoD) services are very popular these days. However, disk storage is a serious bottleneck limiting the scalability of a VoD server. Disk throughput degrades dramatically due to seek time overhead when the server is called upon to serve a large number of simultaneous video streams. To address the performance problem of disk, buffer cache algorithms that utilize RAM have been proposed. Interval caching is a state-of-the-art caching algorithm for a VoD server.  Flash Memory Solid-State Drive (SSD ) is a relatively new storage technology. Its excellent random read performance, low power consumption, and sharply dropping cost per gigabyte are opening new opportunities to efficiently use the device for enterprise systems. On the other hand, it has deficiencies such as poor small random write performance and limited number of erase operations. In this paper, we analyze tradeoffs and potential impact that flash memory SSD can have for a VoD server. Performance of various commercially available flash memory SSD models is studied. We find that low-end flash memory SSD provides better performance than the high-end one while costing less than the high-end one when the I/O request size is large, which is typical for a VoD server. Because of the wear problem and asymmetric read/write performance of flash memory SSD, we claim that interval caching cannot be used with it. Instead, we propose using file-level Least Frequently Used (LFU) due to the highly skewed video access pattern of the VoD workload. We compare the performance of interval caching with RAM and file-level LFU with flash memory by simulation experiments. In addition, from the cost-effectiveness analysis of three different storage configurations, we find that flash memory with hard disk drive is the most cost-effective solution compared to DRAM with hard disk drive or hard disk drive only."
839417,15258,8806,"The future of accelerator programming: abstraction, performance or can we have both?",2014,"In a perfect world, code would only be written once and would run on different devices with high efficiency. To a degree, that used to be the case in the era of frequency scaling on a single core. However, due to power limitations, parallel programming has become necessary to obtain performance gains. But parallel architectures differ substantially from each other, often require specialized knowledge to exploit them, and typically necessitate reimplementation and fine tuning of programs. These slow tasks frequently result in situations where most of the time is spent reimplementing old rather than writing new code.   The goal of our research is to find programming techniques that increase productivity, maintain high performance, and provide abstraction to free the programmer from these unnecessary and time-consuming tasks. However, such techniques usually come at the cost of substantial performance degradation. This paper investigates current approaches to portable accelerator programming, seeking to answer whether they make it possible to combine high efficiency with sufficient algorithm abstraction. It discusses OpenCL as a potential solution and presents three approaches of writing portable code: GPU-centric, CPU-centric, and combined. By applying the three approaches to a real-world program, we show that it is at least sometimes possible to run exactly the same code on many different devices with minimal performance degradation using parameterization. The main contributions of this paper are an extensive review of the current state-of-the-art and our original approach of addressing the stated problem with the  copious-parallelism  technique."
2207212,15258,9836,Low-Latency Mechanisms for Near-Threshold Operation of Private Caches in Shared Memory Multicores,2012,"Near-threshold voltage operation is widely acknowledged as a poten- tial mechanism to achieve an order of magnitude reduction in energy consumption in future processors. However, processors cannot operate reliably below a minimum voltage, Vccmin, since hardware components may fail. SRAM bitcell failures in memory structures, such as caches, typically determine the Vccmin for a processor. Although the last-level shared caches (LLC) in modern multicores are protected using error correcting codes (ECC), the private caches have been left unprotected due to their performance sensitivity to the latency overhead of the ECC. This limits the operation of the processor at near-threshold voltages.In this paper, we propose mechanisms for near-threshold operation of private caches that do not require ECC support. First, we present a fine-grain mechanism to disable cache lines in private caches, with bitcell failures at the target near-threshold voltage. Second, we propose two mechanisms to better manage the capacity-stressed private caches. (1) We utilize the OS-level data classification of private and shared data and evaluate a data placement mechanism that dynamically relocates the private data blocks to the LLC slice that is physically co-located with the requesting core. (2) We propose an in-hardware yet low-overhead runtime profiling of the locality of each cache line that is classified as private data, and only allow such data to be cached in the private caches if it shows high spatio- temporal locality. These mechanisms allow the private caches to rely on the local LLC slice to cache the low-locality private data efficiently, and enable more space to hold the more frequently used private data (as well as the shared data). We show that combining cache line disabling with efficient cache management of private data performs better (in terms of application completion times) than using a single error correction double error detection (SECDED) based ECC mechanism and/or cache line disabling."
1470529,15258,22288,Accelerating MapReduce Analytics Using CometCloud,2012,"MapReduce-Hadoop has emerged as an effectiveframework for large-scale data analytics, providing support forexecuting jobs and storing data in a parallel and distributedmanner. MapReduce has been shown to perform very well onlarge datacenters running applications where the data can beeffectively divided into homogeneous chunks running across homogeneoushardware. However, the performance of MapReduce-Hadoop is far from ideal when either or both hardware anddatasets are heterogeneous. Such heterogeneity is unavoidablein many academic computing environments that use multiplegenerations of hardware, and share resources among users.Heterogeneity is also unavoidable in scientific applications thatprocess a varying number of datasets of different sizes. In thesecases, the performance of MapReduce-Hadoop can be a concern.In this paper, we implement MapReduce on top of CometCloudto address the issue of heterogeneity and support applicationsclasses that involve irregular datasets (e.g. large number of smalldata files or datasets of varying sizes). Furthermore, we developan autonomic manager that can schedule MapReduce tasks basedon user objective, provision resources accordingly, and supporton-demand scale up and cloudbursts. These resources can beselected from a hybrid infrastructure such as local clusters, datacenters, and public clouds. The performance of the developedsolution is verified using a protein data mining applicationoperating on data from the Protein Data Bank. The application isdeployed, based on deadline and budget constraints, on a clusterat Rutgers and/or Amazon EC2 resources. The experimentalresults show that the MapReduce-CometCloud framework caneffectively support applications operating on large numbers ofsmall data files on a heterogeneous and distributed environment,and satisfy user objective autonomically using cloudbursts."
2513443,15258,8306,GangES: gang error simulation for hardware resiliency evaluation,2014,"As technology scales, the hardware reliability challenge affects a broad computing market, rendering traditional redundancy based solutions too expensive. Software anomaly based hardware error detection has emerged as a low cost reliability solution, but suffers from Silent Data Corruptions (SDCs). It is crucial to accurately evaluate SDC rates and identify SDC producing software locations to develop software-centric low-cost hardware resiliency solutions.   A recent tool, called Relyzer, systematically analyzes an entire application's resiliency to single bit soft-errors using a small set of carefully selected error injection sites. Relyzer provides a practical resiliency evaluation mechanism but still requires significant evaluation time, most of which is spent on error simulations.   This paper presents a new technique called GangES (Gang Error Simulator) that aims to reduce error simulation time. GangES observes that a set or gang of error simulations that result in the same intermediate execution state (after their error injections) will produce the same error outcome; therefore, only one simulation of the gang needs to be completed, resulting in significant overall savings in error simulation time. GangES leverages program structure to carefully select when to compare simulations and what state to compare. For our workloads, GangES saves 57% of the total error simulation time with an overhead of just 1.6%   This paper also explores pure program analyses based techniques that could obviate the need for tools such as GangES altogether. The availability of Relyzer+GangES allows us to perform a detailed evaluation of such techniques. We evaluate the accuracy of several previously proposed program metrics. We find that the metrics we considered and their various linear combinations are unable to adequately predict an instruction's vulnerability to SDCs, further motivating the use of Relyzer+GangES style techniques as valuable solutions for the hardware error resiliency evaluation problem"
1600906,15258,11330,Using GPUs to compute large out-of-card FFTs,2011,"The optimization of Fast Fourier Transfer (FFT) problems that can fit into GPU memory has been studied extensively. Such on-card FFT libraries like CUFFT can generally achieve much better performance than their counterparts on a CPU, as the data transfer between CPU and GPU is usually not counted in their performance. This high performance, however, is limited by the GPU memory size. When the FFT problem size increases, the data transfer between system and GPU memory can comprise a substantial part of the overall execution time. Therefore, optimizations for FFT problems that outgrow the GPU memory can not bypass the tuning of data transfer between CPU and GPU. However, no prior study has attacked this problem. This paper is the first effort of using GPUs to efficiently compute large FFTs in the CPU memory of a single compute node.   In this paper, the performance of the PCI bus during the transfer of a batch of FFT subarrays is studied and a blocked buffer algorithm is proposed to improve the effective bandwidth. More importantly, several FFT decomposition algorithms are proposed so as to increase the data locality, further improve the PCI bus efficiency and balance computation between kernels. By integrating the above two methods, we demonstrate an out-of-card FFT optimization strategy and develop an FFT library that efficiently computes large 1D, 2D and 3D FFTs that can not fit into the GPU's memory. On three of the latest GPUs, our large FFT library achieves much better double precision performance than two of the most efficient CPU based libraries, FFTW and Intel MKL. On average, our large FFTs on a single GeForce GTX480 are 46% faster than FFTW and 57% faster than MKL with multiple threads running on a four-core Intel i7 CPU. The speedup on a Tesla C2070 is 1.93x and 2.11x over FFTW and MKL. A peak performance of 21GFLOPS is achieved for a 2D FFT of size 2048x65536 on C2070 with double precision."
1814024,15258,23836,Integrating Asynchronous Task Parallelism with MPI,2013,"Effective combination of inter-node and intra-node parallelism is recognized to be a major challenge for future extreme-scale systems. Many researchers have demonstrated the potential benefits of combining both levels of parallelism, including increased communication-computation overlap, improved memory utilization, and effective use of accelerators. However, current “hybrid programming” approaches often require significant rewrites of application code and assume a high level of programmer expertise. Dynamic task parallelism has been widely regarded as a programming model that combines the best of performance and programmability for shared-memory programs. For distributed-memory programs, most users rely on efficient implementations of MPI. In this paper, we propose HCMPI (Habanero-C MPI), an integration of the Habanero-C dynamic task-parallel programming model with the widely used MPI message-passing interface. All MPI calls are treated as asynchronous tasks in this model, thereby enabling unified handling of messages and tasking constructs. For programmers unfamiliar with MPI, we introduce distributed data-driven futures (DDDFs), a new data-flow programming model that seamlessly integrates intra-node and inter-node data-flow parallelism without requiring any knowledge of MPI. Our novel runtime design for HCMPI and DDDFs uses a combination of dedicated communication and computation specific worker threads. We evaluate our approach on a set of micro-benchmarks as well as larger applications and demonstrate better scalability compared to the most efficient MPI implementations, while offering a unified programming model to integrate asynchronous task parallelism with distributed-memory parallelism."
1751046,15258,10192,OpenADN: A Case for Open Application Delivery Networking,2013,"There are two key issues that prevent Application Service Providers (ASPs) from fully leveraging the cloud advantage. First, in modern enterprise and Internet-based application environments, a separate middlebox infrastructure for providing application delivery services such as security (e.g., firewalls, intrusion detection), performance (e.g., SSL off loaders), and scaling (e.g., load balancers) is deployed. In a cloud datacenter, the ASP does not have any control over the network infrastructure, thus making it hard for them to deploy middleboxes for their cloud-based application deployments. Second, modern services virtualize the application endpoint. A service can no longer be statically mapped to a single end host. Instead, the service is partitioned and replicated across multiple end hosts for better performance and scaling. In enterprise datacenters, service requests are intercepted by an application-level routing service (APR) in the data plane and dynamically mapped to the correct service partition and the best (e.g. least loaded) instance of that partition. However, although multi-cloud (or Inter-cloud) environments allow ASPs to globally distributed their applications over multiple cloud datacenters leased from multiple cloud providers, ASPs need support of a globally distributed APR infrastructure to intelligently route application traffic to the right service instance. But, since such an infrastructure would be extremely hard to own and mange, it is best to design a shared solution where APR could be provided as a service by a third party provider having a globally distributed presence, such as an ISP. Although these requirements seem separate, they can be converged into a single abstraction for supporting application delivery in the cloud context. A sample design of this abstraction is OpenADN, presented here."
1344985,15258,11058,CLAP: recording local executions to reproduce concurrency failures,2013,"We present CLAP, a new technique to reproduce concurrency bugs. CLAP has two key steps. First, it logs thread local execution paths at runtime. Second, offline, it computes memory dependencies that accord with the logged execution and are able to reproduce the observed bug. The second step works by combining constraints from the thread paths and constraints based on a memory model, and computing an execution with a constraint solver.   CLAP has four major advantages. First, logging purely local execution of each thread is substantially cheaper than logging memory interactions, which enables CLAP to be efficient compared to previous approaches. Second, our logging does not require any synchronization and hence with no added memory barriers or fences; this minimizes perturbation and missed bugs due to extra synchronizations foreclosing certain racy behaviors. Third, since it uses no synchronization, we extend CLAP to work on a range of relaxed memory models, such as TSO and PSO, in addition to sequential consistency. Fourth, CLAP can compute a much simpler execution than the original one, that reveals the bug with minimal thread context switches. To mitigate the scalability issues, we also present an approach to parallelize constraint solving, which theoretically scales our technique to programs with arbitrary execution length.   Experimental results on a variety of multithreaded benchmarks and real world concurrent applications validate these advantages by showing that our technique is effective in reproducing concurrency bugs even under relaxed memory models; furthermore, it is significantly more efficient than a state-of-the-art technique that records shared memory dependencies, reducing execution time overhead by 45% and log size by 88% on average."
1462810,15258,9748,"Simulating Big Data Clusters for System Planning, Evaluation, and Optimization",2014,"With the fast development of big data technologies, IT spending on computer clusters is increasing rapidly as well. In order to minimize the cost, architects must plan big data clusters with careful evaluation of various design choices. Current capacity planning methods are mostly trial-and-error or high level estimation based. These approaches, however, are far from efficient, especially with the increasing hardware diversity and software stack complexity. In this paper, we present CSMethod, a novel cluster simulation methodology, to facilitate efficient cluster capacity planning, performance evaluation and optimization, before system provisioning. With our proposed methodology, software stacks are simulated by an abstract yet high fidelity model, Hardware activities derived from software operations are dynamically mapped onto architecture models for processors, memory, storage and networking devices. This hardware/software hybrid methodology allows low overhead, fast and accurate cluster simulation that can be easily carried out on a standard client platform (desktop or laptop). Our experimental results with six popular Hadoop workloads demonstrate that CSMethod can achieve an average error rate of less than six percent, across various software parameters and cluster hardware configurations. We also illustrate the application of the proposed methodology with two real-world use cases: Video-streaming service system planning and Terasort cluster optimization. All our experiments are run on a commodity laptop with execution speeds faster than native executions on a multi-node high-end cluster."
2190335,15258,23497,Sponge: portable stream programming on graphics engines,2011,"Graphics processing units (GPUs) provide a low cost platform for accelerating high performance computations. The introduction of new programming languages, such as CUDA and OpenCL, makes GPU programming attractive to a wide variety of programmers. However, programming GPUs is still a cumbersome task for two primary reasons: tedious performance optimizations and lack of portability. First, optimizing an algorithm for a specific GPU is a time-consuming task that requires a thorough understanding of both the algorithm and the underlying hardware. Unoptimized CUDA programs typically only achieve a small fraction of the peak GPU performance. Second, GPU code lacks efficient portability as code written for one GPU can be inefficient when executed on another. Moving code from one GPU to another while maintaining the desired performance is a non-trivial task often requiring significant modifications to account for the hardware differences. In this work, we propose Sponge, a compilation framework for GPUs using synchronous data flow streaming languages. Sponge is capable of performing a wide variety of optimizations to generate efficient code for graphics engines. Sponge alleviates the problems associated with current GPU programming methods by providing portability across different generations of GPUs and CPUs, and a better abstraction of the hardware details, such as the memory hierarchy and threading model. Using streaming, we provide a write-once software paradigm and rely on the compiler to automatically create optimized CUDA code for a wide variety of GPU targets. Sponge's compiler optimizations improve the performance of the baseline CUDA implementations by an average of 3.2x."
1489984,15258,11330,Locality & utility co-optimization for practical capacity management of shared last level caches,2012,"Shared last-level caches (SLLCs) on chip-multiprocessors play an important role in bridging the performance gap between processing cores and main memory. Although there are already many proposals targeted at overcoming the weaknesses of the least-recently-used (LRU) replacement policy by optimizing either locality or utility for heterogeneous workloads, very few of them are suitable for practical SLLC designs due to their large overhead of log associativity bits per cache line for re-reference interval prediction. The two recently proposed practical replacement policies, TA-DRRIP and SHiP, have significantly reduced the overhead by relying on just 2 bits per line for prediction, but they are oriented towards managing locality only, missing the opportunity provided by utility optimization.   This paper is motivated by our two key experimental observations: (i) the not-recently-used (NRU) replacement policy that entails only one bit per line for prediction can satisfactorily approximate the LRU performance; (ii) since locality and utility optimization opportunities are concurrently present in heterogeneous workloads, the co-optimization of both would be indispensable to higher performance but is missing in existing practical SLLC schemes. Therefore, we propose a novel practical SLLC design, called COOP, which needs just one bit per line for re-reference interval prediction, and leverages lightweight per-core locality & utility monitors that profile sample SLLC sets to guide the co-optimization. COOP offers significant throughput improvement over LRU by 7.67% on a quad-core CMP with a 4MB SLLC for 200 random workloads, outperforming both of the recent practical replacement policies at the in-between cost of 17.74KB storage overhead (TA-DRRIP: 4.53% performance improvement with 16KB storage cost; SHiP: 6.00% performance improvement with 25.75KB storage overhead)."
2456159,15258,22260,Towards an Efficient Online Causal-Event-Pattern-Matching Framework,2013,"Event monitoring and logging, that is, recording the communication events between processes, is a critical component in many highly reliable distributed systems. The event logs enable the identification of certain safety-condition violations, such as race conditions and mutual-exclusion violations, as safety is generally contingent on processes communicating in a specific causally ordered pattern. Previous e orts at finding such patterns have often focused on online techniques, which are unable to identify operational problems as they occur. Online monitoring tools exist but they are often restricted to identifying a specific violation condition, such as a deadlock or a race condition, using dedicated data structures. We address the more general problem of detecting causally related event patterns that can be used to identify various undesired behaviours in the system. The main challenge for online pattern matching is the need to store the partial matches to the pattern, as they may combine with future events to form a complete match. Unlike pattern matching in most other domains, causally ordered patterns can span a potentially unbounded number of events and efficiently searching through this large collection poses a significant challenge. In this paper, we introduce OCEP, an efficient online causalevent- pattern-matching framework that bounds the number of partial matches it stores by reporting only a representative subset of pattern matches. We define a subset of matches as representative if it has at least one occurrence of each event in the pattern on each process, which is applicable for a large class of distributed applications. With this definition, OCEP introduces a backtracking algorithm to efficiently find a representative subset from the history of events. An evaluation of the framework shows that OCEP is capable of handling several frequently occurring violation patterns at the event rates of some representative distributed applications."
2353959,15258,11058,Language-independent sandboxing of just-in-time compilation and self-modifying code,2011,"When dealing with dynamic, untrusted content, such as on the Web, software behavior must be sandboxed, typically through use of a language like JavaScript. However, even for such specially-designed languages, it is difficult to ensure the safety of highly-optimized, dynamic language runtimes which, for efficiency, rely on advanced techniques such as Just-In-Time (JIT) compilation, large libraries of native-code support routines, and intricate mechanisms for multi-threading and garbage collection. Each new runtime provides a new potential attack surface and this security risk raises a barrier to the adoption of new languages for creating untrusted content.   Removing this limitation, this paper introduces general mechanisms for safely and efficiently sandboxing software, such as dynamic language runtimes, that make use of advanced, low-level techniques like runtime code modification. Our  language-independent sandboxing  builds on Software-based Fault Isolation (SFI), a traditionally static technique. We provide a more flexible form of SFI by adding new constraints and mechanisms that allow safety to be guaranteed despite runtime code modifications.   We have added our extensions to both the x86-32 and x86-64 variants of a production-quality, SFI-based sandboxing platform; on those two architectures SFI mechanisms face different challenges. We have also ported two representative language platforms to our extended sandbox: the Mono common language runtime and the V8 JavaScript engine. In detailed evaluations, we find that sandboxing slowdown varies between different benchmarks, languages, and hardware platforms. Overheads are generally moderate and they are close to zero for some important benchmark/platform combinations."
2468156,15258,9836,Virtually-aged sampling DMR: unifying circuit failure prediction and circuit failure detection,2013,"Hardware failure due to wearout is a growing concern. Circuit failure prediction is an approach that is effective if it meets the following requirements: low design complexity, low overheads, generality (supporting various types of wearout including soft and hard breakdown) and high accuracy. State-of-the-art techniques, which typically detect and measure low level circuit properties like gate delay cannot deliver on all four requirements. Moving away from the paradigm of measuring circuit delays is key to satisfying the four design requirements. Our insight is to  virtually age  the processor and thus manifest a wearout fault early -- we convert the delay degradation into a logic fault;  expose the fault  and then  detect the fault.  To virtually age the processor, reducing supply voltage effectively mirrors wearout. For fault exposure, we observe that faults in critical paths are naturally exposed and we develop a technique to expose faults along the non-critical paths using clock phase shifting logic. Our system, Aged-SDMR, combines these two mechanisms to expose wearout faults early and detects them using Sampling DMR. We also develop principles to combine these two mechanisms with any detection technique. We implement a prototype system based on the OpenRISC processor on a Xilinx Zync FPGA. We demonstrate that Aged-SDMR is practical and delivers on all four requirements, has area and energy overheads of 9% and 0.7% respectively, takes at most 0.4 days to detect failure after onset and its early warning window is configurable. More generally, Aged-SDMR provides the capability for low-overhead DMR execution without any missed errors and 100% coverage. It is likely to find broad uses within reliability and elsewhere."
2260259,15258,23836,Robust SIMD: Dynamically Adapted SIMD Width and Multi-Threading Depth,2012,"Architectures that aggressively exploit SIMD often have many data paths execute in lockstep and use multi-threading to hide latency. They can yield high through-put in terms of area- and energy-efficiency for many data-parallel applications. To balance productivity and performance, many recent SIMD organizations incorporate implicit cache hierarchies. Examples of such architectures include Intel's MIC, AMD's Fusion, and NVIDIA's Fermi. However, unlike software-managed streaming memories used in conventional graphics processors (GPUs), hardware-managed caches are more disruptive to SIMD execution, therefore the interaction between implicit caching and aggressive SIMD execution may no longer follow the conventional wisdom gained from streaming memories. We show that due to more frequent memory latency divergence, lower latency in non-L1 data accesses, and relatively unpredictable L1 contention, cache hierarchies favor different SIMD widths and multi-threading depths than streaming memories. In fact, because the above effects are subject to runtime dynamics, a fixed combination of SIMD width and multi-threading depth no longer works ubiquitously across diverse applications or when cache capacities are reduced due to pollution or power saving. To address the above issues and reduce design risks, this paper proposes Robust SIMD, which provides wide SIMD and then dynamically adjusts SIMD width and multi-threading depth according to performance feedback. Robust SIMD can trade wider SIMD for deeper multi-threading by splitting a wider SIMD group into multiple narrower SIMD groups. Compared to the performance generated by running every benchmark on its individually preferred SIMD organization, the same Robust SIMD organization performs similarly -- sometimes even better due to phase adaptation -- and out per-forms the best fixed SIMD organization by 17%. When D-cache capacity is reduced due to runtime disruptiveness, Robust SIMD offers graceful performance degradation, with 25% polluted cache lines in a 32 KB D-cache, Robust SIMD performs 1.4× better compared to a conventional SIMD architecture."
2125614,15258,20649,Power-Aware NoCs through Routing and Topology Reconfiguration,2014,"With the advent of multicore processors and system-on-chip designs, intra-chip communication demands have exacerbated, leading to a growing adoption of scalable networks-on-chip (NoCs) as the interconnect fabric. Today, conventional NoC designs may consume up to 30% of the entire chip's power budget, in large part due to leakage power. In this work, we address this issue by proposing Panthre: our solution deploys power-gating to provide long intervals of uninterrupted sleep to selected units. Packets that would normally use power-gated components are steered away via topology and routing reconfiguration, while Panthre provides low-latency alternate paths to their destinations. The routing reconfiguration operates in a distributed fashion and guarantees that deadlock-free routes are available at all times. At runtime, Panthre adapts to the application's communication patterns by updating its power-gating decisions. It employs a feedback-based distributed mechanism to control the amount of sleeping components and of packets detours, so that performance degradation is kept at a minimum. Our design is flexible, providing a mechanism that designers can use to tradeoff power savings with performance, based on application's requirements.   Our experiments on multi-programmed communication-light workloads from the SPEC CPU2006 suite show that Panthre reduces total network power consumption by 14.5% on average, with only a 1.8% degradation in performance, when all processor nodes are active. At times when 15-25% of the processor cores are communication-idle, Panthre enables leakage power savings of 36.9% on average, while still providing connected and deadlock-free routes for all other nodes."
923425,15258,22288,Placement in Clouds for Application-Level Latency Requirements,2012,"CPU and device virtualization technology allows applications to be hosted on cloud platforms; some of the resulting benefits are lower cost and greater elasticity. In such cloud hosted applications, some components reside on the cloud while others, such as end users and components tied to physical devices, are located outside the cloud. Many applications, e.g., telecom services, have stringent latency requirements in terms of within how much time certain procedures must be completed. The application latency is strongly determined by the locations of all the interacting components that are both within and outside the cloud. In this paper, we study the problem of determining the optimal placement of the application components in the cloud so that the latency requirements of the application can be met. We present a precise formulation of the placement problem which includes a specification of the cloud platform, and collective latency expressions for application-level latency requirements. We show that Message Sequence Charts (MSCs), a widely-used mechanism for describing the execution of application procedures, can be naturally translated into our formalism of collective latency expressions. We present placement algorithms that exploit the Euclidean triangular inequality property of network topologies: (a) an exact algorithm for determining the most optimal placement but which has a worst-case exponential running time, and (b) an algorithm for determining a close to-optimal placement that has a fast polynomial running time. Additionally, we present an exact technique for partitioning a placement problem into smaller sub problems so that greater efficiency and accuracy can be achieved. We evaluate the performance of the algorithms on a representative telecom application --- a distributed deployment of the LTE Mobility Management Entity (MME). Our evaluation results show that our approximate algorithm can outperform a random placement by up to 49% for finding a successful placement."
2956953,15258,9748,Adaptive Configuration Selection for Power-Constrained Heterogeneous Systems,2014,"As power becomes an increasingly important design factor in high-end supercomputers, future systems will likely operate with power limitations significantly below their peak power specifications. These limitations will be enforced through a combination of software and hardware power policies, which will filter down from the system level to individual nodes. Hardware is already moving in this direction by providing power-capping interfaces to the user. The power/performance trade-off at the node level is critical in maximizing the performance of power-constrained cluster systems, but is also complex because of the many interacting architectural features and accelerators that comprise the hardware configuration of a node. The key to solving this challenge is an accurate power/performance model that will aid in selecting the right configuration from a large set of available configurations. In this paper, we present a novel approach to generate such a model offline using kernel clustering and multivariate linear regression. Our model requires only two iterations to select a configuration, which provides a significant advantage over exhaustive search-based strategies. We apply our model to predict power and performance for different applications using arbitrary configurations, and show that our model, when used with hardware frequency-limiting, selects configurations with significantly higher performance at a given power limit than those chosen by frequency-limiting alone. When applied to a set of 36 computational kernels from a range of applications, our model accurately predicts power and performance, it maintains 91% of optimal performance while meeting power constraints 88% of the time. When the model violates a power constraint, it exceeds the constraint by only 6% in the average case, while simultaneously achieving 54% more performance than an oracle."
2258902,15258,23749,A Flexible Framework for Asynchronous in Situ and in Transit Analytics for Scientific Simulations,2014,"High performance computing systems are today composed of tens of thousands of processors and deep memory hierarchies. The next generation of machines will further increase the unbalance between I/O capabilities and processing power. To reduce the pressure on I/Os, the in situ analytics paradigm proposes to process the data as closely as possible to where and when the data are produced. Processing can be embedded in the simulation code, executed asynchronously on helper cores on the same nodes, or performed in transit on staging nodes dedicated to analytics. Today, software environnements as well as usage scenarios still need to be investigated before in situ analytics become a standard practice. In this paper we introduce a framework for designing, deploying and executing in situ scenarios. Based on a component model, the scientist designs analytics workflows by first developing processing components that are next assembled in a dataflow graph through a Python script. At runtime the graph is instantiated according to the execution context, the framework taking care of deploying the application on the target architecture and coordinating the analytics workflows with the simulation execution. Component coordination, zero-copy intra-node communications or inter-nodes data transfers rely on per-node distributed daemons. We evaluate various scenarios performing in situ and in transit analytics on large molecular dynamics systems simulated with Gromacs using up to 2048 cores. We show in particular that analytics processing can be performed on the fraction of resources the simulation does not use well, resulting in a limited impact on the simulation performance (less than9%). Our more advanced scenario combines in situ and in transit processing to compute a molecular surface based on the Quick surf algorithm."
2113581,15258,9836,Imbalanced cache partitioning for balanced data-parallel programs,2013,"This paper investigates partitioning the ways of a shared last-level cache among the threads of a symmetric data-parallel application running on a chip-multiprocessor. Unlike prior work on way-partitioning for unrelated threads in a multiprogramming workload, the domain of multithreaded programs requires  both  throughput and fairness. Additionally, our workloads show no obvious thread differences to exploit: program threads see nearly identical IPC and data reuse as they progress (as expected for a well-written load-balanced data-parallel program).   Despite the balance and symmetry among threads, this paper shows that a balanced partitioning of cache ways between threads is suboptimal. Instead, this paper proposes a strategy of temporarily imbalancing the partitions between different threads to improve cache utilization by adapting to the locality behavior of the threads as captured by dynamic set-specific reuse-distance (SSRD). Cumulative SSRD histograms have knees that correspond to different important working sets; thus, cache ways can be taken away from a thread with only minimal performance impact if that thread is currently operating far from a knee. Those ways can then be given to a single preferred thread to push it over the next knee. The preferred thread is chosen in a round-robin fashion to ensure balanced progress over the execution. The algorithm also effectively handles scenarios where an unpartitioned cache might outperform any sort of explicit partitioning. This dynamic partition imbalance algorithm allows up to 44% reduction in execution time and 91% reduction in misses over an unpartitioned shared cache for 9 benchmarks from the PARSEC-2.0 and SPEC OMP suites."
1202057,15258,9836,Exploiting GPU peak-power and performance tradeoffs through reduced effective pipeline latency,2013,"Modern GPUs share limited hardware resources, such as register files, among a large number of concurrently executing threads. For efficient resource sharing, several buffering and collision avoidance stages are inserted in the GPU pipeline. These additional stages increase the read-after-write (RAW) latencies of instructions. Since GPUs are often architected to hide RAW latencies through extensive multithreading, they typically do not employ power-hungry data-forwarding networks (DFNs). However, we observe that many GPGPU applications do not have enough active threads that are ready to issue instructions to hide these RAW latencies. In this paper, we first demonstrate that DFNs can considerably improve the performance of many compute-intensive GPGPU applications and then propose most recent result forwarding (MoRF) as a low-power alternative to the DFN. Second, for floating-point (FP) operations, we exploit a high-throughput fused multiply-add (HFMA) unit to further reduce both RAW latencies and the number of FMA units in the GPU without impacting instruction throughput. MoRF and HFMA together provide a geometric mean performance improvement of 18% and 29% for integer/single-precision and double-precision GPGPU applications, respectively. Finally, both MoRF and HFMA allow the GPU to effectively mimic a shallower pipeline for a large percentage of instructions. Exploiting such a benefit, we propose low-power pipelines that can reduce peak power consumption by 14% without affecting the performance or increasing the complexity of the forwarding network. The peak power reduction allows GPUs to operate more cores within the same power budget, achieving a geometric mean performance improvement of 33% for double-precision GPGPU applications."
2027262,15258,23497,Power containers: an OS facility for fine-grained power and energy management on multicore servers,2013,"Energy efficiency and power capping are critical concerns in server and cloud computing systems. They face growing challenges due to dynamic power variations from new client-directed web applications, as well as complex behaviors due to multicore resource sharing and hardware heterogeneity. This paper presents a new operating system facility called power containers that accounts for and controls the power and energy usage of individual fine-grained requests in multicore servers. This facility relies on three key techniques---1) online model that attributes multicore power (including shared maintenance power) to concurrently running tasks, 2) alignment of actual power measurements and model estimates to enable online model recalibration, and 3) on-the-fly application-transparent request tracking in multi-stage servers to isolate the power and energy contributions and customize per-request control. Our mechanisms enable new multicore server management capabilities including fair power capping that only penalizes power-hungry requests, and energy-aware request distribution between heterogeneous servers. Our evaluation uses three multicore processors (Intel Woodcrest, Westmere, and SandyBridge) and a variety of server and cloud computing (Google App Engine) workloads. Our results demonstrate the high accuracy of our request power accounting (no more than 11% errors) and the effectiveness of container-enabled power virus isolation and throttling. Our request distribution case study shows up to 25% energy saving compared to an alternative approach that recognizes machine heterogeneity but not fine-grained workload affinity."
1180467,15258,20338,Overclocking the Yahoo!: CDN for faster web page loads,2011,"Fast-loading web pages are key for a positive user experience. Unfortunately, a large number of users suffer from page load times of many seconds, especially for pages with many embedded objects. Most of this time is spent fetching the page and its objects over the Internet.   This paper investigates the impact of optimizations that improve the delivery of content from edge servers at the Yahoo! Content Delivery Network (CDN) to the end users. To this end, we analyze packet traces of 12.3M TCP connections originating from users across the world and terminating at the Yahoo! CDN. Using these traces, we characterize key user-connection metrics at the network, transport, and the application layers. We observe high Round Trip Times (RTTs) and inflated number of round trips per page download (RTT multipliers). Due to inefficiencies in TCP's slow start and the HTTP protocol, we found several opportunities to reduce the RTT multiplier, e.g. increasing TCP's Initial Congestion Window (ICW), using TCP Appropriate Byte Counting (ABC), and using HTTP pipelining.   Using live workloads, we experimentally study the micro effects of these optimizations on network connectivity, e.g. packet loss rate. To evaluate the macro effects of these optimizations on the overall page load time, we use realistic synthetic workloads in a closed laboratory environment. We find that compounding HTTP pipelining with increasing the ICW size can lead to reduction in page load times by up to 80%. We also find that no one configuration fits all users, e.g. increasing the TCP ICW to a certain size may help some users while hurting others."
1883871,15258,8306,Automatic abstraction and fault tolerance in cortical microachitectures,2011,"Recent advances in the neuroscientific understanding of the brain are bringing about a tantalizing opportunity for building synthetic machines that perform computation in ways that differ radically from traditional Von Neumann machines. These brain-like architectures, which are premised on our understanding of how the human neocortex computes, are highly fault-tolerant, averaging results over large numbers of potentially faulty components, yet manage to solve very difficult problems more reliably than traditional algorithms. A key principle of operation for these architectures is that of automatic abstraction: independent features are extracted from highly disordered inputs and are used to create abstract invariant representations of the external entities. This feature extraction is applied hierarchically, leading to increasing levels of abstraction at higher levels in the hierarchy.   This paper describes and evaluates a biologically plausible computational model for this process, and highlights the inherent fault tolerance of the biologically-inspired algorithm. We introduce a stuck-at fault model for such cortical networks, and describe how this model maps to hardware faults that can occur on commodity GPGPU cores used to realize the model in software. We show experimentally that the model software implementation can intrinsically preserve its functionality in the presence of faulty hardware, without requiring any reprogramming or recompilation. This model is a first step towards developing a comprehensive and biologically plausible understanding of the computational algorithms and microarchitecture of computing systems that mimic the human cortex, and to applying them to the robust implementation of tasks on future computing systems built of faulty components."
1250716,15258,9836,Pack & Cap: adaptive DVFS and thread packing under power caps,2011,"The ability to cap peak power consumption is a desirable feature in modern data centers for energy budgeting, cost management, and efficient power delivery. Dynamic voltage and frequency scaling (DVFS) is a traditional control knob in the tradeoff between server power and performance. Multi-core processors and the parallel applications that take advantage of them introduce new possibilities for control, wherein workload threads are packed onto a variable number of cores and idle cores enter low-power sleep states. This paper proposes  Pack & Cap , a control technique designed to make optimal DVFS and thread packing control decisions in order to maximize performance within a power budget. In order to capture the workload dependence of the performance-power Pareto frontier, a multinomial logistic regression (MLR) classifier is built using a large volume of performance counter, temperature, and power characterization data. When queried during runtime, the classifier is capable of accurately selecting the optimal operating point. We implement and validate this method on a real quad-core system running the PARSEC parallel benchmark suite. When varying the power budget during runtime,  Pack & Cap  meets power constraints 82% of the time even in the absence of a power measuring device. The addition of thread packing to DVFS as a control knob increases the range of feasible power constraints by an average of 21% when compared to DVFS alone and reduces workload energy consumption by an average of 51.6% compared to existing control techniques that achieve the same power range."
1733845,15258,8306,GPUWattch: enabling energy optimizations in GPGPUs,2013,"General-purpose GPUs (GPGPUs) are becoming prevalent in mainstream computing, and performance per watt has emerged as a more crucial evaluation metric than peak performance. As such, GPU architects require robust tools that will enable them to quickly explore new ways to optimize GPGPUs for energy efficiency. We propose a new GPGPU power model that is configurable, capable of cycle-level calculations, and carefully validated against real hardware measurements. To achieve configurability, we use a bottom-up methodology and abstract parameters from the microarchitectural components as the model's inputs. We developed a rigorous suite of 80 microbenchmarks that we use to bound any modeling uncertainties and inaccuracies. The power model is comprehensively validated against measurements of two commercially available GPUs, and the measured error is within 9.9% and 13.4% for the two target GPUs (GTX 480 and Quadro FX5600). The model also accurately tracks the power consumption trend over time. We integrated the power model with the cycle-level simulator GPGPU-Sim and demonstrate the energy savings by utilizing dynamic voltage and frequency scaling (DVFS) and clock gating. Traditional DVFS reduces GPU energy consumption by 14.4% by leveraging within-kernel runtime variations. More finer-grained SM cluster-level DVFS improves the energy savings from 6.6% to 13.6% for those benchmarks that show clustered execution behavior. We also show that clock gating inactive lanes during divergence reduces dynamic power by 11.2%."
715946,15258,8306,Reducing memory access latency with asymmetric DRAM bank organizations,2013,"DRAM has been a de facto standard for main memory, and advances in process technology have led to a rapid increase in its capacity and bandwidth. In contrast, its random access latency has remained relatively stagnant, as it is still around 100 CPU clock cycles. Modern computer systems rely on caches or other latency tolerance techniques to lower the average access latency. However, not all applications have ample parallelism or locality that would help hide or reduce the latency. Moreover, applications' demands for memory space continue to grow, while the capacity gap between last-level caches and main memory is unlikely to shrink. Consequently, reducing the main-memory latency is important for application performance. Unfortunately, previous proposals have not adequately addressed this problem, as they have focused only on improving the bandwidth and capacity or reduced the latency at the cost of significant area overhead.   We propose asymmetric DRAM bank organizations to reduce the average main-memory access latency. We first analyze the access and cycle times of a modern DRAM device to identify key delay components for latency reduction. Then we reorganize a subset of DRAM banks to reduce their access and cycle times by half with low area overhead. By synergistically combining these reorganized DRAM banks with support for non-uniform bank accesses, we introduce a novel DRAM bank organization with center high-aspect-ratio mats called CHARM. Experiments on a simulated chip-multiprocessor system show that CHARM improves both the instructions per cycle and system-wide energy-delay product up to 21% and 32%, respectively, with only a 3% increase in die area."
1337935,15258,20649,Multi-Objective Local-Search Optimization using Reliability Importance Measuring,2014,"In recent years, reliability has become a major issue and objective during the design of embedded systems. Here, different techniques to increase reliability like hardware-/software-based redundancy or component hardening are applied systematically during Design Space Exploration (DSE), aiming at achieving highest reliability at lowest possible cost. Existing approaches typically solely provide reliability measures, e.g. failure rate or Mean-Time-To-Failure (MTTF), to the optimization engine, poorly guiding the search which parts of the implementation to change. As a remedy, this work proposes an efficient approach that (a) determines the importance of resources with respect to the system's reliability and (b) employs this knowledge as part of a local search to guide the optimization engine which components/design decisions to investigate. First, we propose a novel approach to derive Importance Measures (IMs) using a structural evaluation of Success Trees (STs). Since ST-based reliability analysis is already used for MTTF calculation, our approach comes at almost no overhead. Second, we enrich the global DSE with a local search. Here, we propose strategies guided by the IMs that directly change and enhance the implementation. In our experimental setup, the available measures to enhance reliability are the selection of hardening levels during resource allocation and software-based redundancy during task binding; exemplarily, the proposed local search considers the selected hardening levels. The results show that the proposed method outperforms a state-of-the-art approach regarding optimization quality, particularly in the search for highly-reliable yet affordable implementations -- at negligible runtime overhead."
854948,15258,22288,De Novo Assembly of High-Throughput Sequencing Data with Cloud Computing and New Operations on String Graphs,2012,"The next-generation sequencing technologies dramatically accelerate the throughput of DNA sequencing in a much faster rate than the growth rate of computer speed as predicted by the i§Moorei¦s Law.i¨ It is a problem even to load and run these sequencing data in memory. There is an urgent need for de novo assemblers to efficiently handle the huge amount of sequencing data using scalable commodity servers in the clouds. In this paper, we present CloudBrush, a parallel algorithm that runs on the MapReduce framework of cloud computing for de novo assembly of high-throughput sequencing data. The algorithm uses Myersi¦s bi-directed string graphs as its basis and consists of two main stages: graph construction and graph simplification. First, a vertex is defined for each non-redundant sequence read. We present a prefix-and-extend algorithm to identify overlaps between a pair of reads and to reduce transitive edges. The graph is further simplified by using conventional operations including path compression, tip removal and bubble removal. We also present a new operation, Similar Neighbour Edge Adjustment, to remove error topology structures in string graphs. Besides, we also disconnect repeat regions by revised A-statistics. The goal is to partition the string graph so that all paths in each connected subgraph correspond to similar subsequences of the underlying genome. We then traverse each connected subgraph to find a long path supported by a sufficient amount of reads to represent the subgraph. Preliminary results show that the CloudBrush assembler, compared with Contrail and Edena on the sequencing data of E. coli genomes, may yield longer contigs."
2346283,15258,23497,Relyzer: exploiting application-level fault equivalence to analyze application resiliency to transient faults,2012,"Future microprocessors need low-cost solutions for reliable operation in the presence of failure-prone devices. A promising approach is to detect hardware faults by deploying low-cost monitors of software-level symptoms of such faults. Recently, researchers have shown these mechanisms work well, but there remains a non-negligible risk that several faults may escape the symptom detectors and result in silent data corruptions (SDCs). Most prior evaluations of symptom-based detectors perform fault injection campaigns on application benchmarks, where each run simulates the impact of a fault injected at a hardware site at a certain point in the application's execution (application fault site). Since the total number of application fault sites is very large (trillions for standard benchmark suites), it is not feasible to study all possible faults. Previous work therefore typically studies a randomly selected sample of faults. Such studies do not provide any feedback on the portions of the application where faults were not injected. Some of those instructions may be vulnerable to SDCs, and identifying them could allow protecting them through other means if needed.   This paper presents Relyzer, an approach that systematically analyzes all application fault sites and carefully picks a small subset to perform selective fault injections for transient faults. Relyzer employs novel fault pruning techniques that prune faults that need detailed study by either predicting their outcomes or showing them equivalent to other faults. We find that Relyzer prunes about 99.78% of the total faults across twelve applications studied here, reducing the faults that require detailed simulation by 3 to 5 orders of magnitude for most of the applications. Fault injection simulations on the remaining faults can identify SDC causing faults in the entire application. Some of Relyzer's techniques rely on heuristics to determine fault equivalence. Our validation efforts show that Relyzer determines fault outcomes with 96% accuracy, averaged across all the applications studied here."
1223941,15258,11330,Hystor: making the best use of solid state drives in high performance storage systems,2011,"With the fast technical improvement, flash memory based Solid State Drives (SSDs) are becoming an important part of the computer storage hierarchy to significantly improve performance and energy efficiency. However, due to its relatively high price and low capacity, a major system research issue to address is on how to make SSDs play their most effective roles in a high-performance storage system in cost- and performance-effective ways.   In this paper, we will answer several related questions with insights based on the design and implementation of a high performance hybrid storage system, called  Hystor . We make the best use of SSDs in storage systems by achieving a set of optimization objectives from both system deployment and algorithm design perspectives. Hystor manages both SSDs and hard disk drives (HDDs) as one single block device with minimal changes to existing OS kernels. By monitoring I/O access patterns at runtime, Hystor can effectively identify blocks that (1) can result in long latencies or (2) are semantically critical (e.g. file system metadata), and stores them in SSDs for future accesses to achieve a significant performance improvement. In order to further leverage the exceptionally high performance of writes in the state-of-the-art SSDs, Hystor also serves as a write-back buffer to speed up write requests. Our measurements on Hystor implemented in the Linux kernel 2.6.25.8 show that it can take advantage of the performance merits of SSDs with only a few lines of changes to the stock Linux kernel. Our system study shows that in a highly effective hybrid storage system, SSDs should play a major role as an independent storage where the best suitable data are adaptively and timely migrated in and retained, and it can also be effective to serve as a write-back buffer."
1974342,15258,23497,Computational sprinting on a hardware/software testbed,2013,"CMOS scaling trends have led to an inflection point where thermal constraints (especially in mobile devices that employ only passive cooling) preclude sustained operation of all transistors on a chip --- a phenomenon called dark silicon. Recent research proposed computational sprinting --- exceeding sustainable thermal limits for short intervals --- to improve responsiveness in light of the bursty computation demands of many media-rich interactive mobile applications. Computational sprinting improves responsiveness by activating reserve cores (parallel sprinting) and/or boosting frequency/voltage (frequency sprinting) to power levels that far exceed the system's sustainable cooling capabilities, relying on thermal capacitance to buffer heat.   Prior work analyzed the feasibility of sprinting through modeling and simulation. In this work, we investigate sprinting using a hardware/software testbed. First, we study unabridged sprints, wherein the computation completes before temperature becomes critical, demonstrating a 6.3x responsiveness gain, and a 6% energy efficiency improvement by racing to idle. We then analyze truncated sprints, wherein our software runtime system must intervene to prevent overheating by throttling parallelism and frequency before the computation is complete. To avoid oversubscription penalties (context switching inefficiencies after a truncated parallel sprint), we develop a sprint-aware task-based parallel runtime. We find that maximal-intensity sprinting is not always best, introduce the concept of sprint pacing, and evaluate an adaptive policy for selecting sprint intensity. We report initial results using a phase change heat sink to extend maximum sprint duration. Finally, we demonstrate that a sprint-and-rest operating regime can actually outperform thermally-limited sustained execution."
2457428,15258,23836,Mapping Dense LU Factorization on Multicore Supercomputer Nodes,2012,"Dense LU factorization is a prominent benchmark used to rank the performance of supercomputers. Many implementations use block-cyclic distributions of matrix blocks onto a two-dimensional process grid. The process grid dimensions drive a trade-off between communication and computation and are architecture- and implementation-sensitive. The critical panel factorization steps can be made less communication-bound by overlapping asynchronous collectives for pivoting with the computation of rank-k updates. By shifting the computation-communication trade-off, a modified block-cyclic distribution can beneficially exploit more available parallelism on the critical path, and reduce panel factorization's memory hierarchy contention on now-ubiquitous multicore architectures. During active panel factorization, rank-1 updates stream through memory with minimal reuse. In a column-major process grid, the performance of this access pattern degrades as too many streaming processors contend for access to memory. A block-cyclic mapping in the row-major order does not encounter this problem, but consequently sacrifices node and network locality in the critical pivoting steps. We introduce 'striding' to vary between the two extremes of row- and column-major process grids. The maximum available parallelism in the critical path work (active panel factorization, triangular solves, and subsequent broadcasts) is bounded by the length or width of the process grid. Increasing one dimension of the process grid decreases the number of distinct processes and nodes in the other dimension. To increase the harnessed parallelism in both dimensions, we start with a tall process grid. We then apply periodic 'rotation' to this grid to restore exploited parallelism along the row to previous levels. As a test-bed for further mapping experiments, we describe a dense LU implementation that allows a block distribution to be defined as a general function of block to processor. Other mappings can be tested with only small, local changes to the code."
1846563,15258,22260,SmartDPSS: Cost-Minimizing Multi-source Power Supply for Datacenters with Arbitrary Demand,2013,"To tackle soaring power costs, significant carbon emission and unexpected power outage, Cloud Service Providers (CSPs) typically equip their Datacenters with a Power Supply System (DPSS) nurtured by multiple sources: (1) smart grid with time-varying electricity prices, (2) uninterrupted power supply (UPS), and (3) renewable energy with intermittent and uncertain supply. It remains a significant challenge how to operate among multiple power supply sources in a complementary manner, to deliver reliable energy to datacenter users with arbitrary demand over time, while minimizing a CSP's operation cost over the long run. This paper proposes an efficient, online control algorithm for DPSS, SmartDPSS, based on the two-timescale Lyapunov optimization techniques. Without requiring a priori knowledge of system statistics, SmartDPSS allows CSPs to make online decisions on how much power demand, including delay-sensitive demand and delay-tolerant demand, to serve at each time, the amount of power to purchase from the long-term-ahead and realtime grid markets, and charging and discharging of UPS over time, in order to fully leverage the available renewable energy and time-varying prices from the grid markets, for minimum operational cost. We thoroughly analyze the performance of our online control algorithm with rigorous theoretical analysis. We also demonstrate its optimality in terms of operational cost, demand service delay, datacenter availability, system robustness and scalability, using extensive simulations based on one-month worth of traces from live power systems."
1979916,15258,8306,iSwitch: coordinating and optimizing renewable energy powered server clusters,2012,"Large-scale computing systems such as data centers are facing increasing pressure to cap their carbon footprint. Integrating emerging clean energy solutions into computer system design therefore gains great significance in the green computing era. While some pioneering work on tracking variable power budget show promising energy efficiency, they are not suitable for data centers due to lack of performance guarantee when renewable generation is low and fluctuant. In addition, our characterization of wind power behavior reveals that data centers designed to track the intermittent renewable power incur up to 4X performance loss due to inefficient and redundant load matching activities. As a result, mitigating operational overhead while still maintaining desired energy utilization becomes the most significant challenge in managing server clusters on intermittent renewable energy generation. In this paper we take a first step in digging into the operational overhead of renewable energy powered data center. We propose iSwitch, a lightweight server power management that follows renewable power variation characteristics, leverages existing system infrastructures, and applies supply/load cooperative scheme to mitigate the performance overhead. Comparing with state-of-the-art renewable energy driven system design, iSwitch could mitigate average network traffic by 75%, peak network traffic by 95%, and reduce 80% job waiting time while still maintaining 96% renewable energy utilization. We expect that our work can help computer architects make informed decisions on sustainable and high-performance system design."
1330202,15258,23836,A Discussion in Favor of Dynamic Scheduling for Regular Applications in Many-core Architectures,2012,"The recent evolution of many-core architectures has resulted in chips where the number of processor elements (PEs) are in the hundreds and continue to increase every day. In addition, many-core processors are more and more frequently characterized by the diversity of their resources and the way the sharing of those resources is arbitrated. On such machines, task scheduling is of paramount importance to orchestrate a satisfactory distribution of tasks with an efficient utilization of resources, especially when fine-grain parallelism is desired or required. In the past, the primary focus of scheduling techniques has been on achieving load balancing and reducing overhead with the aim to increase total performance. This focus has resulted in a scheduling paradigm where Static Scheduling (SS) is preferred to Dynamic Scheduling (DS) for highly regular and embarrassingly parallel applications running on homogeneous architectures. We have revisited the task scheduling problem for these types of applications under the scenario imposed by many-core architectures to investigate whether or not there exists scenarios where DS is better than SS. Our main contribution is the idea that, for highly regular and embarrassingly parallel applications, DS is preferable to SS in some situations commonly found in many-core architectures. We present experimental evidence that shows how the performance of SS is degraded by the new environment on many-core chips. We analyze three reasons that contribute to the superiority of DS over SS on many-core architectures under the situations described: 1) A uniform mapping of work to processors without considering the granularity of tasks is not necessarily scalable under limited amounts of work. 2) The presence of shared resources (i.e. the crossbar switch) produces unexpected and stochastic variations on the duration of tasks that SS is unable to manage properly. 3) Hardware features, such as in-memory atomic operations, greatly contribute to decrease the overhead of DS."
2470260,15258,23497,"Looking back on the language and hardware revolutions: measured power, performance, and scaling",2011,"This paper reports and analyzes measured chip power and performance on five process technology generations executing 61 diverse benchmarks with a rigorous methodology. We measure representative Intel IA32 processors with technologies ranging from 130nm to 32nm while they execute sequential and parallel benchmarks written in native and managed languages. During this period, hardware and software changed substantially: (1) hardware vendors delivered chip multiprocessors instead of uniprocessors, and independently (2) software developers increasingly chose managed languages instead of native languages. This quantitative data reveals the extent of some known and previously unobserved hardware and software trends. Two themes emerge.   (I) Workload: The power, performance, and energy trends of native workloads do not approximate managed workloads. For example, (a) the SPEC CPU2006 native benchmarks on the i7 (45) and i5 (32) draw significantly less power than managed or scalable native benchmarks; and (b) managed runtimes exploit parallelism even when running single-threaded applications. The results recommend architects always include native and managed workloads when designing and evaluating energy efficient hardware.   (II) Architecture: Clock scaling, microarchitecture, simultaneous multithreading, and chip multiprocessors each elicit a huge variety of power, performance, and energy responses. This variety and the difficulty of obtaining power measurements recommends exposing on-chip power meters and when possible structure specific power meters for cores, caches, and other structures. Just as hardware event counters provide a quantitative grounding for performance innovations, power meters are necessary for optimizing energy."
2469869,15258,9589,FlowBender: Flow-level Adaptive Routing for Improved Latency and Throughput in Datacenter Networks,2014,"Datacenter networks provide high path diversity for traffic between machines. Load balancing traffic across these paths is important for both, latency- and throughput-sensitive applications. The standard load balancing techniques used today obliviously hash a flow to a random path. When long flows collide on the same path, this might lead to long lasting congestion while other paths could be underutilized, degrading performance of other flows as well. Recent proposals to address this shortcoming incur significant implementation complexity at the host that would actually slow down short flows (MPTCP), depend on relatively slow centralized controllers for rerouting large congesting flows (Hedera), or require custom switch hardware, hindering near-term deployment (DeTail).   We propose FlowBender, a novel technique that: (1) Load balances distributively at the granularity of flows instead of packets, avoiding excessive packet reordering. (2) Uses end-host-driven rehashing to trigger dynamic flow-to-path assignment. (3) Recovers from link failures within a Retransmit Timeout (RTO). (4) Amounts to less than 50 lines of critical kernel code and is readily deployable in commodity data centers today. (5) Is very robust and simple to tune. We evaluate FlowBender using both simulations and a real testbed implementation, and show that it improves average and tail latencies significantly compared to state of the art techniques without incurring the significant overhead and complexity of other load balancing schemes."
376832,15258,9748,The LOFAR beam former: implementation and performance analysis,2011,"Traditional radio telescopes use large, steel dishes to observe radio sources. The LOFAR radio telescope is different, and uses tens of thousands of fixed, non-movable antennas instead, a novel design that promises groundbreaking research in astronomy. The antennas observe omnidirectionally, and sky sources are observed by signal-processing techniques that combine the data from all antennas.#R##N##R##N#Another new feature of LOFAR is the elaborate use of software to do signal processing in real time, where traditional telescopes use custom-built hardware. The use of software leads to an instrument that is inherently more flexible. However, the enormous data rate (198 Gb/s of input data) and processing requirements compel the use of a supercomputer: we use an IBM Blue Gene/P.#R##N##R##N#This paper presents a collection of new processing pipelines, collectively called the beam-forming pipelines, that greatly enhance the functionality of the telescope. Where our first pipeline could only correlate data to create sky images, the new pipelines allow the discovery of unknown pulsars, observations of known pulsars, and (in the future), to observe cosmic rays and study transient events. Unlike traditional telescopes, we can observe in hundreds of directions simultaneously. This is useful, for example, to search the sky for new pulsars. The use of software allows us to quickly add new functionality and to adapt to new insights that fully exploit the novel features and the power of our unique instrument. We also describe our optimisations to use the Blue Gene/P at very high efficiencies, maximising the effectiveness of the entire telescope. A thorough performance study identifies the limits of our system."
2461275,15258,422,ThermoCast: a cyber-physical forecasting model for datacenters,2011,"Efficient thermal management is important in modern data centers as cooling consumes up to 50% of the total energy. Unlike previous work, we consider proactive thermal management, whereby servers can predict potential overheating events due to dynamics in data center configuration and workload, giving operators enough time to react. However, such forecasting is very challenging due to data center scales and complexity. Moreover, such a physical system is influenced by cyber effects, including workload scheduling in servers. We propose ThermoCast, a novel thermal forecasting model to predict the temperatures surrounding the servers in a data center, based on continuous streams of temperature and airflow measurements. Our approach is (a) capable of capturing cyberphysical interactions and automatically learning them from data; (b) computationally and physically scalable to data center scales; (c) able to provide online prediction with real-time sensor measurements. The paper's main contributions are: (i) We provide a systematic approach to integrate physical laws and sensor observations in a data center; (ii) We provide an algorithm that uses sensor data to learn the parameters of a data center's cyber-physical system. In turn, this ability enables us to reduce model complexity compared to full-fledged fluid dynamics models, while maintaining forecast accuracy; (iii) Unlike previous simulation-based studies, we perform experiments in a production data center. Using real data traces, we show that ThermoCast forecasts temperature better than a machine learning approach solely driven by data, and can successfully predict thermal alarms 4.2 minutes ahead of time."
1397206,15258,22260,Robust Dynamic Provable Data Possession,2012,"Remote Data Checking (RDC) allows clients to efficiently check the integrity of data stored at untrusted servers. This allows data owners to assess the risk of outsourcing data in the cloud, making RDC a valuable tool for data auditing. A robust RDC scheme incorporates mechanisms to mitigate arbitrary amounts of data corruption. In particular, protection against small corruptions (i.e., bytes or even bits) ensures that attacks that modify a few bits do not destroy an encrypted file or invalidate authentication information. Early RDC schemes have focused on static data, whereas later schemes such as DPDP support the full range of dynamic operations on the outsourced data, including insertions, modifications, and deletions. Robustness is required for both static and dynamic RDC schemes that rely on spot checking for efficiency. However, under an adversarial setting there is a fundamental tension between efficient dynamic updates and the encoding required to achieve robustness, because updating even a small portion of the file may require retrieving the entire file. We identify the challenges that need to be overcome when trying to add robustness to a DPDP scheme. We propose the first RDC schemes that provide robustness and, at the same time, support dynamic updates, while requiring small, constant, client storage. Our first construction is efficient in encoding, but has a high communication cost for updates. Our second construction overcomes this drawback through a combination of techniques that includes RS codes based on Cauchy matrices, decoupling the encoding for robustness from the position of symbols in the file, and reducing insert/delete operations to append/modify operations when updating the RS-encoded parity data."
2476111,15258,23836,Bursting the Cloud Data Bubble: Towards Transparent Storage Elasticity in IaaS Clouds,2014,"Storage elasticity on IaaS clouds is an important feature for data-intensive workloads: storage requirements can vary greatly during application runtime, making worst-case over-provisioning a poor choice that leads to unnecessarily tied-up storage and extra costs for the user. While the ability to adapt dynamically to storage requirements is thus attractive, how to implement it is not well understood. Current approaches simply rely on users to attach and detach virtual disks to the virtual machine (VM) instances and then manage them manually, thus greatly increasing application complexity while reducing cost efficiency. Unlike such approaches, this paper aims to provide a transparent solution that presents a unified storage space to the VM in the form of a regular POSIX file system that hides the details of attaching and detaching virtual disks by handling those actions transparently based on dynamic application requirements. The main difficulty in this context is to understand the intent of the application and regulate the available storage in order to avoid running out of space while minimizing the performance overhead of doing so. To this end, we propose a storage space prediction scheme that analyzes multiple system parameters and dynamically adapts monitoring based on the intensity of the I/O in order to get as close as possible to the real usage. We show the value of our proposal over static worst-case over-provisioning and simpler elastic schemes that rely on a reactive model to attach and detach virtual disks, using both synthetic benchmarks and real-life data-intensive applications. Our experiments demonstrate that we can reduce storage waste/cost by 30-40% with only 2-5% performance overhead."
1408202,15258,8912,Community-based resilient electricity sharing: Optimal spatial clustering,2013,"This paper extends our proposing (Yamagata and Seya 2012) concept of a community-based disaster resilient electricity sharing system (DRESS) as a complement or an alternative to the feed-in-tariff (FiT) to achieve CO 2  neutral in cities. In this system, electricity generated from widely introduced solar photovoltaic panels (PVs) is stored to the “cars not in use” in a city. In the central part of the Tokyo metropolitan area, almost half of the cars is used only on weekends and are kept parking during the weekdays. Hence, there exists a huge new potential if those cars are replaced by electric vehicles (EVs) in the future, namely they may be used as new battery storages using vehicle to grid (V2G) at a community level. This study extends our previous paper. Firstly, by using actual ground areas of buildings, we estimate PVs supply potential more accurately. The result shows that the hourly electricity surplus (PV supply minus demand) can be fully stored without waste if 27% of the parking EVs are used as battery storage at the whole city level, although there exist significant spatial differences at local district level. Secondly, based on the geographical demand-supply estimates, we check the possibility of local electricity sharing by combing high and low storage potential districts to form electricity self-sufficient resilient communities. Finally, we analyze the optimal community clustering using Moran's I index. We show that the 40%, instead of 27%, is an optimal EV electricity sharing rate, if we consider the resilience against black-out risk."
956200,15258,23749,"Cost-Efficient, Reliable, Utility-Based Session Management in the Cloud",2014,"We present a model and system for cost-efficient and reliable management of sessions in a Cloud, based on the von Neumann-Morgenstern utility theorem. Our model enables a web application provider to maximize profit while maintaining a desired quality of service. The objective is to determine whether, when, where, and how long to store a session, given multiple storage options with various properties, e.g. cost, capacity, and reliability. Reliability is affected by three factors: how often session state is stored, how many stores are used, and how reliable those stores are. To account for these factors, we use a Markovian reliability model and treat the valid storage options for each session as a von Neumann-Morgenstern lottery. We proceed by representing the resulting problem as a knapsack problem, which can be heuristically solved for a good compromise between efficiency and effectiveness. We analyze the results from a discrete-event simulation involving multiple session management policies, including two utility-based policies: a greedy heuristic policy intended to give real-time performance and a reference policy based on solving the linear programming relaxation of the knapsack problem, giving a theoretical upper bound on achievable utility. As the focus of this work is exploratory, rather than performance-based, we do not directly measure the time required for solving the model. Instead, we give the computational complexity of the algorithms. Our results indicate that otherwise unprofitable services become profitable through utility-based session management in a cloud setting. However, if the costs are much lower than the expected revenues, all policies manage to turn a profit. Different policies performed the best under different circumstances."
759286,15258,8306,SIMD divergence optimization through intra-warp compaction,2013,"SIMD execution units in GPUs are increasingly used for high performance and energy efficient acceleration of general purpose applications. However, SIMD control flow divergence effects can result in reduced execution efficiency in a class of GPGPU applications, classified as divergent applications. Improving SIMD efficiency, therefore, has the potential to bring significant performance and energy benefits to a wide range of such data parallel applications.   Recently, the SIMD divergence problem has received increased attention, and several micro-architectural techniques have been proposed to address various aspects of this problem. However, these techniques are often quite complex and, therefore, unlikely candidates for practical implementation. In this paper, we propose two micro-architectural optimizations for GPGPU architectures, which utilize relatively simple execution cycle compression techniques when certain groups of turned-off lanes exist in the instruction stream. We refer to these optimizations as basic cycle compression (BCC) and swizzled-cycle compression (SCC), respectively. In this paper, we will outline the additional requirements for implementing these optimizations in the context of the studied GPGPU architecture. Our evaluations with divergent SIMD workloads from OpenCL (GPGPU) and OpenGL (graphics) applications show that BCC and SCC reduce execution cycles in divergent applications by as much as 42% (20% on average). For a subset of divergent workloads, the execution time is reduced by an average of 7% for today's GPUs or by 18% for future GPUs with a better provisioned memory subsystem. The key contribution of our work is in simplifying the micro-architecture for delivering divergence optimizations while providing the bulk of the benefits of more complex approaches."
2428160,15258,23497,Underprovisioning backup power infrastructure for datacenters,2014,"While there has been prior work to underprovision the power distribution infrastructure for a datacenter to save costs, the ability to underprovision the backup power infrastructure, which contributes significantly to capital costs, is little explored. There are two main components in the backup infrastructure - Diesel Generators (DGs) and UPS units - which can both be underprovisioned (or even removed) in terms of their power and/or energy capacities. However, embarking on such underprovisioning mandates studying several ramifications - the resulting cost savings, the lower availability, and the performance and state loss consequences on individual applications - concurrently. This paper presents the first such study, considering cost, availability, performance and application consequences of underprovisioning the backup power infrastructure. We present a framework to quantify the cost of backup capacity that is provisioned, and implement techniques leveraging existing software and hardware mechanisms to provide as seamless an operation as possible for an application within the provisioned backup capacity during a power outage. We evaluate the cost-performance-availability trade-offs for different levels of backup underprovisioning for applications with diverse reliance on the backup infrastructure. Our results show that one may be able to completely do away with DGs, compensating for it with additional UPS energy capacities, to significantly cut costs and still be able to handle power outages lasting as high as 40 minutes (which constitute bulk of the outages). Further, we can push the limits of outage duration that can be handled in a cost-effective manner, if applications are willing to tolerate degraded performance during the outage. Our evaluations also show that different applications react differently to the outage handling mechanisms, and that the efficacy of the mechanisms is sensitive to the outage duration. The insights from this paper can spur new opportunities for future work on backup power infrastructure optimization."
1843223,15258,23836,Improving Parallel IO Performance of Cell-based AMR Cosmology Applications,2012,"To effectively model various regions with different resolutions, adaptive mesh refinement (AMR) is commonly used in cosmology simulations. There are two well-known numerical approaches towards the implementation of AMR based cosmology simulations: block-based AMR and cell-based AMR. While many studies have been conducted to improve performance and scalability of block-structured AMR applications, little work has been done for cell-based simulations. In this study, we present a parallel IO design for cell-based AMR cosmology applications, in particular, the ART(Adaptive Refinement Tree) code. First, we design a new data format that incorporates a space filling curve to map between spatial and on-disk locations. This indexing not only enables concurrent IO accesses from multiple application processes, but also allows users to extract local regions without significant additional memory, CPU or disk space overheads. Second, we develop a flexible N-M mapping mechanism to harvest the benefits of N-N and N-1 mappings where N is number of application processes and M is a user-tunable parameter for number of files. It not only overcomes the limited bandwidth issue of an N-1 mapping by allowing the creation of multiple files, but also enables users to efficiently restart the application at a variety of computing scales. Third, we develop a user-level library to transparently and automatically aggregate small IO accesses per process to accelerate IO performance. We evaluate this new parallel IO design by means of real cosmology simulations on production HPC system at TACC. Our preliminary results indicate that it can not only provide the functionality required by scientists (e.g., effective extraction of local regions and flexible process-to file mapping), but also significantly improve IO performance."
2191238,15258,9836,Citadel: Efficiently Protecting Stacked Memory from Large Granularity Failures,2014,"Stacked memory modules are likely to be tightly integrated with the processor. It is vital that these memory modules operate reliably, as memory failure can require the replacement of the entire socket. To make matters worse, stacked memory designs are susceptible to newer failure modes (for example, due to faulty through-silicon vias, or TSVs) that can cause large portions of memory, such as a bank, to become faulty. To avoid data loss from large-granularity failures, the memory system may use symbol-based codes that stripe the data for a cache line across several banks (or channels). Unfortunately, such data-striping reduces memory level parallelism causing significant slowdown and higher power consumption.   This paper proposes Citadel, a robust memory architecture that allows the memory system to retain each cache line within one bank, thus allowing high performance, lower power and efficiently protects the stacked memory from large-granularity failures. Citadel consists of three components, TSV-Swap, which can tolerate both faulty data-TSVs and faulty address-TSVs, Tri Dimensional Parity (3DP), which can tolerate column failures, row failures, and bank failures, and Dynamic Dual Granularity Sparing (DDS), which can mitigate permanent faults by dynamically sparing faulty memory regions either at a row granularity or at a bank granularity. Our evaluations with real-world data for DRAM failures show that Citadel provides performance and power similar to maintaining the entire cache line in the same bank, and yet provides 700x higher reliability than Chip Kill-like ECC codes."
1325979,15258,9856,"ICE: a passive, high-speed, state-continuity scheme",2014,"The amount of trust that can be placed in commodity computing platforms is limited by the likelihood of vulnerabilities in their huge software stacks. Protected-module architectures, such as Intel SGX, provide an interesting alternative by isolating the execution of software modules. To minimize the amount of code that provides support for the protected-module architecture, persistent storage of (confidentiality and integrity protected) states of modules can be delegated to the untrusted operating system. But precautions should be taken to ensure  state continuity : an attacker should not be able to cause a module to use stale states (a so-called  rollback attack ), and while the system is not under attack, a module should always be able to make progress, even when the system could crash or lose power at unexpected, random points in time (i.e., the system should be  crash resilient ).   Providing state-continuity support is non-trivial as many algorithms are vulnerable to attack, require on-chip non-volatile memory, wear-out existing off-chip secure non-volatile memory and/or are too slow for many applications.   We present ICE, a system and algorithm providing state-continuity guarantees to protected modules. ICE's novelty lies in the facts that (1) it does not rely on secure non-volatile storage for every state update (e.g., the slow TPM chip). (2) ICE is a passive security measure. An attacker interrupting the main power supply or any other source of power, cannot break state-continuity. (3) Benchmarks show that ICE already enables state-continuous updates almost 5x faster than writing to TPM NVRAM. With dedicated hardware, performance can be increased 2 orders of magnitude.   ICE's security properties are guaranteed by means of a machine-checked proof and a prototype implementation is evaluated on commodity hardware."
771744,15258,9748,Integrating Multi-GPU Execution in an OpenACC Compiler,2013,"GPUs have become promising computing devices in current and future computer systems due to its high performance, high energy efficiency, and low price. However, lack of high level GPU programming models hinders the wide spread of GPU applications. To resolve this issue, OpenACC is developed as the first industry standard of a directive-based GPU programming model and several implementations are now available. Although early evaluations of the OpenACC systems showed significant performance improvement with modest programming efforts, they also revealed the limitations of the systems. One of the biggest limitations is that the current OpenACC compilers do not automate the utilization of multiple GPUs. In this paper, we present an OpenACC compiler with the capability to execute single GPU OpenACC programs on multiple GPUs. By orchestrating the compiler and the runtime system, the proposed system can efficiently manage the necessary data movements among multiple GPUs memories. To enable advanced communication optimizations in the proposed system, we propose a small set of directives as extensions of OpenACC API. The directives allow programmers to express the patterns of memory accesses in the parallel loops to be offloaded. Inserting a few directives into an OpenACC program can reduce a large amount of unnecessary data movements and thus helps the proposed system drawing great performance from multi-GPU systems. We implemented and evaluated the prototype system on top of CUDA with three data parallel applications. The proposed system achieves up to 6.75x of the performance compared to OpenMP in the 1CPU with 2GPU machine, and up to 2.95x of the performance compared to OpenMP in the 2CPU with 3GPU machine. In addition, in two of the three applications, the multi-GPU OpenACC compiler outperforms the single GPU system where hand-written CUDA programs run."
1903462,15258,20349,Serval: an end-host stack for service-centric networking,2012,"Internet services run on multiple servers in different locations, serving clients that are often mobile and multihomed. This does not match well with today's network stack, designed for communication between fixed hosts with topology-dependent addresses. As a result, online service providers resort to clumsy and management-intensive work-arounds--forfeiting the scalability of hierarchical addressing to support virtual server migration, directing all client traffic through dedicated load balancers, restarting connections when hosts move, and so on.#R##N##R##N#In this paper, we revisit the design of the network stack to meet the needs of online services. The centerpiece of our Serval architecture is a new Service Access Layer (SAL) that sits above an unmodified network layer, and enables applications to communicate directly on service names. The SAL provides a clean service-level control /data plane split, enabling policy, control, and in-stack name-based routing that connects clients to services via diverse discovery techniques. By tying active sockets to the control plane, applications trigger updates to service routing state upon invoking socket calls, ensuring up-to-date service resolution. With Serval, end-points can seamlessly change network addresses, migrate flows across interfaces, or establish additional flows for efficient and uninterrupted service access. Experiments with our high-performance in-kernel prototype, and several example applications, demonstrate the value of a unified networking solution for online services."
1848835,15258,9836,Complementing user-level coarse-grain parallelism with implicit speculative parallelism,2011,"Multi-core and many-core systems are the norm in contemporary processor technology and are expected to remain so for the foreseeable future. Programs using parallel programming primitives like  PThreads  or  OpenMP  often exploit coarse-grain parallelism, because it offers a good trade-off between programming effort versus performance gain. Some parallel applications show limited or no scaling beyond a number of cores. Given the abundant number of cores expected in future many-cores, several cores would remain idle in such cases while execution performance stagnates. This paper proposes using cores that do not contribute to performance improvement for running  implicit  fine-grain  speculative  threads. In particular, we present a many-core architecture and protocol that allow applications with coarse-grain explicit parallelism to further exploit implicit speculative parallelism within each thread. Implicit speculative parallelism frees the programmer from the additional effort to explicitly partition the work into finer and properly synchronized tasks. Our results show that, for a many-core comprising of 128 cores supporting implicit speculative parallelism in clusters of 2 or 4 cores, performance improves on top of the highest scalability point by 41% on average for the 4-core cluster and by 27% on average for the 2-core cluster. These performance improvements come with an energy consumption that is close to -- and sometimes better than -- the baseline. This approach often leads to better performance and energy efficiency compared to existing alternatives such as Core Fusion and Frequency Boosting. We also investigate the tradeoffs between explicit and implicit threads as input dataset sizes vary. Finally, we present a dynamic mechanism to choose the number of explicit and implicit threads, which performs within 6% of the static oracle selection of threads."
131628,15258,20876,Building a high-performance deduplication system,2011,"Modern deduplication has become quite effective at eliminating duplicates in data, thus multiplying the effective capacity of disk-based backup systems, and enabling them as realistic tape replacements. Despite these improvements, single-node raw capacity is still mostly limited to tens or a few hundreds of terabytes, forcing users to resort to complex and costly multi-node systems, which usually only allow them to scale to singledigit petabytes. As the opportunities for deduplication efficiency optimizations become scarce, we are challenged with the task of designing deduplication systems that will effectively address the capacity, throughput, management and energy requirements of the petascale age.#R##N##R##N#In this paper we present our high-performance deduplication prototype, designed from the ground up to optimize overall single-node performance, by making the best possible use of a node's resources, and achieve three important goals: scale to large capacity, provide good deduplication efficiency, and near-raw-disk throughput. Instead of trying to improve duplicate detection algorithms, we focus on system design aspects and introduce novelmechanisms--thatwe combinewith careful implementations of known system engineering techniques. In particular, we improve single-node scalability by introducing progressive sampled indexing and grouped mark-and-sweep, and also optimize throughput by utilizing an event-driven, multi-threaded client-server interaction model. Our prototype implementation is able to scale to billions of stored objects, with high throughput, and very little or no degradation of deduplication efficiency."
994461,15258,23497,Neuromorphic processing: a new frontier in scaling computer architecture,2014,"The desire to build a computer that operates in the same manner as our brains is as old as the computer itself. Although computer engineering has made great strides in hardware performance as a result of Dennard scaling, and even great advances in 'brain like' computation, the field still struggles to move beyond sequential, analytical computing architectures. Neuromorphic systems are being developed to transcend the barriers imposed by silicon power consumption, develop new algorithms that help machines achieve cognitive behaviors, and both exploit and enable further research in neuroscience. In this talk I will discuss a system im-plementing spiking neural networks. These systems hold the promise of an architecture that is event based, broad and shallow, and thus more power efficient than conventional computing solu-tions. This new approach to computation based on modeling the brain and its simple but highly connected units presents a host of new challenges. Hardware faces tradeoffs such as density or lower power at the cost of high interconnection overhead. Consequently, software systems must face choices about new language design. Highly distributed hardware systems require complex place and route algorithms to distribute the execution of the neural network across a large number of highly interconnected processing units. Finally, the overall design, simulation and testing process has to be entirely reimagined. We discuss these issues in the context of the Zeroth processor and how this approach compares to other neuromorphic systems that are becoming available."
2415344,15258,23749,Scalable Multi-purpose Network Representation for Large Scale Distributed System Simulation,2012,"Conducting experiments in large-scale distributed systems is usually time-consuming and labor-intensive. Uncontrolled external load variation prevents to reproduce experiments and such systems are often not available to the purpose of research experiments, e.g. production or yet to deploy systems. Hence, many researchers in the area of distributed computing rely on simulation to perform their studies. However, the simulation of large-scale computing systems raises several scalability issues, in terms of speed and memory. Indeed, such systems now comprise millions of hosts interconnected through a complex network and run billions of processes. Most simulators thus trade accuracy for speed and rely on very simple and easy to implement models. However, the assumptions underlying these models are often questionable, especially when it comes to network modeling. In this paper, we show that, despite a widespread belief in the community, achieving high scalability does not necessarily require to resort to overly simple models and ignore important phenomena. We show that relying on a modular and hierarchical platform representation, while taking advantage of regularity when possible, allows us to model systems such as data and computing centers, peer-to-peer networks, grids, or clouds in a scalable way. This approach has been integrated into the open-source SimGrid simulation toolkit. We show that our solution allows us to model such systems much more accurately than other state-of-the-art simulators without trading for simulation speed. SimGrid is even sometimes orders of magnitude faster."
1599058,15258,20338,When the internet sleeps: correlating diurnal networks with external factors,2014,"As the Internet matures, policy questions loom larger in its operation. When should an ISP, city, or government invest in infrastructure? How do their policies affect use? In this work, we develop a new approach to evaluate how policies, economic conditions and technology correlates with Internet use around the world. First, we develop an adaptive and accurate approach to estimate block availability, the fraction of active IP addresses in each /24 block over short timescales (every 11 minutes). Our estimator provides a new lens to interpret data taken from existing long-term outage measurements, thus requiring no additional traffic. (If new collection was required, it would be lightweight, since on average, outage detection requires less than 20 probes per hour per /24 block; less than 1% of background radiation.) Second, we show that spectral analysis of this measure can identify diurnal usage: blocks where addresses are regularly used during part of the day and idle in other times. Finally, we analyze data for the entire responsive Internet (3.7M /24 blocks) over 35 days. These global observations show when and where the Internet sleeps---networks are mostly always-on in the US and Western Europe, and diurnal in much of Asia, South America, and Eastern Europe. ANOVA (Analysis of Variance) testing shows that diurnal networks correlate negatively with country GDP and electrical consumption, quantifying that national policies and economics relate to networks."
1230593,15258,11058,Taming the parallel effect zoo: extensible deterministic parallelism with LVish,2014,"A fundamental challenge of parallel programming is to ensure that the observable outcome of a program remains deterministic in spite of parallel execution. Language-level enforcement of determinism  is  possible, but existing deterministic-by-construction parallel programming models tend to lack features that would make them applicable to a broad range of problems. Moreover, they lack  extensibility : it is difficult to add or change language features without breaking the determinism guarantee.   The recently proposed  LVars  programming model, and the accompanying  LVish  Haskell library, took a step toward broadly-applicable guaranteed-deterministic parallel programming. The LVars model allows communication through shared  monotonic data structures  to which information can only be added, never removed, and for which the order in which information is added is not observable. LVish provides a Par monad for parallel computation that encapsulates determinism-preserving effects while allowing a more flexible form of communication between parallel tasks than previous guaranteed-deterministic models provided.   While applying LVar-based programming to real problems using LVish, we have identified and implemented three capabilities that extend its reach: inflationary updates other than least-upper-bound writes; transitive task cancellation; and parallel mutation of non-overlapping memory locations. The unifying abstraction we use to add these capabilities to LVish---without suffering added complexity or cost in the core LVish implementation, or compromising determinism---is a form of  monad transformer , extended to handle the Par monad. With our extensions, LVish provides the most broadly applicable guaranteed-deterministic parallel programming interface available to date. We demonstrate the viability of our approach both with traditional parallel benchmarks and with results from a real-world case study: a bioinformatics application that we parallelized using our extended version of LVish."
2322841,15258,23836,Algorithms for the Thermal Scheduling Problem,2013,"The energy costs for cooling a data center constitute a significant portion of the overall running costs. Thermal imbalance and hot spots that arise due to imbalanced workloads lead to significant wasted cooling effort - in order to ensure that no equipment is operating above a certain temperature, the data center may be cooled more than necessary. Therefore it is desirable to schedule the workload in a data center in a thermally aware manner, assigning jobs to machines not just based on local load of the machines, but based on the overall thermal profile of the data center. This is challenging because of the spatial cross-interference between machines, where a job assigned to a machine may impact not only that machine's temperature, but also nearby machines. Here, we continue formal analysis of the thermal scheduling problem that we initiated recently [25]. In that work, the notion of effective load of a machine which is a function of the local load on the machine as well as the load on nearby machines, was introduced, and optimal scheduling policies for a simple model (where cross-effects are restricted within a rack) were presented, under the assumption that jobs can be split among different machines. Here we consider the more realistic problem of integral assignment of jobs, and allow for cross-interference among different machines in adjacent racks in the data center. The integral assignment problem with cross-interference is NP-hard, even for a simple two machine model. We consider three different heat flow models, and give constant factor approximation algorithms for maximizing the number (or total profit) of jobs assigned in each model, without violating thermal constraints. We also consider the problem of minimizing the maximum temperature on any machine when all jobs need to be assigned, and give constant factor algorithms for this problem."
185307,15258,11330,Sparsifying Synchronization for High-Performance Shared-Memory Sparse Triangular Solver,2014,"The last decade has seen rapid growth of single-chip multiprocessors CMPs, which have been leveraging Moore's law to deliver high concurrency via increases in the number of cores and vector width. Modern CMPs execute from several hundreds to several thousands concurrent operations per second, while their memory subsystem delivers from tens to hundreds Giga-bytes per second bandwidth.#R##N##R##N#Taking advantage of these parallel resources requires highly tuned parallel implementations of key computational kernels, which form the back-bone of modern HPC. Sparse triangular solver is one such kernel and is the focus of this paper. It is widely used in several types of sparse linear solvers, and it is commonly considered challenging to parallelize and scale even on a moderate number of cores. This challenge is due to the fact that triangular solver typically has limited task-level parallelism and relies on fine-grain synchronization to exploit this parallelism, compared to data-parallel operations such as sparse matrix-vector multiplication.#R##N##R##N#This paper presents synchronization sparsification technique that significantly reduces the overhead of synchronization in sparse triangular solver and improves its scalability. We discover that a majority of task dependencies are redundant in task dependency graphs which are used to model the flow of computation in sparse triangular solver. We propose a fast and approximate sparsification algorithm, which eliminates more than 90% of these dependencies, substantially reducing synchronization overhead. As a result, on a 12-core Intel® Xeon® processor, our approach improves the performance of sparse triangular solver by 1.6x, compared to the conventional level-scheduling with barrier synchronization. This, in turn, leads to a 1.4x speedup in a pre-conditioned conjugate gradient solver."
1918918,15258,23497,A declarative language approach to device configuration,2011,"C remains the language of choice for hardware programming (device drivers, bus configuration, etc.): it is fast, allows low-level access, and is trusted by OS developers. However, the algorithms required to configure and reconfigure hardware devices and interconnects are becoming more complex and diverse, with the added burden of legacy support, quirks, and hardware bugs to work around. Even programming PCI bridges in a modern PC is a surprisingly complex problem, and is getting worse as new functionality such as hotplug appears. Existing approaches use relatively simple algorithms, hard-coded in C and closely coupled with low-level register access code, generally leading to suboptimal configurations.   We investigate the merits and drawbacks of a new approach: separating hardware configuration logic (algorithms to determine configuration parameter values) from mechanism (programming device registers). The latter we keep in C, and the former we encode in a declarative programming language with constraint-satisfaction extensions. As a test case, we have implemented full PCI configuration, resource allocation, and interrupt assignment in the Barrelfish research operating system, using a concise expression of efficient algorithms in constraint logic programming. We show that the approach is tractable, and can successfully configure a wide range of PCs with competitive runtime cost. Moreover, it requires about half the code of the C-based approach in Linux while offering considerably more functionality. Additionally it easily accommodates adaptations such as hotplug, fixed regions, and quirks."
1115116,15258,9748,Acceleration of Bilateral Filtering Algorithm for Manycore and Multicore Architectures,2012,"Bilateral filtering is an ubiquitous tool for several kinds of image processing applications. This work explores multicore and many core accelerations for the embarrassingly parallel yet compute-intensive bilateral filtering kernel. For many core architectures, we have created a novel pair-symmetric algorithm to avoid redundant calculations. For multicore architectures, we improve the algorithm by use of low-level single instruction multiple data (SIMD) parallelism across multiple threads. We propose architecture specific optimizations, such as exploiting the unique capabilities of special registers available in modern multicore architectures and the rearrangement of data access patterns as per the computations to exploit special purpose instructions. We also propose optimizations pertinent to Nvidia's Compute Unified Device Architecture (CUDA), including utilization of CUDA's implicit synchronization capability and the maximization of single-instruction-multiple-thread efficiency. We present empirical data on the performance gains we achieved over a variety of hardware architectures including Nvidia GTX 280, AMD Barcelona, AMD Shanghai, Intel Harper town, AMD Phenom, Intel Core i7 quad core, and Intel Nehalem 32 core machines. The best performance achieved was (i) 169-fold speedup by the CUDA-based implementation of our pair-symmetric algorithm running on Nvidia's GTX 280 GPU compared to the compiler-optimized sequential code on Intel Core i7, and (ii) 38-fold speedup using 16 cores of AMD Barcelona each equipped with a 4-stage vector pipeline compared to the compiler-optimized sequential code running on the same machine."
1090669,15258,21056,Effects of internet path selection on video-QoE,2011,"This paper presents large scale Internet measurements to understand and improve the effects of Internet path selection on perceived video quality. We systematically study a large number of Internet paths between popular video destinations and clients to create an empirical understanding of location, persistence and recurrence of failures. We map these failures to perceptual quality by reconstructing video clips obtained from the trace to quantify both the perceptual degradations from these failures as well as the fraction of such failures that can be recovered.   We then investigate ways to recover from QoE degradation by choosing one-hop detour paths that preserve application specific policies. We seek simple, scalable path selection strategies  without  the need for background path monitoring or apriori path knowledge of any kind. To do this, we deployed five measurement overlays: one each in the US, Europe, Asia-Pacific, and two spread across the globe. We used these to stream IP-traces of a variety of clips between source-destination pairs while probing alternate paths for an entire week. Our results indicate that a source can recover from upto 90% of the degradations by attempting to restore QoE with any five  randomly  chosen nodes in an overlay. We argue that our results are robust across datasets.   Finally, we design and implement a prototype packet forwarding module called source initiated frame restoration (SIFR). We deployed SIFR on PlanetLab nodes, and compared the performance of SIFR with the default Internet routing. We show that SIFR outperforms IP-path selection by providing higher on-screen perceptual quality."
1637115,15258,23749,Pragmatic Oriented Data Interoperability for Smart Healthcare Information Systems,2014,"Smart healthcare is a complex domain for systems#R##N#integration due to human and technical factors and#R##N#heterogeneous data sources involved. As a part of smart city, it is such a complex area where clinical functions require smartness of multi-systems collaborations for effective communications among departments, and radiology is one of the areas highly relies on intelligent information integration and communication. Therefore, it faces many challenges regarding integration and its#R##N#interoperability such as information collision, heterogeneous data sources, policy obstacles, and procedure mismanagement. The purpose of this study is to conduct an analysis of data, semantic, and pragmatic interoperability of systems integration in radiology department, and to develop a pragmatic interoperability framework for guiding the integration. We select an on-going project at a local hospital for undertaking our case study. The project is to achieve data sharing and interoperability among Radiology Information Systems (RIS), Electronic Patient Record (EPR), and Picture Archiving and Communication Systems (PACS). Qualitative data collection and analysis methods are used. The data sources consisted of documentation including publications and internal working papers, one year of#R##N#non-participant observations and 37 interviews with radiologists, clinicians, directors of IT services, referring clinicians, radiographers, receptionists and secretary. We identified four primary phases of data analysis process for the case study: requirements and barriers identification, integration approach,#R##N#interoperability measurements, and knowledge foundations.#R##N#Each phase is discussed and supported by qualitative data.#R##N#Through the analysis we also develop a pragmatic#R##N#interoperability framework that summaries the empirical#R##N#findings and proposes recommendations for guiding the#R##N#integration in the radiology context."
826146,15258,11375,Improving interrupt response time in a verifiable protected microkernel,2012,"Many real-time operating systems (RTOSes) offer very small interrupt latencies, in the order of tens or hundreds of cycles. They achieve this by making the RTOS kernel fully preemptible, permitting interrupts at almost any point in execution except for some small critical sections. One drawback of this approach is that it is difficult to reason about or formally model the kernel's behavior for verification, especially when written in a low-level language such as C.   An alternate model for an RTOS kernel is to permit interrupts at specific preemption points only. This controls the possible interleavings and enables the use of techniques such as formal verification or model checking. Although this model cannot (yet) obtain the small interrupt latencies achievable with a fully-preemptible kernel, it can still achieve worst-case latencies in the range of 10,000s to 100,000s of cycles. As modern embedded CPUs enter the 1 GHz range, such latencies become acceptable for more applications, particularly when they come with the additional benefit of simplicity and formal models. This is particularly attractive for protected multitasking microkernels, where the (inherently non-preemptible) kernel entry and exit costs dominate the latencies of many system calls.   This paper explores how to reduce the worst-case interrupt latency in a (mostly) non-preemptible protected kernel, and still maintain the ability to apply formal methods for analysis. We use the formally-verified seL4 microkernel as a case study and demonstrate that it is possible to achieve reasonable response-time guarantees. By combining short predictable interrupt latencies with formal verification, a design such as seL4's creates a compelling platform for building mixed-criticality real-time systems."
1153561,15258,9244,Interference-driven resource management for GPU-based heterogeneous clusters,2012,"GPU-based clusters are increasingly being deployed in HPC environments to accelerate a variety of scientific applications. Despite their growing popularity, the GPU devices themselves are under-utilized even for many computationally-intensive jobs. This stems from the fact that the typical GPU usage model is one in which a host processor periodically offloads computationally intensive portions of an application to the coprocessor. Since some portions of code cannot be offloaded to the GPU (for example, code performing network communication in MPI applications), this usage model results in periods of time when the GPU is idle. GPUs could be time-shared across jobs to fill these idle periods, but unlike CPU resources such as the cache, the effects of sharing the GPU are not well understood. Specifically, two jobs that time-share a single GPU will experience resource contention and interfere with each other. The resulting slow-down could lead to missed job deadlines. Current cluster managers do not support GPU-sharing, but instead dedicate GPUs to a job for the job's lifetime.   In this paper, we present a framework to predict and handle interference when two or more jobs time-share GPUs in HPC clusters. Our framework consists of an analysis model, and a dynamic interference detection and response mechanism to detect excessive interference and restart the interfering jobs on different nodes. We implement our framework in Torque, an open-source cluster manager, and using real workloads on an HPC cluster, show that interference-aware two-job colocation (although our method is applicable to colocating more than two jobs) improves GPU utilization by 25%, reduces a job's waiting time in the queue by 39% and improves job latencies by around 20%."
2202049,15258,23836,Taming of the Shrew: Modeling the Normal and Faulty Behaviour of Large-scale HPC Systems,2012,"HPC systems are complex machines that generate a huge volume of system state data called &#x00E2;events&#x00E2;. Events are generated without following a general consistent rule and different hardware and software components of such systems have different failure rates. Distinguishing between normal system behaviour and faulty situation relies on event analysis. Being able to detect quickly deviations from normality is essential for system administration and is the foundation of fault prediction. As HPC systems continue to grow in size and complexity, mining event flows become more challenging and with the upcoming 10 Pet flop systems, there is a lot of interestin this topic. Current event mining approaches do not take into consideration the specific behaviour of each type of events and as a consequence, fail to analyze them according to their characteristics. In this paper we propose a novel way of characterizing the normal and faulty behaviour of the system by using signal analysis concepts. All analysis modules create ELSA (Event Log Signal Analyzer), a toolkit that has the purpose of modelling the normal flow of each state event during a HPC system lifetime, and how it is affected when a failure hits the system. We show that these extracted models provide an accurate view of the system output, which improves the effectiveness of proactive fault tolerance algorithms. Specifically, we implemented a filtering algorithm and short-term fault prediction methodology based on the extracted model and test it against real failure traces from a large-scale system. We show that by analyzing each event according to its specific behaviour, we get a more realistic overview of the entire system."
1843930,15258,23836,Dynamic Operands Insertion for VLIW Architecture with a Reduced Bit-width Instruction Set,2012,"Performance, code size and power consumption are all primary concern in embedded systems. To this effect, VLIW architecture has proven to be useful for embedded applications with abundant instruction level parallelism. But due to the long instruction bus width it often consumes more power and memory space than necessary. One way to lessen this problem is to adopt a reduced bit-width instruction set architecture (ISA) that has a narrower instruction word length. This facilitates a more efficient hardware implementation in terms of area and power by decreasing bus-bandwidth requirements and the power dissipation associated with instruction fetches. Also earlier studies reported that it helps to reduce the code size considerably. In practice, however, it is impossible to convert a given ISA fully into an equivalent reduced bit-width one because the narrow instruction word, due to bit-width restrictions, can encode only a small subset of normal instructions in the original ISA. Consequently, existing processors provide narrow instructions in very limited cases along with severe restrictions on register accessibility. The objective of this work is to explore the possibility of complete conversion, as a case study, of an existing 32-bit VLIW ISA into a 16-bit one that supports effectively all 32-bit instructions. To this objective, we attempt to circumvent the bit-width restrictions by dynamically extending the effective instruction word length of the converted 16-bit operations. At compile time when a 32-bit operation is converted to a 16-bit word format, we compute how many bits are additionally needed to represent the whole 32-bit operation and store the bits separately in the VLIW code. Then at run time, these bits are retrieved on demand and inserted to a proper 16-bit operation to reconstruct the original 32-bit representation. According to our experiment, the code size becomes significantly smaller after the conversion to 16-bit VLIW code. Also at a slight run time cost, the machine with the 16-bit ISA consumes much less energy than the original machine."
2023600,15258,11330,Scaling up matrix computations on shared-memory manycore systems with 1000 CPU cores,2014,"While the growing number of cores per chip allows researchers to solve larger scientific and engineering problems, the parallel efficiency of the deployed parallel software starts to decrease. This unscalability problem happens to both vendor-provided and open-source software and wastes CPU cycles and energy. By expecting CPUs with hundreds of cores to be imminent, we have designed a new framework to perform matrix computations for massively many cores. Our performance analysis on manycore systems shows that the unscalability bottleneck is related to Non-Uniform Memory Access (NUMA): memory bus contention and remote memory access latency. To overcome the bottleneck, we have designed NUMA-aware tile algorithms with the help of a dynamic scheduling runtime system to minimize NUMA memory accesses. The main idea is to identify the data that is, either read a number of times or written once by a thread resident on a remote NUMA node, then utilize the runtime system to conduct data caching and movement between different NUMA nodes. Based on the experiments with QR factorizations, we demonstrate that our framework is able to achieve great scalability on a 48-core AMD Opteron system (e.g., parallel efficiency drops only 3% from one core to 48 cores). We also deploy our framework to an extreme-scale shared-memory SGI machine which has 1024 CPU cores and runs a single Linux operating system image. Our framework continues to scale well, and can outperform the vendor-optimized Intel MKL library by up to 750%."
1744861,15258,11330,An idiom-finding tool for increasing productivity of accelerators,2011,"Suppose one is considering purchase of a computer equipped with accelerators. Or suppose one has access to such a computer and is considering porting code to take advantage of the accelerators. Is there a reason to suppose the purchase cost or programmer effort will be worth it? It would be nice to able to estimate the expected improvements in advance of paying money or time. We exhibit an analytical framework and tool-set for providing such estimates: the tools first look for user-defined idioms that are patterns of computation and data access identified in advance as possibly being able to benefit from accelerator hardware. A performance model is then applied to estimate how much faster these idioms would be if they were ported and run on the accelerators, and a recommendation is made as to whether or not each idiom is worth the porting effort to put them on the accelerator and an estimate is provided of what the  overall application speedup  would be if this were done.   As a proof-of-concept we focus our investigations on Gather/Scatter (G/S) operations and means to accelerate these available on the Convey HC-1 which has a special-purpose personality for accelerating G/S. We test the methodology on two large-scale HPC applications. The idiom recognizer tool saves weeks of programmer effort compared to having the programmer examine the code visually looking for idioms; performance models save yet more time by rank-ordering the best candidates for porting; and the performance models are accurate, predicting G/S runtime speedup resulting from porting to within 10% of speedup actually achieved. The G/S hardware on the Convey sped up these operations 20x, and the overall impact on total application runtime was to improve it by as much as 21%."
2376943,15258,23836,An Ultrafast Scalable Many-Core Motif Discovery Algorithm for Multiple GPUs,2011,"The identification of genome-wide transcription factor binding sites is a fundamental and crucial problem to fully understand the transcriptional regulatory processes. However, the high computational cost of many motif discovery algorithms heavily constraints their application for large-scale datasets. The rapid growth of genomic sequences and gene transcription data further deteriorates the situation and establishes a strong requirement for time-efficient scalable motif discovery algorithms. The emergence of many-core architectures, typically CUDA-enabled GPUs, provides an opportunity to reduce the execution time by an order of magnitude without the loss of accuracy. In this paper, we present mCUDA-MEME, an ultrafast scalable many-core motif discovery algorithm for multiple GPUs based on the MEME algorithm. Our algorithm is implemented using a hybrid combination of the CUDA, OpenMP and MPI parallel programming models in order to harness the powerful compute capability of modern GPU clusters. At present, our algorithm supports OOPS and ZOOPS models, which are sufficient for most motif discovery applications. mCUDAMEME achieves significant speedups for the starting point search stage (and the overall execution) when benchmarked, using real datasets, against parallel MEME running on 32 CPU cores. Speedups of up to 1.4 (1.1) on a single GPU of a Fermi-based Tesla S2050 quad-GPU computing system and up to 10.8 (8.3) on the eight GPUs of a two Tesla S2050 system were observed. Furthermore, our algorithm shows good scalability with respect to dataset size and the number of GPUs (availability:https://sites.google.com/site/yongchaosoftware/mc uda-meme)."
2331786,15258,20774,Work-stealing for mixed-mode parallelism by deterministic team-building,2011,"We show how to extend classical work-stealing to deal with  tightly coupled data parallel tasks  that can  require  any number of threads  r  ≥ 1 for their execution, and term this extension  work-stealing with deterministic team-building . As threads become idle they attempt to join a  team of threads  designated for a task requiring  r  > 1 threads for its execution, alternatively to steal a task, requiring no central coordination. Team building and stealing are done according to a deterministic hierarchy and involve at most a logarithmic number of possibly randomized steal attempts. Threads attempting to join the team for a task requiring a large number of threads may help smaller teams while waiting for the large team to form. Once a team has been formed the threads can in close coordination execute the data parallel task. Implementation can be done with standard lock-free data structures, and takes only a single extra compare-and-swap (CAS) operation per thread to build a team. In the degenerate case where all tasks require only a single thread, the implementation coincides with a locality aware work-stealing implementation. Using a prototype C++ implementation of our extended work-stealing algorithm, a  mixed-mode parallel  Quicksort algorithm with a data parallel partitioning step has been implemented. We compare our (improved) implementation of this algorithm on top of our extended work-stealing scheduler to a standard task-parallel implementation with this scheduler, and with Intel Cilk Plus and Threading Building Blocks. In addition, we also compare to the optimized parallel MCSTL Quicksort. Results are shown for a 32-core Intel Nehalem EX system and a 16-core Sun T2+ system supporting up to 128 hardware threads. The mixed-mode parallel algorithm performs consistently better than the fork-join implementation, often significantly."
1707874,15258,10228,Adjacent channel interference in IEEE 802.11n,2012,"In this paper we analyze the adverse effects of Adjacent Channel Interference (ACI) on 802.11 with a focus on new 802.11n standard. ACI is causing problems that are related to the carrier sensing mechanism in 802.11. On the one hand, the carrier sensing is sometimes too restrictive thus preventing concurrent transmissions which leads to a variant of the exposed terminal problem. On the other hand, the carrier sensing is sometimes too optimistic thus causing packet collisions which is a form of the hidden node problem. Both problems are especially severe in multi-radio systems, where the radios are very closely spaced. Such problems already investigated in 802.11a/b/g still remain with 802.11n. Our results show that the number of available orthogonal channels in IEEE 802.11n depends on the spatial spacing between the radios, channel width (20MHz vs. 40 MHz), RF band (2.4 vs. 5GHz) and traffic pattern. In a multi-radio system the situation is worst, e.g. in the 2.4 GHz we were not able to find 2 orthogonal channels. The adverse effect of ACI can be reduced in two ways. First, by increasing the spatial separation between the radios; a spacing of less than 1 meter already improves the situation significantly, e.g. 40 cm are sufficient to get 2–3 orthogonal 20 MHz channels in the 2.4 GHz band with reduced transmission power. Furthermore, a distance of 90 cm is also sufficient so that a 40 and a 20MHz channel can be used simultaneously without any interference. However, in a multi-radio system the spatial spacing between the radios cannot be increased due to space limitations. The only option to overcome ACI related problems is to reduce the transmit power making power control essential. Finally, our analysis revealed that 802.11 is an inappropriate protocol for multi-channel MAC/routing protocols based on multi-radio systems where an explicit MAC layer link-scheduling is more promising."
923236,15258,9836,Arbitrary Modulus Indexing,2014,"Modern high performance processors require memory systems that can provide access to data at a rate that is well matched to the processor's computation rate. Common to such systems is the organization of memory into local high speed memory banks that can be accessed in parallel. Associative look up of values is made efficient through indexing instead of associative memories. These techniques lose effectiveness when data locations are not mapped uniformly to the banks or cache locations, leading to bottlenecks that arise from excess demand on a subset of locations. Address mapping is most easily performed by indexing the banks using a mod (2 N) indexing scheme, but such schemes interact poorly with the memory access patterns of many computations, making resource conflicts a significant memory system bottleneck. Previous work has assumed that prime moduli are the best choices to alleviate conflicts and has concentrated on finding efficient implementations for them. In this paper, we introduce a new scheme called Arbitrary Modulus Indexing (AMI) that can be implemented efficiently for all moduli, matching or improving the efficiency of the best existing schemes for primes while allowing great flexibility in choosing a modulus to optimize cost/performance trade-offs. We also demonstrate that, for a memory-intensive workload on a modern replay-style GPU architecture, prime moduli are not in general the best choices for memory bank and cache set mappings. Applying AMI to set of memory intensive benchmarks eliminates 98% of bank and set conflicts, resulting in an average speedup of 24% over an aggressive baseline system and a 64% average reduction in memory system replays at reasonable implementation cost."
742610,15258,9772,To cloud or not to cloud?: musings on costs and viability,2011,"In this paper we aim to understand the types of applications for which cloud computing is economically tenable, i.e., for which the cost savings associated with cloud placement outweigh any associated deployment costs.   We discover two scenarios. (i) In an unified client scenario, where the cloud-hosted applications are only accessed by a single cloud customer (or small set of associates), it is important to ensure that the cost savings (mainly computation-related) can offset the often significant client-cloud distance (network costs etc). Today, from a technological, cost-centric point of view, this includes only  compute-intensive applications with at least 1000 CPU cycles per each 32 bits of client-cloud transferred data . Naturally a number of other considerations may make clouds attractive even for less compute intensive tasks (services, security, pay-as-you-go nature etc). (ii) In a multi-client setting on the other hand, when outsourced applications serve numerous different third parties, we show that clouds begin to act similarly in nature to content-distribution networks - their better  network integration  is simply too good to pass on, when compared to locally hosting the applications (and incurring associated network costs). Thus, in multi-client scenarios, today's compute, energy and general technology costs suggest that outsourcing to clouds is profitable for almost any application.   Ultimately, we hope this work will constitute a first step in an objective evaluation of the technological side of costs of outsourcing and computing in general."
684310,15258,23836,Use of Meta-Heuristics for Design of Fuel Loading Pattern in Light Water Reactors Comprising Some Radial and Axial Heterogeneities,2011,"The third generation nuclear core should be attractive from the nuclear fuel cycle management aspect. The main goal is to achieve a good conversion of fertile isotopes into fissile isotopes while respecting safety constraints. Preliminary studies have shown the interest of the core loaded with fertile and heterogeneous fissile assemblies. The purpose of this work is to find out an optimized loading pattern and axial repartition of fissile and fertile elements in regards to the following criteria: power peak and void coefficient minimization. Due to the huge number of possible combinations, we have replaced the global optimization by two simple forms: first optimization of the fertile / fissile repartitions on an assembly in 1D representation, and secondly optimization of the core's loading pattern in 3D representation. The evaluations of the criteria have been done using the neutron physics transport solver MINOS integrated in the new lattice-core APOLLO3 code. The research algorithms used in this study are of an evolutionary algorithm, a Max Min ant system colony algorithm and a particle swarm adapted to our multi criteria approach. These algorithms are distributed using the heterogeneous island's method. A second level of parallelism has been introduced inside each island. Therefore we could increase the number of evaluations while respecting the CPU time limitation of the batch queues available. There are several solutions that stand out from the simulations. Some of them are completely original and have proved to be relevant a posteriori. This method could then be used as a decision support tool for the exploitation reactors and also for the design of new reactors."
744844,15258,23749,Controlling the Deployment of Virtual Machines on Clusters and Clouds for Scientific Computing in CBRAIN,2014,"The emergence of hardware virtualization, notably exploited by cloud infrastructures, led to a paradigm shift in distributed computing by enabling complete software customization and elastic scaling of resources. However, new software architectures and deployment algorithms are still required to fully exploit virtualization in web platforms used for scientific computing, commonly called science gateways. We propose a software architecture and an algorithm to enable and optimize the deployment of virtual machines on clusters and clouds in science gateways. Our architecture is based on 3 design principles: (i) separation between resource provisioning and task scheduling (ii) encapsulation of VMs in regular computing tasks (iii) association of a virtual computing site to each disk image. Our algorithm submits and removes VMs on clusters and clouds based on the current system workload, the number of available job slots in active VMs, the cost and current performance of clouds clusters, and a parameter quantifying the performance-cost trade-off. To cope with variable queuing and booting times, it replicates VMs on independent computing sites selected from a minimization of a make span-cost linear combination in the Pareto set of non-dominated solutions. Make span and cost are estimated from the last measured queuing, booting, and task execution times, using an exponential model of the gain yielded by VM replication. We implement this algorithm in CBRAIN, a science gateway widely used for neuroimaging, and we evaluate it on an infrastructure of 2 clusters and 1 cloud. Results show that it is able to reach some points of the performance-cost trade-off associated to VM deployment."
1856843,15258,23836,A Study of the Behavior of Synchronization Methods in Commonly Used Languages and Systems,2013,"Synchronization is a central issue in concurrency and plays an important role in the behavior and performance of modern programmes. Programming languages and hardware designers are trying to provide synchronization constructs and primitives that can handle concurrency and synchronization issues efficiently. Programmers have to find a way to select the most appropriate constructs and primitives in order to gain the desired behavior and performance under concurrency. Several parameters and factors affect the choice, through complex interactions among (i) the language and the language constructs that it supports, (ii) the system architecture, (iii) possible run-time environments, virtual machine options and memory management support and (iv) applications. We present a systematic study of synchronization strategies, focusing on concurrent data structures. We have chosen concurrent data structures with different number of contention spots. We consider both coarse-grain and fine-grain locking strategies, as well as lock-free methods. We have investigated synchronization-aware implementations in C++, C# (.NET and Mono) and Java. Considering the machine architectures, we have studied the behavior of the implementations on both Intel's Nehalem and AMD's Bulldozer. The properties that we study are throughput and fairness under different workloads and multiprogramming execution environments. For NUMA architectures fairness is becoming as important as the typically considered throughput property. To the best of our knowledge this is the first systematic and comprehensive study of synchronization-aware implementations. This paper takes steps towards capturing a number of guiding principles and concerns for the selection of the programming environment and synchronization methods in connection to the application and the system characteristics."
1217300,15258,23836,Performance Study of SIMD Programming Models on Intel Multicore Processors,2012,"Modern multicore hardware employs a variety of parallel execution units, including multiple CPU cores for executing multiple threads simultaneously, vector units such as the Intel SIMD on the CPU cores, as well as GPU-like processing arrays. Availability of such unprecedented level of parallelism on main-stream computers offers an enormous potential to enable a new generation of computation-intensive nontraditional applications. On the other hand, how to best harness the hardware parallelism presents a new challenge to application programmers, language designers and compiler developers. In this paper, we evaluate the impact of several different parallel execution models, especially the new SIMD vectorization methods, supported by the latest Intel ICC compiler (version 12.1), using three computation-intensive nontraditional parallel applications as the test workload. Unlike traditional numerical programs, these applications use highly irregular data structures and therefore present nontrivial challenges to effective use of SIMD vector units. The first application is a game engine architecture requiring real-time performance. The second application involves a kd-tree traversal, which is typical to the state-of-the-art 3D ray-tracing applications. The last application processes data for large-scale weather visualization system in the order of tens of minutes. We compare the execution time of these codes using different SIMD models supported by ICC in conjunction with parallel threading under TBB and OpenMP."
2457083,15258,9836,Kernel Partitioning of Streaming Applications: A Statistical Approach to an NP-complete Problem,2012,"One of the greatest challenges in computer architecture is how to write efficient, portable, and correct software for multi-core processors. A promising approach is to expose more parallelism to the compiler, through the use of domain-specific languages. The compiler can then perform complex transformations that the programmer would otherwise have had to do. Many important applications related to audio and video encoding, software radio and signal processing have regular behavior that can be represented using a stream programming language. When written in such a language, a portable stream program can be automatically mapped by the stream compiler onto multicore hardware. One of the most difficult tasks of the stream compiler is partitioning the stream program into software threads. The choice of partition significantly affects performance, but finding the optimal partition is an NP-complete problem. This paper presents a method, based on Extreme Value theory (EVT), that statistically estimates the performance of the optimal partition. Knowing the optimal performance improves the evaluation of any partitioning algorithm, and it is the most important piece of information when deciding whether an existing algorithm should be enhanced. We use the method to evaluate a recently-published partitioning algorithm based on a heuristic. We further analyze how the statistical method is affected by the choice of sampling method, and we recommend how sampling should be done. Finally, since a heuristic-based algorithm may not always be available, the user may try to find a good partition by picking the best from a random sample. We analyze whether this approach is likely to find a good partition. To the best of our knowledge, this study is the first application of EVT to a graph partitioning problem."
2124634,15258,23836,Using Shared Memory to Accelerate MapReduce on Graphics Processing Units,2011,"Modern General Purpose Graphics Processing Units (GPGPUs) provide high degrees of parallelism in computation and memory access, making them suitable for data parallel applications such as those using the elastic MapReduce model. Yet designing a MapReduce framework for GPUs faces significant challenges brought by their multi-level memory hierarchy. Due to the absence of atomic operations in the earlier generations of GPUs, existing GPU MapReduce frameworks have problems in handling input/output data with varied or unpredictable sizes. Also, existing frameworks utilize mostly a single level of memory, \emph{i.e.}, the relatively spacious yet slow global memory. In this work, we attempt to explore the potential benefit of enabling a GPU MapReduce framework to use multiple levels of the GPU memory hierarchy. We propose a novel GPU data staging scheme for MapReduce workloads, tailored toward the GPU memory hierarchy. Centering around the efficient utilization of the fast but very small shared memory, we designed and implemented a GPU MapReduce framework, whose key techniques include (1) shared memory staging area management, (2) thread-role partitioning, and (3) intra-block thread synchronization. We carried out evaluation with five popular MapReduce workloads and studied their performance under different GPU memory usage choices. Our results reveal that exploiting GPU shared memory is highly promising for the Map phase (with an average 2.85x speedup over using global memory only), while in the Reduce phase the benefit of using shared memory is much less pronounced, due to the high input-to-output ratio. In addition, when compared to Mars, an existing GPU MapReduce framework, our system is shown to bring a significant speedup in Map/Reduce phases."
649541,15258,9748,Efficient Inter-node MPI Communication Using GPUDirect RDMA for InfiniBand Clusters with NVIDIA GPUs,2013,"GPUs and accelerators have become ubiquitous in modern supercomputing systems. Scientific applications from a wide range of fields are being modified to take advantage of their compute power. However, data movement continues to be a critical bottleneck in harnessing the full potential of a GPU. Data in the GPU memory has to be moved into the host memory before it can be sent over the network. MPI libraries like MVAPICH2 have provided solutions to alleviate this bottleneck using techniques like pipelining. GPUDirect RDMA is a feature introduced in CUDA 5.0, that allows third party devices like network adapters to directly access data in GPU device memory, over the PCIe bus. NVIDIA has partnered with Mellanox to make this solution available for InfiniBand clusters. In this paper, we evaluate the first version of GPUDirect RDMA for InfiniBand and propose designs in MVAPICH2 MPI library to efficiently take advantage of this feature. We highlight the limitations posed by current generation architectures in effectively using GPUDirect RDMA and address these issues through novel designs in MVAPICH2. To the best of our knowledge, this is the first work to demonstrate a solution for internode GPU-to-GPU MPI communication using GPUDirect RDMA. Results show that the proposed designs improve the latency of internode GPU-to-GPU communication using MPI Send/MPI Recv by 69% and 32% for 4Byte and 128KByte messages, respectively. The designs boost the uni-directional bandwidth achieved using 4KByte and 64KByte messages by 2x and 35%, respectively. We demonstrate the impact of the proposed designs using two end-applications: LBMGPU and AWP-ODC. They improve the communication times in these applications by up to 35% and 40%, respectively."
2291187,15258,9836,Reducing memory interference in multicore systems via application-aware memory channel partitioning,2011,"Main memory is a major shared resource among cores in a multicore system. If the interference between different applications' memory requests is not controlled effectively, system performance can degrade significantly. Previous work aimed to mitigate the problem of interference between applications by changing the scheduling policy in the memory controller, i.e., by prioritizing memory requests from applications in a way that benefits system performance.   In this paper, we first present an alternative approach to reducing inter-application interference in the memory system:  application-aware memory channel partitioning (MCP) . The idea is to map the data of applications that are likely to severely interfere with each other to different memory channels. The key principles are to partition onto separate channels 1) the data of light (memory non-intensive) and heavy (memory-intensive) applications, 2) the data of applications with low and high row-buffer locality.   Second, we observe that interference can be further reduced with a combination of memory channel partitioning and scheduling, which we call  integrated memory partitioning and scheduling (IMPS) . The key idea is to 1) always prioritize very light applications in the memory scheduler since such applications cause negligible interference to others, 2) use MCP to reduce interference among the remaining applications.   We evaluate MCP and IMPS on a variety of multi-programmed workloads and system configurations and compare them to four previously proposed state-of-the-art memory scheduling policies. Averaged over 240 workloads on a 24-core system with 4 memory channels, MCP improves system throughput by 7.1% over an application-unaware memory scheduler and 1% over the previous best scheduler, while avoiding modifications to existing memory schedulers. IMPS improves system throughput by 11.1% over an application-unaware scheduler and 5% over the previous best scheduler, while incurring much lower hardware complexity than the latter."
2009161,15258,23836,iTransformer: Using SSD to Improve Disk Scheduling for High-performance I/O,2012,"The parallel data accesses inherent to large-scale data-intensive scientific computing require that data servers handle very high I/O concurrency. Concurrent requests from different processes or programs to hard disk can cause disk head thrashing between different disk regions, resulting in unacceptably low I/O performance. Current storage systems either rely on the disk scheduler at each data server, or use SSD as storage, to minimize this negative performance effect. However, the ability of the scheduler to alleviate this problem by scheduling requests in memory is limited by concerns such as long disk access times, and potential loss of dirty data with system failure. Meanwhile, SSD is too expensive to be widely used as the major storage device in the HPC environment. We propose iTransformer, a scheme that employs a small SSD to schedule requests for the data on disk. Being less space constrained than with more expensive DRAM, iTransformer can buffer larger amounts of dirty data before writing it back to the disk, or prefetch a larger volume of data in a batch into the SSD. In both cases high disk efficiency can be maintained even for concurrent requests. Furthermore, the scheme allows the scheduling of requests in the background to hide the cost of random disk access behind serving process requests. Finally, as a non-volatile memory, concerns about the quantity of dirty data are obviated. We have implemented iTransformer in the Linux kernel and tested it on a large cluster running PVFS2. Our experiments show that iTransformer can improve the I/O throughput of the cluster by 35% on average for MPI/IO benchmarks of various data access patterns."
828983,15258,9244,CMCP: a novel page replacement policy for system level hierarchical memory management on many-cores,2014,"The increasing prevalence of co-processors such as the Intel Xeon Phi, has been reshaping the high performance computing (HPC) landscape. The Xeon Phi comes with a large number of power efficient CPU cores, but at the same time, it's a highly memory constraint environment leaving the task of memory management entirely up to application developers. To reduce programming complexity, we are focusing on application transparent, operating system (OS) level hierarchical memory management.   In particular, we first show that state of the art page replacement policies, such as approximations of the least recently used (LRU) policy, are not good candidates for massive many-cores due to their inherent cost of remote translation lookaside buffer (TLB) invalidations, which are inevitable for collecting page usage statistics. The price of concurrent remote TLB invalidations grows rapidly with the number of CPU cores in many-core systems and outpace the benefits of the page replacement algorithm itself. Building upon our previous proposal, per-core Partially Separated Page Tables (PSPT), in this paper we propose Core-Map Count based Priority (CMCP) page replacement policy, which exploits the auxiliary knowledge of the number of mapping CPU cores of each page and prioritizes them accordingly. In turn, it can avoid TLB invalidations for page usage statistic purposes altogether. Additionally, we describe and provide an implementation of the experimental 64kB page support of the Intel Xeon Phi and reveal some intriguing insights regarding its performance. We evaluate our proposal on various applications and find that CMCP can outperform state of the art page replacement policies by up to 38%. We also show that the choice of appropriate page size depends primarily on the degree of memory constraint in the system."
1935215,15258,23497,Execution migration in a heterogeneous-ISA chip multiprocessor,2012,"Prior research has shown that single-ISA heterogeneous chip multiprocessors have the potential for greater performance and energy efficiency than homogeneous CMPs. However, restricting the cores to a single ISA removes an important opportunity for greater heterogeneity. To take full advantage of a heterogeneous-ISA CMP, however, we must be able to migrate execution among heterogeneous cores in order to adapt to program phase changes and changing external conditions (e.g., system power state).   This paper explores migration on heterogeneous-ISA CMPs. This is non-trivial because program state is kept in an architecture-specific form; therefore, state transformation is necessary for migration. To keep migration cost low, the amount of state that requires transformation must be minimized. This work identifies large portions of program state whose form is not critical for performance; the compiler is modified to produce programs that keep most of their state in an architecture-neutral form so that only a small number of data items must be repositioned and no pointers need to be changed. The result is low migration cost with minimal sacrifice of non-migration performance.   Additionally, this work leverages binary translation to enable instantaneous migration. When migration is requested, the program is immediately migrated to a different core where binary translation runs for a short time until a function call is reached, at which point program state is transformed and execution continues natively on the new core.   This system can tolerate migrations as often as every 100 ms and still retain 95% of the performance of a system that does not do, or support, migration."
1212660,15258,8912,Lessons Learned from the Analysis of System Failures at Petascale: The Case of Blue Waters,2014,"This paper provides an analysis of failures and their impact for Blue Waters, the Cray hybrid (CPU/GPU) supercomputer at the University of Illinois at Urbana-Champaign. The analysis is based on both manual failure reports and automatically generated event logs collected over 261 days. Results include i) a characterization of the root causes of single-node failures, ii) a direct assessment of the effectiveness of system-level fail over as well as memory, processor, network, GPU accelerator, and file system error resiliency, and iii) an analysis of system-wide outages. The major findings of this study are as follows. Hardware is not the main cause of system downtime. This is notwithstanding the fact that hardware-related failures are 42% of all failures. Failures caused by hardware were responsible for only 23% of the total repair time. These results are partially due to the fact that processor and memory protection mechanisms (x8 and x4 Chip kill, ECC, and parity) are able to handle a sustained rate of errors as high as 250 errors/h while providing a coverage of 99.997% out of a set of more than 1.5 million of analyzed errors. Only 28 multiple-bit errors bypassed the employed protection mechanisms. Software, on the other hand, was the largest contributor to the node repair hours (53%), despite being the cause of only 20% of the total number of failures. A total of 29 out of 39 system-wide outages involved the Lustre file system with 42% of them caused by the inadequacy of the automated fail over procedures."
1881649,15258,23497,Paragon: QoS-aware scheduling for heterogeneous datacenters,2013,"Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However, interference between colocated workloads and the difficulty to match applications to one of the many hardware platforms available can degrade performance, violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference, existing solutions are computationally intensive, cannot be applied online and do not scale beyond few applications.   We present Paragon, an online and scalable DC scheduler that is heterogeneity and interference-aware. Paragon is derived from robust analytical methods and instead of profiling each application in detail, it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown, incoming workload with respect to heterogeneity and interference in multiple shared resources, by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. Paragon scales to tens of thousands of servers with marginal scheduling overheads in terms of time or state.   We evaluate Paragon with a wide range of workload scenarios, on both small and large-scale systems, including 1,000 servers on EC2. For a 2,500-workload scenario, Paragon enforces performance guarantees for 91% of applications, while significantly improving utilization. In comparison, heterogeneity-oblivious, interference-oblivious and least-loaded schedulers only provide similar guarantees for 14%, 11% and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical."
1213040,15258,11157,Adaptive Set-Granular Cooperative Caching,2012,"Current Chip Multiprocessors (CMPs) consist of several cores, cache memories and interconnection networks in the same chip. Private last level cache (LLC) configurations assign a static portion of the LLC to each core. This provides lower latency and isolation, at the cost of depriving the system of the possibility of reassigning underutilized resources. A way of taking advantage of underutilized resources in other private LLCs in the same chip is to use the coherence mechanism to determine the state of those caches and spill lines to them. Also, it is well known that memory references are not uniformly distributed across the sets of a set-associative cache. Therefore, applying a uniform spilling policy to all the sets in a cache may not be the best option. This paper proposes Adaptive Set-Granular Cooperative Caching (ASCC), which measures the degree of stress of each set and performs spills between spiller and potential receiver sets, while it tackles capacity problems. Also, it adds a neutral state to prevent sets from being either spillers or receivers when it could be harmful. Furthermore, we propose Adaptive Variable-Granularity Cooperative Caching (AVGCC), which dynamically adjusts the granularity for applying these policies. Both techniques have a negligible storage overhead and can adapt to many core environments using scalable structures. AVGCC improved average performance by 7.8% and reduced average memory latency by 27% related to a traditional private LLC configuration in a 4-core CMP. Finally, we propose an extension of AVGCC to provide Quality of Service that increases the average performance gain to 8.1%."
114761,15258,20876,Composable reliability for asynchronous systems,2012,"Distributed systems designs often employ replication to solve two different kinds of availability problems. First, to prevent the loss of data through the permanent destruction or disconnection of a distributed node, and second, to allow prompt retrieval of data when some distributed nodes respond slowly. For simplicity, many systems further handle crash-restart failures and timeouts by treating them as a permanent disconnection followed by the birth of a new node, relying on peer replication rather than persistent storage to preserve data. We posit that for applications deployed in modern managed infrastructures, delays are typically transient and failed processes and machines are likely to be restarted promptly, so it is often desirable to resume crashed processes from persistent checkpoints. In this paper we present MaceKen, a synthesis of complementary techniques including Ken, a lightweight and decentralized rollback-recovery protocol that transparently masks crash-restart failures by careful handling of messages and state checkpoints; and Mace, a programming toolkit supporting development of distributed applications and application-specific availability via replication. MaceKen requires near-zero additional developer effort--systems implemented in Mace can immediately benefit from the Ken protocol by virtue of following the Mace execution model. Moreover, this model allows multiple, independently developed application components to be seamlessly composed, preserving strong global reliability guarantees. Our implementation is available as open source software."
2263678,15258,23836,A Self-tuning Failure Detection Scheme for Cloud Computing Service,2012,"Cloud computing is an increasingly important solution for providing services deployed in dynamically scalable cloud networks. Services in the cloud computing networks may be virtualized with specific servers which host abstracted details. Some of the servers are active and available, while others are busy or heavy loaded, and the remaining are offline for various reasons. Users would expect the right and available servers to complete their application requirements. Therefore, in order to provide an effective control scheme with parameter guidance for cloud resource services, failure detection is essential to meet users' service expectations. It can resolve possible performance bottlenecks in providing the virtual service for the cloud computing networks. Most existing Failure Detector (FD) schemes do not automatically adjust their detection service parameters for the dynamic network conditions, thus they couldn't be used for actual application. This paper explores FD properties with relation to the actual and automatic fault-tolerant cloud computing networks, and find a general non-manual analysis method to self-tune the corresponding parameters to satisfy user requirements. Based on this general automatic method, we propose specific and dynamic Self-tuning Failure Detector, called SFD, as a major breakthrough in the existing schemes. We carry out actual and extensive experiments to compare the quality of service performance between the SFD and several other existing FDs. Our experimental results demonstrate that our scheme can automatically adjust SFD control parameters to obtain corresponding services and satisfy user requirements, while maintaining good performance. Such an SFD can be extensively applied to industrial and commercial usage, and it can also significantly benefit the cloud computing networks."
1390373,15258,23620,A compiler and run-time system for network programming languages,2012,"Software-defined networks (SDNs) are a new kind of network architecture in which a controller machine manages a distributed collection of switches by instructing them to install or uninstall packet-forwarding rules and report traffic statistics. The recently formed Open Networking Consortium, whose members include Google, Facebook, Microsoft, Verizon, and others, hopes to use this architecture to transform the way that enterprise and data center networks are implemented.   In this paper, we define a high-level, declarative language, called NetCore, for expressing packet-forwarding policies on SDNs. NetCore is expressive, compositional, and has a formal semantics. To ensure that a majority of packets are processed efficiently on switches---instead of on the controller---we present new compilation algorithms for NetCore and couple them with a new run-time system that issues rule installation commands and traffic-statistics queries to switches. Together, the compiler and run-time system generate efficient rules whenever possible and outperform the simple, manual techniques commonly used to program SDNs today. In addition, the algorithms we develop are generic, assuming only that the packet-matching capabilities available on switches satisfy some basic algebraic laws.   Overall, this paper delivers a new design for a high-level network programming language; an improved set of compiler algorithms; a new run-time system for SDN architectures; the first formal semantics and proofs of correctness in this domain; and an implementation and evaluation that demonstrates the performance benefits over traditional manual techniques."
1898436,15258,23836,A Fast Parallel Implementation of Molecular Dynamics with the Morse Potential on a Heterogeneous Petascale Supercomputer,2012,"Molecular Dynamics (MD) simulations have been widely used in the study of macromolecules. To ensure an acceptable level of statistical accuracy relatively large number of particles are needed, which calls for high performance implementations of MD. These days heterogeneous systems, with their high performance potential, low power consumption, and high price-performance ratio, offer a viable alternative for running MD simulations. In this paper we introduce a fast parallel implementation of MD simulation with the Morse potential on Tianhe-1A, a petascale heterogeneous supercomputer. Our code achieves a speedup of 3.6$\times$ on one NVIDIA Tesla M2050 GPU (containing 14 Streaming Multiprocessors) compared to a 2.93GHz six-core Intel Xeon X5670 CPU. In addition, our code runs faster on 1024 compute nodes (with two CPUs and one GPU inside a node) than on 4096 GPU-excluded nodes, effectively rendering one GPU more efficient than six six-core CPUs. Our work shows that large-scale MD simulations can benefit enormously from GPU acceleration in petascale supercomputing platforms. Our performance results are achieved by using (1) a patch-cell design to exploit parallelism across the simulation domain, (2) a new GPU kernel developed by taking advantage of Newton's Third Law to reduce redundant force computation on GPUs, (3) two optimization methods including a dynamic load balancing strategy that adjusts the workload, and a communication overlapping method to overlap the communications between CPUs and GPUs."
1298853,15258,22260,Harmony: Dynamic Heterogeneity-Aware Resource Provisioning in the Cloud,2013,"Data centers today consume tremendous amount of energy in terms of power distribution and cooling. Dynamic capacity provisioning is a promising approach for reducing energy consumption by dynamically adjusting the number of active machines to match resource demands. However, despite extensive studies of the problem, existing solutions for dynamic capacity provisioning have not fully considered the heterogeneity of both workload and machine hardware found in production environments. In particular, production data centers often comprise several generations of machines with different capacities, capabilities and energy consumption characteristics. Meanwhile, the workloads running in these data centers typically consist of a wide variety of applications with different priorities, performance objectives and resource requirements. Failure to consider heterogenous characteristics will lead to both sub-optimal energy-savings and long scheduling delays, due to incompatibility between workload requirements and the resources offered by the provisioned machines. To address this limitation, in this paper we present HARMONY, a Heterogeneity-Aware Resource Management System for dynamic capacity provisioning in cloud computing environments. Specifically, we first use the K-means clustering algorithm to divide the workload into distinct task classes with similar characteristics in terms of resource and performance requirements. Then we present a novel technique for dynamically adjusting the number of machines of each type to minimize total energy consumption and performance penalty in terms of scheduling delay. Through simulations using real traces from Google's compute clusters, we found that our approach can improve data center energy efficiency by up to 28% compared to heterogeneity-oblivious solutions."
1727827,15258,20338,Demystifying porn 2.0: a look into a major adult video streaming website,2013,"The Internet has evolved into a huge video delivery infrastructure, with websites such as YouTube and Netflix appearing at the top of most traffic measurement studies. However, most traffic studies have largely kept silent about an area of the Internet that (even today) is poorly understood: adult media distribution. Whereas ten years ago, such services were provided primarily via peer-to-peer file sharing and bespoke websites, recently these have converged towards what is known as ``Porn 2.0''. These popular web portals allow users to upload, view, rate and comment videos for free. Despite this, we still lack even a basic understanding of how users interact with these services. This paper seeks to address this gap by performing the first large-scale measurement study of one of the most popular Porn 2.0 websites: YouPorn. We have repeatedly crawled the website to collect statistics about 183k videos, witnessing over 60 billion views. Through this, we offer the first characterisation of this type of corpus, highlighting the nature of YouPorn's repository. We also inspect the popularity of objects and how they relate to other features such as the categories to which they belong. We find evidence for a high level of flexibility in the interests of its user base, manifested in the extremely rapid decay of content popularity over time, as well as high susceptibility to browsing order. Using a small-scale user study, we validate some of our findings and explore the infrastructure design and management implications of our observations."
1726088,15258,23497,Integrated 3D-stacked server designs for increasing physical density of key-value stores,2014,"Key-value stores, such as Memcached, have been used to scale web services since the beginning of the Web 2.0 era. Data center real estate is expensive, and several industry experts we have spoken to have suggested that a significant portion of their data center space is devoted to key value stores. Despite its wide-spread use, there is little in the way of hardware specialization for increasing the efficiency and density of Memcached; it is currently deployed on commodity servers that contain high-end CPUs designed to extract as much instruction-level parallelism as possible. Out-of-order CPUs, however have been shown to be inefficient when running Memcached.   To address Memcached efficiency issues, we propose two architectures using 3D stacking to increase data storage efficiency. Our first 3D architecture, Mercury, consists of stacks of ARM Cortex-A7 cores with 4GB of DRAM, as well as NICs. Our second architecture, Iridium, replaces DRAM with NAND Flash to improve density. We explore, through simulation, the potential efficiency benefits of running Memcached on servers that use 3D-stacking to closely integrate low-power CPUs with NICs and memory. With Mercury we demonstrate that density may be improved by 2.9X, power efficiency by 4.9X, throughput by 10X, and throughput per GB by 3.5X over a state-of-the-art server running optimized Memcached. With Iridium we show that density may be increased by 14X, power efficiency by 2.4X, and throughput by 5.2X, while still meeting latency requirements for a majority of requests."
2239376,15258,8306,Vantage: scalable and efficient fine-grain cache partitioning,2011,"Cache partitioning has a wide range of uses in CMPs, from guaranteeing quality of service and controlled sharing to security-related techniques. However, existing cache partitioning schemes (such as way-partitioning) are limited to coarse-grain allocations, can only support few partitions, and reduce cache associativity, hurting performance. Hence, these techniques can only be applied to CMPs with 2-4 cores, but fail to scale to tens of cores.   We present Vantage, a novel cache partitioning technique that overcomes the limitations of existing schemes: caches can have tens of partitions with sizes specified at cache line granularity, while maintaining high associativity and strong isolation among partitions. Vantage leverages cache arrays with good hashing and associativity, which enable soft-pinning a large portion of cache lines. It enforces capacity allocations by controlling the replacement process. Unlike prior schemes, Vantage provides strict isolation guarantees by partitioning most (e.g. 90%) of the cache instead of all of it. Vantage is derived from analytical models, which allow us to provide strong guarantees and bounds on associativity and sizing independent of the number of partitions and their behaviors. It is simple to implement, requiring around 1.5% state overhead and simple changes to the cache controller.   We evaluate Vantage using extensive simulations. On a 32-core system, using 350 multiprogrammed workloads and one partition per core, partitioning the last-level cache with conventional techniques  degrades  throughput for 71% of the workloads versus an unpartitioned cache (by 7% average, 25% maximum degradation), even when using 64-way caches. In contrast, Vantage improves throughput for 98% of the workloads, by 8% on average (up to 20%), using a  4-way cache ."
2103438,15258,23836,A Predictive Model for Solving Small Linear Algebra Problems in GPU Registers,2012,"We examine the problem of solving many thousands of small dense linear algebra factorizations simultaneously on Graphics Processing Units (GPUs). We are interested in problems ranging from several hundred of rows and columns to 4 x 4 matrices. Problems of this size are common, especially in signal processing. However, they have received very little attention from current numerical linear algebra libraries for GPUs, which have thus far focused only on very large problems found in traditional supercomputing applications and benchmarks. To solve small problems efficiently we tailor our implementation to the GPUs inverted memory hierarchy and multi-level parallelism hierarchy. We provide a model of the GPU memory subsystem that can accurately predict and explain the performance of our approach across different problem sizes. As a motivating example, we look at space-time adaptive radar processing, a real-time application that requires hundreds of independent QR factorizations of small complex matrices (e.g. 240 × 66). For realistic matrix sizes from a standard radar processing benchmark, our implementation on an NVIDIA Quadro 6000 GPU runs 2.8 × to 25 × faster than Intel's Math Kernel Library (MKL) on an Intel Core i7-2600. For the QR factorizations of 5,000 56 × 56 single-precision matrices, our approach runs 29 × faster than MKL and 140 × faster than the state-of-the-art linear algebra library for GPUs. In each of these cases we are using the GPU's hardwareaccelerated division and square root functions that are accurate up to 22 mantissa bits."
1794647,15258,20774,Brief announcement: the problem based benchmark suite,2012,"This announcement describes the problem based benchmark suite (PBBS). PBBS is a set of benchmarks designed for comparing parallel algorithmic approaches, parallel programming language styles, and machine architectures across a broad set of problems. Each benchmark is defined concretely in terms of a problem specification and a set of input distributions. No requirements are made in terms of algorithmic approach, programming language, or machine architecture. The goal of the benchmarks is not only to compare runtimes, but also to be able to compare code and other aspects of an implementation (e.g., portability, robustness, determinism, and generality). As such the code for an implementation of a benchmark is as important as its runtime, and the public PBBS repository will include both code and performance results.   The benchmarks are designed to make it easy for others to try their own implementations, or to add new benchmark problems. Each benchmark problem includes the problem specification, the specification of input and output file formats, default input generators, test codes that check the correctness of the output for a given input, driver code that can be linked with implementations, a baseline sequential implementation, a baseline multicore implementation, and scripts for running timings (and checks) and outputting the results in a standard format. The current suite includes the following problems: integer sort, comparison sort, remove duplicates, dictionary, breadth first search, spanning forest, minimum spanning forest, maximal independent set, maximal matching, K-nearest neighbors, Delaunay triangulation, convex hull, suffix arrays, n-body, and ray casting. For each problem, we report the performance of our baseline multicore implementation on a 40-core machine."
415557,15258,9748,GPU-Accelerated HMM for Speech Recognition,2014,"Speech recognition is used in a wide range of applications and devices such as mobile phones, in-car entertainment systems and web-based services. Hidden Markov Models (HMMs) is one of the most popular algorithmic approaches applied in speech recognition. Training and testing a HMM is computationally intensive and time-consuming. Running multiple applications concurrently with speech recognition could overwhelm the compute resources, and introduce unwanted delays in the speech processing, eventually dropping words in the process due to buffer overruns. Graphics processing units (GPUs) have become widely accepted as accelerators which offer massive amounts of parallelism. The host processor (the CPU) can offload compute-intensive portions of an application to the GPU, leaving the CPU to focus on serial tasks and scheduling operations. In this paper, we provide a parallelized Hidden Markov Model to accelerate isolated words speech recognition. We experiment with different optimization schemes and make use of optimized GPU computing libraries to speedup the computation on GPUs. We also explore the performance benefits of using advanced GPU features for concurrent execution of multiple compute kernels. The algorithms are evaluated on multiple Nvidia GPUs using CUDA as a programming framework. Our GPU implementation achieves better performance than traditional serial and multithreaded implementations. When considering the end-to-end performance of the application, which includes both data transfer and computation, we achieve a 9x speedup for training with the use of a GPU over a multi-threaded version optimized for a multi-core CPU."
1917533,15258,9748,Java with Auto-parallelization on Graphics Coprocessing Architecture,2013,"GPU-based many-core accelerators have gained a footing in supercomputing. Their widespread adoption yet hinges on better parallelization and load scheduling techniques to utilize the hybrid system of CPU and GPU cores easily and efficiently. This paper introduces a new user-friendly compiler framework and runtime system, dubbed Japonica, to help Java applications harness the full power of a heterogeneous system. Japonica unveils an all-round system design unifying the programming style and language for transparent use of both CPU and GPU resources, automatically parallelizing all kinds of loops and scheduling workloads efficiently across the CPU-GPU border. By means of simple user annotations, sequential Java source code will be analyzed, translated and compiled into a dual executable consisting of CUDA kernels and multiple Java threads running on GPU and CPU cores respectively. Annotated loops will be automatically split into loop chunks (or tasks) being scheduled to execute on all available GPU/CPU cores. Implementing a GPU-tailored thread-level speculation (TLS) model, Japonica supports speculative execution of loops with moderate dependency densities and privatization of loops having only false dependencies on the GPU side. Our scheduler also supports task stealing and task sharing algorithms that allow swift load redistribution across GPU and CPU. Experimental results show that Japonica, on average, can run 10x, 2.5x and 2.14x faster than the best serial (1-thread CPU), GPU-alone and CPU-alone versions respectively."
2113126,15258,23497,Region scheduling: efficiently using the cache architectures via page-level affinity,2012,"The performance of modern many-core platforms strongly depends on the effectiveness of using their complex cache and memory structures. This indicates the need for a memory-centric approach to platform scheduling, in which it is the locations of memory blocks in caches rather than CPU idleness that determines where application processes are run. Using the term 'memory region' to denote the current set of physical memory pages actively used by an application, this paper presents and evaluates region-based scheduling methods for multicore platforms. This involves (i) continuously and at runtime identifying the memory regions used by executable entities, and their sizes, (ii) mapping these regions to caches to match performance goals, and (iii) maintaining region to cache mappings by ensuring that entities run on processors with direct access to the caches containing their regions. Region scheduling can implement policies that (i) offer improved performance to applications by 'unifying' the multiple caches present on the underlying physical machine and/or by 'balancing' cache usage to take maximum advantage of available cache space, (ii) better isolate applications from each other, particularly when their performance is strongly affected by cache availability, and also (iii) take advantage of standard scheduling and CPU-based load balancing when regioning is ineffective. The paper describes region scheduling and its system-level implementation and evaluates its performance with micro-benchmarks and representative multi-core applications. Single applications see performance improvements of up to 15% with region scheduling, and we observe 40% latency improvements when a platform is shared by multiple applications. Superior isolation is shown to be particularly important for cache-sensitive or real-time codes."
2426831,15258,23836,A Very Fast Simulator for Exploring the Many-Core Future,2011,"Although multi-core architectures with a large number of cores (many-cores'') are considered the future of computing systems, there are currently few practical tools to quickly explore both their design and general program scalability. In this paper, we present \emph{SiMany}, a discrete-event-based many-core simulator able to support more than a thousand cores while being orders of magnitude faster than existing flexible approaches. One of the difficult challenges for a reasonably realistic many-core simulation is to model faithfully the potentially high concurrency a program can exhibit. SiMany uses a novel virtual time synchronization technique, called \emph{spatial synchronization}, to achieve this goal in a completely \emph{local} and \emph{distributed} fashion, which diminishes interactions and preserves locality. Compared to previous simulators, it raises the level of \emph{abstraction} by focusing on modeling concurrent interactions between cores, which enables fast coarse comparisons of high-level architecture design choices and parallel programs performance. Sequential pieces of code are executed \emph{natively} for maximal speed. We exercise the simulator with a set of dwarf-like task-based benchmarks with dynamic control flow and irregular data structures. Scalability results are validated through comparison with a cycle-level simulator up to 64 cores. They are also shown consistent with well-known benchmark characteristics. We finally demonstrate how SiMany can be used to efficiently compare the benchmarks' behavior over a wide range of architectural organizations, such as polymorphic architectures and network of clusters."
1727550,15258,8806,An I/O scheduler based on fine-grained access patterns to improve SSD performance and lifespan,2014,"Although the many benefits delivered by Solid State Disks (SSDs), they also pose some unique and serious challenges to I/O and file system designers. Unlike HDDs and other memory devices, SSDs cannot perform in-place updates. A block has to be erased before it can be re-written. Moreover, the costs of different SSD operations are highly asymmetric. A write operation in an SSD is an order of magnitude slower than a read operation, and an erase operation is in turn an order of magnitude slower than a write. Moreover, a block can endure only a limited number of erasures before it wears out.   Most SSDs employ a log-structured Flash-Translation-Layer (FTL) to solve the not-in-place update problem. The unique operations of the FTLs, together with the asymmetric overheads of different operations, imply that many traditional solutions optimized for HDDs do not work well for SSDs. For example, sequential writes that are not perfectly aligned to the flash block boundary, may reduce performance and increase wearing overhead.   In this paper, we proposed a novel I/O scheduler which is based on fine-grained access patterns in a per-process per-stream manner. These patterns are used to guide a set of novel scheduling policies, including  pre-alignment, inner-padding, write merging, merging-and-splitting , to improve the write performance of SSDs that adopt log-structured FTLs. Simulation results show that these policies can improve write performance by up to 60%. Moreover, the schemes reduce SSD erasure cycle by up to 64%, which is directly translated to a major improvement on the lifespan of SSDs."
1122505,15258,11330,Automatic SIMD vectorization of fast fourier transforms for the larrabee and AVX instruction sets,2011,"The well-known shift to parallelism in CPUs is often associated with multicores. However another trend is equally salient: the increasing parallelism in per-core single-instruction multiple-date (SIMD) vector units. Intel's SSE and IBM's VMX (compatible to AltiVec) both offer 4-way (single precision) floating point, but the recent Intel instruction sets AVX and Larrabee (LRB) offer 8-way and 16-way, respectively. Compilation and optimization for vector extensions is hard, and often the achievable speed-up by using vectorizing compilers is small compared to hand-optimization using intrinsic function interfaces. Unfortunately, the complexity of these intrinsics interfaces increases considerably with the vector length, making hand-optimization a nightmare. In this paper, we present a peephole-based vectorization system that takes as input the vector instruction semantics and outputs a library of basic data reorganization blocks such as small transpositions and perfect shuffles that are needed in a variety of high performance computing applications. We evaluate the system by generating the blocks needed by the program generator Spiral for vectorized fast Fourier transforms (FFTs). With the generated FFTs we achieve a vectorization speed-up of 5.5--6.5 for 8-way AVX and 10--12.5 for 16-way LRB. For the latter instruction counts are used since no timing information is available. The combination of the proposed system and Spiral thus automates the production of high performance FFTs for current and future vector architectures."
2560936,15258,9244,Enhancement of Xen's scheduler for MapReduce workloads,2011,"As the trends move towards data outsourcing and cloud computing, the efficiency of distributed data centers increases in importance. Cloud-based services such as Amazon's EC2 rely on virtual machines (VMs) to host MapReduce clusters for large data processing. However, current VM scheduling does not provide adequate support for MapReduce workloads, resulting in degraded overall performance. For example, when multiple MapReduce clusters run on a single physical machine, the existing VMMscheduler does not guarantee fairness across clusters.   In this work, we present theMapReduce Group Scheduler (MRG). The MRG scheduler implements three mechanisms to improve the efficiency and fairness of the existing VMM scheduler. First, the characteristics of MapReduce workloads facilitate batching of I/O requests from VMs working on the same job, which reduces the number of context switches and brings other benefits. Second, because most MapReduce workloads incur a significant amount of I/O blocking events and the completion of a job depends on the progress of all nodes, we propose a two-level scheduling policy to achieve proportional fair sharing across both MapReduce clusters and individual VMs. Finally, the proposed MRG scheduler also operates on symmetric multi-processor (SMP) enabled platforms. The key to these improvements is to group the scheduling of VMs belonging to the same MapReduce cluster.   We have implemented the proposed scheduler by modifying the existing Xen hypervisor and evaluated the performance on Hadoop, an open source implementation of MapReduce. Our evaluations, using four representative MapReduce benchmarks, show that the proposed scheduler reduces context switch overhead and achieves increased proportional fairness across multiple MapReduce clusters, without penalizing the completion time of MapReduce jobs."
1645456,15258,9748,Efficient Routing Mechanisms for Dragonfly Networks,2013,"High-radix hierarchical networks are cost-effective topologies for large scale computers. In such networks, routers are organized in super nodes, with local and global interconnections. These networks, known as Dragonflies, outperform traditional topologies such as multi-trees or tori, in cost and scalability. However, depending on the traffic pattern, network congestion can lead to degraded performance. Misrouting (non-minimal routing) can be employed to avoid saturated global or local links. Nevertheless, with the current deadlock avoidance mechanisms used for these networks, supporting misrouting implies routers with a larger number of virtual channels. This exacerbates the buffer memory requirements that constitute one of the main constraints in high-radix switches. In this paper we introduce two novel deadlock-free routing mechanisms for Dragonfly networks that support on-the-fly adaptive routing. Using these schemes both global and local misrouting are allowed employing the same number of virtual channels as in previous proposals. Opportunistic Local Misrouting obtains the best performance by providing the highest routing freedom, and relying on a deadlock-free escape path to the destination for every packet. However, it requires Virtual Cut-Through flow-control. By contrast, Restricted Local Misrouting prevents the appearance of cycles thanks to a restriction of the possible routes within super nodes. This makes this mechanism suitable for both Virtual Cut-Through and Wormhole networks. Evaluations show that the proposed deadlock-free routing mechanisms prevent the most frequent pathological issues of Dragonfly networks. As a result, they provide higher performance than previous schemes, while requiring the same area devoted to router buffers."
2501124,15258,9836,RowClone: fast and energy-efficient in-DRAM bulk data copy and initialization,2013,"Several system-level operations trigger bulk data copy or initialization. Even though these bulk data operations do not require any computation, current systems transfer a large quantity of data back and forth on the memory channel to perform such operations. As a result, bulk data operations consume high latency, bandwidth, and energy--degrading both system performance and energy efficiency.   In this work, we propose  RowClone , a new and simple mechanism to perform bulk copy and initialization completely within DRAM -- eliminating the need to transfer any data over the memory channel to perform such operations. Our key observation is that DRAM can internally and efficiently transfer a large quantity of data (multiple KBs) between a row of DRAM cells and the associated row buffer. Based on this, our primary mechanism can quickly copy an entire row of data from a source row to a destination row by first copying the data from the source row to the row buffer and then from the row buffer to the destination row, via two back-to-back  activate  commands. This mechanism, which we call the Fast Parallel Mode of RowClone, reduces the latency and energy consumption of a 4KB bulk copy operation by 11.6x and 74.4x, respectively, and a 4KB bulk zeroing operation by 6.0x and 41.5x, respectively. To efficiently copy data between rows that do not share a row buffer, we propose a second mode of RowClone, the Pipelined Serial Mode, which uses the shared internal bus of a DRAM chip to quickly copy data between two banks. RowClone requires only a 0.01% increase in DRAM chip area.   We quantitatively evaluate the benefits of RowClone by focusing on fork, one of the frequently invoked system calls, and five other copy and initialization intensive applications. Our results show that RowClone can significantly improve both single-core and multi-core system performance, while also significantly reducing main memory bandwidth and energy consumption."
1899004,15258,9748,Probabilistic Best-Fit Multi-dimensional Range Query in Self-Organizing Cloud,2011,"With virtual machine (VM) technology being increasingly mature, computing resources in modern Cloud systems can be partitioned in fine granularity and allocated on demand with pay-as-you-go model. In this work, we study the resource query and allocation problems in a Self-Organizing Cloud (SOC), where host machines are connected by a peer-to-peer (P2P) overlay network on the Internet. To run a user task in SOC, the requester needs to perform a multi-dimensional range search over the P2P network for locating host machines that satisfy its minimal demand on each type of resources. The multi-dimensional range search problem is known to be challenging as contentions along multiple dimensions could happen in the presence of the uncoordinated analogous queries. Moreover, low resource matching rate may happen while restricting query delay and network traffic. We design a novel resource discovery protocol, namely Proactive Index Diffusion CAN (PID-CAN), which can proactively diffuse resource indexes over the nodes and randomly route query messages among them. Such a protocol is especially suitable for the range query that needs to maximize its best-fit resource shares under possible competition along multiple resource dimensions. Via simulation, we show that PID-CAN could keep stable and optimized searching performance with low query delay and traffic overhead, for various test cases under different distributions of query ranges and competition degrees. It also performs satisfactorily in dynamic node-churning situation."
503888,15258,9748,Analyzing Put/Get APIs for Thread-Collaborative Processors,2014,"In High-Performance Computing (HPC), GPU-based accelerators are pervasive for two reasons: first, GPUs provide a much higher raw computational power than traditional CPUs. Second, power consumption increases sub-linearly with the performance increase, making GPUs much more energy-efficient in terms of GFLOPS/Watt than CPUs. Although these advantages are limited to a selected set of workloads, most HPC applications can benefit a lot from GPUs. The top 11 entries of the current Green500 list (November 2013) are all GPU-accelerated systems, which supports the previous statements. For system architects the use of GPUs is challenging though, as their architecture is based on thread-collaborative execution and differs significantly from CPUs, which are mainly optimized for single-thread performance. The interfaces to other devices in a system, in particular the network device, are still solely optimized for CPUs. This makes GPU-controlled IO a challenge, although it is desirable for savings in terms of energy and time. This is especially true for network devices, which are a key component in HPC systems. In previous work we have shown that GPUs can directly source and sink network traffic for Infiniband devices without any involvement of the host CPUs, but this approach does not provide any performance benefits. Here we explore another API for Put/Get operations that can overcome some limitations. In particular, we provide a detailed reasoning about the issues that prevent performance advantages when directly controlling IO from the GPU domain."
1424330,15258,9836,"Linearly compressed pages: a low-complexity, low-latency main memory compression framework",2013,"Data compression is a promising approach for meeting the increasing memory capacity demands expected in future systems. Unfortunately, existing compression algorithms do not translate well when directly applied to main memory because they require the memory controller to perform non-trivial computation to locate a cache line within a compressed memory page, thereby increasing access latency and degrading system performance. Prior proposals for addressing this performance degradation problem are either costly or energy inefficient.   By leveraging the key insight that all cache lines within a page should be compressed to the same size, this paper proposes a new approach to main memory compression-- Linearly Compressed Pages  (LCP)--that avoids the performance degradation problem without requiring costly or energy-inefficient hardware. We show that any compression algorithm can be adapted to fit the requirements of LCP, and we specifically adapt two previously-proposed compression algorithms to LCP: Frequent Pattern Compression and Base-Delta-Immediate Compression.   Evaluations using benchmarks from SPEC CPU2006 and five server benchmarks show that our approach can significantly increase the effective memory capacity (by 69% on average). In addition to the capacity gains, we evaluate the benefit of transferring consecutive compressed cache lines between the memory controller and main memory. Our new mechanism considerably reduces the memory bandwidth requirements of most of the evaluated benchmarks (by 24% on average), and improves overall performance (by 6.1%/13.9%/10.7% for single-/two-/four-core workloads on average) compared to a baseline system that does not employ main memory compression. LCP also decreases energy consumed by the main memory subsystem (by 9.5% on average over the best prior mechanism)."
825647,15258,20338,Internet nameserver IPv4 and IPv6 address relationships,2013,"The modern Domain Name System (DNS) provides not only resolution, but also enables intelligent client routing, e.g. for Content Distribution Networks (CDNs). The adoption of IPv6 presents CDNs the opportunity to utilize different paths when optimizing traffic, and the challenge of appropriately mapping IPv6 DNS queries. This work seeks to discover the associations between Internet DNS client resolver IPv6 address(es) and IPv4 address(es). We design and implement two new techniques, one passive and one active, to gather resolver pairings. The passive technique, deployed in Akamai's production DNS infrastructure, opportunistically discovered 674k (IPv4, IPv6) associated address pairs within a six-month period. We find that 34% of addresses are one-to-one, i.e. appear in no other pair, a fraction that increases to ~50% when aggregating IPv6 addresses into /64 prefixes. The one-to-one associations are suggestive, but not a sufficient condition, of dual-stack DNS recursive resolvers. We further substantiate our inferences via PTR records and software versions, and manual verification of sample pairings by three major Network Operators. Complex associations, where e.g. distributed DNS resolution leads to inferred address groupings that span continents and many autonomous systems exist, a subset of which we explore in more depth using the active probing technique. Among potential uses, Akamai is currently utilizing screened output from the passive technique, in conjunction with prior knowledge of IPv4, to inform IPv6 geolocation within its CDN."
714498,15258,9836,"Profiling Data-Dependence to Assist Parallelization: Framework, Scope, and Optimization",2012,"This paper describes a tool using one or more executions of a sequential program to detect parallel portions of the program. The tool, called Par wiz, uses dynamic binary instrumentation, targets various forms of parallelism, and suggests distinct parallelization actions, ranging from simple directive tagging to elaborate loop transformations. The first part of the paper details the link between the program's static structures (like routines and loops), the memory accesses performed by the program, and the dependencies that are used to highlight potential parallelism. This part also describes the instrumentation involved, and the general architecture of the system. The second part of the paper puts the framework into action. The first study focuses on loop parallelism, targeting OpenMP parallel-for directives, including privatization when necessary. The second study is an adaptation of a well-known vectorization technique based on a slightly richer dependence description, where the tool suggests an elaborate loop transformation. The third study views loops as a graph of (hopefully lightly) dependent iterations. The third part of the paper explains how the overall cost of data-dependence profiling can be reduced. This cost has two major causes: first, instrumenting memory accesses slows down the program, and second, turning memory accesses into dependence graphs consumes processing time. Par wiz uses static analysis of the original (binary) program to provide data at a coarser level, moving from individual accesses to complete loops whenever possible, thereby reducing the impact of both sources of inefficiency."
2490658,15258,8306,Benefits and limitations of tapping into stored energy for datacenters,2011,"Datacenter power consumption has a significant impact on both its recurring electricity bill (Op-ex) and one-time construction costs (Cap-ex). Existing work optimizing these costs has relied primarily on throttling devices or workload shaping, both with performance degrading implications. In this paper, we present a novel knob of energy buffer (eBuff) available in the form of UPS batteries in datacenters for this cost optimization. Intuitively, eBuff stores energy in UPS batteries during valleys - periods of lower demand, which can be drained during peaks - periods of higher demand. UPS batteries are normally used as a fail-over mechanism to transition to captive power sources upon utility failure. Furthermore, frequent discharges can cause UPS batteries to fail prematurely. We conduct detailed analysis of battery operation to figure out feasible operating regions given such battery lifetime and datacenter availability concerns. Using insights learned from this analysis, we develop peak reduction algorithms that combine the UPS battery knob with existing throttling based techniques for minimizing datacenter power costs. Using an experimental platform, we offer insights about Op-ex savings offered by eBuff for a wide range of workload peaks/valleys, UPS provisioning, and application SLA constraints. We find that eBuff can be used to realize 15-45% peak power reduction, corresponding to 6-18% savings in Op-ex across this spectrum. eBuff can also play a role in reducing Cap-ex costs by allowing tighter overbooking of power infrastructure components and we quantify the extent of such Cap-ex savings. To our knowledge, this is the first paper to exploit stored energy - typically lying untapped in the datacenter - to address the peak power draw problem."
2492474,15258,23497,Whole-system persistence,2012,"Today's databases and key-value stores commonly keep all their data in main memory. A single server can have over 100 GB of memory, and a cluster of such servers can have 10s to 100s of TB. However, a storage back end is still required for recovery from failures. Recovery can last for minutes for a single server or hours for a whole cluster, causing heavy load on the back end. Non-volatile main memory (NVRAM) technologies can help by allowing near-instantaneous recovery of in-memory state. However, today's software does not support this well. Block-based approaches such as persistent buffer caches suffer from data duplication and block transfer overheads. Recently, user-level persistent heaps have been shown to have much better performance than these. However they require substantial application modification and still have significant runtime overheads. This paper proposes whole-system persistence (WSP) as an alternative. WSP is aimed at systems where all memory is non-volatile. It transparently recovers an application's entire state, making a failure appear as a suspend/resume event. Runtime overheads are eliminated by using flush on fail: transient state in processor registers and caches is flushed to NVRAM only on failure, using the residual energy from the system power supply. Our evaluation shows that this approach has 1.6--13 times better runtime performance than a persistent heap, and that flush-on-fail can complete safely within 2--35\% of the residual energy window provided by standard power supplies."
2595730,15258,23836,GLocks: Efficient Support for Highly-Contended Locks in Many-Core CMPs,2011,"Synchronization is of paramount importance to exploit thread-level parallelism on many-core CMPs. In these architectures, synchronization mechanisms usually rely on shared variables to coordinate multithreaded access to shared data structures thus avoiding data dependency conflicts. Lock synchronization is known to be a key limitation to performance and scalability. On the one hand, lock acquisition through busy waiting on shared variables generates additional coherence activity which interferes with applications. On the other hand, lock contention causes serialization which results in performance degradation. This paper proposes and evaluates \textit{GLocks}, a hardware-supported implementation for highly-contended locks in the context of many-core CMPs. \textit{GLocks} use a token-based message-passing protocol over a dedicated network built on state-of-the-art technology. This approach skips the memory hierarchy to provide a non-intrusive, extremely efficient and fair lock implementation with negligible impact on energy consumption or die area. A comprehensive comparison against the most efficient shared-memory-based lock implementation for a set of micro benchmarks and real applications quantifies the goodness of \textit{GLocks}. Performance results show an average reduction of 42% and 14% in execution time, an average reduction of 76% and 23% in network traffic, and also an average reduction of 78% and 28% in energy-delay$^2$ product (ED$^2$P) metric for the full CMP for the micro benchmarks and the real applications, respectively. In light of our performance results, we can conclude that \textit{GLocks} satisfy our initial working hypothesis. \textit{GLocks} minimize cache-coherence network traffic due to lock synchronization which translates into reduced power consumption and execution time."
1230777,15258,8912,Characterizing Application Memory Error Vulnerability to Optimize Datacenter Cost via Heterogeneous-Reliability Memory,2014,"Memory devices represent a key component of datacenter total cost of ownership (TCO), and techniques used to reduce errors that occur on these devices increase this cost. Existing approaches to providing reliability for memory devices pessimistically treat all data as equally vulnerable to memory errors. Our key insight is that there exists a diverse spectrum of tolerance to memory errors in new data-intensive applications, and that traditional one-size-fits-all memory reliability techniques are inefficient in terms of cost. For example, we found that while traditional error protection increases memory system cost by 12.5%, some applications can achieve 99.00% availability on a single server with a large number of memory errors without any error protection. This presents an opportunity to greatly reduce server hardware cost by provisioning the right amount of memory reliability for different applications. Toward this end, in this paper, we make three main contributions to enable highly-reliable servers at low datacenter cost. First, we develop a new methodology to quantify the tolerance of applications to memory errors. Second, using our methodology, we perform a case study of three new dataintensive workloads (an interactive web search application, an in-memory key -- value store, and a graph mining framework) to identify new insights into the nature of application memory error vulnerability. Third, based on our insights, we propose several new hardware/software heterogeneous-reliability memory system designs to lower datacenter cost while achieving high reliability and discuss their trade-o s. We show that our new techniques can reduce server hardware cost by 4.7% while achieving 99.90% single server availability."
2056170,15258,22260,Delay-Cognizant Reliable Delivery for Publish/Subscribe Overlay Networks,2011,"The number of real-world applications that require QoS guarantees is constantly increasing and they often follow the publish/subscribe (pub/sub)messaging paradigm, which provides loosely coupled many-to-many communication. Many QoS-aware systems use overlay networks as they allow flexible routing. To provide QoS-aware pub/sub messaging in overlay networks, the messaging system should be adaptive to the changes in network conditions (such as delay and failures). However, many pub/sub systems depend on a flexed routing topology and it is costly to rebuild this topology in case of failures. This study seeks to address this challenge with Delay-Cognizant Reliable Delivery (DCRD), a novel and delay-aware dynamic routing algorithm to provide reliable message delivery for pub/sub overlay networks. For reliable message delivery, DCRD no longer uses a flxed routing topology. Instead, it dynamically switches among different links to bypass link failures and increase the chance to meet QoS requirement. Each node tries different neighboring nodes in an order that is mathematically proven to minimize the expected delay of packet delivery. With all possible neighboring nodes sorted this way, DCRD guarantees that packets are delivered as long as there exists a path between the publisher and subscriber and that the expected delay is minimized. DCRD is extensively evaluated in simulation with comparison to existing tree-based routing approaches as well as a multi path approach using different network topologies, delay constraints, and loss probabilities. Simulation results show that DCRD performs better than all the baselines, providing reliable message delivery and satisfying the delay requirement for more than 98% of messages when the link failure probability is 4% or less."
1900093,15258,23836,PGAS for Distributed Numerical Python Targeting Multi-core Clusters,2012,"In this paper we propose a parallel programming model that combines two well-known execution models: Single Instruction, Multiple Data (SIMD) and Single Program, Multiple Data (SPMD). The combined model supports SIMD-style data parallelism in global address space and supports SPMD-style task parallelism in local address space. One of the most important features in the combined model is that data communication is expressed by global data assignments instead of message passing. We implement this combined programming model into Python, making parallel programming with Python both highly productive and performing on distributed memory multi-core systems. We base the SIMD data parallelism on DistNumPy, an auto-parallel zing version of the Numerical Python (NumPy) package that allows sequential NumPy programs to run on distributed memory architectures. We implement the SPMD task parallelism as an extension to DistNumPy that enables each process to have direct access to the local part of a shared array. To harvest the multi-core benefits in modern processors we exploit multi-threading in both SIMD and SPMD execution models. The multi-threading is completely transparent to the user -- it is implemented in the runtime with Open MP and by using multi-threaded libraries when available. We evaluate the implementation of the combined programming model with several scientific computing benchmarks using two representative multi-core distributed memory systems -- an Intel Nehalem cluster with Infini band interconnects and a Cray XE-6 supercomputer -- up to 1536 cores. The benchmarking results demonstrate scalable good performance."
1776077,15258,8306,The yin and yang of power and performance for asymmetric hardware and managed software,2012,"On the  hardware  side, asymmetric multicore processors present software with the challenge and opportunity of optimizing in two dimensions: performance and power. Asymmetric multicore processors (AMP) combine general-purpose  big  (fast, high power) cores and  small  (slow, low power) cores to meet power constraints. Realizing their energy efficiency opportunity requires workloads with differentiated performance and power characteristics.   On the software side, managed workloads written in languages such as C#, Java, JavaScript, and PHP are ubiquitous. Managed languages abstract over hardware using Virtual Machine (VM) services (garbage collection, interpretation, and/or just-in-time compilation) that together impose substantial energy and performance costs, ranging from 10% to over 80%. We show that these services manifest a differentiated performance and power workload. To differing degrees, they are parallel, asynchronous, communicate infrequently, and are not on the application?s critical path.   We identify a synergy between AMP and VM services that we exploit to attack the 40% average energy overhead due to VM services. Using measurements and very conservative models, we show that adding small cores tailored for VM services should deliver, at least, improvements in performance of 13%, energy of 7%, and performance per energy of 22%. The  yin  of VM services is overhead, but it meets the  yang  of small cores on an AMP. The  yin  of AMP is exposed hardware complexity, but it meets the  yang  of abstraction in managed languages. VM services fulfill the AMP requirement for an asynchronous, non-critical, differentiated, parallel, and ubiquitous workload to deliver energy efficiency. Generalizing this approach beyond system software to applications will require substantially more software and hardware investment, but these results show the potential energy efficiency gains are significant."
2196677,15258,23836,Managing Asynchronous Operations in Coarray Fortran 2.0,2013,"As the gap between processor speed and network latency continues to increase, avoiding exposed communication latency is critical for high performance on modern supercomputers. One can hide communication latency by overlapping it with computation using non-blocking data transfers, or avoid exposing communication latency by moving computation to the location of data it manipulates. Coarray Fortran 2.0 (CAF 2.0) - a partitioned global address space language - provides a rich set of asynchronous operations for avoiding exposed latency including asynchronous copies, function shipping, and asynchronous collectives. CAF 2.0 provides event variables to manage completion of asynchronous operations that use explicit completion. This paper describes CAF 2.0's finish and cofence synchronization constructs, which enable one to manage implicit completion of asynchronous operations. finish ensures global completion of a set of asynchronous operations across the members of a team. Because of CAF 2.0's SPMD model, its semantics and implementation of finish differ significantly from those of finish in X10 and HabaneroC. cofence controls local data completion of implicitlysynchronized asynchronous operations. Together these constructs provide the ability to tune a program's performance by exploiting the difference between local data completion, local operation completion, and global completion of asynchronous operations, while hiding network latency. We explore subtle interactions between cofence, finish, events, asynchronous copies and collectives, and function shipping. We justify their presence in a relaxed memory model for CAF 2.0. We demonstrate the utility of these constructs in the context of two benchmarks: Unbalanced Tree Search (UTS), and HPC Challenge RandomAccess. We achieve 74%-77% parallel efficiency for 4K-32K cores for UTS using the T1WL spec, which demonstrates scalable performance using our synchronization constructs. Our cofence micro-benchmark shows that for a producer-consumer scenario, using local data completion rather than local operation completion yields superior performance."
2245809,15258,23497,Aikido: accelerating shared data dynamic analyses,2012,"Despite a burgeoning demand for parallel programs, the tools available to developers working on shared-memory multicore processors have lagged behind. One reason for this is the lack of hardware support for inspecting the complex behavior of these parallel programs. Inter-thread communication, which must be instrumented for many types of analyses, may occur with any memory operation. To detect such thread communication in software, many existing tools require the instrumentation of all memory operations, which leads to significant performance overheads. To reduce this overhead, some existing tools resort to random sampling of memory operations, which introduces false negatives. Unfortunately, neither of these approaches provide the speed and accuracy programmers have traditionally expected from their tools. In this work, we present Aikido, a new system and framework that enables the development of efficient and transparent analyses that operate on shared data. Aikido uses a hybrid of existing hardware features and dynamic binary rewriting to detect thread communication with low overhead. Aikido runs a custom hypervisor below the operating system, which exposes per-thread hardware protection mechanisms not available in any widely used operating system. This hybrid approach allows us to benefit from the low cost of detecting memory accesses with hardware, while maintaining the word-level accuracy of a software-only approach. To evaluate our framework, we have implemented an Aikido-enabled vector clock race detector. Our results show that the Aikido enabled race-detector outperforms existing techniques that provide similar accuracy by up to 6.0x, and 76% on average, on the PARSEC benchmark suite."
759318,15258,23836,Predicting an Optimal Sparse Matrix Format for SpMV Computation on GPU,2014,"Many-threaded architecture based Graphics Processing Units (GPUs) are good for general purpose computations for achieving high performance. The processor has latency hiding mechanism through which it hides the memory access time in such a way that when one warp (group of 32 threads) is computing, the other warps perform memory bound access. But for memory access bound irregular applications such as Sparse Matrix Vector Multiplication (SpMV), memory access times are high and hence improving the performance of such applications on GPU is a challenging research issue. Further, optimizing SpMV time on GPU is an important task for iterative applications like jacobi and conjugate gradient. However, there is a need to consider the overheads caused while computing SpMV on GPU. Transforming the input matrix to a desired format and communicating the data from CPU to GPU are non-trivial overheads associated with SpMV computation on GPU. If the chosen format is not suitable for the given input sparse matrix then desired performance improvements cannot be achieved. Motivated by this observation, this paper proposes a method to chose an optimal sparse matrix format, focusing on the applications where CPU to GPU communication time and pre-processing time are nontrivial. The experimental results show that the predicted format by the model matches with that of the actual high performing format when total SpMV time in terms of pre-processing time, CPU to GPU communication time and SpMV computation time on GPU, is taken into account. The model predicts an optimal format for any given input sparse matrix with a very small overhead of prediction within an application. Compared to the format to achieve high performance only on GPU, our approach is more comprehensive and valuable. This paper also proposes to use a communication and pre-processing overhead optimizing sparse matrix format to be used when these overheads are non trivial."
1013427,15258,11058,Adaptive input-aware compilation for graphics engines,2012,"While graphics processing units (GPUs) provide low-cost and efficient platforms for accelerating high performance computations, the tedious process of performance tuning required to optimize applications is an obstacle to wider adoption of GPUs. In addition to the programmability challenges posed by GPU's complex memory hierarchy and parallelism model, a well-known application design problem is target portability across different GPUs. However, even for a single GPU target, changing a program's input characteristics can make an already-optimized implementation of a program perform poorly. In this work, we propose Adaptic, an adaptive input-aware compilation system to tackle this important, yet overlooked, input portability problem. Using this system, programmers develop their applications in a high-level streaming language and let Adaptic undertake the difficult task of input portable optimizations and code generation. Several input-aware optimizations are introduced to make efficient use of the memory hierarchy and customize thread composition. At runtime, a properly optimized version of the application is executed based on the actual program input. We perform a head-to-head comparison between the Adaptic generated and hand-optimized CUDA programs. The results show that Adaptic is capable of generating codes that can perform on par with their hand-optimized counterparts over certain input ranges and outperform them when the input falls out of the hand-optimized programs' comfort zone. Furthermore, we show that input-aware results are sustainable across different GPU targets making it possible to write and optimize applications once and run them anywhere."
1873374,15258,23749,VM Economics for Java Cloud Computing: An Adaptive and Resource-Aware Java Runtime with Quality-of-Execution,2012,"Resource management in Cloud Computing has been dominated by system-level virtual machines to enable the management of resources using a coarse grained approach, largely in a manner independent from the applications running on these infrastructures. However, in such environments, although different types of applications can be running, the resources are delivered equally to each one, missing the opportunity to manage the available resources in a more efficient and application driven way. So, as more applications target managed runtimes, high level virtualization is a relevant abstraction layer that has not been properly explored to enhance resource usage, control, and effectiveness. We propose a VM economics model to manage cloud infrastructures, governed by a quality-of-execution (QoE) metric and implemented by an extended virtual machine. The Adaptive and Resource-Aware Java Virtual Machine (ARA-JVM) is a cluster-enabled virtual execution environment with the ability to monitor base mechanisms (e.g. thread cheduling, garbage collection, memory or network consumptions) to assess application's performance and reconfigure these mechanisms in runtime according to previously defined resource allocation policies. Reconfiguration is driven by incremental gains in quality-of-execution (QoE), used by the VM economics model to balance relative resource savings and perceived performance degradation. Our work in progress, aims to allow cloud providers to exchange resource slices among virtual machines, continually addressing where those resources are required, while being able to determine where the reduction will be more economically effective, i.e., will contribute in lesser extent to performance degradation."
1757949,15258,9836,Amoeba-Cache: Adaptive Blocks for Eliminating Waste in the Memory Hierarchy,2012,"The fixed geometries of current cache designs do not adapt to the working set requirements of modern applications, causing significant inefficiency. The short block lifetimes and moderate spatial locality exhibited by many applications result in only a few words in the block being touched prior to eviction. Unused words occupy between 17 -- 80% of a 64K L1 cache and between 1% -- 79% of a 1MB private LLC. This effectively shrinks the cache size, increases miss rate, and wastes on-chip bandwidth. Scaling limitations of wires mean that unused-word transfers comprise a large fraction (11%) of on-chip cache hierarchy energy consumption. We propose Amoeba-Cache, a design that supports a variable number of cache blocks, each of a different granularity. Amoeba-Cache employs a novel organization that completely eliminates the tag array, treating the storage array as uniform and morph able between tags and data. This enables the cache to harvest space from unused words in blocks for additional tag storage, thereby supporting a variable number of tags (and correspondingly, blocks). Amoeba-Cache adjusts individual cache line granularities according to the spatial locality in the application. It adapts to the appropriate granularity both for different data objects in an application as well as for different phases of access to the same data. Overall, compared to a fixed granularity cache, the Amoeba-Cache reduces miss rate on average (geometric mean) by 18% at the L1 level and by 18% at the L2 level and reduces L1 -- L2 miss bandwidth by ?46%. Correspondingly, Amoeba-Cache reduces on-chip memory hierarchy energy by as much as 36% (mcf) and improves performance by as much as 50% (art)."
1053113,15258,22288,Dragonfly: Cloud Assisted Peer-to-Peer Architecture for Multipoint Media Streaming Applications,2013,"Technology trends are not only transforming the hardware landscape of end-user devices but are also dramatically changing the types of software applications that are deployed on these devices. With the maturity of cloud computing during the past few years, users increasingly rely on networked applications that are deployed in the cloud. In particular, new applications will emerge where user interactions will be based on real-time continuous media streams instead of the traditional request-response types of interfaces. Furthermore, many of these applications will be multi-user streaming media based interactions instead of a single user interaction with an application. In this paper, we propose a geographic location-aware, hybrid, scalable cloud assisted peer-to-peer (P2P) architecture to support such applications that targets low administration cost, reduced bandwidth consumption, low latency, low initial investment cost and optimized resource usage. The main objective is to develop an efficient media delivery system that leverages locality. We propose a 3-layer novel architecture that uses at the core the cloud for application management, 2-tier edge cloud for supporting geo-dispersed user groups, and at the lowest level peer-to-peer dynamic overlays for locally clustered user groups. The proposed architecture manages multiple streaming sessions simultaneously and each streaming session is an independent entity. Our experiments on PlanetLab show that the dynamic construction and maintenance of delivering streams at both the user-level P2P overlay and edge cloud are indeed feasible and effective."
1199220,15258,11330,Processing data streams with hard real-time constraints on heterogeneous systems,2011,"Data stream processing applications such as stock exchange data analysis, VoIP streaming, and sensor data processing pose two conflicting challenges: short per-stream latency -- to satisfy the milliseconds-long, hard real-time constraints of each stream, and high throughput -- to enable efficient processing of as many streams as possible. High-throughput programmable accelerators such as modern GPUs hold high potential to speed up the computations. However, their use for hard real-time stream processing is complicated by slow communications with CPUs, variable throughput changing non-linearly with the input size, and weak consistency of their local memory with respect to CPU accesses. Furthermore, their coarse grain hardware scheduler renders them unsuitable for unbalanced multi-stream workloads.   We present a general, efficient and practical algorithm for hard real-time stream scheduling in heterogeneous systems. The algorithm assigns incoming streams of different rates and deadlines to CPUs and accelerators. By employing novel stream schedulability criteria for accelerators, the algorithm finds the assignment which simultaneously satisfies the aggregate throughput requirements of all the streams and the deadline constraint of each stream alone.   Using the AES-CBC encryption kernel, we experimented extensively on thousands of streams with realistic rate and deadline distributions. Our framework outperformed the alternative methods by allowing 50% more streams to be processed with provably deadline-compliant execution even for deadlines as short as tens milliseconds. Overall, the combined GPU-CPU execution allows for up to 4-fold throughput increase over highly-optimized multi-threaded CPU-only implementations."
1388394,15258,9244,Taming massive distributed datasets: data sampling using bitmap indices,2013,"With growing computational capabilities of parallel machines, scientific simulations are being performed at finer spatial and temporal scales, leading to a data explosion. The growing sizes are making it extremely hard to store, manage, disseminate, analyze, and visualize these datasets, especially as neither the memory capacity of parallel machines, memory access speeds, nor disk bandwidths are increasing at the same rate as the computing power. Sampling can be an effective technique to address the above challenges, but it is extremely important to ensure that dataset characteristics are preserved, and the loss of accuracy is within acceptable levels. In this paper, we address the data explosion problems by developing a novel sampling approach, and implementing it in a flexible system that supports server-side sampling and data subsetting. We observe that to allow subsetting over scientific datasets, data repositories are likely to use an indexing technique. Among these techniques, we see that bitmap indexing can not only effectively support subsetting over scientific datasets, but can also help create samples that preserve both value and spatial distributions over scientific datasets. We have developed algorithms for using bitmap indices to sample datasets. We have also shown how only a small amount of additional metadata stored with bitvectors can help assess loss of accuracy with a particular subsampling level. Some of the other properties of this novel approach include: 1) sampling can be flexibly applied to a subset of the original dataset, which may be specified using a value-based and/or a dimension-based subsetting predicate, and 2) no data reorganization is needed, once bitmap indices have been generated. We have extensively evaluated our method with different types of datasets and applications, and demonstrated the effectiveness of our approach."
700673,15258,23836,Network Delay-Aware Load Balancing in Selfish and Cooperative Distributed Systems,2013,"We consider a geographically distributed request processing system composed of various organizations and their servers connected by the Internet. The latency a user observes is a sum of communication delays and the time needed to handle the request on a server. The handling time depends on the server congestion, i.e. the total number of requests a server must handle. We analyze the problem of balancing the load in a network of servers in order to minimize the total observed latency. We consider both cooperative and selfish organizations (each organization aiming to minimize the latency of the locally-produced requests). The problem can be generalized to the task scheduling in a distributed cloud; or to content delivery in an organizationally-distributed CDNs. In a cooperative network, we show that the problem is polynomially solvable. We also present a distributed algorithm iteratively balancing the load. We show how to estimate the distance between the current solution and the optimum based on the amount of load exchanged by the algorithm. During the experimental evaluation, we show that the distributed algorithm is efficient, therefore it can be used in networks with dynamically changing loads. In a network of selfish organizations, we prove that the price of anarchy (the worst-case loss of performance due to selfishness) is low when the network is homogeneous and the servers are loaded (the request handling time is high compared to the communication delay). After relaxing these assumptions, we assess the loss of performance caused by the selfishness experimentally, showing that it remains low. Our results indicate that a set of servers handling requests, connected in a heterogeneous network, can be efficiently managed by a distributed algorithm. Additionally, even if the network is organizationally distributed, with individual organizations optimizing performance of their requests, the network remains efficient."
2233835,15258,8306,Fractal++: closing the performance gap between fractal and conventional coherence,2014,"Cache coherence protocol bugs can cause multicores to fail. Existing coherence verification approaches incur state explosion at small scales or require considerable human effort. As protocols' complexity and multicores' core counts increase, verification continues to be a challenge. Recently, researchers proposed fractal coherence which achieves scalable verification by enforcing observational equivalence between sub-systems in the coherence protocol. A larger subsystem is verified implicitly if a smaller sub-system has been verified. Unfortunately, fractal protocols suffer from two fundamental limitations: (1) indirect-communication: sub-systems cannot directly communicate and (2) partially-serialinvalidations: cores must be invalidated in a specific, serial order. These limitations disallow common performance optimizations used by conventional directory protocols: replyforwarding where caches communicate directly and parallel invalidations. Therefore, fractal protocols lack performance scalability while directory protocols lack verification scalability. To enable both performance and verification scalability, we propose Fractal++ which employs a new class of protocol optimizations for verification-constrained architectures: decoupled-replies, contention-hints, and fully-parallel-fractal-invalidations. The first two optimizations allow reply-forwarding-like performance while the third optimization enables parallel invalidations in fractal protocols. Unlike conventional protocols, Fractal++ preserves observational equivalence and hence is scalably verifiable. In 32- core simulations of single- and four-socket systems, Fractal++ performs nearly as well as a directory protocol while providing scalable verifiability whereas the best-performing previous fractal protocol performs 8% on average and up to 26% worse with a single-socket and 12% on average and up to 34% worse with a longer-latency multi-socket system"
2342037,15258,122,ULCC: a user-level facility for optimizing shared cache performance on multicores,2011,"Scientific applications face serious performance challenges on multicore processors, one of which is caused by access contention in last level shared caches from multiple running threads. The contention increases the number of long latency memory accesses, and consequently increases application execution times. Optimizing shared cache performance is critical to reduce significantly execution times of multi-threaded programs on multicores. However, there are two unique problems to be solved before implementing cache optimization techniques on multicores at the user level. First, available cache space for each running thread in a last level cache is difficult to predict due to access contention in the shared space, which makes cache conscious algorithms for single cores ineffective on multicores. Second, at the user level, programmers are not able to allocate cache space at will to running threads in the shared cache, thus data sets with strong locality may not be allocated with sufficient cache space, and cache pollution can easily happen. To address these two critical issues, we have designed ULCC (User Level Cache Control), a software runtime library that enables programmers to explicitly manage and optimize last level cache usage by allocating proper cache space for different data sets of different threads. We have implemented ULCC at the user level based on a page-coloring technique for last level cache usage management. By means of multiple case studies on an Intel multicore processor, we show that with ULCC, scientific applications can achieve significant performance improvements by fully exploiting the benefit of cache optimization algorithms and by partitioning the cache space accordingly to protect frequently reused data sets and to avoid cache pollution. Our experiments with various applications show that ULCC can significantly improve application performance by nearly 40%."
1815424,15258,23836,Bandwidth Reduction through Multithreaded Compression of Seismic Images,2011,"One of the main challenges of modern computer systems is to overcome the ever more prominent limitations of disk I/O and memory bandwidth, which today are thousands-fold slower than computational speeds. In this paper, we investigate reducing memory bandwidth and overall I/O and memory access times by using multithreaded compression and decompression of large datasets. Since the goal is to achieve a significant overall speedup of I/O, both level of compression achieved and efficiency of the compression and decompression algorithms, are of importance. Several compression methods for efficient disk access for large seismic datasets are implemented and empirically tested on on several modern CPUs and GPUs, including the Intel i7 and NVIDIA c2050 GPU. To reduce I/O time, both lossless and lossy symmetrical compression algorithms as well as hardware alternatives, are tested. Results show that I/O speedup may double by using an SSD vs. HDD disk on larger seismic datasets. Lossy methods investigated include variations of DCT-based methods in several dimensions, and combining these with lossless compression methods such as RLE (Run-Length Encoding) and Huffman encoding. Our best compression rate (0.16%) and speedups (6 for HDD and 3.2 for SSD) are achieved by using DCT in 3D and combining this with a modified RLE for lossy methods. It has an average error of 0.46% which is very acceptable for seismic applications. A simple predictive model for the execution time is also developed and shows an error of maximum 5% vs. our obtained results. It should thus be a good tool for predicting when to take advantage of multithreaded compression. This model and other techniques developed in this paper should also be applicable to several other data intensive applications."
2771392,15258,20876,ORDER: object centric deterministic replay for Java,2011,"Deterministic replay systems, which record and replay non-deterministic events during program execution, have many applications such as bug diagnosis, intrusion analysis and fault tolerance. It is well understood how to replay native (e.g., C) programs on multi-processors, while there is little work for concurrent java applications on multicore. State-of-the-art work for Java either assumes data-race free execution, or relies on static instrumentation, which leads to missing some necessary nondeterministic events.#R##N##R##N#This paper proposes the ORDER framework to record and reproduce non-deterministic events inside Java virtual machine (JVM). Based on observations of good locality at object level for threads and frequent object movements due to garbage collection, ORDER records and replays non-deterministic data accesses by logging and enforcing the order in which threads access objects. This essentially eliminates unnecessary dependencies introduced by address changes of objects during garbage collection and enjoys good locality as well as less contention, which may result in scalable performance on multicore. Further, by dynamically instrumenting Java code in the JVM compilation pipeline, ORDER naturally covers non-determinism in dynamically loaded classes.#R##N##R##N#We have implemented ORDER based on Apache Harmony. Evaluation on SPECjvm2008, PseudoJBB2005, and JRuby shows that ORDER only incurs 108% performance overhead on average and scales well on a 16-core Xeon testbed. Evaluation with a real-world application, JRuby, shows that several real-world concurrency bugs can be successfully reproduced."
808520,15258,9772,Cuanta: quantifying effects of shared on-chip resource interference for consolidated virtual machines,2011,"Workload consolidation is very attractive for cloud platforms due to several reasons including reduced infrastructure costs, lower energy consumption, and ease of management. Advances in virtualization hardware and software continue to improve resource isolation among consolidated workloads but a particular form of resource interference is yet to see a commercially widely adopted solution -  the interference due to shared processor caches . Existing solutions for handling cache interference require new hardware features, extensive software changes, or reduce the achieved overall throughput. A crucial requirement for effective consolidation is to be able to predict the impact of cache interference among consolidated workloads. In this paper, we present a practical technique for predicting performance interference due to shared processor cache which works on current processor architectures and requires minimal software changes. While performance degradation can be empirically measured for a given placement of consolidated workloads, the number of possible placements grows exponentially with the number of workloads and actual measurement of degradation is thus not practical for every possible placement. Our technique predicts the degradation for any possible placement using only a linear number of measurements, and can be used to select the most efficient consolidation pattern, for required performance and resource constraints. An average prediction error of less than 4% is achieved across a wide variety of benchmark workloads, using Xen VMM on Intel Core 2 Duo and Nehalem quad-core processor platforms. We also illustrate the usefulness of our prediction technique in realizing better workload placement decisions for given performance and resource cost objectives."
867574,15258,9836,Insertion and promotion for tree-based PseudoLRU last-level caches,2013,"Last-level caches mitigate the high latency of main memory. A good cache replacement policy enables high performance for memory intensive programs. To be useful to industry, a cache replacement policy must deliver high performance without high complexity or cost. For instance, the costly least-recently-used (LRU) replacement policy is not used in highly associative caches; rather, inexpensive policies with similar performance such as PseudoLRU are used.   We propose a novel last-level cache replacement algorithm with approximately the same complexity and storage requirements as tree-based PseudoLRU, but with performance matching state of the art techniques such as dynamic re-reference interval prediction (DRRIP) and protecting distance policy (PDP). The algorithm is based on PseudoLRU, but uses set-dueling to dynamically adapt its insertion and promotion policy. It has slightly less than one bit of overhead per cache block, compared with two or more bits per cache block for competing policies.   In this paper, we give the motivation behind the algorithm in the context of LRU with improved placement and promotion, then develop this motivation into a PseudoLRU-based algorithm, and finally give a version using set-dueling to allow adaptivity to changing program behavior. We show that, with a 16-way set-associative 4MB last-level cache, our adaptive PseudoLRU insertion and promotion algorithm yields a geometric mean speedup of 5.6% over true LRU over all the SPEC CPU 2006 benchmarks using far less overhead than LRU or other algorithms. On a memory-intensive subset of SPEC, the technique gives a geometric mean speedup of 15.6%. We show that the performance is comparable to state-of-the-art replacement policies that consume more than twice the area of our technique."
772705,15258,20774,Scheduling irregular parallel computations on hierarchical caches,2011,"For nested-parallel computations with low depth (span, critical path length) analyzing the work, depth, and  sequential  cache complexity suffices to attain reasonably strong bounds on the   parallel  runtime and cache complexity on machine models with either shared or private caches. These bounds, however, do not extend to general hierarchical caches, due to limitations in (i) the cache-oblivious (CO) model used to analyze cache complexity and (ii) the schedulers used to map computation tasks to processors. This paper presents the  parallel cache-oblivious (PCO)  model, a relatively simple modification to the CO model that can be used to account for costs on a broad range of cache hierarchies. The first change is to avoid capturing artificial data sharing among parallel threads, and the second is to account for parallelism-memory imbalances within tasks. Despite the more restrictive nature of PCO compared to CO, many algorithms have the same asymptotic cache complexity bounds.   The paper then describes a new scheduler for hierarchical caches, which extends recent work on space-bounded schedulers to allow for computations with arbitrary  work imbalance  among parallel subtasks. This scheduler attains provably good cache performance and runtime on parallel machine models with hierarchical caches, for nested-parallel computations analyzed using the PCO model. We show that under reasonable assumptions our scheduler is work efficient in the sense that the cost of the cache misses are evenly balanced across the processors--- i.e. , the runtime can be determined within a constant factor by taking the total cost of the cache misses analyzed for a computation and dividing it by the number of processors. In contrast, to further support our model, we show that no scheduler can achieve such bounds (optimizing for both cache misses and runtime) if work, depth, and sequential cache complexity are the only parameters used to analyze a computation."
1162127,15258,11330,MDR: performance model driven runtime for heterogeneous parallel platforms,2011,"We present a runtime framework for the execution of work-loads represented as parallel-operator directed acyclic graphs (PO-DAGs) on heterogeneous multi-core platforms. PO-DAGs combine coarse-grained parallelism at the graph level with fine-grained parallelism within each node, lending naturally to exploiting the intra --- and inter-processing element parallelism present in heterogeneous platforms. We identify four important criteria - Suitability, Locality, Availability and Criticality (SLAC) --- and show that all these criteria must be considered by a heterogeneous runtime framework in order to achieve good performance under varying application and platform characteristics.   The proposed model driven runtime (MDR) considers all the aforementioned factors, and tradeoffs among them, by utilizing performance models. These performance models are used to drive key run-time decisions such as mapping of tasks to PEs, scheduling of tasks on each PE, and copying data between memory spaces.   We discuss the software architecture and implementation of MDR, and evaluate it using several benchmark programs on three different heterogeneous platforms that contain multi-core CPUs and GPUs. The hardware platforms represent server, laptop, and netbook class systems. MDR achieves up to 4.2X speedup (1.5X on average) over the best of CPU-only, GPU-only, round-robin, GPU-first, and utilization-driven schedulers. We also perform a sensitivity analysis that establishes the importance of considering all four SLAC criteria in order to achieve high performance execution in a heterogeneous runtime framework."
952811,15258,22288,"Elastic Resources Framework in IaaS, Preserving Performance SLAs",2013,"Elasticity in cloud systems provides the flexibility to acquire and relinquish computing resources on demand. However, in current virtualized systems resource allocation is mostly static. Resources are allocated during VM instantiation and any change in workload leading to significant increase or decrease in resources is handled by VM migration. Hence, cloud users tend to characterize their workloads at a coarse grained level which potentially leads to under-utilized VM resources or under performing application. A more flexible and adaptive resource allocation mechanism would benefit variable workloads, such as those characterized by web servers. In this paper, we present an elastic resources framework for IaaS cloud layer that addresses this need. The framework provisions for application workload forecasting engine, that predicts at run-time the expected demand, which is input to the resource manager to modulate resource allocation based on the predicted demand. Based on the prediction errors, resources can be over-allocated or under-allocated as compared to the actual demand made by the application. Over-allocation leads to unused resources and under allocation could cause under performance. To strike a good trade-off between over-allocation and under-performance we derive an excess cost model. In this model excess resources allocated are captured as over-allocation cost and under-allocation is captured as a penalty cost for violating application service level agreement (SLA). Confidence interval for predicted workload is used to minimize this excess cost with minimal effect on SLA violations. An example case-study for an academic institute web server workload is presented. Using the confidence interval to minimize excess cost, we achieve significant reduction in resource allocation requirement while restricting application SLA violations to below 2-3%."
1982552,15258,20774,"Tradeoffs between synchronization, communication, and computation in parallel linear algebra computations",2014,"This paper derives tradeoffs between three basic costs of a parallel algorithm: synchronization, data movement, and computational cost. These tradeoffs are lower bounds on the execution time of the algorithm which are independent of the number of processors, but dependent on the problem size. Therefore, they provide lower bounds on the parallel execution time of any algorithm computed by a system composed of any number of homogeneous components, each with associated computational, communication, and synchronization payloads. We employ a theoretical model counts the amount of work and data movement as a maximum of any execution path during the parallel computation. By considering this metric, rather than the total communication volume over the whole machine, we obtain new insights into the characteristics of parallel schedules for algorithms with non-trivial dependency structures. We also present reductions from BSP and LogP algorithms to our execution model, extending our lower bounds to these two models of parallel computation. We first develop our results for general dependency graphs and hypergraphs based on their expansion properties, then we apply the theorem to a number of specific algorithms in numerical linear algebra, namely triangular substitution, Gaussian elimination, and Krylov subspace methods. Our lower bound for LU factorization demonstrates the optimality of Tiskin's LU algorithm answering an open question posed in his paper, as well as of the 2.5D LU algorithm which has analogous costs. We treat the computations in a general manner by noting that the computations share a similar dependency hypergraph structure and analyzing the communication requirements of lattice hypergraph structures."
2431355,15258,23749,Scalable Memcached Design for InfiniBand Clusters Using Hybrid Transports,2012,"Mem cached is a general-purpose key-value based distributed memory object caching system. It is widely used in data-center domain for caching results of database calls, API calls or page rendering. An efficient Mem cached design is critical to achieve high transaction throughput and scalability. Previous research in the field has shown that the use of high performance interconnects like InfiniBand can dramatically improve the performance of Mem cached. The Reliable Connection (RC) is the most commonly used transport model for InfiniBand implementations. However, it has been shown that RC transport imposes scalability issues due to high memory consumption per connection. Such a characteristic is not favorable for middle wares like Mem cached, where the server is required to serve thousands of clients. The Unreliable Datagram (UD) transport offers higher scalability, but has several other limitations, which need to be efficiently handled. In this context, we introduce a hybrid transport model which takes advantage of the best features of RC and UD to deliver scalability and performance higher than that of a single-transport. To the best of our knowledge, this is the first effort aimed at studying the impact of using a hybrid of multiple transport protocols on Mem cached performance. We present comprehensive performance analysis using micro benchmarks, application benchmarks and realistic industry workloads. Our performance evaluations reveal that our Hybrid transport delivers performance comparable to that of RC, while maintaining a steady memory footprint. Mem cached Get latency for 4byte data size, is 4.28µs and 4.86µs for RC and hybrid transports, respectively. This represents a factor of twelve improvement over the performance of SDP. In evaluations using Apache Olio benchmark with 1,024 clients, Mem cached execution time using RC, UD and hybrid transports are 1.61, 1.96 and 1.70 seconds, respectively. Further, our scalability analysis with 4,096 client connections reveal that our proposed hybrid transport achieves good memory scalability."
210006,15258,11223,Simple testing can prevent most critical failures: an analysis of production failures in distributed data-intensive systems,2014,"Large, production quality distributed systems still fail periodically, and do so sometimes catastrophically, where most or all users experience an outage or data loss. We present the result of a comprehensive study investigating 198 randomly selected, user-reported failures that occurred on Cassandra, HBase, Hadoop Distributed File System (HDFS), Hadoop MapReduce, and Redis, with the goal of understanding how one or multiple faults eventually evolve into a user-visible failure. We found that from a testing point of view, almost all failures require only 3 or fewer nodes to reproduce, which is good news considering that these services typically run on a very large number of nodes. However, multiple inputs are needed to trigger the failures with the order between them being important. Finally, we found the error logs of these systems typically contain sufficient data on both the errors and the input events that triggered the failure, enabling the diagnose and the reproduction of the production failures.#R##N##R##N#We found the majority of catastrophic failures could easily have been prevented by performing simple testing on error handling code - the last line of defense - even without an understanding of the software design. We extracted three simple rules from the bugs that have lead to some of the catastrophic failures, and developed a static checker, Aspirator, capable of locating these bugs. Over 30% of the catastrophic failures would have been prevented had Aspirator been used and the identified bugs fixed. Running Aspirator on the code of 9 distributed systems located 143 bugs and bad practices that have been fixed or confirmed by the developers."
2422950,15258,9748,Data-Driven Tasks and Their Implementation,2011,"Dynamic task parallelism has been identified as a prerequisite for improving productivity and performance on future many-core processors. In dynamic task parallelism, computations are created dynamically and the runtime scheduler is responsible for scheduling the computations across processor cores. The sets of task graphs that can be supported by a dynamic scheduler depend on the underlying task primitives in the parallel programming model, with various classes of fork-join structures used most often in practice. However, many researchers have advocated the benefits of more general task graph structures, and have shown that the use of these task graph structures can lead to improved performance. In this paper, we propose an extension to task parallelism called Data-Driven Tasks (DDTs) that can be used to create arbitrary task graph structures. Unlike a normal task that starts execution upon creation, a DDT specifies its input constraints in an await clause containing a list of Data-Driven Futures (DDFs). A DDF can be viewed as a container with a full/empty state that obeys a dynamic single-assignment rule. The runtime scheduler will then ensure that a task is only scheduled when all the DDFs in its await clause become available (full). There is no constraint on which task performs a put() operation on a DDF. We describe five scheduling algorithms (Coarse-Grain Blocking, Fine-Grain Blocking, Delayed Async, Rollback & Replay, Data-Driven) that can be used to implement DDTs, and include performance evaluations of these five algorithms on a variety of benchmark programs and multi-core platforms. Our results show that the Data-Driven scheduler is the best approach for implementing DDTs, both from the viewpoints of memory efficiency and scalable parallelism."
938439,15258,507,"JustMyFriends: full SQL, full transactional amenities, and access privacy",2012,"A major obstacle to using Cloud services for many enterprises is the fear that the data will be stolen. Bringing the Cloud in-house is an incomplete solution to the problem because that implies that data center personnel as well as myriad repair personnel must be trusted. An ideal security solution would be to share data among precisely the people who should see it (my friends) and nobody else.   Encryption might seem to be an easy answer. Each friend could download the data, update it perhaps, and return it to a shared untrusted repository. But such a solution permits no concurrency and therefore no real sharing.   JustMyFriends ensures sharing among friends without revealing unencrypted data to anyone outside of a circle of trust. In fact, non-friends (such as system administrators) see only encrypted blobs being added to a persistent store. JustMyFriends allows data sharing and full transactions. It supports the use of all SQL including stored procedures, updates, and arbitrary queries. Additionally, it provides full access privacy, preventing the host from discovering patterns or correlations in the user's data access behavior.   The demonstration will show how friends in an unnamed government agency can coordinate the management of a spy network in a transactional fashion. Demo visitors will be able to play the roles of station chiefs and/or of troublemakers. As station chiefs, they will write their own transactions and queries, logout, login. As troublemakers, visitors will be able to play the role of a curious observer, kill client processes, and in general try to disrupt the system."
1650330,15258,339,"Vanity, cracks and malware: insights into the anti-copy protection ecosystem",2012,"Today, a large amount of software products include mechanisms to counter software piracy. However, most protection mechanisms can be easily circumvented by applying software patches (cracks) or license key generators (keygens) with seemingly no financial incentives. Our research shows that the distribution of cracks and keygens not only allows miscreants to generate revenue (e.g. through advertising or malware infections), but it also leads to high risks for the end-users of pirated software. We collected more than 43,900 download links and analyzed more than 23,100 (3,551 unique) real-world cracks, showing that these tools are heavily used by criminals to spread malware. Our results indicate that even state of the art virus scanners can not fully protect users from these threats. Moreover, we conducted a manual analysis, showing how many cracks and keygens actually work and how much effort is necessary to acquire them. In addition, we made our data-set publicly available to the research community."
2390639,15258,343,Towards comprehensive social sharing of recommendations: augmenting push with pull,2013,"On today's online social networks, a user can discover only those recommendations that her friends put in the effort to share. Therefore, we present the  PullRec  framework for enabling users to  pull  recommendations from their friends.  PullRec  employs two measures to minimize the effort involved in sharing recommendations. First, to reduce the onus on users to express their recommendations,  PullRec  proactively logs all the entities about which a user may have an opinion and attempts to infer the user's opinions. Second, to ensure that users are not spammed with irrelevant queries, when a user queries for recommendations on a certain topic,  PullRec  notifies only those friends of the user who are likely to have relevant recommendations.  PullRec  is a step towards enabling a user to discover all recommendations that her friends are willing to share with her."
1450434,15258,343,PEERING: An AS for Us,2014,"Internet routing suffers from persistent and transient failures, circuitous routes, oscillations, and prefix hijacks. A major impediment to progress is the lack of ways to conduct impactful interdomain research. Most research is based either on passive observation of existing routes, keeping researchers from assessing how the Internet will respond to route or policy changes; or simulations, which are restricted by limitations in our understanding of topology and policy.   We propose a new class of interdomain research: researchers can instantiate an AS of their choice, including its intradomain topology and interdomain interconnectivity, and connect it with the live Internet to exchange routes and traffic with real interdomain neighbors. Instead of being observers of the Internet ecosystem, researchers become members. Towards this end, we present the Peering testbed. In its nascent stage, the testbed has proven extremely useful, resulting in a series of studies that were nearly impossible for researchers to conduct in the past. In this paper, we present a vision of what the testbed can provide. We sketch how to extend the testbed to enable future innovation, taking advantage of the rise of IXPs to expand our testbed."
2222056,15258,339,"Routing Bottlenecks in the Internet: Causes, Exploits, and Countermeasures",2014,"How pervasive is the vulnerability to link-flooding attacks that degrade connectivity of thousands of Internet hosts? Are some geographic regions more vulnerable than others? Do practical countermeasures exist? To answer these questions, we introduce the notion of the routing bottlenecks and show that it is a fundamental property of Internet design; i.e., it is a consequence of route-cost minimizations. We illustrate the pervasiveness of routing bottlenecks in an experiment comprising 15 countries and 15 cities distributed around the world, and measure their susceptibility to scalable link-flooding attacks. We present the key characteristics of routing bottlenecks, including size, link type, and distance from host destinations, and suggest specific structural and operational countermeasures to link-flooding attacks. These countermeasures can be deployed by network operators without needing major Internet redesign."
884989,15258,343,Cognitive bias in network services,2012,"The assumption of rationality is fundamental to large part of network economics literature. In this paper, we use a simple definition of rationality based on economic self-interest and test for such behavior using real data on how users purchase and consume mobile network services. If users acted in their best (optimal) interest, then they would opt for the tariff that best suits their demands. However, that need not be the case, as users can fall prey to biases that can lead them to make  seemingly  sub-optimal choices. Such biases are hard to characterize and in this paper we empirically study how end-users purchase  and  use network services.   We find that most customers choose sub-optimal tariffs, and that median and mean overpayment is 26% and 37%, respectively, of the user optimal tariff bill. Additionally, we observe not only that perception of traffic usage biases the tariff choice but also that the choice of tariff biases traffic usage: the traffic demand grows substantially when users switch from pay-as-you-go to a bundle tariff, and that traffic demand on a bundle is not uniformly spread across time."
86751,15258,293,Characterizing delays in norwegian 3g networks,2012,"This paper presents a first look at long-term delay measurements from data connections in 3 Norwegian 3G Networks. We have performed active measurements for more than 6 months from 90 voting locations used in a trial with electronic voting during this fall's regional elections. Our monitors are geographically spread across all of Norway, and give an unprecedented view of the performance and stability of the total 3G infrastructure of a country. In this paper, we focus on delay characteristics. We find large differences in delay between different monitors. More interestingly, we observe that the delay characteristics of the different operators are very different, pointing to operator-specific network design and configurations as the most important factor for delays."
1446235,15258,339,SICE: a hardware-level strongly isolated computing environment for x86 multi-core platforms,2011,"SICE is a novel framework to provide hardware-level isolation and protection for sensitive workloads running on x86 platforms in compute clouds. Unlike existing isolation techniques, SICE does not rely on any software component in the host environment (i.e., an OS or a hypervisor). Instead, the security of the isolated environments is guaranteed by a trusted computing base that only includes the hardware, the BIOS, and the System Management Mode (SMM). SICE provides fast context switching to and from an isolated environment, allowing isolated workloads to time-share the physical platform with untrusted workloads. Moreover, SICE supports a large range (up to 4GB) of isolated memory. Finally, the most unique feature of SICE is the use of multicore processors to allow the isolated environments to run concurrently and yet securely beside the untrusted host. We have implemented a SICE prototype using an AMD x86 hardware platform. Our experiments show that SICE performs fast context switching (67 microseconds) to and from the isolated environment and that it imposes a reasonable overhead (3% on all but one benchmark) on the operation of an isolated Linux virtual machine. Our prototype demonstrates that, subject to a careful security review of the BIOS software and the SMM hardware implementation, current hardware architecture already provides abstractions that can support building strong isolation mechanisms using a very small SMM software foundation of about 300 lines of code."
1880852,15258,122,Time-warp: lightweight abort minimization in transactional memory,2014,"The notion of permissiveness in Transactional Memory (TM) translates to only aborting a transaction when it cannot be accepted in any history that guarantees correctness criterion. This property is neglected by most TMs, which, in order to maximize implementation's efficiency, resort to aborting transactions under overly conservative conditions. In this paper we seek to identify a sweet spot between permissiveness and efficiency by introducing the Time-Warp Multi-version algorithm (TWM). TWM is based on the key idea of allowing an update transaction that has performed stale reads (i.e., missed the writes of concurrently committed transactions) to be serialized by committing it in the past, which we call a time-warp commit. At its core, TWM uses a novel, lightweight validation mechanism with little computational overheads. TWM also guarantees that read-only transactions can never be aborted. Further, TWM guarantees Virtual World Consistency, a safety property that is deemed as particularly relevant in the context of TM. We demonstrate the practicality of this approach through an extensive experimental study, where we compare TWM with four other TMs, and show an average performance improvement of 65% in high concurrency scenarios."
491314,15258,293,Ingress Point Spreading: A New Primitive for Adaptive Active Network Mapping,2014,"Among outstanding challenges to Internet-wide topology mapping using active probes is balancing efficiency, e.g. induced load and time, with coverage. Toward maximizing probe utility, we introduce Ingress Point Spreading (IPS). IPS utilizes ingress diversity discovered in prior rounds of probing to rank-order available vantage points such that future probes traverse all known paths into a target network. We implement and deploy IPS to probe ~49k random prefixes drawn from the global BGP table using a distributed collection of vantage points. As compared to existing mapping systems, we discover 12% more unique vertices and 12% more edges using ~50% fewer probes, in half the time."
134919,15258,293,Scalable Accurate Consolidation of Passively Measured Statistical Data,2014,"Passive probes continuously collect a significant amount of traffic volume, and autonomously generate statistics on a large number of metrics. A common statistical output of passive probe is represented by probability mass functions (pmf). The need for consolidation of several pmfs arises in two contexts, namely: (i) whenever a central point collects and aggregates measurement of multiple disjoint vantage points, and (ii) whenever a local measurement processed at a single vantage point needs to be distributed over multiple cores of the same physical probe, in order to cope with growing link capacity. Taking an experimental approach, we study both cases assessing the impact of different consolidation strategies, obtaining general design and tuning guidelines."
2337102,15258,507,A scalable lock manager for multicores,2013,"Modern implementations of DBMS software are intended to take advantage of high core counts that are becoming common in high-end servers. However, we have observed that several database platforms, including MySQL, Shore-MT, and a commercial system, exhibit throughput collapse as load increases into oversaturation (where there are more request threads than cores), even for a workload with little or no logical contention for locks, such as a read-only workload. Our analysis of MySQL identifies latch contention within the lock manager as the bottleneck responsible for this collapse.   We design a lock manager with reduced latching, implement it in MySQL, and show that it avoids the collapse and generally improves performance. Our efficient implementation of a lock manager is enabled by a staged allocation and deallocation of locks. Locks are preallocated in bulk, so that the lock manager only has to perform simple list manipulation operations during the acquire and release phases of a transaction. Deallocation of the lock data structures is also performed in bulk, which enables the use of fast implementations of lock acquisition and release as well as concurrent deadlock checking."
553245,15258,293,Towards active measurements of edge network outages,2013,"End-to-end reachability is a fundamental service of the Internet. We study network outages caused by natural disasters [2,5], and political upheavals [8].#R##N##R##N#We propose a new approach to outage detection using active probing. Like prior outage detection methods [3,4], our method uses ICMP echo requests (pings) to detect outages, but we probe with greater density and finer granularity, showing pings can detect outages without supplemental probing.#R##N##R##N#The main contribution of our work is to define how to interpret pings as outages (      $\S$    2): defining an outage as a sharp change in block responsiveness relative to recent behavior. We also provide preliminary analysis of outage rate in the Internet edge. Space constrains this poster abstract to only sketches of our approach; details and validation are in our technical report [6]. Our data is available at no charge, see    http://www.isi.edu/ant/traces/internet_outages/       ."
2430912,15258,122,Automatic formal verification of MPI-based parallel programs,2011,"The Toolkit for Accurate Scientific Software (TASS) is a suite of tools for the formal verification of MPI-based parallel programs used in computational science. TASS can verify various safety properties as well as compare two programs for functional equivalence. The TASS front end takes an integer  n  ≥ 1 and a C/MPI program, and constructs an abstract model of the program with  n  processes. Procedures, structs, (multi-dimensional) arrays, heap-allocated data, pointers, and pointer arithmetic are all representable in a TASS model. The model is then explored using symbolic execution and explicit state space enumeration. A number of techniques are used to reduce the time and memory consumed. A variety of realistic MPI programs have been verified with TASS, including Jacobi iteration and manager-worker type programs, and some subtle defects have been discovered. TASS is written in Java and is available from http://vsl.cis.udel.edu/tass under the Gnu Public License."
1463221,15258,343,Detecting price and search discrimination on the internet,2012,"Price discrimination, setting the price of a given product for each customer individually according to his valuation for it, can benefit from extensive information collected online on the customers and thus contribute to the profitability of e-commerce services. Another way to discriminate among customers with different willingness to pay is to steer them towards different sets of products when they search within a product category ( i.e ., search discrimination). Our main contribution in this paper is to empirically demonstrate the existence of signs of both price and search discrimination on the Internet, and to uncover the information vectors used to facilitate them. Supported by our findings, we outline the design of a large-scale, distributed watchdog system that allows users to detect discriminatory practices."
1880238,15258,339,Populated IP addresses: classification and applications,2012,"Populated IP addresses (PIP) -- IP addresses that are associated with a large number of user requests are important for online service providers to efficiently allocate resources and to detect attacks. While some PIPs serve legitimate users, many others are heavily abused by attackers to conduct malicious activities such as scams, phishing, and malware distribution. Unfortunately, commercial proxy lists like Quova have a low coverage of PIP addresses and offer little support for distinguishing good PIPs from abused ones. In this study, we propose PIPMiner, a fully automated method to extract and classify PIPs through analyzing service logs. Our methods combine machine learning and time series analysis to distinguish good PIPs from abused ones with over 99.6% accuracy. When applying the derived PIP list to several applications, we can identify millions of malicious Windows Live accounts right on the day of their sign-ups, and detect millions of malicious Hotmail accounts well before the current detection system captures them."
150675,15258,293,Detecting pedophile activity in bittorrent networks,2012,"The wide spread of Peer-to-Peer networks makes multimedia files available to users all around the world. However, Peer-to-Peer networks are often used to spread illegal material, while keeping the source of the data and the acquiring users anonymous. In this paper we analyze activity measurements in the BitTorrent network and examine child sex abuse activity through the Mininova web portal. We detect and characterize pedophilic material in the network, and also analyze different aspects of the abusers activity. We hope our results will help law enforcement teams detecting child molesters and tracking them down earlier."
1717500,15258,339,Combining control-flow integrity and static analysis for efficient and validated data sandboxing,2011,"In many software attacks, inducing an illegal control-flow transfer in the target system is one common step. Control-Flow Integrity (CFI) protects a software system by enforcing a pre-determined control-flow graph. In addition to providing strong security, CFI enables static analysis on low-level code. This paper evaluates whether CFI-enabled static analysis can help build efficient and validated data sandboxing. Previous systems generally sandbox memory writes for integrity, but avoid protecting confidentiality due to the high overhead of sandboxing memory reads. To reduce overhead, we have implemented a series of optimizations that remove sandboxing instructions if they are proven unnecessary by static analysis. On top of CFI, our system adds only 2.7% runtime overhead on SPECint2000 for sandboxing memory writes and adds modest 19% for sandboxing both reads and writes. We have also built a principled data-sandboxing verifier based on range analysis. The verifier checks the safety of the results of the optimizer, which removes the need to trust the rewriter and optimizer. Our results show that the combination of CFI and static analysis has the potential of bringing down the cost of general inlined reference monitors, while maintaining strong security."
2898226,15258,8228,An empirical study of morphing on network traffic classification,2012,"Network morphing aims at masking traffic to degrade the performance of traffic identification and classification. Several morphing strategies have been proposed as promising approaches, very few works, however, have investigated their impact on the actual traffic classification performance. This work sets out to fulfill this gap from an empirical study point of view. It takes into account different morphing strategies exerted on packet size and/or inter-arrival time. The results show that not all morphing strategies can effectively obfuscate traffic classification. Different morphing strategies perform distinctively, among which the integration of packet size and inter arrival time morphing is the best, and the packet size based method is the worst. The three classifiers also exhibit distinct robustness to the morphing, with C4.5 being the most robust and Naive Bayes being the weakest. In addition, our study shows that classifiers can learn nontrivial information merely from the traffic direction patterns, which partially explains the weakness of packet size based morphing methods."
449698,15258,293,Dissecting 3G uplink delay by measuring in an operational HSPA network,2011,"Users expect mobile Internet access via 3G technologies to be comparable to wired access in terms of throughput and latency. HSPA achieves this for throughput, whereas delay is significantly higher.#R##N##R##N#In this paper we measure the overall latency introduced by HSUPA and accurately dissect it into contributions of USB-modem (UE), base station (NodeB) and network controller (RNC). We achieve this by combining traces recorded at each interface along the data-path of a public operational UMTS network. The actively generated sample traffic covers real-time applications.#R##N##R##N#Results show the delay to be strongly dependent on the packet size, with random components depending on synchronization issues. We provide models for latency of single network entities as well as accumulated delay. These findings allow to identify optimum settings in terms of low latency, both for application and network parameters."
1143664,15258,507,SpongeFiles: mitigating data skew in mapreduce using distributed memory,2014,"Data skew is a major problem for data processing platforms like MapReduce. Skew causes worker tasks to spill to disk what they cannot fit in memory, which slows down the task and the overall job. Moreover, performance of other jobs sharing same disk degrades. In many cases, this situation occurs even as the cluster has plenty of spare memory it is just not used evenly. We introduce SpongeFiles, a novel distributed-memory abstraction tailored to data processing environments like MapReduce. A SpongeFile is a logical byte array, comprised of large chunks that can be stored in a variety of locations in the cluster. Spilled data goes to SpongeFiles, which route it to the nearest location with sufficient capacity (local memory, remote memory, local disk, or remote disk as a last resort). By enabling memory-sapped nodes to tap into the spare capacity of their neighbors, SpongeFiles minimize expensive disk spilling, thereby improving performance. In our experiments with Hadoop and Pig, SpongeFiles reduce overall job runtimes by up to 55% and by up to 85% under disk contention."
28144,15258,293,A measurement of mobile traffic offloading,2013,"A promising way to use limited 3G mobile resources efficiently is 3G mobile traffic offloading through WiFi by the user side. However, we currently do not know enough about how effective the mobile traffic offloading is in the wild. In this paper, we report the results of a two-day-long user-based measurement of mobile traffic offloading by over 400 android smartphone users in Japan. We first explain that the variation of aggregated traffic volume via WiFi is much greater than that via 3G in our dataset. Next, we show that the traffic volume offloading through WiFi is common over whole weekend and weekday night, though weekday rush hours have less chance of traffic offloading. Our results emphasize that a small fraction of users contribute to a large fraction of offload traffic volume. In fact, our per-user level analysis reveals that the top 30% of users downloaded over 90% of their total traffic volume via WiFi. However, bottom 20% of users stuck to 3G only and over 50% of users turned off the WiFi interface in business hours. Also, 17.4% of the total traffic volume was generated by users whose WiFi traffic volume was less than 1MB. We observed that some hybrid users downloaded most of their traffic volume via WiFi in shorter durations. In this sense, there is more room to improve the current traffic offloading by promoting users to use WiFi more effectively. Furthermore, we demonstrate that WiFi offloading is mainly performed by access points (APs) in homes while the use of public WiFi APs is still uncommon in our dataset."
1830824,15258,122,Eliminating global interpreter locks in ruby through hardware transactional memory,2014,"Many scripting languages use a Global Interpreter Lock (GIL) to simplify the internal designs of their interpreters, but this kind of lock severely lowers the multi-thread per-formance on multi-core machines. This paper presents our first results eliminating the GIL in Ruby using Hardware Transactional Memory (HTM) in the IBM zEnterprise EC12 and Intel 4th Generation Core processors. Though prior prototypes replaced a GIL with HTM, we tested real-istic programs, the Ruby NAS Parallel Benchmarks (NPB), the WEBrick HTTP server, and Ruby on Rails. We devised a new technique to dynamically adjust the transaction lengths on a per-bytecode basis, so that we can optimize the likelihood of transaction aborts against the relative overhead of the instructions to begin and end the transactions. Our results show that HTM achieved 1.9- to 4.4-fold speedups in the NPB programs over the GIL with 12 threads, and 1.6- and 1.2-fold speedups in WEBrick and Ruby on Rails, respectively. The dynamic transaction-length adjustment chose the best transaction lengths for any number of threads and applications with sufficiently long running times."
1013182,15258,369,How Much Can Wi-Fi Offload? A Large-Scale Dense-Urban Indoor Deployment Study,2012,"this paper is envisaged to provide a first quantitative study on how much indoor deployed Wi-Fi can offload the operator's 3G HSPA macro cellular networks in a real large-scale dense-urban scenario. Wi-Fi has been perceived as a cost-effective mean of adding wireless capacity by leveraging low-cost access points and unlicensed spectrum. However, the quantitative offloading gain that Wi-Fi can achieve is still unknown. We studied the Wi-Fi offloading gain as a function of access point density, where it is shown that 10 access points/km2 can already boost average user throughput by 300% and the gain increases linearly proportional to the access point density. Indoor Wi-Fi deployment also significantly reduces the number of users in outage, especially for indoor area. A user is considered to be in outage if they have a user throughput less than 512 kbps. We also propose three Wi-Fi deployment algorithms: Traffic-centric, Outage-centric, Uniform Random. Simulation results show that Traffic-centric performs best in boosting average user throughput while Outage-centric performs best in reducing user outage. Finally, Wi-Fi offloading solution is compared with another offloading solution - HSPA Femto cell. We show that Wi-Fi provides both much higher average user throughput and network outage reduction than HSPA Femto cells by exploring 20 MHz unlicensed ISM band."
1827802,15258,369,Equivalent Tapped Delay Line Channel Responses with Reduced Taps,2013,"Typically, a multipath channel response can be characterized as a sum of Rayleigh-fading ''rays'', each defined by a time delay and a mean-square amplitude. Therefore, the channel response can be largely described by a power delay profile (PDP), which is the set of mean-square ray amplitudes and relative delays. Here, we address the following question: Given an actual (or ''true'') PDP, PDP(τ), which may have many rays, is there a 3-ray (i.e. 3- tap) equivalent response, derivable from PDP(τ), that can be used to accurately estimate the average bit error rate,  , vs. receiver input signal- to-noise ratio, SNR? The results reported here give an affirmative answer, e.g., for   values down to = 10 -4 , the required SNR using a 3-tap equivalent channel response is less than 1.1 dB larger than that required for the ''true'' channel. This agreement can be improved upon, suggesting further work on deriving and evaluating equivalent 3-tap channels. We discuss the benefits of such simplifications for hardware emulators as well as for simulation and analysis."
914338,15258,507,Scalable atomic visibility with RAMP transactions,2014,"Databases can provide scalability by partitioning data across several servers. However, multi-partition, multi-operation transactional access is often expensive, employing coordination-intensive locking, validation, or scheduling mechanisms. Accordingly, many real-world systems avoid mechanisms that provide useful semantics for multi-partition operations. This leads to incorrect behavior for a large class of applications including secondary indexing, foreign key enforcement, and materialized view maintenance. In this work, we identify a new isolation model---Read Atomic (RA) isolation---that matches the requirements of these use cases by ensuring atomic visibility: either all or none of each transaction's updates are observed by other transactions. We present algorithms for Read Atomic Multi-Partition (RAMP) transactions that enforce atomic visibility while offering excellent scalability, guaranteed commit despite partial failures (via synchronization independence), and minimized communication between servers (via partition independence). These RAMP transactions correctly mediate atomic visibility of updates and provide readers with snapshot access to database state by using limited multi-versioning and by allowing clients to independently resolve non-atomic reads. We demonstrate that, in contrast with existing algorithms, RAMP transactions incur limited overhead---even under high contention---and scale linearly to 100 servers."
1130501,15258,369,Probabilistic Routing Based on History of Messages in Delay Tolerant Networks,2011,"Unexpected disconnections, long transmission latencies and network heterogeneity that DTN is meant to support make the routing problem in DTN very complicated. In DTN, probabilistic based routing protocols make use of nodes' mobility history to gauge delivery likelihood of nodes. However, the delivery likelihood of the nodes is not the only factor that affects the message delivery likelihood. In this paper, a detailed analysis of routing in DTN reveals the forwarding decisions that could go wrong due to the store-and-forward nature of DTN. Based on the analysis, we propose a history of messages concept which Probabilistic Routing Protocol using History of Encounters and Transitivity (PRoPHET) can utilize to improve the chances of message delivery. Our simulations show that using the messages' history improves the message delivery performance of PRoPHET and is comparable to MaxProp."
1071304,15258,507,The big data ecosystem at LinkedIn,2013,"The use of large-scale data mining and machine learning has proliferated through the adoption of technologies such as Hadoop, with its simple programming semantics and rich and active ecosystem. This paper presents LinkedIn's Hadoop-based analytics stack, which allows data scientists and machine learning researchers to extract insights and build product features from massive amounts of data. In particular, we present our solutions to the ``last mile'' issues in providing a rich developer ecosystem. This includes easy ingress from and egress to online systems, and managing workflows as production processes. A key characteristic of our solution is that these distributed system concerns are completely abstracted away from researchers. For example, deploying data back into the online system is simply a 1-line Pig command that a data scientist can add to the end of their script. We also present case studies on how this ecosystem is used to solve problems ranging from recommendations to news feed updates to email digesting to descriptive analytical dashboards for our members."
2430016,15258,293,SyFi: a systematic approach for estimating stateful firewall performance,2012,"Due to the lack of a standardized methodology for reporting firewall performance, current datasheets are designed for marketing and provide inflated throughput measurements obtained under unrealistic scenarios. As a result, customers lack usable metrics to select a device that best meets their needs.#R##N##R##N#In this paper, we develop a systematic approach to estimate the performance offered by stateful firewalls. To do so, we first conduct extensive experiments with two enterprise firewalls in a wide range of configurations and traffic profiles to identify the characteristics of a network's traffic that affect firewall performance. Based on the observations from our measurements, we develop a model that can estimate the expected performance of a particular stateful firewall when deployed in a customer's network. Our model ties together a succinct set of network traffic characteristics and firewall benchmarks. We validate our model with a third enterprise-grade firewall, and find that it predicts firewall throughput with less than 6-10% error across a range of traffic profiles."
130825,15258,293,"Mobile Network Performance from User Devices: A Longitudinal, Multidimensional Analysis",2014,"In the cellular environment, operators, researchers and end users have poor visibility into network performance for devices. Improving visibility is challenging because this performance depends factors that include carrier, access technology, signal strength, geographic location and time. Addressing this requires longitudinal, continuous and large-scale measurements from a diverse set of mobile devices and networks.#R##N##R##N#This paper takes a first look at cellular network performance from this perspective, using 17 months of data collected from devices located throughout the world. We show that (i) there is significant variance in key performance metrics both within and across carriers; (ii) this variance is at best only partially explained by regional and time-of-day patterns; (iii) the stability of network performance varies substantially among carriers. Further, we use the dataset to diagnose the causes behind observed performance problems and identify additional measurements that will improve our ability to reason about mobile network behavior."
1478933,15258,343,Machiavellian routing: improving internet availability with BGP poisoning,2011,"We propose a new approach to mitigate disruptions of Internet connectivity. The Internet was designed to always find a route if there is a policy-compliant path; however, in many cases, connectivity is disrupted despite the existence of an underlying valid path. The research community has done considerable work on this problem, much of it focused on short-term outages that occur during route convergence. There has been less progress on addressing avoidable long-lasting outages. Our measurements show that long-lasting events contribute significantly to overall unavailability.   To address these long-term problems, we develop a system, Machiavellian routing, for automatic failure remediation, centered around the use of BGP poisoning. With poisoning, an edge network can cause other networks to send traffic to it via paths that avoid a problem in a particular transit ISP. We describe the key challenges to using poisoning to improve Internet connectivity, and we develop a set of techniques to use it predictably, accurately, and effectively."
710101,15258,369,Capacity and Power Allocation of Dual-Hop AF Relaying over Rayleigh Fading Channels,2012,"In this paper, we investigate the capacity and optimal power allocation (PA) scheme between the source and relay for a dual-hop amplify-and-forward (AF) system over non-symmetric Rayleigh fading channels with channel information available at the relay. At first, a closed-form expression of the mutual information (MI) between the input and output of the considered channel is obtained. Since only the exponential integral is involved, the derived expression is useful in finding the optimal PA to achieve the capacity. By further considering high and low signal-to-noise ratio (SNR) regimes, we present tight yet simple approximations to this MI, which can be used to show the advantage of knowing channel information at the relay. Then, focusing on the problem of optimal PA, we first derive a closed- form derivative of the MI. A simple bisection method is then proposed to find the optimal PA scheme. While uniform PA is shown to achieve the capacity at any SNR over the symmetric channel, its optimality can only be observed at low SNRs over a non- symmetric channel. In other SNR regimes, numerical results reveal that uniform PA experiences a significant loss. A comparison between the dual-hop and direct transmission scheme is also made, where we show that the dual-hop scheme using the optimal PA can provide impressive rate increases in medium SNR ranges in various network configurations."
34088,15258,293,Diagnosing Path Inflation of Mobile Client Traffic,2014,"As mobile Internet becomes more popular, carriers and content providers must engineer their topologies, routing configurations, and server deployments to maintain good performance for users of mobile devices. Understanding the impact of Internet topology and routing on mobile users requires broad, longitudinal network measurements conducted from mobile devices. In this work, we are the first to use such a view to quantify and understand the causes of geographically circuitous routes from mobile clients using 1.5 years of measurements from devices on 4 US carriers. We identify the key elements that can affect the Internet routes taken by traffic from mobile users (client location, server locations, carrier topology, carrier/content-provider peering). We then develop a methodology to diagnose the specific cause for inflated routes. Although we observe that the evolution of some carrier networks improves performance in some regions, we also observe many clients - even in major metropolitan areas - that continue to take geographically circuitous routes to content providers, due to limitations in the current topologies."
1417791,15258,339,CloudER: a framework for automatic software vulnerability location and patching in the cloud,2012,"In a virtualization-based cloud infrastructure, customers of the cloud deploy virtual machines (VMs) with their own applications and customized runtime environments. The cloud provider supports the execution of these VMs without detailed knowledge of the guest applications and operating systems in the VMs. In addition to elastic resource provisioning for the VMs, a desirable value-added service the cloud provider can provide is the emergency response to runtime incidences of software bugs and vulnerabilities. The challenge is to facilitate the automatic runtime detection, location, and patching of the software vulnerability -- outside the VMs and without the source code. In this paper, we present CloudER, a cloud emergency room architecture that automatically detect, locate, and patch software vulnerabilities in cloud application binaries at runtime. CloudER leverages an existing taint-based system (Demand Emulation) for runtime anomaly detection, employs new algorithms for software vulnerability location and patch generation, and adapts a virtual machine introspection system (XenAccess) for dynamic patching. Our preliminary evaluation experiments with a number of real-world server applications show that CloudER achieves timely response to runtime software faults or attacks from outside the VMs. The main contributions of this paper are highlighted as follows: (1) CloudER is an integrated architecture that improves the runtime reliability of cloud applications. It covers the full life cycle of exploit detection, culprit instruction location, patch generation and application, and execution state recording and reset -- all performed from outside the protected VM and without the source code of the applications. (2) While leveraging existing techniques for taint-based exploit detection, CloudER involves new methods for culprit instruction location and binary patch generation. The methods cover some of the most common types of software vulnerabilities and the patches generated are of small size (tens of bytes). (3) CloudER incurs reasonable performance overhead to the application in comparison with running the application in an unprotected VM. The interruption to the production VM's execution (for culprit instruction location and patch generation) is less than half a minute in our experiments with real-world applications."
2258385,15258,343,Tiny packet programs for low-latency network control and monitoring,2013,"Networking researchers and practitioners strive for a greater degree of control and programmability to rapidly innovate in production networks. While this desire enjoys commercial success in the control plane through efforts such as OpenFlow, the dataplane has eluded such programmability. In this paper, we show how end-hosts can coordinate with the network to implement a wide-range of network tasks, by embedding tiny programs into packets that execute directly in the  dataplane . Our key contribution is a programmatic interface between end-hosts and the switch ASICs that does not sacrifice raw performance. This interface allows network tasks to be refactored into two components: (a) a simple program that executes on the ASIC, and (b) an expressive task distributed across end-hosts. We demonstrate the promise of this approach by implementing three tasks using read/write programs: (i) detecting short-lived congestion events in high speed networks, (ii) a rate-based congestion control algorithm, and (iii) a forwarding plane network debugger."
2159681,15258,343,A Highly Available Software Defined Fabric,2014,"Existing SDNs rely on a collection of intricate, mutually-dependent mechanisms to implement a logically centralized control plane. These cyclical dependencies and lack of clean separation of concerns can impact the availability of SDNs, such that a handful of link failures could render entire portions of an SDN non-functional. This paper shows why and when this could happen, and makes the case for taking a fresh look at architecting SDNs for robustness to faults from the ground up. Our approach carefully synthesizes various key distributed systems ideas -- in particular, reliable flooding, global snapshots, and replicated controllers. We argue informally that it can offer high availability in the face of a variety of network failures, but much work needs to be done to make our approach scalable and general. Thus, our paper represents a starting point for a broader discussion on approaches for building highly available SDNs."
2435710,15258,369,Deployment of LTE In-Band Relay and Micro Base Stations in a Realistic Metropolitan Scenario,2011,"Complementing macro-only cellular networks with low-powered base stations is a promising deployment solution to improve both network coverage and capacity, and cope with exploding data traffic in the coming years. In Beyond 3G Networks, such as LTE-Advanced, Relay Nodes and micro base stations can transmit on the same spectrum as the overlaying macro layer, and guarantee higher spatial reuse through cell splitting. Differently from previous research studies, this paper specifically aims at evaluating and comparing the potential of LTE relay and micro deployment in a realistic metropolitan scenario. A heuristic deployment algorithm which combines network coverage and realistic spatial user density information is also proposed. The results show that for the downlink, in-band relays can be deployed to improve network coverage, but not substantially the network capacity due to the limitation of the wireless backhaul link. In-band micro deployment, on the other hand, is the best solution to boost downlink network capacity (up to 5 times), while also providing full network coverage."
1880777,15258,369,Energy-Constrained Wi-Fi Offloading Method Using Prefetching,2014,"The explosive growth of mobile data traffic causes immense pressure on the limited spectrum of cellular networks (3G/4G) and the deterioration in the quality of wireless communication. Even though mobile network operators deploy WiFi access points (WiFi APs) to offload the traffic from 3G/4G to WiFi, WiFi connectivity is far from ubiquitous. To increase opportunities of offloading, some methods leveraging delay tolerance are proposed. These methods, however, cause a poor performance on delay sensitive applications like Web browsing and streaming of video and audio. To address this problem, we introduce a WiFi offloading method using prefetching. While a user stays in a WiFi area, our method predicts the Web pages that will be requested by the user over 3G/4G after leaving from the WiFi area, and performs prefetching of those pages over WiFi. This allows the user to browse prefetched pages instantly without downloading them over 3G/4G. The simulation results show that our method achieved approximately 11% of offloading of data traffic, suppressing energy consumption within the amount consumed when performing communication only over 3G/4G."
1665858,15258,122,Work-stealing with configurable scheduling strategies,2013,"Work-stealing systems are typically oblivious to the nature of the tasks they are scheduling. They do not know or take into account how long a task will take to execute or how many subtasks it will spawn. Moreover, task execution order is typically determined by an underlying task storage data structure, and cannot be changed. There are thus possibilities for optimizing task parallel executions by providing information on specific tasks and their preferred execution order to the scheduling system.   We investigate generalizations of work-stealing and introduce a framework enabling applications to dynamically provide hints on the nature of specific tasks using  scheduling strategies . Strategies can be used to independently control both local task execution and steal order. Strategies allow optimizations on specific tasks, in contrast to more conventional  scheduling policies  that are typically global in scope. Strategies are  composable  and allow different, specific scheduling choices for different parts of an application simultaneously. We have implemented a work-stealing system based on our strategy framework. A series of benchmarks demonstrates beneficial effects that can be achieved with scheduling strategies."
2322123,15258,339,POSTER: Introducing pathogen: a real-time virtualmachine introspection framework,2013,"In recent years, malware has grown extremely rapidly in complexity and rates of system infection. Current generation anti-virus and anti-malware software provides system protection through the use of locally installed monitoring agents, which are dependent upon vendor generated signature and heuristic based rules. However, because these monitoring agents are installed within the systems they are trying to protect, they themselves are potential targets of attack by malware. Pathogen overcomes this issue by using a real-time system monitoring and analysis framework that utilises Virtual Machine introspection (VMI) to allow the monitoring of a system without the need for any locally installed agents. One of the main research problems in VMI is how to parse and interpret the memory of an executing system from outside of that system. Pathogen's contribution is a lightweight introspection framework that bridges the semantic gap."
1817598,15258,122,Task mapping stencil computations for non-contiguous allocations,2014,"We examine task mapping algorithms for systems that allocate jobs non-contiguously. Several studies have shown that task placement affects job running time. We focus on jobs with a stencil communication pattern and use experiments on a Cray XE to evaluate novel task mapping algorithms as well as some adapted to this setting. This is done with the miniGhost miniApp which mimics the performance of CTH, a shock physics application. Our strategies improve average and single-run times by as much as 28% and 36% over a baseline strategy, respectively."
1235002,15258,343,Towards systematic roadmaps for networked systems,2012,"Networked systems have benefited from unprecedented growth in hardware capabilities, but, as we move closer to the end of the Moore's law era, future networked systems are likely to be more constrained by hardware capabilities than they have been in the past. We take the position that the networking community should, in response to this development, proactively and systematically develop  networking roadmaps , which attempt to predict how trends in hardware capabilities will impact networked systems. In this paper, we discuss a possible methodology for developing networking roadmaps, and present two case studies that illustrate the methodology and reveal how increasing hardware unreliability can affect the performance of routing and transport protocols."
1609212,15258,339,Content-based isolation: rethinking isolation policy design on client systems,2013,"Modern client platforms, such as iOS, Android, Windows Phone, and Windows 8, have progressed from a per-user isolation policy, where users are isolated but a user's applications run in the same isolation container, to an application isolation policy, where different applications are isolated from one another. However, this is not enough because mutually distrusting content can interfere with one another inside a single application. For example, an attacker-crafted image may compromise a photo editor application and steal other images processed by the editor.   In this paper, we advocate a content-based principal model in which the OS treats content owners as its principals and isolates content of different owners from one another. Our key contribution is to generalize the content-based principal model from web browsers, namely, the same-origin policy, into an isolation policy that is suitable for all applications. The key challenge we faced is to support flexible isolation granularities while remaining compatible with the web. In this paper, we present the design, implementation, and evaluation of our prototype system that tackles this challenge."
1063490,15258,369,Characterizing and Exploiting Temporal-Spatial Radio Resource Margins in Cellular Networks,2014,"Understanding the characteristics of spectrum utilization is essential in providing guidelines for resource allocation. In this paper, a detailed measurement analysis of spectrum efficiency is performed, with data collected from tens of thousands of base stations during fifteen months. We examine the characteristics of radio resource margins (RM) extensively, including its temporal skewness, diurnal patterns, weekly periodicity and spatial skewness. Main findings include that radio resources are not utilized efficiently both temporally and spatially, and radio RM and traffic load show strong weekly periodicity which is predictable. Inspired by the inefficient utilization of radio resources, we then devise an optimization scheme for dynamic radio resources reconfiguration and experimental results prove that it improves radio resources utilization efficiency and traffic load balance significantly."
1626856,15258,507,PLANET: making progress with commit processing in unpredictable environments,2014,"Latency unpredictability in a database system can come from many factors, such as load spikes in the workload, inter-query interactions from consolidation, or communication costs in cloud computing or geo-replication. High variance and high latency environments make developing interactive applications difficult, because transactions may take too long to complete, or fail unexpectedly. We propose Predictive Latency-Aware NEtworked Transactions (PLANET), a new transaction programming model and underlying system support to address this issue. The model exposes the internal progress of the transaction, provides opportunities for application callbacks, and incorporates commit likelihood prediction to enable good user experience even in the presence of significant transaction delays. The mechanisms underlying PLANET can be used for admission control, thus improving overall performance in high contention situations. In this paper, we present this new transaction programming model, demonstrate its expressiveness via several use cases, and evaluate its performance using a strongly consistent geo-replicated database across five data centers."
161552,15258,293,Speed measurements of residential internet access,2012,"The spread of residential broadband Internet access is raising the question of how to measure Internet speed. We argue that available bandwidth is a key metric of access link speed. Unfortunately, the performance of available bandwidth estimation tools has rarely been tested from hosts connected to residential networks. This paper compares the accuracy and overhead of state-of-the-art available bandwidth estimation tools from hosts connected to commercial ADSL and cable networks. Our results show that, when using default settings, some tools underestimate the available bandwidth by more than 60%. We demonstrate using controlled testbeds that this happens because current home gateways have a limited packet forwarding rate."
2071858,15258,122,The tasks with effects model for safe concurrency,2013,"Today's widely-used concurrent programming models either provide weak safety guarantees, making it easy to write code with subtle errors, or are limited in the class of programs that they can express. We propose a new concurrent programming model based on  tasks with effects  that offers strong safety guarantees while still providing the flexibility needed to support the many ways that concurrency is used in complex applications. The core unit of work in our model is a dynamically-created task. The model's key feature is that each task has programmer-specified  effects , and a run-time scheduler is used to ensure that two tasks are run concurrently only if they have non-interfering effects. Through the combination of statically verifying the declared effects of tasks and using an effect-aware run-time scheduler, our model is able to guarantee strong safety properties, including data race freedom and atomicity. It is also possible to use our model to write programs and computations that can be statically proven to behave deterministically. We describe the tasks with effects programming model and provide a formal dynamic semantics for it. We also describe our implementation of this model in an extended version of Java and evaluate its use in several programs exhibiting various patterns of concurrency."
1519482,15258,8228,Reducing backhaul costs for mobile content delivery — An analytical study,2012,"Mobile carriers are currently facing the tremendous challenge of coping with the rapid data traffic growth stemming from smart phones and data dongles. Recent studies have shown that caching of high volume content within carrier networks has the potential of substantial cost savings in network resources. This paper analyzes the effectiveness of caching in mobile carrier networks, being enabled by distributed mobility gateways and content caches, and estimates how much cost savings an operator can expect for different cache deployment scenarios. The study considers various backhaul network characteristics and several content replication strategies."
1569430,15258,8228,Multi-functional emulator for traffic analysis,2013,"We present the versatile functionality of our novel user behavior based traffic emulation system in this paper. We show the unique feature of the system, i. e., it is capable of working on different platforms (Windows, Android), on different access technologies (wired, WiFi, 3G) and as a remote controlled system on different sites (Europe, Asia, South America). Our examples exhibit some of the manifold traffic analysis possibilities as a result of this key functionality. We have also made our system available to the public [1]."
1736692,15258,507,LinkBench: a database benchmark based on the Facebook social graph,2013,"Database benchmarks are an important tool for database researchers and practitioners that ease the process of making informed comparisons between different database hardware, software and configurations. Large scale web services such as social networks are a major and growing database application area, but currently there are few benchmarks that accurately model web service workloads.   In this paper we present a new synthetic benchmark called LinkBench. LinkBench is based on traces from production databases that store social graph data at Facebook, a major social network. We characterize the data and query workload in many dimensions, and use the insights gained to construct a realistic synthetic benchmark. LinkBench provides a realistic and challenging test for persistent storage of social and web service data, filling a gap in the available tools for researchers, developers and administrators."
1679323,15258,208,From Task Graphs to Concrete Actions: A New Task Mapping Algorithm for the Future Internet of Things,2014,"Task mapping, which basically consists of mapping a set of tasks onto a set of nodes, is a well-known problem in distributed computing research. As a particular case of distributed systems, the Internet of Things (IoT) poses a set of renewed challenges, because of its scale, heterogeneity and properties traditionally associated with wireless sensor networks (WSN), shared sensing, continous processing and real time computing. To handle IoT features, we present a formalization of the task mapping problem that captures the varying consumption of resources and various constraints (location, capabilities, QoS) in order to compute a mapping that guarantees the lifetime of the concurrent tasks inside the network and the fair allocation of tasks among the nodes. It results in a binary programming problem for which we provide an efficient heuristic that allows its resolution in polynomial time. Our experiments show that our heuristic: (i) gives solutions that are close to optimal and (ii) can be implemented on reasonably powerful Things and performed directly within the network, without requiring any centralized infrastructure."
799203,15258,369,Use of Coordinated Multipoint Transmission for Relaxation of Relay Link Bottlenecks,2014,"The emerging Long Term Evolution-Advanced (LTE-A) standard promises improvements in throughput and reduction in costs-per-bit, through use of techniques, such as, relaying and coordinated multipoint (CoMP) transmission and reception. The inherent self-backhauling of relays nodes makes them an attractive solution in areas where backhaul is either unavailable or costly. However, the performance of the backhaul relay link limits overall performance of relay systems, particularly for relays deployed in the cell edge. In this paper, we propose CoMP-enhancements in order to relax the relay link bottleneck. We study this proposed approach through system simulations of a selected realistic deployment scenario. The results demonstrate that use of a quantized co-phasing (QCP) CoMP technique provides significant signal- to-interference-plus- noise-ratio (SINR) gains and end-to-end throughput improvements for user equipment connected to the relays, even with simple scheduling techniques."
563138,15258,293,Detecting and analyzing automated activity on twitter,2011,"We present a method for determining whether a Twitter account exhibits automated behavior in publishing status updates known as tweets. The approach uses only the publicly available timestamp information associated with each tweet. After evaluating its effectiveness, we use it to analyze the Twitter landscape, finding that 16% of active accounts exhibit a high degree of automation. We also find that 11% of accounts that appear to publish exclusively through the browser are in fact automated accounts that spoof the source of the updates."
2450595,15258,339,"Detecting stealthy, distributed SSH brute-forcing",2013,"In this work we propose a general approach for detecting distributed malicious activity in which individual attack sources each operate in a stealthy, low-profile manner. We base our approach on observing statistically significant changes in a parameter that summarizes aggregate activity, bracketing a distributed attack in time, and then determining which sources present during that interval appear to have coordinated their activity. We apply this approach to the problem of detecting stealthy distributed SSH bruteforcing activity, showing that we can model the process of legitimate users failing to authenticate using a beta-binomial distribution, which enables us to tune a detector that trades off an expected level of false positives versus time-to-detection. Using the detector we study the prevalence of distributed bruteforcing, finding dozens of instances in an extensive 8-year dataset collected from a site with several thousand SSH users. Many of the attacks---some of which last months---would be quite difficult to detect individually. While a number of the attacks reflect indiscriminant global probing, we also find attacks that targeted only the local site, as well as occasional attacks that succeeded."
1056322,15258,369,Puncturing of CRC Codes for IEEE 802.11ah,2013,"In some cases, like the proposed IEEE 802.11ah draft specification, there arises a need to have a short Cyclic Redundancy Check (CRC) code to detect errors on the information bits in the various signal fields. While an optimum CRC of the required length can be chosen for this, in order to minimize complexity it may be desirable to puncture an existing CRC generator to reduce the number of parity bits transmitted. In this paper we evaluate puncturing of a CRC-8 generator to generate a 4-bit CRC such that the minimum Hamming distance of the resultant code is 2."
2447042,15258,343,Intelligent design enables architectural evolution,2011,"What does it take for an Internet architecture to be evolvable? Despite our ongoing frustration with today's rigid IP-based architecture and the research community's extensive research on clean-slate designs, it remains unclear how to best design for architectural evolvability. We argue here that evolvability is far from mysterious. In fact, we claim that only a few intelligent design changes are needed to support evolvability. While these changes are definitely nonincremental (i.e., cannot be deployed in an incremental fashion starting with today's architecture), they follow directly from the well-known engineering principles of indirection, modularity, and extensibility."
1707018,15258,422,ISIS: a networked-epidemiology based pervasive web app for infectious disease pandemic planning and response,2014,"We describe ISIS, a high-performance-computing-based application to support computational epidemiology of infectious diseases. ISIS has been developed over the last seven years in close coordination with public health and policy experts. It has been used in a number of important federal planning and response exercises. ISIS grew out of years of experience in developing and using HPC-oriented models of complex socially coupled systems. This identified the guiding principle that  complex models will be used by domain experts only if they can do realistic analysis without becoming computing experts .   Using ISIS, one can carry out detailed computational experiments as they pertain to planning and response in the event of a pandemic. ISIS is designed to support networked epidemiology -- study of epidemic processes over social contact networks. The current system can handle airborne infectious diseases such as influenza, pertussis, and smallpox. ISIS is comprised of the following basic components: ( i ) a web app that serves as the user-interface, ( ii ) a middleware that coordinates user interaction via the web app with backend models and databases, ( iii ) a backend computational modeling framework that is comprised of highly resolved epidemic simulations combined with highly realistic control strategies that include pharmaceutical as well as non-pharmaceutical interventions and ( iv ) a backend data management framework that manages complex unstructured and semi-structured data.   ISIS has been used in over a dozen case studies defined by the DoD, DHHS, NIH, BARDA and NSC. We describe three recent studies illustrating the use of ISIS in real-world settings:( i ) uses of ISIS during the H1N1 pandemic,  Cii ) supporting a US military planning exercise, and ( iii ) distribution of limited stockpile of pharmaceuticals using public and private outlets."
151171,15258,293,Pitfalls in HTTP traffic measurements and analysis,2012,"Being responsible for more than half of the total traffic volume in the Internet, HTTP is a popular subject for traffic analysis. From our experiences with HTTP traffic analysis we identified a number of pitfalls which can render a carefully executed study flawed. Often these pitfalls can be avoided easily. Based on passive traffic measurements of 20.000 European residential broadband customers, we quantify the potential error of three issues: Non-consideration of persistent or pipelined HTTP requests, mismatches between the Content-Type header field and the actual content, and mismatches between the Content-Length header and the actual transmitted volume. We find that 60% (30%) of all HTTP requests (bytes) are persistent (i.e., not the first in a TCP connection) and 4% are pipelined. Moreover, we observe a Content-Type mismatch for 35% of the total HTTP volume. In terms of Content-Length accuracy our data shows a factor of at least 3.2 more bytes reported in the HTTP header than actually transferred."
122257,15258,374,WiFiHop - mitigating the Evil twin attack through multi-hop detection,2011,"Public hotspots have undeniable benefits for both users and providers. Users get ubiquitous internet access and providers attract new potential clients. However, the security mechanisms currently available (e.g. WEP, WPA) fail to prevent a myriad of attacks. A particularly damaging attack to public WiFi networks is the evil twin attack, where an attacker masquerades as a legitimate provider to mount wireless interposition attacks. This paper proposes WiFiHop, a client-sided tool that leverages the intrinsic multi-hop characteristics of the evil twin attack, to detect it. The proposed tool is technology independent (e.g. network bandwidth or latency), and detects the attacks in real time (i.e. before any user traffic is transmitted). It works with both open and encrypted networks. This tool was tested in a real-life scenario, and its effectiveness demonstrated."
2535636,15258,8306,Replay debugging: leveraging record and replay for program debugging,2014,"Hardware-assisted Record and Deterministic Replay (RnR) of programs has been proposed as a primitive for debugging hard-to-repeat software bugs. However, simply providing support for repeatedly stumbling on the same bug does not help diagnose it. For bug diagnosis, developers typically want to modify the code, e.g., by creating and operating on new variables, or printing state. Unfortunately, this renders the RnR log inconsistent and makes Replay Debugging (i.e., debugging while using an RnR log for replay) dicey at best   This paper presents rdb, the first scheme for replay debugging that guarantees exact replay. rdb relies on two mechanisms. The first one is compiler support to split the instrumented application into two executables: one that is identical to the original program binary, and another that encapsulates all the added debug code. The second mechanism is a runtime infrastructure that replays the application and, without affecting it in any way, invokes the appropriate debug code at the appropriate locations. We describe an implementation of rdb based on LLVM and Pin, and show an example of how rdb's replay debugging helps diagnose a real bug"
1454412,15258,8228,Constructing a virtual networking environment in a Geo-distributed programmable layer-2 networking environment (G-PLaNE),2012,"With Cloud Computing technology occupying the majority of future Internet research and development work, research on deploying and extending existing capabilities onto a newly emerging infrastructure becomes more significant. For example, extending the virtual network provisioning capability onto a Geo-distributed programmable layer-2 networking environment (G-PLaNE) is a novel attempt and is different from in a single domain system. In this paper, we aim to illustrate how to construct the virtual networking environment upon our self-designed resource provisioning system consisting of multiple clusters through G-PLaNE. Experimenters and researchers are able to develop and explore their own mechanisms in our platform. Furthermore, a concrete example named Secure and Resilient Virtual Trust Routing (SeRViTR) is given to illustrate how this can be constructed over G-PLaNE."
505459,15258,293,Measuring and characterizing end-to-end route dynamics in the presence of load balancing,2011,"Since Paxson's study over ten years ago, the Internet has changed considerably. In particular, routers often perform load balancing. Disambiguating routing changes from load balancing using traceroute-like probing requires a large number of probes. Our first contribution is FastMapping, a probing method that exploits load balancing characteristics to reduce the number of probes needed to measure accurate route dynamics. Our second contribution is to reappraise Paxson's results using datasets with high-frequency route measurements and complete load balancing information. Our analysis shows that, after removing dynamics due to load balancing, Paxson's observations on route prevalence and persistence still hold."
644890,15258,293,Internet censorship in china: where does the filtering occur?,2011,"China filters Internet traffic in and out of the country. In order to circumvent the firewall, it is helpful to know where the filtering occurs. In this work, we explore the AS-level topology of China's network, and probe the firewall to find the locations of filtering devices. We find that even though most filtering occurs in border ASes, choke points also exist in many provincial networks. The result suggests that two major ISPs in China have different approaches placing filtering devices."
1606875,15258,343,Reclaiming the Brain: Useful OpenFlow Functions in the Data Plane,2014,"Software-defined networks (SDNs) have the potential to radically simplify the network management by providing a programmatic interface to a logically centralized controller. However, outsourcing the management to the software controller comes at a price, and good tradeoffs have to be found between the benefits of a fine-grained control and its costs.   In this paper, we show that OpenFlow, the predominant SDN protocol, allows to implement powerful functions in the south, i.e., in the data plane. Our approach, called SmartSouth, can be used to reduce interactions with the control plane as well as to make the network more robust. Moreover, while rendering the data plane smarter, SmartSouth only relies on the standard OpenFlow match-action paradigm; thus, the data plane functions remain formally verifiable---a key benefit of SDN. To demonstrate the potential of SmartSouth, we discuss four basic applications: (1) topology snapshot, (2) anycast, (3) blackhole- and (4) critical node detection."
1256937,15258,507,On brewing fresh espresso: LinkedIn's distributed data serving platform,2013,"Espresso is a document-oriented distributed data serving platform that has been built to address LinkedIn's requirements for a scalable, performant, source-of-truth primary store. It provides a hierarchical document model, transactional support for modifications to related documents, real-time secondary indexing, on-the-fly schema evolution and provides a timeline consistent change capture stream. This paper describes the motivation and design principles involved in building Espresso, the data model and capabilities exposed to clients, details of the replication and secondary indexing implementation and presents a set of experimental results that characterize the performance of the system along various dimensions.   When we set out to build Espresso, we chose to apply best practices in industry, already published works in research and our own internal experience with different consistency models. Along the way, we built a novel generic distributed cluster management framework, a partition-aware change- capture pipeline and a high-performance inverted index implementation."
1792928,15258,8228,Radio resource management algorithms for efficient QoS provisioning over cognitive radio networks,2013,"This paper proposes two radio resource management (RRM) algorithms for efficient QoS provisioning over an infrastructure-based cognitive radio network architecture that enables for TV White Spaces exploitation. QoS provisioning and policy management is achieved via a spectrum broker that coordinates the RRM process among LTE secondary systems, under the real time secondary spectrum market policy. The proposed RRM algorithms administrate the economics of the transactions between the spectrum broker and secondary systems, following a fixed-price and an auction-based trading process. The validity of the proposed algorithms is verified via a number of tests, carried under controlled experimental conditions (i.e. simulations), evaluating spectrum broker benefit and secondary systems service rate."
101213,15258,293,How Vulnerable Are Unprotected Machines on the Internet,2014,"How vulnerable are unprotected machines on the Internet? Utilizing Amazon's Elastic Compute Cloud (EC2) service and our own VMware ESXi server, we launched and monitored 18 Windows machines (Windows 2008, XP and 7) without anti-virus or firewall protection at two distinct locations on the Internetin the cloud and on-premise. Some machines ran a wide-open configuration with all ports open and services emulated, while others had a out-of-the-box configuration with default ports and services. After launching, all machines received port scans within minutes and vulnerability probes within a couple of hours. Although all machines with wide-open configurations attracted exploitations within a day, machines with out-of-the-box configurations observed very few vulnerability exploitations regardless of their locations. From our months-long experiment we found that: a) attackers are constantly searching for victims; b) the more opening ports/listening services a machine has, the more risks it is exposed to; c) brute-force logins are the most common type of attack; d) exploitations targeting vulnerabilities of software or operating systems are not widely observed."
1513203,15258,8228,A centralised broker-based CR network architecture for TVWS exploitation under the RTSSM policy,2012,"The paper discusses the TV white spaces exploitation by a prototype centralised cognitive radio network architecture, under the real time secondary spectrum management scheme. Vital part of this architecture is a spectrum broker that coordinates the radio resources allocation process among secondary systems, as well as the transactions of spectrum trading following a fixed-price policy. Efficient broker operation as a matter of maximum-possible spectrum utilisation and minimum fragmentation is obtained by decision-making methods based on Backtracking, Simulated Annealing and Genetic algorithm. The validity of the proposed approach is verified via a number of experiments under controlled conditions, while its performance is evaluated against a number of secondary systems competing for TVWS exploitation, each one featuring different transmission characteristics."
1592019,15258,507,Fast database restarts at facebook,2014,"Facebook engineers query multiple databases to monitor and analyze Facebook products and services. The fastest of these databases is Scuba, which achieves subsecond query response time by storing all of its data in memory across hundreds of servers. We are continually improving the code for Scuba and would like to push new software releases at least once a week. However, restarting a Scuba machine clears its memory. Recovering all of its data from disk --- about 120 GB per machine --- takes 2.5-3 hours to read and format the data per machine. Even 10 minutes is a long downtime for the critical applications that rely on Scuba, such as detecting user-facing errors. Restarting only 2% of the servers at a time mitigates the amount of unavailable data, but prolongs the restart duration to about 12 hours, during which users see only partial query results and one engineer needs to monitor the servers carefully. We need a faster, less engineer intensive, solution to enable frequent software upgrades.   In this paper, we show that using shared memory provides a simple, effective, fast, solution to upgrading servers. Our key observation is that we can decouple the memory lifetime from the process lifetime. When we shutdown a server for a planned upgrade, we know that the memory state is valid (unlike when a server shuts down unexpectedly). We can therefore use shared memory to preserve memory state from the old server process to the new process. Our solution does not increase the server memory footprint and allows recovery at memory speeds, about 2-3 minutes per server. This solution maximizes uptime and availability, which has led to much faster and more frequent rollouts of new features and improvements. Furthermore, this technique can be applied to the in-memory state of any database, even if the memory contains a cache of a much larger disk-resident data set, as in most databases."
2283625,15258,343,Toward software-defined middlebox networking,2012,"Current middlebox (MB) management mechanisms are clumsy and unsuitable for taking full advantage of new MB deployment models and diverse MB functionality. Instead, we advocate for mechanisms that help exercise unified control over the key factors influencing MB operations. Our goal is to realize a  software-defined MB networking  framework to simplify management of complex, diverse functionalities and engender rich deployments. We discuss the major challenges that arise---representing, manipulating, and knowledgeably controlling MB state---and we present initial thoughts on the appropriate abstractions and interfaces to address them."
1769774,15258,343,The price is right: towards location-independent costs in datacenters,2011,"The performance and cost for tenants in today's datacenters depends on the location of their virtual machines within the datacenter. However, a tenant's location is a knob for the provider and is of no interest to the tenant. Hence, this paper argues for  location independent tenant costs in datacenters . We show how a change in today's IaaS offerings, coupled with a simple pricing scheme, can achieve this. We discuss how such a pricing model can be implemented and show that the consequent increase in system throughput can lead to a win-win situation- tenant costs are location independent and lower while provider revenue increases too."
2115344,15258,122,LHlf: lock-free linear hashing (poster paper),2012,"LHlf is a new hash table designed to allow very high levels of concurrency. The table is lock free and grows and shrinks auto-matically according to the number of items in the table. Insertions, lookups and deletions are never blocked. LHlf is based on linear hashing but adopts recursive split-ordering of the items within a bucket to be able to split and merge lists in a lock free manner. LHlf is as fast as the best previous lock-free design and in addition it offers stable performance, uses less space, and supports both expansions and contractions."
167617,15258,293,On multi---gigabit packet capturing with multi---core commodity hardware,2012,"Nowadays commodity hardware is offering an ever increasing degree of parallelism (CPUs with more and more cores, NICs with parallel queues). However, most of the existing network monitoring software has not yet been designed with high parallelism in mind. Therefore we designed a novel packet capturing engine, named PFQ, that allows efficient capturing and in---kernel aggregation, as well as connection---aware load balancing. Such an engine is based on a novel lockless queue and allows parallel packet capturing to let the user---space application arbitrarily define its degree of parallelism. Therefore, both legacy applications and natively parallel ones can benefit from such a capturing engine. In addition, PFQ outperforms its competitors both in terms of captured packets and CPU consumption."
1158058,15258,369,Less-than-Best-Effort Capacity Sharing over High BDP Networks with LEDBAT,2013,"There has been a renewed interest at the Internet Engineering Task Force (IETF) in using Less-than-Best Effort (LBE) methods for background applications. IETF recently published a RFC for Low Extra Delay Background Transport (LEDBAT), a congestion control algorithm for LBE transmissions. This paper provides an analysis of LEDBAT performance over congested large bandwidth × delay product (LBDP) networks, and assesses the validity of having a fixed target queuing time. In particular, we lead a study of the impact of this target queuing delay when LEDBAT is used over 4G satellite networks. The rationale is to explore the possibility to grab the unused 4G satellite links' capacity to carry non-commercial traffic. We show that this is achievable with LEDBAT. However, depending on the fluctuation of the load, performance improvements could be obtained by properly setting the target value. We generalize this evaluation over different congested LBDP networks and confirm that the target value might need to be adjusted to networks' and traffic's characteristics. Further work will study whether and how this parameter should be dynamically adapted, and LEDBAT's congestion control improved."
868534,15258,422,Connecting users across social media sites: a behavioral-modeling approach,2013,"People use various social media for different purposes. The information on an individual site is often incomplete. When sources of complementary information are integrated, a better profile of a user can be built to improve online services such as verifying online information. To integrate these sources of information, it is necessary to identify individuals across social media sites. This paper aims to address the cross-media user identification problem. We introduce a methodology (MOBIUS) for finding a mapping among identities of individuals across social media sites. It consists of three key components: the first component identifies users' unique behavioral patterns that lead to information redundancies across sites; the second component constructs features that exploit information redundancies due to these behavioral patterns; and the third component employs machine learning for effective user identification. We formally define the cross-media user identification problem and show that MOBIUS is effective in identifying users across social media sites. This study paves the way for analysis and mining across social media sites, and facilitates the creation of novel online services across sites."
817293,15258,122,Internally deterministic parallel algorithms can be fast,2012,"The virtues of deterministic parallelism have been argued for decades and many forms of deterministic parallelism have been described and analyzed. Here we are concerned with one of the strongest forms, requiring that for any input there is a  unique  dependence graph representing a trace of the computation annotated with every operation and value. This has been referred to as  internal determinism , and implies a sequential semantics--- i.e. , considering any sequential traversal of the dependence graph is sufficient for analyzing the correctness of the code. In addition to returning deterministic results, internal determinism has many advantages including ease of reasoning about the code, ease of verifying correctness, ease of debugging, ease of defining invariants, ease of defining good coverage for testing, and ease of formally, informally and experimentally reasoning about performance. On the other hand one needs to consider the possible downsides of determinism, which might include making algorithms (i) more complicated, unnatural or special purpose and/or (ii) slower or less scalable.   In this paper we study the effectiveness of this strong form of determinism through a broad set of benchmark problems. Our main contribution is to demonstrate that for this wide body of problems, there exist efficient internally deterministic algorithms, and moreover that these algorithms are natural to reason about and not complicated to code. We leverage an approach to determinism suggested by Steele (1990), which is to use nested parallelism with commutative operations. Our algorithms apply several diverse programming paradigms that fit within the model including (i) a strict functional style (no shared state among concurrent operations), (ii) an approach we refer to as  deterministic reservations , and (iii) the use of commutative, linearizable operations on data structures. We describe algorithms for the benchmark problems that use these deterministic approaches and present performance results on a 32-core machine. Perhaps surprisingly, for all problems, our internally deterministic algorithms achieve good speedup and good performance even relative to prior nondeterministic solutions."
1789544,15258,343,Compressing IP forwarding tables for fun and profit,2012,"About what is the smallest size we can compress an IP Forwarding Information Base (FIB) down to, while still guaranteeing fast lookup? Is there some notion of FIB entropy that could serve as a compressibility metric? As an initial step in answering these questions, we present a FIB data structure, called Multibit Burrows-Wheeler transform (MBW), that is fundamentally pointerless, can be built in linear time, guarantees theoretically optimal longest prefix match, and compresses to higher-order entropy. Measurements on a Linux prototype provide a first glimpse of the applicability of MBW."
2100442,15258,122,Efficient deadlock avoidance for streaming computation with filtering,2012,"Parallel streaming computations have been studied extensively, and many languages, libraries, and systems have been designed to support this model of computation. In particular, we consider acyclic streaming computations in which individual nodes can choose to  filter , or discard, some of their inputs in a data-dependent manner. In these applications, if the channels between nodes have finite buffers, the computation can  deadlock . One method of deadlock avoidance is to augment the data streams between nodes with occasional  dummy messages ; however, for general DAG topologies, no polynomial time algorithm is known to compute the intervals at which dummy messages must be sent to avoid deadlock.   In this paper, we show that deadlock avoidance for streaming computations with filtering can be performed efficiently for a large class of DAG topologies. We first present a new method where each dummy message is tagged with a destination, so as to reduce the number of dummy messages sent over the network. We then give efficient algorithms for dummy interval computation in series-parallel DAGs. We finally generalize our results to a larger graph family, which we call the  CS4 DAGs , in which every undirected Cycle is Single-Source and Single-Sink ( CS  4 ). Our results show that, for a large set of application topologies that are both intuitively useful and formalizable, the streaming model with filtering can be implemented safely with reasonable overhead."
1118224,15258,507,Warding off the dangers of data corruption with amulet,2011,"Occasional corruption of stored data is an unfortunate byproduct of the complexity of modern systems. Hardware errors, software bugs, and mistakes by human administrators can corrupt important sources of data. The dominant practice to deal with data corruption today involves administrators writing ad hoc scripts that run data-integrity tests at the application, database, file-system, and storage levels. This manual approach is tedious, error-prone, and provides no understanding of the potential system unavailability and data loss if a corruption were to occur. We introduce the Amulet system that addresses the problem of verifying the correctness of stored data proactively and continuously. To our knowledge, Amulet is the first system that: (i) gives administrators a declarative language to specify their objectives regarding the detection and repair of data corruption; (ii) contains optimization and execution algorithms to ensure that the administrator's objectives are met robustly and with least cost, e.g., using pay-as-you cloud resources; and (iii) provides timely notification when corruption is detected, allowing proactive repair of corruption before it impacts users and applications. We describe the implementation and a comprehensive evaluation of Amulet for a database software stack deployed on an infrastructure-as-a-service cloud provider."
2219505,15258,293,On Understanding User Interests through Heterogeneous Data Sources,2014,"User interests can be learned from multiple sources, each of them presenting only partial facets. We propose an approach to merge user information from disparate data sources to enable a more complete, enriched view of user interests. Using our approach, we show that merging different sources results in three times of more interest categories in user profiles than with each single source and that merged profiles can capture much more common interests among a group of users, which is key to group profiling."
1140290,15258,517,Automated and Isolated Tests for Complex Middleware Products: The Case of BPEL Engines,2014,"Today, a plethora of enterprise middleware solutions are available, leading to the problem of choosing the right tool for a specific use case. Automated tests can support the selection of such software by determining decision relevant metrics, like e.g., throughput or the degree of standard conformance. To avoid side effects between tests, test isolation, i.e., to provide fresh instances of the software for each test execution, is essential. However, middleware suites are inherently complex, provide a large range of configuration options, have tedious or sometimes manual installation procedures, and long startup times. These idiosyncrasies aggravate the creation of fresh instances of such middleware suites, leading to slower turnaround times and increasing the cost for ensuring test isolation. We aim to overcome these issues with methods and tools from the area of virtualization and devops. In this work, we focus on BPEL engines which are common middleware components in Web Service based SOAs. We applied our proposed method to the BPEL Engine Test System (betsy), a conformance test suite and testing tool for BPEL engines. Results reveal that our method a) enables automatic creation of fresh instances of software without manual installation steps, b) reduces the time to create these fresh instance dramatically, and c) introduces only a neglectable performance overhead, therefore, reducing the overall costs of testing complex software."
1819788,15258,343,FreeDOM: a new baseline for the web,2012,"Free web services often face growing pains. In the current client-server access model, the cost of providing a service increases with its popularity. This leads organizations that want to provide services free-of-charge to rely to donations, advertisements, or mergers with larger companies to cope with operational costs.   This paper proposes an alternative architecture for deploying services that allows more web services to be offered for free. We leverage recent developments in web technologies to combine the portability of the existing web with the user-powered scalability of distributed P2P solutions. We show how this solution addresses issues of user security, data sharing, and application distribution. By employing an easily composable communication interface and rich storage permissions, the FreeDOM architecture encourages flexible interactions between applications while enforcing privacy controls. We demonstrate the applicability of this architecture by presenting a SQL database and a community-supported Wiki as case studies."
307612,15258,293,Clockscalpel: understanding root causes of internet clock synchronization inaccuracy,2011,"Synchronizing clocks is an integral part of modern network and security architectures. However, the ability to synchronize clocks in modern networks is not well-understood. In this work, we use testbeds equipped with a high-accuracy GPS receiver to acquire ground truth, to study the accuracy of probe-based synchronization techniques to over 1861 public time servers. We find that existing synchronization protocols provide a median error of 2 - 5 ms, but suffer from a long-tail. We analyze sources of inaccuracy by decoupling and quantifying different network factors. We found that most inaccuracies stem from asymmetry of propagation delay and queueing delay. We discuss possible schemes to compensate these errors to improve synchronization accuracy."
93799,15258,293,An End-to-End Measurement Study of Modern Cellular Data Networks,2014,"With the significant increase in cellular data usage, it is critical to better understand the characteristics and behavior of cellular data networks. With both laboratory experiments and crowd-sourcing measurements, we investigated the characteristics of the cellular data networks for the three mobile ISPs in Singapore. We found that i) the transmitted packets tend to arrive in bursts; ii) there can be large variations in the instantaneous throughput over a short period of time; iii) large separate downlink buffers are typically deployed, which can cause high latency when the throughput is low; and iv) the networks typically implement some form of fair queuing policy."
830590,15258,507,X-FTL: transactional FTL for SQLite databases,2013,"In the era of smartphones and mobile computing, many popular applications such as Facebook, twitter, Gmail, and even Angry birds game manage their data using SQLite. This is mainly due to the development productivity and solid transactional support. For transactional atomicity, however, SQLite relies on less sophisticated but costlier page-oriented journaling mechanisms. Hence, this is often cited as the main cause of tardy responses in mobile applications.   Flash memory does not allow data to be updated in place, and the copy-on-write strategy is adopted by most flash storage devices. In this paper, we propose X-FTL, a transactional flash translation layer(FTL) for SQLite databases. By offloading the burden of guaranteeing the transactional atomicity from a host system to flash storage and by taking advantage of the copy-on-write strategy used in modern FTLs, X-FTL drastically improves the transactional throughput almost for free without resorting to costly journaling schemes. We have implemented X-FTL on an SSD development board called OpenSSD, and modified SQLite and ext4 file system minimally to make them compatible with the extended abstractions provided by X-FTL. We demonstrate the effectiveness of X-FTL using real and synthetic SQLite workloads for smartphone applications, TPC-C benchmark for OLTP databases, and FIO benchmark for file systems."
1510306,15258,122,Compiler aided manual speculation for high performance concurrent data structures,2013,"Speculation is a well-known means of increasing parallelism among concurrent methods that are usually but not always independent. Traditional nonblocking data structures employ a particularly restrictive form of speculation. Software transactional memory (STM) systems employ a much more general---though typically blocking---form, and there is a wealth of options in between.   Using several different concurrent data structures as examples, we show that manual addition of speculation to traditional lock-based code can lead to significant performance improvements. Successful speculation requires careful consideration of profitability, and of how and when to validate consistency. Unfortunately, it also requires substantial modifications to code structure and a deep understanding of the memory model. These latter requirements make it difficult to use in its purely manual form, even for expert programmers. To simplify the process, we present a compiler tool, CSpec, that automatically generates speculative code from baseline lock-based code with user annotations. Compiler-aided manual speculation keeps the original code structure for better readability and maintenance, while providing the flexibility to chose speculation and validation strategies. Experiments on UltraSPARC and x86 platforms demonstrate that with a small number annotations added to lock-based code, CSpec can generate speculative code that matches the performance of best-effort hand-written versions."
1029099,15258,343,CARE: content aware redundancy elimination for challenged networks,2012,"This paper presents the design of a novel architecture called CARE (Content-Aware Redundancy Elimination) that enables maximizing the informational value that challenged networks offer their users. We focus on emerging applications for situational awareness in disaster affected regions. Motivated by advances in computer vision algorithms, we propose to incorporate image similarity detection algorithms in the forwarding path of these networks. The purpose is to handle the large generation of redundant content. We outline the many issues involved in such a vision. With a Delay-Tolerant Network (DTN) setup, our simulations demonstrate that CARE can substantially boost the number of unique messages that escape the disaster zone, and it can also deliver them faster. These benefits are achieved despite the energy overhead needed by the similarity detectors."
921675,15258,122,Distributed merge trees,2013,"Improved simulations and sensors are producing datasets whose increasing complexity exhausts our ability to visualize and comprehend them directly. To cope with this problem, we can detect and extract significant features in the data and use them as the basis for subsequent analysis. Topological methods are valuable in this context because they provide robust and general feature definitions.   As the growth of serial computational power has stalled, data analysis is becoming increasingly dependent on massively parallel machines. To satisfy the computational demand created by complex datasets, algorithms need to effectively utilize these computer architectures. The main strength of topological methods, their emphasis on global information, turns into an obstacle during parallelization.   We present two approaches to alleviate this problem. We develop a distributed representation of the merge tree that avoids computing the global tree on a single processor and lets us parallelize subsequent queries. To account for the increasing number of cores per processor, we develop a new data structure that lets us take advantage of multiple shared-memory cores to parallelize the work on a single node. Finally, we present experiments that illustrate the strengths of our approach as well as help identify future challenges."
2547461,15258,343,Beehive: Towards a Simple Abstraction for Scalable Software-Defined Networking,2014,"Simplicity is a prominent advantage of Software-Defined Networking (SDN), and is often exemplified by implementing a complicated control logic as a simple control application on a centralized controller. In practice, however, SDN controllers turn into distributed systems due to performance and reliability limitations, and the supposedly simple control applications transform into complex logics that demand significant effort to design and optimize.   In this paper, we present Beehive, a distributed control platform aiming at simplifying this process. Our proposal is built around a programming abstraction which is almost identical to a centralized controller yet enables the platform to automatically infer how applications maintain their state and depend on one another. Using this abstraction, the platform automatically generates the distributed version of each control application, while preserving its behavior. With runtime instrumentation, the platform dynamically migrates applications among controllers aiming to optimize the control plane as a whole. Beehive also provides feedback to identify design bottlenecks in control applications, helping developers enhance the performance of the control plane. Our prototype shows that Beehive significantly simplifies the process of realizing distributed control applications."
803883,15258,507,"A high-throughput in-memory index, durable on flash-based SSD: insights into the winning solution of the SIGMOD programming contest 2011",2012,"Growing memory capacities and the increasing number of cores on modern hardware enforces the design of new in-memory indexing structures that reduce the number of memory transfers and minimizes the need for locking to allow massive parallel access. However, most applications depend on hard durability constraints requiring a persistent medium like SSDs, which shorten the latency and throughput gap between main memory and hard disks. In this paper, we present our winning solution of the SIGMOD Programming Contest 2011. It consists of an in-memory indexing structure that provides a balanced read/write performance as well as non-blocking reads and single-lock writes. Complementary to this index, we describe an SSD-optimized logging approach to fit hard durability requirements at a high throughput rate."
2346651,15258,122,Reducing contention through priority updates,2013,"Memory contention can be a serious performance bottleneck in concurrent programs on shared-memory multicore architectures. Having all threads write to a small set of shared locations, for example, can lead to orders of magnitude loss in performance relative to all threads writing to distinct locations, or even relative to a single thread doing all the writes. Shared write access, however, can be very useful in parallel algorithms, concurrent data structures, and protocols for communicating among threads. We study the \priority update operation as a useful primitive for limiting write contention in parallel and concurrent programs. A priority update takes as arguments a memory location, a new value, and a comparison function >p that enforces a partial order over values. The operation atomically compares the new value with the current value in the memory location, and writes the new value only if it has higher priority according to >p. On the implementation side, we show that if implemented appropriately, priority updates greatly reduce memory contention over standard writes or other atomic operations when locations have a high degree of sharing. This is shown both experimentally and theoretically. On the application side, we describe several uses of priority updates for implementing parallel algorithms and concurrent data structures, often in a way that is deterministic, guarantees progress, and avoids serial bottlenecks. We present experiments showing that a variety of such algorithms and data structures perform well under high degrees of sharing. Given the results, we believe that the priority update operation serves as a useful parallel primitive and good programming abstraction as (1) the user largely need not worry about the degree of sharing, (2) it can be used to avoid non-determinism since, in the common case when >p is a total order, priority updates commute, and (3) it has many applications to programs using shared data."
838049,15258,20774,Reducing contention through priority updates,2013,"Memory contention can be a serious performance bottleneck in concurrent programs on shared-memory multicore architectures. Having all threads write to a small set of shared locations, for example, can lead to orders of magnitude loss in performance relative to all threads writing to distinct locations, or even relative to a single thread doing all the writes. Shared write access, however, can be very useful in parallel algorithms, concurrent data structures, and protocols for communicating among threads.   We study the priority update operation as a useful primitive for limiting write contention in parallel and concurrent programs. A  priority update  takes as arguments a memory location, a new value, and a comparison function >  p   that enforces a partial order over values. The operation atomically compares the new value with the current value in the memory location, and writes the new value only if it has  higher priority  according to >  p  . On the implementation side, we show that if implemented appropriately, priority updates greatly reduce memory contention over standard writes or other atomic operations when locations have a high degree of sharing. This is shown both experimentally and theoretically. On the application side, we describe several uses of priority updates for implementing parallel algorithms and concurrent data structures, often in a way that is deterministic, guarantees progress, and avoids serial bottlenecks. We present experiments showing that a variety of such algorithms and data structures perform well under high degrees of sharing. Given the results, we believe that the priority update operation serves as a useful parallel primitive and good programming abstraction as (1) the user largely need not worry about the degree of sharing, (2) it can be used to avoid non-determinism since, in the common case when >  p   is a total order, priority updates commute, and (3) it has many applications to programs using shared data."
1225541,15258,507,Medusa: A Parallel Graph Processing System on Graphics Processors,2014,"Medusa is a parallel graph processing system on graphics processors (GPUs). The core design of Medusa is to enable developers to leverage the massive parallelism and other hardware features of GPUs by writing sequential C/C++ code for a small set of APIs. This simplifies the implementation of parallel graph processing on the GPU. The runtime system of Medusa automatically executes the user-defined APIs in parallel on the GPU, with a series of optimizations based on the architecture features of GPUs and characteristics of graph applications. In this paper, we present an overview of the Medusa system and a case study of adopting Medusa to a research project on social network simulations. With Medusa, users without GPU programming experiencecan quickly implement their graph operations on the GPU, which accelerates the discovery and findings of domain-specific applications."
1540364,15258,369,A Comparative Study of Mixed Traffic Scenarios for Different Scheduling Algorithms in WiMAX,2012,"WiMAX promises an advanced framework to support Quality-of-Service (QoS) requirements of different types of applications and scheduling is a key part in its QoS provisioning. The scheduling algorithms used in this paper are based on our proposed Greedy-Latency scheduler, a modified form of Greedy algorithm which can guarantee delay requirements of real-time applications while optimising the system throughput. Our study of TCP performance in WiMAX shows that unlike UDP traffic, there are fluctuations in TCP throughput even for low traffic loads. It is seen that employing Automatic Repeat reQuest (ARQ) and setting the right TCP window size are crucial for a stable optimal TCP performance. WiMAX QoS mechanism can successfully maintain the inter-class priority between TCP traffic in Best Effort (BE) class and UDP in higher priority Real- Time Polling Service (rtPS) class. For intra-class scenarios, it is observed that TCP flows in general need a protection mechanism as the UDP traffic tend to seize the channel. The proposed Greedy-Scheduler can provide better intra-class protection for TCP flows due to its packet dropping policy."
1113387,15258,507,WattDB: an energy-proportional cluster of wimpy nodes,2011,"The constant growth of data in all businesses leads to bigger database servers. While peak load times require fast and heavyweight hardware to guarantee performance, idle times are a waste of energy and money. Todays DBMSs have the ability to cluster several servers for performance and fault tolerance. Nevertheless, they do not support dynamic powering of the cluster's nodes based on the current workload.   In this demo, we propose a newly developed DBMS running on clustered commodity hardware, which is able to dynamically power nodes. The demo allows the user to interact with the DBMS and adjust workloads, while the cluster's reaction is shown in real-time."
1791611,15258,343,The web interface should be radically refactored,2011,"The Web API conflates two conflicting goals: serving developers by supporting a wide and growing suite of functionality, and providing applications with an isolated execution environment. We propose to split the API into two levels of interface: a low-level interface that governs the relationship between the application and the browser, and a set of high-level interfaces that govern the relationship between the application and its developer. We delineate a tiny set of properties needed by the low-level interface. We argue that this restructuring provides significant benefit to both developers and users."
674549,15258,293,Dissecting Round Trip Time on the Slow Path with a Single Packet,2014,"Researchers and operators often measure Round Trip Time when monitoring, troubleshooting, or otherwise assessing network paths. However, because it combines all hops traversed along both the forward and reverse path, it can be difficult to interpret or to attribute delay to particular path segments.#R##N##R##N#In this work, we present an approach using a single packet to dissect the RTT in chunks mapped to specific portions of the path. Using the IP Prespecified Timestamp option directed at intermediate routers, it provides RTT estimations along portions of the slow path. Using multiple vantage points (116 PlanetLab nodes), we show that the proposed approach can be applied on more than 77% of the considered paths. Finally, we present preliminary results for two use cases (home network contribution to the RTT and per-Autonomous System RTT contribution) to demonstrate its potential in practical scenarios."
677678,15258,507,A system for energy-efficient data management,2014,"Energy consumption of computer systems has increased at a steep rate in recent years. Following extensive energyrelated research and practice in the hardware and OS communities, much attention has been paid to developing energy-efficient applications. With database systems being a heavy energy consumer in modern data centers, we face the challenge of designing DBMSs with energy as a first-class performance goal. This paper presents our on-goingwork in designing and implementing a DBMS that enables significant energy conservations while maintaining other performance targets. We follow two new strategies in DBMS implementation to achieve our system design goal. The first one is to change the resource consumption patterns via energy-aware query optimization and reorganizing data records to enable load consolidation in disks. The second strategy is active control of power modes of hardware (i.e., CPU and hard disks) toward energy reduction. Specifically, we use control-theoretic techniques to allowdynamic adjustment of CPU frequency and online data migration to achieve disk load consolidation. Preliminary results have shown the effectiveness of our design."
737180,15258,122,An overview of Medusa: simplified graph processing on GPUs,2012,"Graphs are the de facto data structures for many applications, and efficient graph processing is a must for the application performance. GPUs have an order of magnitude higher computational power and memory bandwidth compared to CPUs and have been adopted to accelerate several common graph algorithms. However, it is difficult to write correct and efficient GPU programs and even more difficult for graph processing due to the irregularities of graph structures. To address those difficulties, we propose a programming framework named Medusa to simplify graph processing on GPUs. Medusa offers a small set of APIs, based on which developers can define their application logics by writing sequential code without awareness of GPU architectures. The Medusa runtime system automatically executes the developer defined APIs in parallel on the GPU, with a series of graph-centric optimizations. This poster gives an overview of Medusa, and presents some preliminary results."
1226828,15258,339,Efficient dynamic provable possession of remote data via balanced update trees,2013,"The emergence and availability of remote storage providers prompted work in the security community that allows a client to verify integrity and availability of the data she outsourced to an untrusted remove storage server at a relatively low cost. Most recent solutions to this problem allow the client to read and update (insert, modify, or delete) stored data blocks while trying to lower the overhead associated with verifying data integrity. In this work we develop a novel and efficient scheme, computation and communication overhead of which is orders of magnitude lower than those of other state-of-the-art schemes. Our solution has a number of new features such as a natural support for operations on ranges of blocks, and revision control. The performance guarantees that we achieve stem from a novel data structure, termed  balanced update tree , and removing the need to verify update operations."
1897743,15258,122,Correct and efficient work-stealing for weak memory models,2013,"Chase and Lev's concurrent deque is a key data structure in shared-memory parallel programming and plays an essential role in work-stealing schedulers. We provide the first correctness proof of an optimized implementation of Chase and Lev's deque on top of the POWER and ARM architectures: these provide very relaxed memory models, which we exploit to improve performance but considerably complicate the reasoning. We also study an optimized x86 and a portable C11 implementation, conducting systematic experiments to evaluate the impact of memory barrier optimizations. Our results demonstrate the benefits of hand tuning the deque code when running on top of relaxed memory models."
671525,15258,422,Research on SaaS Resource Management Method Oriented to Periodic User Behavior,2013,"With the development of Internet technology, SaaS is gaining popularity as a kind of innovative mode of software applications. In order to meet the needs of the periodic user behavior better, allocate virtual resource more reasonable and achieve the targets of SaaS Service performance optimization and energy conservation, this paper puts forward one SaaS resource management method oriented to periodic user behavior. This method takes the periodic user behavior as the research object, predicts future resource demand by predicting and matching concurrent requests and resource occupancy, then allocates the resource by demands. The results show that this strategy has good usability and validity and it can predict the user future demand for resources accurately. This method also lays a foundation for further performance optimization and energy conservation."
231007,15258,293,Understanding HTTP Traffic and CDN Behavior from the Eyes of a Mobile ISP,2014,"Today's Internet is dominated by HTTP services and Content Delivery Networks (CDNs). Popular web services like Facebook and YouTube are hosted by highly distributed CDNs like Akamai and Google. Understanding this new complex Internet scenario is paramount for network operators, to control the traffic on their networks and to improve the quality experienced by their customers, specially when something goes wrong. This paper studies the most popular HTTP services and their underlying hosting networks, through the analysis of a full week of HTTP traffic traces collected at an operational mobile network."
1486211,15258,507,DBalancer: distributed load balancing for NoSQL data-stores,2013,"Unanticipated load spikes or skewed data access patterns may lead to severe performance degradation in data serving applications, a typical problem of distributed NoSQL data-stores. In these cases, load balancing is a necessary operation. In this demonstration, we present the DBalancer, a generic distributed module that can be installed on top of a typical NoSQL data-store and provide an efficient and highly configurable load balancing mechanism. Balancing is performed by simple message exchanges and typical data movement operations supported by most modern NoSQL data-stores. We present the system's architecture, we describe in detail its modules and their interaction and we implement a suite of different algorithms on top of it. Through a web-based interactive GUI we allow the users to launch NoSQL clusters of various sizes, to apply numerous skewed and dynamic workloads and to compare the implemented load balancing algorithms. Videos and graphs showcasing each algorithm's effect on a number of indicative performance and cost metrics will be created on the fly for every setup. By browsing the results of different executions users will be able to grasp each algorithm's balancing mechanisms and performance impact in a number of representative setups."
2303468,15258,122,Algorithm-based recovery for HPL,2011,"When more processors are used for a calculation, the probability that one will fail during the calculation increases. Fault tolerance is a technique for allowing a calculation to survive a failure, and includes recovering lost data. A common method of recovery is diskless checkpointing. However, it has high overhead when a large amount of data is involved, as is the case with matrix operations. A checksum-based method allows fault tolerance of matrix operations with lower overhead. This technique is applicable to the LU decomposition in the benchmark HPL."
1922150,15258,122,QoS aware storage cache management in multi-server environments,2011,"In this paper, we propose a novel two-step approach to the management of the storage caches to provide predictable performance in multi-server storage architectures: (1) An adaptive QoS decomposition and optimization step uses max-flow algorithm to determine the best decomposition of application-level QoS to sub-QoSs such that the application performance is optimized, and (2) A storage cache allocation step uses feedback control theory to allocate shared storage cache space such that the specified QoSs are satisfied throughout the execution."
2038516,15258,369,A Measurement Based Energy Model for IEEE 802.16e Mobile WiMAX Devices,2012,"The operational time of modern smart-phones with one filling of the accumulator is one of the most important performance parameter for the customers of new devices. This is the reason why extensive research has been performed in the fields of battery design and system optimization with regard on energy consumption. Due to the fact that the radio part of a smart-phone is one of the major energy consumers, a special focus has to be set on different approaches and strategies how to reduce the energy that has to be spent for the transmission of a certain amount of data. However, before new energy saving protocols can be efficiently developed one needs to have detailed knowledge on the different factors which impact the energy efficiency. In this paper, we present a measurement based energy model for IEEE 802.16e conform Mobile WiMAX devices. For this purpose, extensive measurements of the energy consumption of a Mobile WiMAX USB Stick have been performed for different system parameterizations, different data sizes and different application data rates. From the results of the measurements analytic models have been derived which allow for the calculation of the energy that has to be spent per successfully submitted bit. These analytic formulas can now be integrated in system level simulators for the evaluation of the energy efficiency of newly designed protocols."
2176221,15258,122,Lock contention aware thread migrations,2014,"On a cache-coherent multicore multiprocessor system, the performance of a multithreaded application with high lock contention is very sensitive to the distribution of application threads across multiple processors. This is because the distribution of threads impacts the frequency of lock transfers between processors, which in turn impacts the frequency of last-level cache (LLC) misses that lie on the critical path of execution. Inappropriate distribution of threads across processors increases LLC misses in the critical path and significantly degrades performance of multithreaded programs. To alleviate the above problem, this paper overviews a thread migration technique, which migrates threads of a multithreaded program across multicore processors so that threads seeking locks are more likely to find the locks on the same processor."
2110678,15258,122,SpiceC: scalable parallelism via implicit copying and explicit commit,2011,In this paper we present an approach to parallel programming called SpiceC. SpiceC simplifies the task of parallel programming through a combination of an intuitive computation model and SpiceC directives. The SpiceC parallel computation model consists of multiple threads where every thread has a private space for data and all threads share data via a shared space. Each thread performs computations using its private space thus offering isolation which allows for speculative computations. SpiceC provides easy to use SpiceC compiler directives using which the programmers can express different forms of parallelism. It allows developers to express high level constraints on data transfers between spaces while the tedious task of generating the code for the data transfers is performed by the compiler. SpiceC also supports data transfers involving dynamic data structures without help from developers. SpiceC allows developers to create clusters of data to enable parallel data transfers. SpiceC programs are portable across modern chip multiprocessor based machines that may or may not support cache coherence. We have developed implementations of SpiceC for shared memory systems with and without cache coherence. We evaluate our implementation using seven benchmarks of which four are parallelized speculatively. Our compiler generated implementations achieve speedups ranging from 2x to 18x on a 24 core system.
2558368,15258,122,Singe: leveraging warp specialization for high performance on GPUs,2014,"We present Singe, a Domain Specific Language (DSL) compiler for combustion chemistry that leverages warp specialization to produce high performance code for GPUs. Instead of relying on traditional GPU programming models that emphasize data-parallel computations, warp specialization allows compilers like Singe to partition computations into sub-computations which are then assigned to different warps within a thread block. Fine-grain synchronization between warps is performed efficiently in hardware using producer-consumer named barriers. Partitioning computations using warp specialization allows Singe to deal efficiently with the irregularity in both data access patterns and computation. Furthermore, warp-specialized partitioning of computations allows Singe to fit extremely large working sets into on-chip memories. Finally, we describe the architecture and general compilation techniques necessary for constructing a warp-specializing compiler. We show that the warp-specialized code emitted by Singe is up to 3.75X faster than previously optimized data-parallel GPU kernels."
2748,15258,293,Understanding IPv6 populations in the wild,2013,"With the global exhaustion of the IPv4 address pool, there has been significant interest in understanding the adoption of IPv6. Previous studies have shown that IPv6 traffic continues to be a very small fraction of the overall total traffic in any network, but its use is gradually increasing. Utilizing a novel display advertising approach to reach behind NAT and other firewall devices, we engage in a seven-month study of IPv6 in which we observe 14M unique IPv6 addresses including native IPv6, teredo, as well as 6to4. We exploit the intrinsic information within IPv6 addresses in order to infer IPv6 properties, such as, coarse grained geographic location, ISPs, the use of native IPv6 versus transition techniques, cone NAT usage, and even network interface manufacturer identifiers. We find that while the number of native IPV6 addresses in the wild is small (1.3%) a large number of IPv6 hosts are IPv6 capable via transition techniques such as teredo and 6to4."
2338905,15258,122,A speculation-friendly binary search tree,2012,"We introduce the first binary search tree algorithm designed for speculative executions. Prior to this work, tree structures were mainly designed for their pessimistic (non-speculative) accesses to have a bounded complexity. Researchers tried to evaluate transactional memory using such tree structures whose prominent example is the red-black tree library developed by Oracle Labs that is part of multiple benchmark distributions. Although well-engineered, such structures remain badly suited for speculative accesses, whose step complexity might raise dramatically with contention.   We show that our  speculation-friendly tree  outperforms the existing transaction-based version of the AVL and the red-black trees. Its key novelty stems from the  decoupling  of update operations: they are split into one transaction that modifies the abstraction state and multiple ones that restructure its tree implementation in the background. In particular, the speculation-friendly tree is shown correct, reusable and it speeds up a transaction-based travel reservation application by up to 3.5x."
1937100,15258,293,Measurement artifacts in netflow data,2013,"Flows provide an aggregated view of network traffic by grouping streams of packets. The resulting scalability gain usually excuses the coarser data granularity, as long as the flow data reflects the actual network traffic faithfully. However, it is known that the flow export process may introduce artifacts in the exported data. This paper extends the set of known artifacts by explaining which implementation decisions are causing them. In addition, we verify the artifacts' presence in data from a set of widely-used devices. Our results show that the revealed artifacts are widely spread among different devices from various vendors. We believe that these results provide researchers and operators with important insights for developing robust analysis applications."
477664,15258,293,Route flap damping made usable,2011,"The Border Gateway Protocol (BGP), the de facto inter-domain routing protocol of the Internet, is known to be noisy. The protocol has two main mechanisms to ameliorate this, MinRouteAdvertisementInterval (MRAI), and Route Flap Damping (RFD). MRAI deals with very short bursts on the order of a few to 30 seconds. RFD deals with longer bursts, minutes to hours. Unfortunately, RFD was found to severely penalize sites for being well-connected because topological richness amplifies the number of update messages exchanged. So most operators have disabled it. Through measurement, this paper explores the avenue of absolutely minimal change to code, and shows that a few RFD algorithmic constants and limits can be trivially modified, with the result being damping a non-trivial amount of long term churn without penalizing well-behaved prefixes' normal convergence process."
2335364,15258,339,On the feasibility of software attacks on commodity virtual machine monitors via direct device assignment,2014,"The security of virtual machine monitors (VMMs) is a challenging and active field of research. In particular, due to the increasing significance of hardware virtualization in cloud solutions, it is important to clearly understand existing and arising VMM-related threats. Unfortunately, there is still a lot of confusion around this topic as many attacks presented in the past have never been implemented in practice or tested in a realistic scenario.   In this paper, we shed light on VM related threats and defences by implementing, testing, and categorizing a wide range of known and unknown attacks based on directly assigned devices. We executed these attacks on an exhaustive set of VMM configurations to determine their potential impact. Our experiments suggest that most of the previously known attacks are ineffective in current VMM setups.   We also developed an automatic tool, called PTFuzz, to discover hardware-level problems that affects current VMMs. By using PTFuzz, we found several cases of unexpected hardware behaviour, and a major vulnerability on Intel platforms that potentially impacts a large set of machines used in the wild. These vulnerabilities affect unprivileged virtual machines that use a directly assigned device (e.g., network card) and have all the existing hardware protection mechanisms enabled. Such vulnerabilities either allow an attacker to generate a host-side interrupt or hardware faults, violating expected isolation properties. These can cause host software (e.g., VMM) halt as well as they might open the door for practical VMM exploitations.   We believe that our study can help cloud providers and researchers to better understand the limitations of their current architectures to provide secure hardware virtualization and prepare for future attacks."
132250,15258,293,Pathperf: path bandwidth estimation utilizing websites,2013,"Most bandwidth estimation tools require access to both ends of a measured path, which is increasingly difficult considering the constantly expanding size of the Internet. We present Pathperf, a tool for estimating bulk transfer capacity by downloading files from websites at one end of a path. We collect 3.3 million websites in 22,656 ASes and leverage DNS infrastructure to deliver website information. Comparing with Iperf, Pathperf saves more than 50% of the network traffic and its relative error rate is under 10%."
217956,15258,293,Non-cooperative diagnosis of submarine cable faults,2011,"Submarine cable faults are not uncommon events in the Internet today. However, their impacts on end-to-end path quality have received almost no attention. In this paper, we report path-quality measurement results for a recent SEA-ME-WE 4 cable fault in 2010. Our measurement methodology captures the path-quality degradation due to the cable fault, in terms of delay, asymmetric packet losses, and correlation between loss and delay. We further leverage traceroute data to infer the root causes of the performance degradation."
1923783,15258,293,Unmasking the growing UDP traffic in a campus network,2012,"Transmission control protocol (TCP) has been the dominating protocol for Internet traffic for the past decades. Most network research based on traffic analysis (e.g., router buffer sizing and traffic classification) has been conducted assuming the dominance of TCP over other protocols. However, a few recent traffic statistics are showing a sign of significant UDP traffic growth at various points of Internet links [21]. In this paper we show that the UDP traffic has grown significantly in recent years on our campus network; we have observed a 46-fold increase in volume (from 0.47% to 22.0% of total bytes) in the past four years. The trace collected in 2011 shows that the grown volume is not from a small number of UDP hosts nor port numbers. In addition, the recent UDP flows are not sent at constant bit rate (CBR) for most cases, and the aggregated traffic shows burstiness close to TCP traffic."
1938346,15258,122,OoOJava: software out-of-order execution,2011,Developing parallel software using current tools can be challenging. Even experts find it difficult to reason about the use of locks and often accidentally introduce race conditions and deadlocks into parallel software. OoOJava is a compiler-assisted approach that leverages developer annotations along with static analysis to provide an easy-to-use deterministic parallel programming model. OoOJava extends Java with a task annotation that instructs the compiler to consider a code block for out-of-order execution. OoOJava executes tasks as soon as their data dependences are resolved and guarantees that the execution of an annotated program preserves the exact semantics of the original sequential program. We have implemented OoOJava and achieved an average speedup of 16.6x on our ten benchmarks.
637576,15258,339,Process out-grafting: an efficient out-of-VM approach for fine-grained process execution monitoring,2011,"Recent rapid malware growth has exposed the limitations of traditional in-host malware-defense systems and motivated the development of secure virtualization-based out-of-VM solutions. By running vulnerable systems as virtual machines (VMs) and moving security software from inside the VMs to outside, the out-of-VM solutions securely isolate the anti-malware software from the vulnerable system. However, the presence of semantic gap also leads to the compatibility problem in not supporting existing defense software. In this paper, we present process out-grafting, an architectural approach to address both isolation and compatibility challenges in out-of-VM approaches for fine-grained process-level execution monitoring. Specifically, by relocating a suspect process from inside a VM to run side-by-side with the out-of-VM security tool, our technique effectively removes the semantic gap and supports existing user-mode process monitoring tools without any modification. Moreover, by forwarding the system calls back to the VM, we can smoothly continue the execution of the out-grafted process without weakening the isolation of the monitoring tool. We have developed a KVM-based prototype and used it to natively support a number of existing tools without any modification. The evaluation results including measurement with benchmark programs show it is effective and practical with a small performance overhead."
2167851,15258,339,Self-service cloud computing,2012,"Modern cloud computing infrastructures use virtual machine monitors (VMMs) that often include a large and complex administrative domain with privileges to inspect client VM state. Attacks against or misuse of the administrative domain can compromise client security and privacy. Moreover, these VMMs provide clients inflexible control over their own VMs, as a result of which clients have to rely on the cloud provider to deploy useful services, such as VM introspection-based security tools.   We introduce a new self-service cloud (SSC) computing model that addresses these two shortcomings. SSC splits administrative privileges between a system-wide domain and per-client administrative domains. Each client can manage and perform privileged system tasks on its own VMs, thereby providing flexibility. The system-wide administrative domain cannot inspect the code, data or computation of client VMs, thereby ensuring security and privacy. SSC also allows providers and clients to establish mutually trusted services that can check regulatory compliance while respecting client privacy. We have implemented SSC by modifying the Xen hypervisor. We demonstrate its utility by building user domains to perform privileged tasks such as memory introspection, storage intrusion detection, and anomaly detection."
840278,15258,122,Using GPU's to accelerate stencil-based computation kernels for the development of large scale scientific applications on heterogeneous systems,2012,"We present CaCUDA - a GPGPU kernel abstraction and a parallel programming framework for developing highly efficient large scale scientific applications using stencil computations on hybrid CPU/GPU architectures. CaCUDA is built upon the Cactus computational toolkit, an open source problem solving environment designed for scientists and engineers. Due to the flexibility and extensibility of the Cactus toolkit, the addition of a GPGPU programming framework required no changes to the Cactus infrastructure, guaranteeing that existing features and modules will continue to work without modification. CaCUDA was tested and benchmarked using a 3D CFD code based on a finite difference discretization of Navier-Stokes equations."
2056960,15258,122,WuKong: effective diagnosis of bugs at large system scales,2013,"A key challenge in developing large scale applications (both in system size and in input size) is finding bugs that are latent at the small scales of testing, only manifesting when a program is deployed at large scales. Traditional statistical techniques fail because no error-free run is available at deployment scales for training purposes. Prior work used  scaling models  to detect anomalous behavior at large scales without being trained on correct behavior at that scale. However, that work cannot localize bugs automatically. In this paper, we extend that work in three ways: (i) we develop an automatic diagnosis technique, based on  feature reconstruction ; (ii) we design a heuristic to effectively prune the feature space; and (iii) we validate our design through one fault-injection study, finding that our system can effectively localize bugs in a majority of cases."
1839375,15258,122,An infrastructure for dynamic optimization of parallel programs,2012,"Object-oriented programming languages like Java provide only low-level constructs (e.g., starting a thread) to describe concurrency. High-level abstractions (e.g., thread pools) are merely provided as a library. As a result, a compiler is not aware of the high-level semantics of a parallel library and therefore misses important optimization opportunities. This paper presents a simple source language extension based on which a compiler is provided with the opportunity to perform new optimizations that are particularly effective for parallel code."
1994242,15258,122,Fine-grain parallel megabase sequence comparison with multiple heterogeneous GPUs,2014,"This paper proposes and evaluates a parallel strategy to execute the exact Smith-Waterman (SW) algorithm for megabase DNA sequences in heterogeneous multi-GPU platforms. In our strategy, the computation of a single huge SW matrix is spread over multiple GPUs, which communicate border elements to the neighbour, using a circular buffer mechanism that hides the communication overhead. We compared 4 pairs of human-chimpanzee homologous chromosomes using 2 different GPU environments, obtaining a performance of up to 140.36 GCUPS (Billion of cells processed per second) with 3 heterogeneous GPUS."
