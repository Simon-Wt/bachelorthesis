ID_Article,communityId,ID_RelatedVenue,title,year,abstract
1661558,15510,339,Beheading hydras: performing effective botnet takedowns,2013,"Devices infected with malicious software typically form botnet armies under the influence of one or more command and control (C&C) servers. The botnet problem reached such levels where federal law enforcement agencies have to step in and take actions against botnets by disrupting (or taking down) their C&Cs, and thus their illicit operations. Lately, more and more private companies have started to independently take action against botnet armies, primarily focusing on their DNS-based C&Cs. While well-intentioned, their C&C takedown methodology is in most cases ad-hoc, and limited by the breadth of knowledge available around the malware that facilitates the botnet.   With this paper, we aim to bring order, measure, and reason to the botnet takedown problem. We propose a takedown analysis and recommendation system, called rza, that allows researchers to perform two tasks: 1) a postmortem analysis of past botnet takedowns, and 2) provide recommendations on how to successfully execute future botnet takedowns. As part of our system evaluation, we perform a postmortem analysis of the recent Kelihos, Zeus and 3322.org takedowns. We show that while some of these takedowns were effective, others did not appear to have a significant long-term impact on the targeted botnet. In addition to the postmortem analysis, we provide takedown recommendation metrics for 45 currently active botnets, where we find that 42 of them can likely be disabled entirely by using a DNS-based takedown strategy only."
1060141,15510,339,POSTER: How Distributed Are Today's DDoS Attacks?,2014,"Today botnets are responsible for most of the DDoS attacks on the Internet. Understanding the characteristics of such DDoS attacks is critical to develop effective DDoS mitigation schemes. In this poster, we present some preliminary findings, mainly concerning the distribution of the attackers, of today's DDoS attacks. Our investigation is based on 50,704 different Internet DDoS attacks collected within a seven-month period for activities across the globe. These attacks were launched by 674 botnet generations from 23 different bonet families with a total of 9026 victim IPs belonging to 1074 organizations that are collectively located in 186 countries. We find that different from the traditional widely distributed intuition, most of these DDoS attacks are not widely distributed as the attackers are mostly from the same region, i.e., highly regionalized. We also find that different botnet families have strong target preferences in the same area as well. These findings refresh our understanding on the modern DDoS attacks."
93281,15510,374,Statistical Properties of Pseudo Random Sequences and Experiments with PHP and Debian OpenSSL,2014,"NIST SP800-22 (2010) proposed the state of the art statistical test- ing techniques for testing the quality of (pseudo) random generators. However, it is easy to construct natural functions that are considered as GOOD pseudo- random generators by the NIST SP800-22 test suite though the output of these functions is easily distinguishable from the uniform distribution. This paper pro- poses solutions to address this challenge by using statistical distance based testing techniques. We carried out both NIST tests and LIL based tests on the following pseudorandom generators by generating more than 200TB of data in total: (1) the standard C linear congruential generator, (2) Mersenne Twister pseudoran- dom generator, (3) PHP random generators (including Mersenne Twister and Lin- ear Congruential based), and (4) Debian Linux (CVE-2008-0166) pseudorandom generator with OpenSSL 0.9.8c-1. As a first important result, our experiments show that, PHP pseudorandom generator implementation (both linear congru- ential generators and Mersenne Twister generators) outputs completely insecure bits if the output is not further processed. As a second result, we illustrate the advantages of our LIL based testing over NIST testing. It is known that Debian Linux (CVE-2008-0166) pseudorandom generator based on OpenSSL 0.9.8c-1 is flawed and the output sequences are predictable. Our LIL tests on these sequences discovered the flaws in Debian Linux implementation. However, NIST SP800-22 test suite is not able to detect this flaw using the NIST recommended parameters. It is concluded that NIST SP800-22 test suite is not sufficient and distance based LIL test techniques be included in statistical testing practice. It is also recom- mended that all pseudorandom generator implementations be comprehensively tested using state-of-the-art statistically robust testing tools."
1205268,15510,8228,Verification of switching network properties using satisfiability,2012,"In this paper, we consider a network of OpenFlow switches as an acyclic network of high-dimensional Boolean functions. We reduce classic network properties to logic functions over the variables of this network, and demonstrate that these properties hold if and only if the conjunction of the derived Boolean network and proposition is satisfied. We demonstrate that the derived satisfiability instance is polynomially related to the size of the switch network and the network property. The problem of verification of OpenFlow networks is thus demonstrated to be in the class NP. We show that OpenFlow Verification is NP-complete by a reduction from SAT. We further consider a slight restriction in the OpenFlow rule set to prefix rules, and demonstrate that OpenFlow Verification is polynomial when the ruleset is restricted to prefix rules."
999489,15510,339,POSTER: Password Entering and Transmission Security,2014,"The most popular form of user authentication on websites is the use of passwords. When entering a password, it is crucial that the website uses HTTPS (for the entire content). However, this is often not the case. We propose PassSec - a Firefox Add-On to support users to detect password fields on which their password might be endangered. In addition, PassSec displays a non-blocking warning next to the password field, once users click into the password field. The user is provided with possible consequences of entering a password, recommendations and further information if wanted."
667341,15510,339,Discovering records of private VoIP calls without wiretapping,2012,"Call-record analysis is one of the oldest tools used in defense, law-enforcement, and business intelligence. For example, the NSA collected over 1.9 trillion call records between 2001 and 2004 [1]. A call-record database allows both single link (e.g., time, initiation, frequency of a call) and cluster analysis of calls in the temporal, spatial, and frequency domains. It can also indicate overlaps among different clusters, such as those obtained from different investigations, and similarity of clusters, such as those obtained when a group of targets changes their phone numbers but not their communication habits [10, 12]."
1243659,15510,339,"Televisions, video privacy, and powerline electromagnetic interference",2011,"We conduct an extensive study of information leakage over the powerline infrastructure from eight televisions (TVs) spanning multiple makes, models, and underlying technologies. In addition to being of scientific interest, our findings contribute to the overall debate of whether or not measurements of residential powerlines reveal significant information about the activities within a home. We find that the power supplies of modern TVs produce discernible electromagnetic interference (EMI) signatures that are indicative of the video content being displayed. We measure the stability of these signatures over time and across multiple instances of the same TV model, as well as the robustness of these signatures in the presence of other noisy electronic devices connected to the same powerline."
932654,15510,339,POSTER: Study of Software Plugin-based Malware,2014,"Security issues of software plugins are seldom studied in existing researches. The plugin mechanism provides a convenient way to extend an application's functionality. However, it may also introduce susceptibility to new security issues. For example, attackers can create a malicious plugin to accomplish intended goals stealthily. In this poster, we propose a Software Plugin-based Malware (SPM) model and implement SPM prototypes for Microsoft Office, Adobe Reader and mainstream browsers, with the aim to study the development feasibility of such malware and illustrate their potential threats."
1128977,15510,339,An Epidemiological Study of Malware Encounters in a Large Enterprise,2014,"We present an epidemiological study of malware encounters in a large, multi-national enterprise. Our data sets allow us to observe or infer not only malware presence on enterprise computers, but also malware entry points, network locations of the computers (i.e., inside the enterprise network or outside) when the malware were encountered, and for some web-based malware encounters, web activities that gave rise to them. By coupling this data with demographic information for each host's primary user, such as his or her job title and level in the management hierarchy, we are able to paint a reasonably comprehensive picture of malware encounters for this enterprise. We use this analysis to build a logistic regression model for inferring the risk of hosts encountering malware; those ranked highly by our model have a >3x higher rate of encountering malware than the base rate. We also discuss where our study confirms or refutes other studies and guidance that our results suggest."
1391090,15510,339,OASIS: on achieving a sanctuary for integrity and secrecy on untrusted platforms,2013,"We present OASIS, a CPU instruction set extension for externally verifiable initiation, execution, and termination of an isolated execution environment with a trusted computing base consisting solely of the CPU. OASIS leverages the hardware components available on commodity CPUs to achieve a low-cost, low-overhead design."
866003,15510,339,An ontology- and Bayesian-based approach for determining threat probabilities,2011,Information security risk management is crucial for ensuring long-term business success and thus numerous approaches to implementing an adequate information security risk management strategy have been proposed. The subjective threat probability determination is one of the main reasons for an inadequate information security strategy endangering the organization in performing its mission. To address the problem we developed an ontology- and Bayesian-based approach to determine threat probabilities taking general information security knowledge and organization-specific knowledge about existing control implementations and attacker profiles into account. The elaborated concepts enable risk managers to comprehensibly quantify by the Bayesian threat probability determination the current security status of their organization.
1109673,15510,339,"Summary Abstract for the 7th ACM International Workshop on Cyber Security Analytics, Intelligence and Automation",2014,"The 7th ACM International Workshop on Cyber Security Analytics, Intelligence and Automation (SafeConfig) is held as part of ACM Computer and Communications Security CCS 2014. SafeConfig 14, following many successful preceding workshops, is concerned with developing new security techniques and approaches that offer proactive, intelligent and a holistic security analytics based on analyzing the system artifacts including system traces, configurations, logs, incident reports, alarms and network traffic. Scalable analytics techniques are essential to handle large volumes of data and to normalize, model, integrate, analyze and respond to threats in real time."
952043,15510,339,Hardware enhanced security,2012,"Building a secure computing system requires careful coordination among all layers in the system from hardware to software. Even if secure by itself, a higher layer protection mechanism may be bypassed if lower layer software or hardware is vulnerable. Additionally, hardware complements software through its efficiency, tamper resistance, etc. There have been significant efforts recently in hardware communities that aim to leverage hardware strengths to secure software layers, and also to secure hardware itself. This tutorial presents some of these hardware-enhanced security techniques to the security community."
2636032,15510,374,Patrol: Revealing Zero-Day Attack Paths through Network-Wide System Object Dependencies,2013,"��������� ��������������� ���������������� � � � � � � � � � � � � � � � � � � � � � � � � � � �� � �� �� !� ! !� !� ! �#! � �#! �#! � �� � � � � � � � & �� � � & � � � � & � � �� �� �� �� �� �� �� ' �� �� ' �� ' �� �� !� ! � � � � � ! � � ! ! �� �� !� �� �� !� �� �� �� �� �� !� �� �� !� � $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# $� �# #! � � � ! #! � () � � � � �& �& � � � �) � �) � �) � � � � �) � � � � ! �� � � � � � �� � �� � ' � �� �! �� �� �� �� �� �� �� � �� � !� � �� �* �� �� �� �+ �� �� �� �� �� �� � �� �� �% � � �� �� � �� !� �� �� !� �% � � �� �� �� �� !� � �� �� �� � �� �� �� �� !� �� !� � �� �� �� �� !� � � ���$� �� � ( �� �� � ���$� �� ���$� �� .����� ���$� �� � ���$� �� ���$� ���$� �� ���$� ���$� �� ���$� ���$� �� .����� ���$� �� ���$� �� .����� ���$� �� � ���$� �� ���$� ���$� �� ���$� �� $ ���$� �� ���$� �� .����� ���$� �� � ���$� �� � � � �� ��  � � �� �� �� �� � � �� �*�� �� !# � � � � ! � � � �� � �� �� �� � !� !� �� �� � �� �! �� �� � � �� �#! � !� �� � �� �� � �� �� � �� � �� � �� � � �� � ' �� �� �� � �� � �! �� �� �� #! �� � ( � �� � �� � � � � �� �� � ! � �� � ��� �� / � � � � �� �� � � �� !� � �� � ��  �� � � () �� !� �� !� �� � � ! �� � � �� � $ �� � �� �� �� �� � �� �� �� � ���* �� � �� �� ���* �� �� � � �� �� � �� �� � �� �! �� � �� �! �� �! �� �� � � �� � �� � � � � � � � � � � � � � � � � � � � � � � � �� !� � � � � �*� �� ���� �� � �� ( �� � (� �� � � � �*� � � � � � � � �*� �� �� �� � � !� � �*� �� ��� �� ���* �� �� � � � � � ' (� & �� �� �� �� � �� �� �� � � �� � �� �� � �� � �� � �� �� ����� �� � � �� ��� )� �� � � � � � � � �� � !� � � � �*� � !� � � � � �*� � �� � �*� � � � �*� � �� � � � � �*� � �� � � � � � � � �*� � �� � �*� � �� � �*� � � � �*� � �� � � � �� � !� � �� � �*� � � � �� �� �� � �� � $ �� � � � � �� � �*� � �� � !� �� !� �� � !� �� !� �� �� �� �� ��) � �� �� !� �� �� � � ���� � � � �� !� �� �� �� �� � � � � � !� � � � � � �� � � � � � � � � � !� � � � � �� � �� �� � �� � �� �* �� � �� � � �� �* �� �� �* � � � �� �� � �� ! �& ) !( )� � )� !( )� !( )� !( )� !( ) !( )� !( �� �� �� �� �� )� �! �� �� �� �� ) !( �� !� �� !� ) � �  �   � !  �  �� �  �  �  � � �� �� �� � �* �� �� �! �� � � �� �� �� �� � �� �  �� !� ( !� �� � �� � �$� � �� � � �� �� �� �� � �� !� *! �* �� �� ��  �� �� �� �� �� �� �� �� � �� �� �� � � � ���$� �� ���$� ( �� � �� ���$� ���$� �� .����� ���$� �� � ���$� �� ���$� ���$� �� $ ���$� �� .����� ���$� �� ���$� ���$� �� � ���$� �� ���$ � � � � !� �� ' ��*  � * )� �� � � !� �� �� �� �� � �� �! �� �! �� �� �� �� �� �� � � � �� � �! � � �� � !� �� � �� � �! !� �( � ! � ��  �+ � �! !� �� � �! !� �#� � � � ��  �� ! � �! !� � �( ��(�� � �  �� !( #, � �! !� �� � � ��  �+ � � �+  � �! !� �� � �! ��� �� � �! !� !( �! � �! !� ) �! � � � !( �! ! � � � �! !� ) �! ! ��) � � � !( �! � � �! !� ) �! !( �! � ��  �� !( )� � � �! !� �� � �� � �! !� ) �! �� � � �+ !( � � � ��  �� !( �� � ��  �+ !( � � � ��  �� !( �& � � � �+ !( �! � � � �! !� �� � �� � ��  �� !( )� �� ��  �+ !( � � �! !�  � �� � �+  � �! !�  � � ��  �+  � �� � � � �� � �� � �� � � �� !� ! � ! � �� � ! � � �� � ( � ! ;� � �� �! � �/ �# � � � � � � � ! � � �� � � � �� � � � �� �& �� �� ' � � ) !( � � � !( �! � )� !( � � � ��  �� !( )� � � � � �� �� �� � � � � � � � � � � � � � � !� � � � � � � � !� � !� � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � � �� � � � �� � !� � � � � � � � � � � � � � � � � � �� � � � �� � � � �� � � � �� � !� � � � � � � � �� � !� � � � � � !� � � � !� � � � � � !� � � � � !� � � � � � � � � �� � � � � � � � � � � � � !� � � � � � � � � �� � � � �� � � � � � � � �� � � � � � � � � �� � � � � � �� � � � !� � !� � � !� � !� � � � �� � � � �� � � � � � � � !� � � � � � � � � � !� � � � !� � � � � � !� � � � � � � � � � � !� � !� � � � �� � �� � �� � � � �� � �� � ! �� �# �� ! �� �� �� �! �� �! �� �� �� !� � � �� �� � ��� �� � �( �� � �� � � �� � * �� � �, �� � � �� #��� � �� � � �� � � �� � � �� � �� � �� !��� � �� � � �� � �# �� � �% �� � � � �� � � �� !��� �� �� �� ���� �) �� ! �� �� � �� � �� !��� � �� � ' �� � �� !��� ' �� � � �� � � �� ' �� � �� � �� ' ' �� � �� !�� �� � �*� �� !��� �� � �� ' � �� � �� !��� � ' �� ! ' �� � �� �� � �� � �� � � �� � ( � �� � �� � �& �� � ��! �� � ��%� �� �� �� ' �� !��� � �� � �� � � �� � � �� !��� ' ' �� � � � � � � � � �� !� �� �� !� � �� � � �� ' �� � � �� � � � � � � � �! � � � � � �� � � � � � � � ! � � ! � �� � � ���* . �� �� � �� � �� �� � ' (� �� � �� � �� � � � �  � �  � � � < �� ���* �� �� �� � '� � �� �� �� �� ��% �� �� �� � � �� �� �� �� � �� � �� !� � !� � �*� �� � �� � (! �� ( �� �� �) �� � �� � � �� �� � �� � � �� � ����� �� �� �� �� �� �� � )� �� � �� � ���* �� ! �� � �� '� � � �*� �� � ���* �� �� *� � � � �� �� �� !� � � �� �! �� � � � !� � !� � � � �*� � � � �� � � � �� �� �$ � ��� �� � � �� � �� � �� � � �� �� � �� � �� �� � �� � ��"
2411371,15510,20754,Phishing Our Employees,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
2676897,15510,20754,Dr. Strangecode,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1983544,15510,20754,Eternal War in Memory,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1464525,15510,20754,Does the Cloud of Surveillance Have a Silver Lining,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1646154,15510,20754,The Anthropologist's View on Privacy,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1651111,15510,20754,Is Bitcoin a Decentralized Currency,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1678006,15510,20754,"The IEEE Symposium on Security and Privacy, in Retrospect",2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1162361,15510,20754,The TrueCrypt On-Disk Format--An Independent View,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1121011,15510,20754,Educating Engineers: Teaching Privacy in a World of Open Doors,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
326223,15510,20754,"A Symposium, a Magazine, and a Community",2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
914931,15510,20754,The Enduring Importance of Transparency,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1037029,15510,20754,Silver Bullet Talks with Yoshi Kohno,2014,nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull
1879869,15510,20754,How Changing Technology Affects Security,2012,"We are vastly short of skilled security people. Therefore, we will never have more than we do now and those we have will never again make as much money as now they do."
1084279,15510,20754,Your Memory Is Now a Vendor Service,2012,"We no longer provide the context for anything we do, so the systems we deal with provide it for us. This implies that they know more about us and we have less privacy."
708230,15510,20754,Inviting More Heartbleed,2014,Doing the same thing over and over and expecting a different result is nuts. The authors make a simple proposal on doing something different.
1130951,15510,20754,Expanding to Meet Readers' Needs,2014,This editorial describes how IEEE Security a Privacy has expanded its offerings to more effectively meet readers' needs.
1577957,15510,20754,A Key to the Castle,2012,Understanding and providing incentives for good security behavior can be more effective and welcome than disruptive or constraining technology.
1400769,15510,20754,Communicating Covertly through CPU Monitoring,2013,This paper show covert channels using the CPU load are possible between clients connected to a multicore remote server.
1633324,15510,20754,The Threat in the Cloud,2013,"If we're going to stick all the cryptographic services in cloud-based virtual machines, how secure can we expect them to be? The answer is-unfortunately-not very."
1101101,15510,20754,The IEEE Symposium on Security and Privacy Is Moving to San Francisco,2012,"The authors discuss the IEEE Symposium on Security and Privacy, which because of its growing popularity, is moving to a larger venue this year."
35893,15510,9969,The End of Crypto,2012,"This talk will reflect on the core purposes of cryptology, and the extent to which those purposes are served --- and servable --- in today's digital environment."
1417089,15510,20754,"Politics, Love, and Death in a World of No Privacy",2013,Is privacy possible in a state in which everyone's interests are visible via their postings&#x2014;and those of their friends&#x2014;on online social networks?
1766660,15510,20754,Breaking-in Research,2013,"Great research, by definition, will have valuable impacts. But just because an activity is undertaken by a researcher and has valuable impacts does not make it great research&#x2014;or even research."
1167360,15510,20754,Challenges in Power System Information Security,2012,"Achieving all-encompassing component-level security in power system IT infrastructures is difficult, owing to its cost and potential performance implications."
1336212,15510,20754,"It All Depends, and Increasingly So",2011,"The new editors of this department introduce themselves, explain how they plan to develop the department, and ask readers to submit articles and send feedback."
769886,15510,20754,Privacy Issues in Identity Verification,2014,"Identity verification plays an important role in creating trust in the economic system. It can, and should, be done in a way that doesn't decrease individual privacy."
693546,15510,374,Dismantling iClass and iClass Elite,2012,"ESORICS 2012 : 17th European Symposium on Research in Computer Security, Pisam Italy, September 10-12, 2012"
1948848,15510,20754,Experience-Based Access Management: A Life-Cycle Framework for Identity and Access Management Systems,2011,"Experience-based access management incorporates models, techniques, and tools to reconcile differences between the ideal access model and the enforced access control."
2662873,15510,20754,On Abandonment,2013,"If seizing an abandoned code base is too big a stretch for you before breakfast, then start with a certifying authority that goes bankrupt: Who gets the keys?"
2459972,15510,20754,Network-Based Root of Trust for Installation,2011,A network-based system installation method that binds a file system to its installer and disk image thwarts many known attacks against the installation process.
1355783,15510,20754,Silver Bullet Talks with Nate Fick,2014,"Nate Fick, CEO of Endgame, discusses cybersecurity, the term cyberwar from a Marine's perspective, and his time at the Center for a New American Security."
2665892,15510,20754,Giving Back,2012,Editor-in-chief John Viega closes out his term with a discussion about why he served and how other people can get involved to give back to the security community.
988338,15510,20754,All Space Will Be Public Space,2011,"In a world in which people voluntarily live their private lives in public, we need to work with behavioral science to design and create safe public spaces."
1396514,15510,20754,Accountable? The Problems and Solutions of Online Ad Optimization,2014,"Online advertising can be a marketer's dream, but it can also facilitate fraud. The author provides an overview of the problems of online ad optimization and offers some solutions."
1073392,15510,20754,Are All Types of Internet Voting Unsafe,2013,"Everyone knows online voting comes with risks of tampering. How do public and private online elections differ, and do those differences alter the risks in any way?"
696025,15510,20754,Helping You Protect You,2014,"Guest editors M. Angela Sasse and Charles C. Palmer speak with security practitioners about what companies are doing to keep customers secure, and what users can do to stay safe."
1396611,15510,339,Privacy preserving boosting in the cloud with secure half-space queries,2012,This poster presents a preliminary study on the PerturBoost approach that aims to provide efficient and secure classifier learning in the cloud with both data and model privacy preserved.
713706,15510,20754,Can We Be Too Careful,2012,"How can we know if a technology's risk or benefit is greater? From electronic voting machines to backscatter machines, our ever increasing technology is raising issues we must address."
1644677,15510,20754,Walls and Gates,2013,"Complexity should live at a single privilege level, isolated by strong walls and simple gates from other privilege levels. When we don't follow that principle, security failures become more likely."
812807,15510,20754,Provable Security in the Real World,2011,"Provable security plays an important role in the design and analysis of systems using cryptography. However, protocols can be vulnerable to attacks outside the scope of the existing formal analyses."
1229850,15510,20754,Operations with Degraded Security,2011,"Modern systems aren't designed to support some ongoing operations after their security is compromised. Using the ResiliNets model, the authors discuss five strategies for operating in a degraded security environment."
1955171,15510,20754,Attack surface inflation,2011,"The attack surface, a term familiar to most readers of S&P, has been a focus of effort for the bet ter part of a decade now. It's an easy concept to grasp and one not limited to information security."
2345672,15510,20754,How Certification Systems Fail: Lessons from the Ware Report,2012,"The 1970 Security Controls for Computer Systems report, which helped shape computer systems' standard evaluation criteria, can shed light on current certification systems' shortcomings."
1556319,15510,20754,Attacks on GPS Time Reliability,2014,Malicious events can cause GPS signals to be lost altogether or deliberately incorrect. This article examines two types of such events--jamming and spoofing--and possible defenses against them.
1821593,15510,20754,Complementary Perspectives on Privacy and Security: Economics,2013,"Economics and behavioral economics offer different but complementary approaches to understanding privacy and security. This article explains briefly their differences and similarities, and why they matter in our thinking about security and privacy."
2505557,15510,20754,The Dependable Systems-of-Systems Design Challenge,2013,"Systems of systems are becoming more prevalent and more critical to industry and society. Designing these systems is difficult; designing them to be dependable is an even greater challenge. However, there are ways to ease this process."
1085556,15510,20754,Silver Bullet Talks with Matthew Green,2014,"Matthew Green, an assistant research professor at Johns Hopkins Information Security Institute, talks about the difference between theoretical and applied cryptography, blogs, and back doors."
852035,15510,20754,Guest Editors' Introduction: Shouldn't All Security Be Usable?,2011,"Usability is defined as the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use. It is more than a well-designed user interface."
1332653,15510,20754,Trust in Man/Machine Security Systems,2013,"The more machine security is automated, and the more the machine is expected to enforce security without human intervention, the greater the impact of a successful attack. If this sounds like an argument for interface simplicity, it is."
2119754,15510,8912,Continuous mission-oriented assessment (CMA) of assurance,2011,This paper reports ongoing work on a novel mission-oriented information assurance (IA) assessment approach that contrasts runtime measurements and observations against user-specified requirements.
1523200,15510,20754,Never Waste a Crisis,2011,"Computer security crises can be opportunities to improve a company's security and strengthen its commitment to security. Some general guidelines, along with lessons from the JBIG2 incident, can help you reach these goals."
1208727,15510,20754,The Value of Capture-the-Flag Exercises in Education: An Interview with Chris Eagle,2011,IEEE Security & Privacy talks with Chris Eagle of the US Naval Postgraduate School about capture-the-flag exercises and their applicability to high school and college computer science education.
2451699,15510,20754,Circumvention of Security: Good Users Do Bad Things,2013,"Conventional wisdom is that the textbook view describes reality, and only bad people (not good people trying to get their jobs done) break the rules. And yet it doesn't, and good people circumvent."
926537,15510,20754,Authorship Is Continuous: Managing Code Plagiarism,2013,"Code plagiarism is an increasing problem in computer science courses. To deal with this problem, the Vipassana software tool gives instructors improved visibility into their students' programming process."
1659493,15510,20754,Reflecting on Some Past Predictions,2012,"Are computer security experts good futurists? This article examines some of the predictions from 2002 from practitioners, researchers, and corporate managers, and then assesses how well they did at guessing the state of security in 2012."
2020307,15510,20358,The webinos project,2012,This poster paper describes the webinos project and presents the architecture and security features developed in webinos. It highlights the main objectives and concepts of the project and describes the architecture derived to achive the objectives.
2682237,15510,20754,Incident Coordination,2011,"Realtime inter-network defense, a standardized incident-handling format, lets organizations understand threats and incident types as they emerge and coordinate incident handling using secure and automated methods."
2352690,15510,20754,A Shortage of Privacy Engineers,2013,Companies have an urgent need for trained privacy engineers who can hit the ground running. New courses and degree programs are needed to train students for these privacy engineering jobs.
1540967,15510,20754,Insights on the Security and Dependability of Industrial Control Systems,2014,The authors discuss the findings of a recent research seminar on the security and dependability of industrial control systems and provide an overview of major challenges in the field and areas where current research should focus.
678578,15510,20754,When $80 Billion Is Not Enough,2011,The exploitation of cyberinsecurity is shown to be a nation-state activity thus asking whether private initiative must driven to risk-commensurate reaction or ignored as having missed its chance.
1729310,15510,20754,The Invisible Computers,2011,"Marc Donner's valedictory EIC message addresses the ubiquity of computers as system components, whose embedded, interconnected systems have prompted a new generation of security and privacy issues."
2508194,15510,20754,"Rogue-Access-Point Detection: Challenges, Solutions, and Future Directions",2011,"Rogue devices are an increasingly dangerous reality in the insider threat problem domain. Industry, government, and academia need to be aware of this problem and promote state-of-the-art detection methods."
2704267,15510,20754,Security Think,2011,"The author discusses the problem of how a security specialist should think. In particular, such a person should know how to evaluate complex systems and look for vulnerabilities created by interactions. It's hard to do, and even harder to teach."
957007,15510,20754,"Ten Years On, How Are We Doing? (Spoiler Alert: We Have No Clue)",2012,"As this magazine closes out its 10th anniversary year, its editor in chief gives the industry a report card for the past decade, both to see how well it did and to set some goals for the next 10 years."
2733284,15510,20754,Folk Security,2012,"One of the most important, and most overlooked, ways that we learn is by social learning by hearing stories from our friends. Stories are a valuable and underutilized tool for helping people learn how to make better and more secure decisions."
1827063,15510,20754,Security Analytics and Measurements,2012,"The magazine's founding editor in chief, George Cybenko, and his first successor, Carl E. Landwehr, provide perspectives on the need for measuring security and the meaning of those measurements in the context of adversarial dynamics."
1503587,15510,20754,"Big Data, Big Brother, Big Money",2013,"Government snooping, recently publicized, is now using the same data sources that corporations use to watch us. The same records used by federal agencies to search for terrorists are used, with fewer controls, by corporations searching for customers."
1436065,15510,20754,The Case for Mobile Two-Factor Authentication,2011,"User authentication is a core building block of any secure collaborative computing system. And, because of the enhanced interaction between mobile applications and Web ser vices, mobile device user authentication is even more frequent."
1346973,15510,20754,Moving Target [Guest editors' introduction],2014,Moving-target technologies can significantly raise the bar for attackers even without requiring that the distribution of vulnerabilities in the underlying systems be reduced. These techniques should be essential tools for every system architect.
2323384,15510,20754,Securing Information Technology in Healthcare,2013,"Dartmouth College's Institute for Security, Technology, and Society conducted three workshops on securing information technology in healthcare, attended by a diverse range of experts in the field. This article summarizes the workshops."
2146960,15510,20754,Was Stuxnet an Act of War? Decoding a Cyberattack,2011,"Violations of privacy online threaten an individual's sense of security-and relate to the problem of protecting human security in cyberspace. In the cyber and noncyber realms, prospects for human security are shaped by policies designed."
826149,15510,20754,The State of Embedded-Device Security (Spoiler Alert: It's Bad),2012,"Embedded-systems security is a mess, and the embedded-software industry needs to start focusing on it. This will involve moving beyond just the technology to rethink our assumptions of how people will actually use and maintain embedded devices."
921986,15510,20754,Control Systems for the Power Grid and Their Resiliency to Attacks,2014,"Most government, industry, and academic efforts to protect the power grid have focused on information security mechanisms for preventing and detecting attacks. In addition to these mechanisms, control engineering can help improve power grid security."
1142170,15510,20754,The Eyes Have It: Surveillance and How It Evolved,2014,"This article presents a brief history of surveillance, technological and otherwise. It includes a discussion of some of the issues technologists should consider when building software and hardware to capture and analyze personal characteristics, habits, movements, and more."
1593222,15510,20754,A View from the C-Suite,2013,Businesses need to make tradeoffs: they need to balance resources between delivering technology that will help them grow while committing resources to protect the enterprise. This special issue taps into the business view of information security.
1477096,15510,20754,Silver Bullet Talks with Neil Daswani,2012,"Gary McGraw interviews Neil Daswani, a manager in Twitter's revenue engineering team. He was formerly the CTO and cofounder of Dasient, an Internet security company that Twitter purchased in January 2012."
1233948,15510,20754,Electronic Identity Cards for User Authentication—Promise and Practice,2012,"Electronic identity (elD) cards promise to supply a nationwide user authentication mechanism. The core technology seems ready for mass deployment, but application issues might hamper elD adoption."
1432928,15510,20754,"Educating Cyber Professionals: A View from Academia, the Private Sector, and Government",2012,"How do we solve the workforce problem? Guest editor Mischel Kwon brought together a group of people from government, private-sector, and academic backgrounds to discuss the challenges in educating cyber professionals."
795405,15510,20754,Progress Is Infectious,2012,"Models in network science, public health, and immunology can and should inspire developments in cybersecurity but could also inspire nefarious players. It would be wise to explore this in future research sooner rather than later."
1239447,15510,339,POSTER: SHAMROCK: self contained cryptography and key management processor,2013,"In this poster, we describe a one-size-fits-many Intellectual Property (IP) core which integrates advanced key management technology and streaming encryption into a single component to protect data in-transit."
1387113,15510,20754,"Salmon, Songs, and Blankets: Creativity on the Northwest Coast",2011,"The First Nations groups in British Columbia (and nearby Native American groups in Alaska) recognized the ownership of songs and dances, and transferred them as items of value; they did so in a social system rather than a legal one."
1184363,15510,20754,Securing Collaborative Intrusion Detection Systems,2011,Statistic-poisoning attacks inject incorrect security sensor reports into the repository of collaborative intrusion detection systems to corrupt the published attack statistics. A robust approach to computing attack statistics can help counter this threat.
1557280,15510,20754,Advancing Cybersecurity Education,2014,The incoming department editor discusses trends over the past five years of the Education department and current and new topics she'd like to see going forward in an attempt to advance the art and practice of cybersecurity education.
1026280,15510,20754,Lessons Learned from Building a High-Assurance Crypto Gateway,2011,The construction of a complex secure system composed from both secure and insecure components presents a variety of challenges to the designer. The example system described here highlights some lessons learned from first-hand experience in attempting such a task.
1595391,15510,20754,The Untapped Potential of Trusted Execution Environments on Mobile Devices,2014,"Hardware-based trusted execution environments (TEEs) have been available in mobile devices for more than a decade, but their use has been limited. The On-board Credential system safely opens up TEEs so application developers can use their functionality to improve security and usability."
1600644,15510,20754,Avoiding a War on Unauthorized Computation,2013,"Any attempt to regulate&#x2014;or, indeed, legally define&#x2014;exploits will cause irreparable harm to both coder freedoms and consumer systems' trustworthiness. It will reduce the sum of our knowledge about how systems can and cannot behave&#x2014;and thus of what they can and cannot be trusted with."
2616573,15510,20358,The W3C web cryptography API: motivation and overview,2014,The W3C Web Cryptography API is the standard API for accessing cryptographic primitives in Javascript-based environments. We describe the motivations behind the creation of the W3C Web Cryptography API and give a high-level overview with motivating use-cases while addressing objections.
1795252,15510,20754,Making Sense from Snowden: What's Significant in the NSA Surveillance Revelations,2013,"Did Edward Snowden cause irreparable harm, or did he reveal facts that should be publicly examined? What are the facts, anyhow? This article seeks to put the Snowden revelations in context, explaining what's new, why it matters, and what might happen next."
990624,15510,20754,Targeted Cyberattacks: A Superset of Advanced Persistent Threats,2013,"Targeted cyberattacks play an increasingly significant role in disrupting the online social and economic model, not to mention the threat they pose to nation-states. A variety of components and techniques come together to bring about such attacks."
1218010,15510,20754,What Should Crypto Look Like,2014,"Usability failures are the leading technical cause of phishing attacks and unintended plaintext emails, and share much of the blame for the problems with the Web's PKI. The security community should pay more attention to what cryptography should look like."
1117979,15510,20754,Mobile Devices and Location Privacy: Where Do We Go from Here?,2011,"The eruption of concern over mobile device tracking has led to important public debate over location privacy. These cases demonstrate a lack of transparency in mobile systems, with users in the dark about how companies collect and use their location information."
903730,15510,20754,On Adversary Models and Compositional Security,2011,A unified view of a wide range of adversary classes and composition principles for reasoning about security properties of systems are cornerstones of a science of security. They provide a systematic basis for security analysis by explaining and predicting attacks on systems.
2427984,15510,20754,Toward Effective Cybersecurity Education,2013,A February 2013 workshop addressed the challenges of higher education in cybersecurity. The participants discussed what advice to offer regarding the most effective way to produce graduates of the highest caliber who will become the leading cybersecurity professionals.
940653,15510,20754,"Verification, Validation, and Evaluation in Information Security Risk Management",2011,"By surveying verification, validation, and evaluation methods referenced in information security risk management (ISRM) literature, the authors discuss in which ISRM phases particular methods should be applied and demonstrate appropriate methods with a real-world example."
1580351,15510,20754,"The Common Criteria Meets Realpolitik: Trust, Alliances, and Potential Betrayal",2012,"The Common Criteria for Information Technology Security Evaluation aims to become a global standard for IT security certification. However, it faces challenges owing to its rigid framework, rapid technology changes, and the increased militarization of cyberspace."
1102790,15510,20754,Secure Software Installation on Smartphones,2011,"This overview of iOS, Android, BlackBerry, and Symbian security frameworks includes a novel classification of third-party-application installation models. It also discusses how controlled app marketplaces fit in the smartphone security ecosystem."
2381210,15510,22260,Authentication and Access Control in the Internet of Things,2012,"Due to the inherent vulnerabilities of the Internet, security and privacy issues should be considered and addressed before the Internet of Things is widely deployed. This paper mainly analyzes existing authentication and access control methods, and then, it designs a feasible one for the Internet of Things."
1086939,15510,20754,Security Education against Phishing: A Modest Proposal for a Major Rethink,2012,"When tempted by a good deal online, users don't focus on security warnings; rather, they look for signs to confirm a site's trustworthiness. User education needs to focus on challenging and correcting the misconceptions that guide current behavior."
1571842,15510,20754,Ten Years of Trustworthy Computing: Lessons Learned,2011,"In the 10 years since Microsoft launched its Trusted Computing Initiative, Microsoft has invested billions on the security of their software. In this article, we learn that, while they haven't gotten out all the bugs, Microsoft has had a significant positive impact on the way we think about secure software."
1288319,15510,20754,Are You Smarter than the TSA? (Hint: No),2012,"An asymmetric enemy makes us spend a dollar on every single thing that might happen while he spends money on the one thing that will. We can't win the enemy's spending game, so we need to focus on spending money on a smaller number of things."
1255880,15510,20754,Using Whitelisting to Combat Malware Attacks at Fannie Mae,2013,"Security-awareness training and antivirus software can't entirely prevent the downloading of malware. To supplement these defenses, cybersecurity staff at Fannie Mae successfully implemented application whitelisting, which allows only approved software to execute."
2498613,15510,20754,The Clouds Roll By,2012,Technology changes have driven us first away from centralized computer services and now back toward centralization. Security and reliability are likely to improve as expertise is also centralized and fewer demands are placed on the relatively inexperienced individual users.
818839,15510,8494,A 1-bit Physically Unclonable Function based on a two-neurons CNN,2013,"We propose to exploit a two-neurons Cellular Neural Network (CNN) to design a basic 1-bit Physically Unclonable Function (PUF). The analysis discussed in this work, derived from the general theory of CNNs, has been validated by experimental results."
786888,15510,20754,Academic Impact at the Federal Trade Commission,2012,How does academic privacy and security research result in real-world privacy protection or enhancement? This isn't just an issue of broader research impact but a fundamental scientific research question. A major means to accomplish impact is through existing regulation and oversight institutions.
852629,15510,20754,Forensic Methods for Detecting Insider Turning Behaviors,2012,"This paper focuses on the use of forensic methodologies and methods for detecting subversions, an approach that may help to mitigate risk in a substantial portion of cases of types characterized to date. In essence, we look for the telltale signs of cover-ups."
1333842,15510,20754,Cybersecurity Education in Universities,2013,"An educated computer security workforce is essential to building trustworthy systems. Yet, issues about what should be taught and how are being ignored by many of the university faculty who teach cybersecurity courses--a problematic situation. Author Fred Schneider explores the issues."
2365736,15510,20754,A Transatlantic Convergence on Privacy,2011,Both the European Union and US recently released major reports on privacy. These significant and long-awaited government reports provide new insights into how regulators on both sides of the Atlantic view privacy challenges. They also reveal the extent to which those views are converging.
1643255,15510,20754,Guest Editors' Introduction: The Science of Security,2011,"We're a long way from establishing a science of security comparable to the traditional physical sciences, and even from knowing whether such a goal is even achievable. Nevertheless, the articles in this special issue hint at the possibility and promise of foundational approaches to security."
1148959,15510,20754,Caller ID: Whose Privacy?,2014,"Today, we consider it routine to see the name of the person calling us when our phone rings. When this service was introduced, it was debated: was a telephone caller entitled to anonymity? We opted for disclosure, and we should remember that maximum privacy isn't always the best public policy."
1241135,15510,20754,Driving for Big Data? Privacy Concerns in Vehicular Networking,2014,"Communicating vehicles will change road traffic as we know it. With current versions of European and US standards in mind, the authors discuss privacy and traffic surveillance issues in vehicular network technology and outline research directions that could address these issues."
993462,15510,20754,Should Sniffing Wi-Fi Be Illegal?,2014,Should it be against the law to sniff Wi-Fi packets? This question not only has ramifications for Wi-Fi and wiretapping but also poses broader questions about how we use law to protect online privacy. It leads us to consider many important and recurring debates about the collision of law and technology.
1483014,15510,20754,An Anthropological Approach to Studying CSIRTs,2014,The ethnographic method of participant observation can help researchers better understand the challenges computer security incident response teams face by illuminating underlying assumptions and tacit practices that shape how tools are actually used in different contexts.
2062956,15510,20754,Hover: Trustworthy Elections with Hash-Only Verification,2012,"Hover (Hash-Only Verification), an end-to-end (E2E) verifiable voting system with distributed trust, uses only a collision-resistant hash function for verification. Such verification could make E2E elections more accessible to people without a strong cryptography background."
1332202,15510,20754,Bloatware Comes to the Smartphone,2012,"The author explores the security and privacy implications of the now-common industry practice of installing bloatware on phones sold by cellular carriers. Is it merely annoying, or do smartphone users face more serious concerns? Do the economic advantages outweigh the security and privacy concerns?"
1734745,15510,20754,Help! Is There a Trustworthy-Systems Doctor in the House?,2013,"A multidisciplinary PhD in trustworthy systems can combine knowledge and practices from computer science, information systems, software engineering, and information technology. Such a program will create individuals who can lead teams of specialists that can address the varied functional and protection challenges of information systems."
1437066,15510,20754,Principles of Cyberwarfare,2011,"The principles of kinetic warfare are well documented, but are not always applicable to cyberwarfare. Differences between cyberspace and the real world suggest some additional principles. This article proposes some principles of cyberwarfare. This is not intended to be a comprehensive list but rather suggestions leading toward discussion and dialogue."
1335323,15510,20754,Static Analysis in Motion,2012,"As part of this special issue on static analysis, guest editor Brian Chess put together a roundtable discussion with leaders in the field. Here, they discuss their views on where static analysis is today and what's required to make it an effective part of creating secure and reliable software."
1395883,15510,339,POSTER: On the Capability of DNS Cache Poisoning Attacks,2014,"Cache poisoning is a serious threat to today's DNS, and Kaminsky cache poisoning is proposed as the most effective. We develop a maximum-efficiency attack model of Kaminsky cache poisoning, which is built on persistent poisoning attempts optimized for more than one windows of opportunity. Using the model, we illustrate the effects of Kaminsky cache poisoning and the optimal number of outstanding queries in terms of probability of compromise."
1837476,15510,20754,Experimenting with Incentives: Security in Pilots for Future Grids,2014,"Electricity grids are in a transition phase. With the rise of renewable energy, energy prosumers, and electric vehicles, traditional models of matching supply and demand are no longer adequate. Grid pilot projects can help identify ways to improve cybersecurity in future grids."
728780,15510,20754,"Privacy, Ethics, and Analytics",2011,"When using the analytics process, companies should consider the risks it poses to individuals' information privacy as well as develop responsible measures to accompany its use. This set of ethical standards calls on companies to adopt accountable approaches that reflect the specific risks in a given use of the analytics process."
1996613,15510,22021,Constructing Boolean functions in odd number of variables with maximum algebraic immunity,2011,"The algebraic immunity of cryptographic Boolean functions with odd number of variables is studied in this paper. We prove that minor modifications of functions achieving maximum algebraic immunity yield functions which are bound to have maximum or almost maximum algebraic immunity. Based on this, a new efficient algorithm to produce functions of guaranteed maximum algebraic immunity is developed. Moreover, it is shown that known constructions of functions with maximum algebraic immunity may also be generalized by using the same concepts."
2666779,15510,20332,A Simple Logical Approach to Reasoning with and about Trust,2011,"Trust is an approach to managing the uncertainty about autonomous entities and the information they store, and so can play an important role in any decentralized system. As a result, trust has been widely studied in multiagent systems and related fields such as the semantic web. Here we introduce a simple approach to reasoning about trust with logic."
1610194,15510,20754,"Trust, but Verify",2014,"Do you believe the software packages you buy and install are secure? Today that belief is largely a matter of faith. Could a third-party verification process, whether similar to Underwriters Laboratories or the US Food and Drug Administration, give us greater assurance of secure software?"
1367609,15510,20754,"Resilience: What Is It, and How Much Do We Want?",2012,"The word “resilience” is increasingly popular to designate some properties we want from systems. When we use this word, do we all mean the same concept? Or the same set of multiple concepts? How do we know when we've achieved it, or them, or a certain amount of them? To design systems, write contracts, or manage organizations, we need some common view about all this."
2465714,15510,20754,The Future of Authentication,2012,"As part of this special issue on authentication, guest editors Richard Chow, Markus Jakobsson, and Jesus Molina put together a roundtable discussion with leaders in the field, who discuss here their views on the biggest problems in authentication, potential solutions, and the direction in which the field is moving."
2376082,15510,20754,Fighting the Last War,2012,"It would be nice to get rid of passwords entirely, but that isn't going to happen any time soon. What we need are better ways of entering, storing, and using passwords, ways that respond to today's threats instead of yesterday's. Sticking with checklists based on yesterday's technology is not the way to secure today's systems."
2521452,15510,8235,Hot updates for Java based smart cards,2011,"Systems need to be updated in order to correct vulnerabilities, fix bugs but also to enhance functionalities. Traditional software update mechanisms usually stop the software that need to be updated, apply the update then restart the system. However, this approach is not appropriate in critical systems such as banking or telecommunications."
902469,15510,20754,Emerging Techniques for Field Device Security,2014,"Industrial control systems (ICSs) rely on embedded devices to control essential processes. State-of-the-art security solutions can't detect attacks on these devices at the hardware or firmware level. To improve ICS cybersecurity, defensive measures should focus on inspectability, trustworthiness, and diversity."
1625774,15510,20754,Building Security In: Preparing for a Software Security Career,2013,"Carnegie Mellon University's Software Engineering Institute (SEI) has developed a set of software assurance curriculum guidance documents, which provides a foundation for preparing a software security workforce. This article describes the SEI Software Assurance Curriculum Project's work and the curriculum guidance documents. A case study illustrates how individuals could use the curriculum guidance."
1314200,15510,339,The first workshop on language support for privacy-enhancing technologies (PETShop'13),2013,"The Workshop on Language Support for Privacy-Enhancing Technologies (PETShop'13) aims at bringing together researchers from the areas of security, programming languages, compiler construction, and program verification to exchange ideas and research results to improve the practicality of state of the art cryptographic privacy-enhancing technologies."
1641410,15510,20754,Silver Bullet Talks with Bart Miller,2014,"Bart Miller, professor of computer science at the University of Wisconsin-Madison and chief scientist of the Department of Homeland Security's Software Assurance Marketplace (SWAMP) research facility, discusses Heartbleed, fuzz testing, his work on dynamic instrumentation of binaries, and the SWAMP project."
637415,15510,20754,Stand Your Ground,2012,"According to the authors, there is no sane, no rational, no informed person who does not recognize that protection from the risks of Internet use comes down to a choice: blind faith or self-defense. All versions of trust us, and you'll be okay are probabilistic falsities. They use this essay to discuss trust and its role in security."
1271327,15510,20754,Crossing the Great Divide: Transferring Security Technology from Research to the Market,2013,"The challenges of transferring cybersecurity technologies are varied and span a wide range from detailed technical issues to market, sales, and production issues. It often seems that there is an art to successfully crossing the great divide. Are there cybersecurity-specific issues and challenges that make technology transfer more difficult?"
139184,15510,8228,Use of Linear Error-Correcting Subcodes in Flow Watermarking for Channels with Substitution and Deletion Errors,2013,An invisible flow watermarking QIM scheme based on linear error-correcting subcodes for channels with substitution and deletion errors is proposed in this paper. The evaluation of scheme demonstrates similar to known scheme performance but with lower complexity as soon as its implementation is mainly based on linear decoding operations.
148208,15510,9969,Inverting HFE systems is quasi-polynomial for all fields,2011,"In this paper, we present and prove the first closed formula bounding the degree of regularity of an HFE system over an arbitrary finite field. Though these bounds are not necessarily optimal, they can be used to deduce 1. if D, the degree of the corresponding HFE polynomial, and q, the size of the corresponding finite field, are fixed, inverting HFE system is polynomial for all fields;"
1510937,15510,20754,Primitive-Chaining Exploits: A Real-World Example,2012,"Attackers can gain unauthenticated remote control of the program counter through CVE-2010-3972, a vulnerability in Microsoft's Internet Information Services FTP 7.5. This example of primitive chaining shows that attackers can combine information about the operating system, application, and vulnerability to create a viable exploit."
202705,15510,9969,Computational Fuzzy Extractors,2013,"Fuzzy extractors derive strong keys from noisy sources. Their security is defined information-theoretically, which limits the length of the derived key, sometimes making it too short to be useful. We ask whether it is possible to obtain longer keys by considering computational security, and show the following."
2108963,15510,20754,Big Data Analytics for Security,2013,"Big data is changing the landscape of security tools for network monitoring, security information and event management, and forensics; however, in the eternal arms race of attack and defense, security researchers must keep exploring novel ways to mitigate and contain sophisticated attackers."
2220418,15510,20754,Beyond Planted Bugs in Trusting Trust: The Input-Processing Frontier,2014,"Big data is changing the landscape of security tools for network monitoring, security information and event management, and forensics; however, in the eternal arms race of attack and defense, security researchers must keep exploring novel ways to mitigate and contain sophisticated attackers."
918207,15510,20754,The Price of Privacy,2012,"Simply declaring privacy to be a legal right doesn't provide any resources to enforce it. If privacy was an economic transaction, meaning that people pay for it, then their payments would provide resources to protect it. Would we have better privacy if people were paying for it directly rather than trying to get it via political campaigns?"
1229647,15510,20754,An Organizational Psychology Perspective to Examining Computer Security Incident Response Teams,2014,"Generally, computer security incident response team (CSIRT) managers and team members focus only on individual-level skills. The field of organizational psychology can contribute to an understanding of the full range of CSIRT job requirements, which include working as a team and within a larger multiteam system."
1236971,15510,20754,Does Profiling Make Us More Secure,2012,&#x0093;Profiling&#x0094; means making predictions about likely user behavior based on collected characteristics and activities. Shari Lawrence Pfleeger and Marc Rogers brought together a group of researchers from a variety of disciplines to discuss whether profiling and prediction actually make us secure.
1553355,15510,20754,Making Successful Security Decisions: A Qualitative Evaluation,2012,"How do IT security managers make decisions in the absence of empirical data, and how do they know these decisions are successful? Some security managers seem more successful at making decisions than others. Are they guessing, or are they using some tacit knowledge? To address these questions, a study employed open-ended interviews with highly regarded, experienced security practitioners."
1286546,15510,8494,Design of security enhanced TPM chip against invasive physical attacks,2012,"A TPM (Trusted Platform Module) is a hardware-based secure device that is very strong against software-based attacks; however, the keys inside a TPM can be extracted by invasive physical attacks such as memory attacks and bus probing attacks. To protect the keys from these threats, we propose a new TPM architecture based on a Physical Unclonable Function."
1193009,15510,20754,Basing Cybersecurity Training on User Perceptions,2012,"The authors investigated users' understanding of online security by conducting in-depth interviews to identify correct perceptions, myths, and potential misperceptions. Participants were aware of and concerned with online and computer security but lacked a complete skill set to protect their computer systems, identities, and information online."
939864,15510,20754,Silver Bullet Talks with Randy Sabett,2012,"Gary McGraw talks to Randy Sabett, a lawyer with the ZwillGen cyberlaw firm in Washington, DC, about cybercrime and the law. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
442726,15510,9969,Attribute-Based Encryption for Circuits from Multilinear Maps,2012,"In this work, we provide the first construction of Attribute-Based Encryption (ABE) for general circuits. Our construction is based on the existence of multilinear maps. We prove selective security of our scheme in the standard model under the natural multilinear generalization of the BDDH assumption. Our scheme achieves both Key-Policy and Ciphertext-Policy variants of ABE."
1753540,15510,20754,Developing Secure Products in the Age of Advanced Persistent Threats,2012,Advanced persistent threats (APTs) are making technology providers reconsider their security assumptions for secure product development. This article suggests an industry roadmap for rethinking product security in the face of APTs. It also describes steps EMC has taken to implement this roadmap and strengthen its product development practices.
1042049,15510,8912,"The Third International Workshop on Dependability of Clouds, Data Centers and Virtual Machine Technology DCDV 2013",2013,"The Third International Workshop on Dependability of Clouds, Data Centers, and Virtual Machine Technology (DCDV 2013) features papers covering various aspects of dependability and security in Clouds and Data Centers. Four sessions covering Cloud and Data Center Networking, Dependability Evaluation, Mobile and Cloud Computing, and Virtualization and Cloud include eleven papers."
937386,15510,20754,Conflicts between Intrusion Detection and Privacy Mechanisms for Wireless Sensor Networks,2013,"Both active and passive attackers pose a threat for wireless sensor networks. So, intrusion detection systems and privacy mechanisms must be deployed, usually at the same time. Yet this coexistence might result in the malfunction or inefficiency of one of these components. Several techniques and principles can help minimize such problems."
1001352,15510,339,Belief semantics of authorization logic,2013,"A formal belief semantics for authorization logics is given. The belief semantics is proved to subsume a standard Kripke semantics. The belief semantics yields a direct representation of principals' beliefs, without resorting to the technical machinery used in Kripke semantics. A proof system is given for the logic; that system is proved sound with respect to the belief and Kripke semantics. The soundness proofs are mechanized in Coq."
1714168,15510,20754,Electronic Voting Security 10 Years after the Help America Vote Act,2012,"Merle S. King, executive director of the Center for Election Systems at Kennesaw State University, and Brian Hancock, director of voting system testing and certification at the US Election Assistance Commission (EAC), discuss e-voting security 10 years after the Help American Vote Act (HAVA)."
2405673,15510,20754,How Private Is the Internet,2011,"Most common uses of the Internet are email, Web surfing, and transactions ranging from e-commerce to bill paying. This paper discussed on how to prevent eavesdropping and eliminate possible attack modalities. HTTPS allows for the growing work of e-commerce, online banking and bill paying, and other activities requiring secure information exchange."
2145399,15510,8912,An analysis of signature overlaps in Intrusion Detection Systems,2011,"An Intrusion Detection System (IDS) protects computer networks against attacks and intrusions, in combination with firewalls and anti-virus systems. One class of IDS is called signature-based network IDSs, as they monitor network traffic, looking for evidence of malicious behaviour as specified in attack descriptions (referred to as signatures)."
1988170,15510,23827,Exception handling for dynamic information flow control,2014,"Exceptions are a source of information leaks, which are difficult to handle as they allow for non-local control transfer. Existing dynamic information flow control techniques either ignore unstructured control flow or are restrictive. This work presents a more permissive solution for controlling information leaks using program analysis techniques."
2646913,15510,20754,Measuring Security,2011,"The field of computer and communications security begs for a foundational science to guide system design and to reveal the safety, security, and possible fragility of the complex systems we depend on today. To achieve this goal, we must devise suitable metrics for objectively comparing and evaluating the security of system designs and organizations."
1330003,15510,20754,Automating Efficient RAM-Model Secure Computation,2014,"RAM-model secure computation addresses the inherent limitations of circuit-model secure computation considered in almost all previous work. Here, we describe the first automated approach for RAM-model secure computation in the semi-honest model. We define an intermediate representation called SCVM and a corresponding type system suited for RAM-model secure computation. Leveraging compile-time optimizations, our approach achieves order-of-magnitude speedups compared to both circuit-model secure computation and the state-of-art RAM-model secure computation."
2001239,15510,339,New time-memory-data trade-off attack on the estream finalists and modes of operation of block ciphers,2012,"In this paper, we introduce a new time-memory-data trade-off attack which can perform better than existing ones by Biryukov-Shamir (BS-TMD [1]), Hong-Sarkar (HS-TMD [8]) and Dunkelman-Keller (DK-TMD [5]). Current Estream ciphers are resistant to these attacks because the state size is too big for the BS-TMD attack, while the pre-processing is at least as expensive as exhaustive search for the HS-TMD and DK-TMD attacks."
1440332,15510,11330,Author retrospective AEGIS: architecture for tamper-evident and tamper-resistant processing,2014,"AEGIS is a single-chip secure processor that can be used to protect the integrity and confidentiality of an application program from both physical and software attacks. We briefly describe the history behind this architecture and its key features, discuss main observations and lessons from the project, and list limitations of AEGIS and how recent research addresses them."
1674563,15510,20754,"This Time, It's Personal: Recent Discussions on Concepts of Personal Information",2012,"Under privacy regulation, what exactly is personal information? This is an important concept in a changing landscape of technology and information disclosure, in which it's becoming increasingly easier to identify and reidentify individuals. Legal scholars have provided some insights into the evolving nature of personal information and how we might incorporate notions of identifiability risk into regulation."
1947801,15510,20754,China's Data Privacy Regulations: A Tricky Tradeoff between ICT's Productive Utilization and Cybercontrol,2014,"China's data privacy regulations contrast sharply with other major economies owing to internal and external pressures the Chinese government faces. Whereas the EU places high priority on protecting personal data and the US emphasizes self-regulation by businesses, China's regulations focus on cybercontrol measures."
16499,15510,10286,Proxy Re-encryption from Lattices,2014,We propose a new unidirectional proxy re-encryption scheme based on the hardness of the LWE problem. Our construction is collusionsafe and does not require any trusted authority for the re-encryption key generation. We extend a recent trapdoor definition for a lattice of Micciancio and Peikert. Our proxy re-encryption scheme is provably CCA-1 secure in the selective model under the LWE assumption.
1389159,15510,20754,Aligning the Compasses: A Journey through Compliance and Technology,2014,"Technology's role in compliance is surprisingly human, and addressing those human traits up front leads to far more successful compliance outcomes. The era of big data requires big compliance, and a fundamental part of big compliance today and going forward is the reconciliation of the written rules with a very real set of technologies employed by an organization."
2286092,15510,8228,Privacy management in global organisations,2012,"Meeting privacy requirements can be challenging for global organisations, particularly where future Internet service provision models are involved. In this paper approaches will be explained that can be used to help address these issues, with a focus on some of the solutions that the author has been involved in developing in HP Labs that are currently being used, rolled out or are the subjects of further research."
906701,15510,20754,Addressing Information Risk in Turbulent Times,2011,Turbulent times exacerbate many existing information risks and create new security management challenges. Discussions and interviews with chief information security officers from a broad range of large firms about how they addressed the challenges of the economic downturn provide both actionable ideas and clues for future research.
2733338,15510,20754,Detecting Cheaters,2011,Brains are specially designed to deal with cheating in social exchanges. The evolutionary psychology explanation is that evolved brain heuristics for the social problems that prehistoric ancestor had to deal with. Propositional calculus is a system for deducing conclusions from true premises. It uses variables for statements because the logic works regardless of what the statements are.
2208506,15510,20754,Building Security In: A Road to Competency,2013,"The Software Assurance (SwA) Competency Model provides a foundation for assessing and advancing software security professionals' capability. A span of competency levels and their decomposition into competencies, based on the knowledge and skills in the SwA Core Body of Knowledge, enable organizations or individuals to determine SwA competency. Organizations can also adapt the model's features to their domain, culture, or structure."
1735026,15510,20754,Tamper Detection in the EPC Network Using Digital Watermarking,2011,One of the most relevant problems in radio frequency identification (RFID) technology is the lack of security measures in its wireless communication channel between the reader and tag. This article analyzes potential data tampering threats in the electronic product code (EPC) network and proposes solutions using fragile watermarking technologies.
1198282,15510,22021,Precise evaluation of leaked information with universal 2 privacy amplification in the presence of quantum attacker,2012,"We treat secret key extraction when the eavesdropper has correlated quantum states. We propose quantum privacy amplification theorems different from Renner's, which are based on quantum conditional Renyi entropy of order 1 + s. Using those theorems, we derive an exponential decreasing rate for leaked information and the asymptotic equivocation rate, which have not been derived hitherto in the quantum setting."
1325545,15510,20754,"Security Measurement Steps, Missteps, and Next Steps",2012,"Over the past decade, this magazine has focused on a wide variety of important issues, each of which contributes not only to our understanding of security but also to innovative and effective solutions to security problems. Measurement has frequently held star and supporting roles in many of these articles. The author describes the past, present, and future for measurement's role in security."
244855,15510,11345,Square Span Programs with Applications to Succinct NIZK Arguments,2014,"We use SSPs to construct succinct non-interactive zero-knowledge arguments of knowledge. For performance, our proof system is defined over Type III bilinear groups; proofs consist of just 4 group elements, verified in just 6 pairings. Concretely, using the Pinocchio libraries, we estimate that proofs will consist of 160 bytes verified in less than 6 ms."
1425446,15510,20754,Quantifying Information Flow for Dynamic Secrets,2014,"A metric is proposed for quantifying leakage of information about secrets and about how secrets change over time. The metric is used with a model of information flow for probabilistic, interactive systems with adaptive adversaries. The model and metric are implemented in a probabilistic programming language and used to analyze several examples. The analysis demonstrates that adaptivity increases information flow."
1078634,15510,20754,Physical Unclonable Functions: A Primer,2014,"Physical unclonable functions (PUFs) make use of the measurable intrinsic randomness of physical systems to establish signatures for those systems. PUFs provide a means to generate unique keys that don't need to be stored in nonvolatile memory, and they offer exciting opportunities for new authentication and supply chain security technologies."
1126403,15510,20754,Integrity in Embedded Control Networks,2013,"As threats from malicious attackers increase, integrity approaches in networked embedded systems will have to evolve to provide both the security and safety aspects of integrity in a unified approach. And they'll have to do it on a shoestring, using only a few bits per message. To help achieve this, you can exploit two embedded-systems characteristics: the periodic sampling of messages and the system's inertia."
1486125,15510,339,Large-scale DNS data analysis,2012,"DNS data is increasingly used in security analysis, intrusion detection, and research. Even small DNS collection systems can generate enormous amounts of DNS traffic, requiring tera-scale storage. As a result, researchers looking at DNS traffic must often develop real-time, in-line analysis tools."
540338,15510,374,Model-Checking Bisimulation-Based Information Flow Properties for Infinite State Systems,2012,"Bisimulation-based information flow properties were introduced by Focardi and Gorrieri [1] as a way of specifying security properties for transition system models. These properties were shown to be decidable for finite-state systems. In this paper, we study the problem of verifying these properties for some well-known classes of infinite state systems. We show that all the properties are undecidable for each of these classes of systems."
1271652,15510,20754,Adapting Law Enforcement Frameworks to Address the Ethical Problems of CCTV Product Propagation,2014,"The development of video sharing and analytic capabilities is outpacing ethical debate and governance policy. To mitigate privacy abuse and prevent unauthorized data sharing, an inter-entity audit framework, based on a law enforcement methodology, documents video-sharing activity without duplicating existing access control mechanisms."
763616,15510,20754,It's Time for Trustworthy Systems,2012,"The time for truly trustworthy systems, backed by machine checked formal proof and analysis, has arrived. Over the past few decades, advances in formal verification and analysis technologies mean that these tools can now scale sufficiently to cover the entire software trusted computing base of appropriately designed real world systems."
2088751,15510,20754,Disinformation: A Taxonomy,2011,"This article outlines steps towards a disinformation theory, a simplified and generalized notion of communication that is intended to be, in some way, misleading or deceptive. The model is derived from Shannon's communications model, but with an intentional “noise source” and an unintended receiver. Alterations of an image containing a message are used to illustrate a variety of disinformation techniques."
1694597,15510,20754,Developer-Driven Threat Modeling: Lessons Learned in the Trenches,2011,"This article describes EMC/s real-world experiences with threat modeling, including major challenges encountered, lessons learned, and a description of the company's current developer-driven approach.Threat modeling is a conceptual exercise in which we analyze a system's architecture or design to find security flaws and reduce architectural risk."
2098675,15510,339,CL-PRE: a certificateless proxy re-encryption scheme for secure data sharing with public cloud,2012,"We propose CL-PRE, a  certificateless proxy re-encryption  scheme for secure data sharing with public cloud, which leverages maximal cloud resources to reduce the computing and communication cost for data owner. Towards running proxy in public cloud environment, we further propose  multi-proxy CL-PRE  and  randomized CL-PRE , which enhance the security and robustness of CL-PRE. We implement all CL-PRE schemes and evaluate their security and performance."
771125,15510,20754,Are Things Getting Worse,2012,"Today's systems might be purposefully designed, but they'll evolve and grow. The key to future dependable infrastructure and services is to align incentives (for example, for profitability, resilience, structure, and innovation) to ensure that initial systems are adaptable, then shape their growth so that services and systems develop with the right levels of resilience and redundancy."
1811758,15510,20754,Using Cloud Computing to Implement a Security Overlay Network,2013,"This article proposes and analyzes a general cloud-based security overlay network that can be used as a transparent overlay network to provide services such as intrusion detection systems, antivirus and antispam software, and distributed denial-of-service prevention. The authors analyze each of these in-cloud security services in terms of resiliency, effectiveness, performance, flexibility, control, and cost."
772697,15510,20754,A Gentle Introduction to Risk-Limiting Audits,2012,"Risk-limiting audits provide statistical assurance that election outcomes are correct by manually examining portions of the audit trail-paper ballots or voter-verifiable paper records. This article sketches two types of risk-limiting audits, ballot-polling audits and comparison audits, and gives example computations. These audits do not require in-house statistical expertise."
1231499,15510,339,Poster: practical embedded remote attestation using physically unclonable functions,2011,"We present the design and implementation of a lightweight remote attestation scheme for embedded devices that combines software attestation with Physically Unclonable Functions (PUFs). In contrast to standard software attestation, our scheme (i) is secure against collusion attacks to forge the attestation checksum, (ii) allows for the authentication and attestation of remote provers, and (iii) enables the detection of hardware attacks on the prover."
859026,15510,339,SIW 2014: First Workshop on Security Information Workers,2014,"The human element is often considered the weakest element in security. Although many kinds of humans interact with systems that are designed to be secure, one particular type of human is especially important, the security information worker. Security information workers include software developers, system administrators, and intelligence analysts. This workshop aims to develop and stimulate discussion about security information workers."
1624866,15510,20754,Resilient to the Unexpected,2011,"In evaluating systemic risk and resilience we need to move from powerful metaphors to usable models that address different types of uncertainty. The complex adaptive nature of infrastructures provide a wide range of interconnected challenges, such as those posed by the simple question what is the system?. In answering this we should recognize the importance of the soft intangible infrastructures."
2684698,15510,20358,Localized CAPTCHA testing on users and farms,2014,"The paper describes the experience of resisting the large-scale solving of CAPTCHA through the CAPTCHA-farms and presents the results of experimenting with different types of textual CAPTCHA on the farm worker and casual user crowds. Localization of CAPTCHA led to cutting twice the absolute volume of CAPTCHA parsing, but introducing the semantics into the test complicated it to casual users and was not found promising."
2739786,15510,11345,Certifying RSA,2012,"We propose an algorithm that, given an arbitrary N of unknown factorization and prime e ≥ N1/4+e, certifies whether the RSA function RSAN,e(x) :=xe mod N defines a permutation over ℤ*N or not. The algorithm uses Coppersmith's method to find small solutions of polynomial equations and runs in time O(e−8 log2N). Previous certification techniques required e>N."
989194,15510,20754,Gone in 15 Seconds: The Limits of Privacy Transparency and Control,2013,"Even simpler or more usable privacy controls and notices might not improve users' decision-making regarding sharing of personal information. Control might paradoxically increase riskier disclosure by soothing privacy concerns. Transparency might be easily muted, and its effect arbitrarily controlled, through simple framing or misdirections."
1695498,15510,20754,Enlightened Security: Shedding Light on What Works and Why,2013,"As we mature and move toward enlightened security, this magazine will explore why we do what we do and what we know about cause and effect. We will also broaden content to address dependability and policy, and to apply contributions that other disciplines can make to our understanding of security, privacy, and reliability. The featured Web extra identifies and thanks the reviewers who served our publication in 2012."
1169674,15510,20754,By Executive Order: Delivery of Cyber Intelligence Imparts Cyber Responsibilities,2013,"The US, like most countries, is grappling with how to handle cybersecurity issues, especially threats to critical infrastructure. How and where should a government intervene, and which entities have responsibility for notice and action? The authors comment on a recent US Executive Order and its evolution from failed attempts to enact cybersecurity legislation. Although the details are specific to the US, the lessons are applicable to everyone."
1413123,15510,20754,The Old Is New Again,2013,"The invention of copying 50 years ago offered convenience to readers and was a socially good thing. Preventing it would not have caused a major increase in individual paper subscription, then or now. Instead, without copying, readers would either have to go to a library or, more likely, not read at all. The same arguments appear today, this time about electronics."
2690695,15510,20754,Metadata = Surveillance,2014,"Ever since reporters began publishing stories about NSA activities, based on documents provided by Edward Snowden, we've been repeatedly assured by government officials that it's only metadata. This might fool the average person, but it shouldn't fool those of us in the security field. Metadata equals surveillance data, and collecting metadata on people means putting them under surveillance."
2141449,15510,20561,Impacts of Malicious Data on Real-Time Price of Electricity Market Operations,2012,Impacts of malicious data data attack on the real-time electricity market are studied. It is assumed that an adversary has access to a limitted number of meters and has the ability to construct data attack based on what it observes. Different observation models are considered. A geometric framework is introduced based on which upper and lower bounds on the optimal data attack are obtained and evaluated in simulations.
1272962,15510,20754,What Engineers Should Know about US Security and Privacy Law,2013,"As new technology challenges our assumptions about security and privacy, lawmakers respond by attempting to curb and avoid the most egregious risks to the public. In this article, the authors examine how emerging US security and privacy laws create new requirements that constrain software development affecting business owners and developers who want to design security and privacy into IT systems."
1976737,15510,9969,Recent Advances and Existing Research Questions in Platform Security,2012,"In this talk I will provide a description of recent uses Intel has made of cryptography in our platforms, including providing a hardware random number generator, using anonymous signatures, and improving performance of cryptographic algorithms. I will discuss how processor capabilities could be used more effectively by cryptographic algorithms. I will then discuss research questions in cryptographic protocols and platform security that are motivated by our goals."
2289909,15510,20754,NICE: Creating a Cybersecurity Workforce and Aware Public,2012,"The National Initiative for Cybersecurity Education (NICE) aims to create an operational, sustainable, and continually improving program for cybersecurity awareness, education, training, and workforce development. As part of the initiative, the NICE Cybersecurity Workforce Framework aims to codify cybersecurity talent; define the cybersecurity workforce in common terms; and tie the workforce's various jobs, competencies, and responsibilities into a common architecture."
1680236,15510,20754,Twitsper: Tweeting privately,2013,"Although today's online social networks provide some privacy controls to protect a user's shared content from other users, these controls aren't sufficiently expressive to provide fine-grained protection. Twitsper offers fine-grained control over who sees a Twitter user's messages, enabling private group communication while preserving Twitter's commercial interests."
1411252,15510,20754,Empathy and Security,2011,"While researching his new book, security expert Bruce Schneier examined the role morals play in providing security. Because security professionals spend most of their time dealing with attackers for whom morals aren't sufficient to keep them from doing what they shouldn't be doing, Schneier suggests that we may need to start looking at ways to enhance the natural security systems our species has evolved over the millennia."
702949,15510,339,Poster: applying unsupervised context-based analysis for detecting unauthorized data disclosure,2011,"In this paper, we propose a new unsupervised approach for identifying suspicious access to sensitive relational data. In the proposed method, a tree-like model encapsulates the characteristics of the result-set (i.e., data) that the user normally access within each possible context. During the detection phase, result-sets are examined against the induced model and a similarity score is derived."
1487214,15510,20754,Training an Army of Security Ninjas,2012,"At Adobe, the Asset (Adobe Software Security Engineering Team) Certification Program has changed people's attitudes toward software security. This in turn has influenced how employees develop software and fix reported issues. In addition, employees' increased awareness and understanding has allowed Asset to transition from teaching basic concepts to having more in-depth conversations about software security."
992149,15510,20754,"Implementing Effective Controls in a Mobile, Agile, Cloud-Enabled Enterprise",2013,"In today's enterprise, security teams that call for security to be everyone's responsibility and built in, not bolted on are struggling to protect their businesses in the face of consumerization, mobility, cloud, and agile business environments. This article offers tangible techniques to turn these cliches into reality while considering the cultural and trust barriers that hinder the implementation of effective controls."
1356838,15510,20754,Lessons from VAX/SVS for High-Assurance VM Systems,2012,"The authors take a look back at VAX/SVS, a high-assurance virtual machine monitor (VMM) project from the 1980s, extracting its most pertinent lessons, including reference monitor architectural principles, approaches to verifiable and tamperproof access control, the benefits of layering, the impacts of minimization and verification, and the reasons behind its cancellation."
2066759,15510,339,Key-insulated symmetric key cryptography and mitigating attacks against cryptographic cloud software,2012,"Software-based attacks (e.g., malware) pose a big threat to cryptographic software because they can compromise the associated cryptographic keys in their entirety. In this paper, we investigate key-insulated symmetric key cryptography, which can mitigate the damage caused by repeated attacks against cryptographic software. To illustrate the feasibility of key-insulated symmetric key cryptography, we also report a proof-of-concept implementation in the Kernel-based Virtual Machine (KVM) environment."
2326559,15510,9874,Authenticated encryption: how reordering can impact performance,2012,"In this work, we look at authenticated encryption schemes from a new perspective. As opposed to analyzing the security of different methods of constructing authenticated encryption schemes, we investigate the effect of the method used to construct an authenticated encryption scheme on the performance of the construction. We show that, by performing the authentication operation before the encryption operation, the security requirements on the authentication operation can be relaxed, leading to more efficient constructions, without affecting the security of the overall construction."
1940983,15510,339,Expressive CP-ABE with partially hidden access structures,2012,"At Eurocrypt 2005, Sahai and Waters [7] introduced the concept of attribute-based encryption (ABE). ABE enables public key based one-to-many encryption and is envisioned as a promising cryptographic primitive for realizing scalable and fine-grained access control systems. There are two kinds of ABE schemes [1], key-policy ABE (KP-ABE) and ciphertext-policy ABE (CP-ABE) schemes. This paper, our concern is on the latter."
2207114,15510,11345,Non-interactive and re-usable universally composable string commitments with adaptive security,2011,"We present the first provably secure constructions of universally composable (UC) commitments (in pairing-friendly groups) that simultaneously combine the key properties of being non-interactive, supporting commitments to strings (instead of bits only), and offering re-usability of the common reference string for multiple commitments. Our schemes are also adaptively secure assuming reliable erasures."
1194678,15510,339,Poster: an implementation of the fully homomorphic smart-vercauteren crypto-system,2011,"Since the discovery of a fully homomorphic cryptographic scheme by Gentry, a number of different schemes have been proposed that apply the bootstrap technique of Gentry's original approach. However, to date no implementation of fully homomorphic encryption has been publicly released. This poster presents a working implementation of the Smart-Vercauteren scheme that will be freely available and gives substantial implementation hints."
1366214,15510,20754,Focus on Policy,2013,"Edward Snowden's revelations are bringing discussions about technology back into a healthier balance with discussions of related policy and research, and they've initiated a robust and too-long-absent debate about the roles of technology and policy in a healthy, vibrant, and fair society. We encourage this engagement and will continue to provide credible information to further the discussion about what is possible, desirable, and ethical."
2047782,15510,20754,iOS Data Recovery Using Low-Level NAND Images,2013,"To recover erased data from iOS devices, specialists use a brute-force method to decrypt the passwords, then extract data images directly from low-level NAND storage and analyze the redundancy caused by its file translation layer (FTL) behavior. iOS devices' garbage collection strategy significantly affects data recovery."
1291856,15510,20754,Stranger Visions: A Provocation,2013,"Genetic monitoring has been the subject of science fiction for years, but with biotechnology's decreasing costs and increasing accessibility through DIY bio and community laboratories, it's becoming a reality. In this new world, the very things that make us human, such as hair, skin, and saliva, become a liability as we constantly shed them in public, leaving artifacts for anyone to mine for information."
927265,15510,23634,Constant-Round Concurrent Zero Knowledge from P-Certificates,2013,"We present a constant-round concurrent zero-knowledge protocol for NP. Our protocol relies on the existence of families of collision-resistant hash functions, and a new, but in our eyes, natural complexity-theoretic assumption: the existence of P-certificates-that is, succinct non-interactive proofs/arguments for P. As far as we know, our results yield the first constant-round concurrent zero-knowledge protocol for NP with an explicit zero-knowledge simulator based on any assumption."
848994,15510,21102,Extension of iVAT to asymmetric matrices,2013,"The iVAT algorithm reorders (symmetric) dissimilarity data so that an image of the data may reveal cluster substructure. This paper extends the method so that it can handle asymmetric dissimilarity data. The extension is based on replacing the asymmetric input data with its unique least-squared error approximation by a symmetric matrix. Examples are given to illustrate the new method, called asymmetric iVAT (asiVAT)."
1124362,15510,20754,New Strategies for Employment? Internet Skills and Online Privacy Practices during People's Job Search,2013,"How does online know-how relate to people's tendencies to manage their privacy? A survey of a diverse group of young adults' online skills and privacy practices reveals patterns of online privacy management, specifically with job search in mind. Findings suggest that women, Whites, and those with higher Internet privacy skills are more likely to manage their online profiles actively."
1118833,15510,20754,Embracing the Kobayashi Maru: Why You Should Teach Your Students to Cheat,2011,"Every day, security professionals face off against adversaries who don't play by the rules. Traditional information security education programs further compound the problem by forcing students to behave in a flawlessly ethical manner. As an alternative, this article suggests techniques for fostering creativity and an adversary mindset in information security students through carefully structured classroom cheating exercises."
1114309,15510,20754,Moving-Target Defenses for Computer Networks,2014,"One of the criticisms of traditional security approaches is that they present a static target for attackers. Critics state, with good justification, that by allowing the attacker to reconnoiter a system at leisure to plan an attack, defenders are immediately disadvantaged. To address this, the concept of moving-target defense (MTD) has recently emerged as a new paradigm for protecting computer networks and systems."
1456242,15510,339,Security implications in Kerberos by the introduction of smart cards,2012,"Public key Kerberos (PKINIT) is a standardized authentication and key establishment protocol which is used by the Windows active directory subsystem. In this paper we show that card-based public key Kerberos is flawed. In particular, access to a user's card enables an adversary to impersonate that user even after the adversary's access to the card is revoked. The attack neither exploits physical properties of the card, nor extracts any of its secrets."
1771814,15510,8494,Performance study on block-based image steganalysis,2011,"Block-based image steganalysis, which uses smaller homogenous blocks from a given test image, was previously proposed to improve the steganalysis performance. Performance study on block-based image steganalysis in terms of block sizes and block numbers is conducted in this research. First, we analyze the dependence of the steganalysis performance on one of these two factors, and show that a larger block size and a larger block number will lead to better steganalysis performance. Our study is verified by experimental results. For a given test image, there exists a trade-off between the block size and the block number, and it is shown that a balance between the block size and the block number can result in better steganalysis performance."
1712367,15510,339,POSTER: Protecting Against Data Exfiltration Insider Attacks Through Application Programs,2014,"In this paper, we describe a system that distinguishes between legitimate and malicious database transactions performed by application programs. Our system is particularly useful for protecting against code-modification attacks performed by insiders who have access to and can change the programs' source code to make them execute different queries than those they are expected to execute. Our system works with any type of DBMS and requires minimum modification to application programs."
2445434,15510,20754,Systems Security Engineering,2011,"Systems engineers solve large problems by breaking them down into well-defined pieces, while preserving the problem definition for use in validating the solution. A new systems-engineering security road map recommends that systems engineers and security engineers converge on empirical methods. The trend should be to escape from best-practices checklists and return to core systems-engineering methods, processes, and tools."
2908997,15510,22288,A propagation model of passive social network worm,2012,"Social network worm incidents of the past years have shown us how vulnerable our networks are and how fast a worm can spread. Compared with traditional network worm, social network worm is more based on Social Engineering technology, which makes the worm more underground and hardly controllable. To be able to defend against social network worms, we need to understand their propagation model. In this paper, we analyze the behavior of social network worm and compare between the existing worm propagation models, introducing Self-Organizing Map algorithm, we formally define and describe analytically a new model, which complies with this scenario."
911733,15510,20754,Humans in the Loop,2014,"Edward Snowden's revelations are bringing discussions about technology back into a healthier balance with discussions of related policy and research, and they've initiated a robust and too-long-absent debate about the roles of technology and policy in a healthy, vibrant, and fair society. SaP encourages this engagement and will continue to provide credible information to further the discussion about what is possible, desirable, and ethical."
2765458,15510,9969,Efficient Multiparty Protocols via Log-Depth Threshold Formulae (Extended Abstract),2013,"We put forward a new approach for the design of efficient multiparty protocols: 1. Design a protocol π for a small number of parties (say, 3 or 4) which achieves security against a single corrupted party. Such protocols are typically easy to construct, as they may employ techniques that do not scale well with the number of corrupted parties. 2. Recursively compose π with itself to obtain an efficient n-party pro- tocol which achieves security against a constant fraction of corrupted parties."
1305317,15510,20754,More Is Not the Answer,2014,"Progress in user security has been slow for several reasons. First, the Web's scale and diversity make one-size-fits-all approaches hard. Second, the competition for user attention is fierce: there are no pools of unexploited user effort to be had. Third, persuasion is the only tool we have, mandates being often impossible or undesirable. We need to find new techniques to improve user security."
773061,15510,20754,Better Together: Usability and Security Go Hand in Hand,2014,"Securing computer systems has traditionally been the domain of system administrators using technology to protect computer systems from attack. However, in many systems, human users are critical to the security process. There's a growing realization that technology alone can't protect security if users don't properly deploy and utilize it. Ultimately, it's users who create passwords and choose whether to adhere to security procedures."
878456,15510,8228,Hinky: Defending against Text-Based Message Spam on Smartphones,2011,We present a defense platform against text-based message SPAM on SmartPhones. We focus in particular on Short Message Service (SMS) based SPAM. Our solution relies on a social network based collaborative approach to filter this type of spam using Bloom filters and content hashing. We detail the design of the supporting framework and validate its efficiency in minimizing false positive and limiting the storage space.
1103435,15510,20754,Detecting Fraud on Websites,2011,"Beyond some specific vertical markets that have been dealing with fraud for ages such as financial institutions and retailers most software and services have zero ability to detect someone committing fraud against them or their users. Most sites happily take whatever requests and input users give them, thinking it's legitimate.Fortunately, there are fairly straightforward things every website can do to detect online fraud."
884221,15510,23827,Trainees’ Competency Based-Assessment Methods in Cyber Forensics Education or Training Programmes – A Review,2011,"Cyber Forensics Investigations training or education is relatively new. The nature of Cyber Forensics is multidisciplinary, which enforces proliferations to diverse training programmes, from a handful of day’s workshop to Masters Degree in Cyber Forensics. Thus, researchers found that the world lacks experts of Cyber Forensics due to some factors. Consequently, this paper focuses to analyze the trainees’ Competency Based-Assessment implementation. The study finds that Cyber Forensics training or education has inappropriate trainees’ Competency Based-Assessment below 50%."
726032,15510,20754,Building Reliable and Secure Virtual Machines Using Architectural Invariants,2014,"HyperTap is a hypervisor-level monitoring framework for virtual machines (VMs). It uses hardware architectural invariants properties defined and enforced by a hardware platform to establish the root of trust for logging data and events. HyperTap also supports continuous, event-driven VM monitoring, which enables both capturing the system state and responding rapidly to actions of interest."
1473683,15510,20754,Keeping Secrets on Low-Cost Chips,2013,"In the mass markets in which chips are integrated into everyday objects, the cost pressures are great, but so is the need for security. To help resolve the conflict between cost and security, a new strategy embeds cryptographic algorithms into a cryptographic protocol such that they only need to be protected against single-execution side-channel attacks. To do this, the strategy introduces a key derivation function that's particularly easy to implement and protect."
2293276,15510,20754,Potential Attacks on Onboard Aerospace Systems,2012,"Because security is becoming a major concern for aircraft manufacturers and satellite makers, vulnerability discovery and countermeasures should be integrated into onboard computing systems early during their development. Attacks against aerospace computer systems fall into two main classes. One aims to corrupt the computing system's core functions; the other targets fault-tolerance mechanisms (error detection and recovery)."
1329732,15510,20754,IT for Oppression,2013,"The Internet is becoming a tool for oppressive governments. Whether it's Syria using Facebook to help identify and arrest dissidents or China using its Great Firewall to limit access to international news throughout the country, repressive regimes all over the world are using the Internet to more efficiently implement surveillance, censorship, propaganda, and control. They're getting really good at it, and the IT industry is helping."
1779819,15510,20754,The Importance of Security Engineering,2012,"Columnist Bruce Schneier makes the case for the community needing to learn to talk about security from a nontechnical angle, especially for policy makers, who need to learn how to follow a logical approach instead of an emotional one&#x2014;an approach that includes threat modeling, failure analysis, searching for unintended consequences, and everything else in an engineer's approach to design."
251310,15510,20592,Password managers: attacks and defenses,2014,"We study the security of popular password managers and their policies on automatically filling in Web passwords. We examine browser built-in password managers, mobile password managers, and 3rd party managers. We observe significant differences in autofill policies among password managers. Several autofill policies can lead to disastrous consequences where a remote network attacker can extract multiple passwords from the user's password manager without any interaction with the user. We experiment with these attacks and with techniques to enhance the security of password managers. We show that our enhancements can be adopted by existing managers."
1933113,15510,20754,A Tool to Analyze Potential I/O Attacks against PCs,2014,"Instead of making the CPU execute malware, I/O attacks exploit peripheral devices and, as such, can't be detected by traditional anti-malware techniques. The proposed multipurpose FPGA-based tool can help analyze such attacks and be programmed to mimic a malicious I/O controller, host a Trojan horse, and even apply fuzzing techniques to identify vulnerabilities that could be exploited from I/O controllers or peripheral devices."
90252,15510,10286,Constant-Round multi-party private set union using reversed laurent series,2012,"We introduce the idea of associating a set of elements with a  rational function  represented using a  reversed Laurent series  . Using this representation, we propose private set-union protocols in the multi-party setting, assuming an honest majority. Our protocols are the first efficient protocol for private set union with constant round complexity (in both the semi-honest and malicious settings), as well as the first with statistical security (in the semi-honest setting)."
2614720,15510,9874,Length-doubling ciphers and tweakable ciphers,2012,"We motivate and describe a mode of operation HEM (resp., THEM) that turns a n-bit blockcipher into a variable-input-length cipher (resp., tweakable cipher) that acts on strings of [n..2n−1] bits. Both HEM and THEM are simple and intuitive and use only two blockcipher calls, while prior work at least takes three. We prove them secure in the sense of strong PRP and tweakable strong PRP, assuming the underlying blockcipher is a strong PRP."
890847,15510,20754,Towards a Semantics of Phish,2012,"Phishing constitutes more than half of all reported security incident son the Internet. The attacks cause users to erroneously trust websites and enter sensitive data because the email notifications and the website look familiar. Our hypothesis is that familiarity can be defined formally using history data from the user's computer, and effective presentation of the data can help users distinguishphishing messages from trustworthy messages."
1721302,15510,20754,A Cyberoperations Program,2013,"To conduct cyberoperations, not only must you understand computers, networks, and protocols, you must also determine what circumstances actions may be taken in and who can take them. In addition, you must consider strategies and policies as well as those actions' possible side effects, in both cyberspace and the natural world. At the US Naval Postgraduate School and elsewhere, educators are preparing computer science graduates to meet these challenges."
359457,15510,8228,Analysis of revocation strategies for anonymous Idemix credentials,2011,"In an increasing information-driven society, preserving privacy is essential. Anonymous credentials promise a solution to protect the user's privacy. However, to ensure accountability, efficient revocation mechanisms are essential. Having classified existing revocation strategies, we implemented one variant for each. In this paper we describe our classification and compare our implementations. Finally, we present a detailed analysis and pragmatic evaluation of the strategies."
1511466,15510,9856,BetterAuth: web authentication revisited,2012,"This paper presents BetterAuth, an authentication protocol for Web applications. Its design is based on the experiences of two decades with the Web. BetterAuth addresses existing attacks on Web authentication, ranging from network attacks to Cross-site Request Forgery up to Phishing. Furthermore, the protocol can be realized completely in standard JavaScript. This allows Web applications an early adoption, even in a situation with limited browser support."
1697694,15510,20754,The Weird Machines in Proof-Carrying Code,2014,"We review different attack vectors on Proof-Carrying Code (PCC) related to policy, memory model, machine abstraction, and formal system. We capture the notion of weird machines in PCC to formalize the shadow execution arising in programs when their proofs do not sufficiently capture and disallow the execution of untrusted computations. We suggest a few ideas to improve existing PCC systems so they are more resilient to memory attacks."
853541,15510,20754,I Still Know What You Visited Last Summer: Leaking Browsing History via User Interaction and Side Channel Attacks,2011,"History sniffing attacks allow web sites to learn about users' visits to other sites. The major browsers have recently adopted a defense against the current strategies for history sniffing. In a user study with 307 participants, we demonstrate that history sniffing remains feasible via interactive techniques which are not covered by the defense. While these techniques are slower and cannot hope to learn as much about users' browsing history, we see no practical way to defend against them."
2724711,15510,20358,3DOC: 3D object CAPTCHA,2014,"Current 2D CAPTCHA mechanisms can be easily defeated by character recognition and segmentation attacks by automated machines. Recently, 3D CAPTCHA schemes have been proposed to overcome the weaknesses of 2D CAPTCHA for a few websites. However, researchers also demonstrate the offline pre-processing techniques to break 3D CAPTCHA. In this work, we propose a novel 3D object based CAPTCHA scheme that projects the CAPTCHA image over a 3D object. We develop the prototype and present the proof-of-concept of 3D object based CAPTCHA scheme to protect websites against automated attacks."
1342358,15510,339,User-level secure deletion on log-structured file systems,2012,"Deleting a file from a storage medium serves two purposes: it reclaims storage resources and ensures that any sensitive information contained in the file becomes inaccessible. When done for the latter purpose, it is critical that the file is  securely  deleted, meaning that its content does not persist on the storage medium after deletion. Secure deletion is the act of deleting data from a storage medium such that the data is afterwards irrecoverable from the storage medium. The time between deleting data and it becoming irrecoverable is called the  deletion latency ."
1881257,15510,11345,The five-card trick can be done with four cards,2012,"The five-card trick invented by Boer allows Alice and Bob to securely compute the AND function of their secret inputs using five cards--three black cards and two red cards--with identical backs. This paper shows that such a secure computation can be done with only four cards. Specifically, we give a protocol to achieve a secure computation of AND using only four cards--two black and two red. Our protocol is optimal in the sense that the number of required cards is minimum."
2714438,15510,20754,Open Assurance,2013,"We must come to terms with the openness of networks, the vulnerability of systems, and the nature of threats they face and reexamine what design and assurance information needs to be kept confidential in critical systems. Does the empowerment enabled by the cloud, the globalization of Internet access, and education provide the resources so that more openness is not just an increased risk but a real benefit? Are we at a stage where we should make radical changes to how we assure software-based systems?"
836705,15510,20754,Guest editors' introduction: Software Assurance for the Masses,2012,"The guest editors of this special theme issue describe how they selected articles from a wide variety of static analysis experts from research teams, academia, government, and commercial software companies. The broad spectrum of ideas covered range from the practicality of building and making static analysis tools usable in a major software company to ways of cataloging the problem space of vulnerabilities in software."
1161754,15510,339,VIPER: verifying the integrity of PERipherals' firmware,2011,"Recent research demonstrates that malware can infect peripherals' firmware in a typical x86 computer system, e.g., by exploiting vulnerabilities in the firmware itself or in the firmware update tools. Verifying the integrity of peripherals' firmware is thus an important challenge. We propose software-only attestation protocols to verify the integrity of peripherals' firmware, and show that they can detect all known software-based attacks. We implement our scheme using a Netgear GA620 network adapter in an x86 PC, and evaluate our system with known attacks."
1725529,15510,339,Honeywords: making password-cracking detectable,2013,"We propose a simple method for improving the security of hashed passwords: the maintenance of additional ``honeywords'' (false passwords) associated with each user's account. An adversary who steals a file of hashed passwords and inverts the hash function cannot tell if he has found the password or a honeyword. The attempted use of a honeyword for login sets off an alarm. An auxiliary server (the ``honeychecker'') can distinguish the user password from honeywords for the login routine, and will set off an alarm if a honeyword is submitted."
1455792,15510,20754,Silver Bullet Talks with Jon Callas,2014,"Jon Callas, chief technology officer at Silent Circle, talks to Gary McGraw about the early days of computing, nascent cryptography, Lavabit, Edward Snowden, and software security versus reality. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
1294271,15510,20754,Bridging the Gap in Computer Security Warnings: A Mental Model Approach,2011,"Computer security warnings are intended to protect users and their computers. However, research suggests that these warnings might be largely ineffective because they're frequently ignored. The authors describe a mental model interview study designed to gain insight into how advanced and novice computer users perceive and respond to computer warnings. Developers can leverage the approaches of advanced users to design more effective warnings for novice users."
1188103,15510,339,POSTER: Sniffing and propagating malwares through WPAD deception in LANs,2013,"The Web Proxy Auto-Discovery (WPAD) protocol is always used to locate a URL of a configuration file through DHCP, DNS or some other discovery methods. WPAD is a very convenience way for the management of network administrator. However, in the meantime, it may lead to a potential compromise to our LANs. In this poster, we propose a novel attack method based on WPAD protocol which can be used by attacker to intercept traffic, sniff and propagate malwares in LAN."
1426261,15510,339,Poster: using quantified risk and benefit to strengthen the security of information sharing,2011,Risk and benefit are two implicit key factors to determine accesses in secure information sharing. Recent researches have shown that they can be explicitly quantified and used to improve the flexibility in information systems. This paper introduces the motivation and a technical design of Quantified riSk and Benefit adaptive Access Control (QSBAC) to strengthen the security of information sharing. The paper also introduces the key issues to design policies in QSBAC.
1780009,15510,20754,Silver Bullet Talks with Ralph Langner,2011,"Gary McGraw interviews Ralph Langner, the founder and CEO of Langner Communications, a German company focused on control system security. He has more than 20 years' experience working with computerized control systems and was the first researcher to determine that Stuxnet was a directed cyberattack against Iran. Hear the full podcast at www.computer.org/security/podcasts or www.cigital.com/silverbullet."
3183818,15510,9969,Public Keys,2012,"We performed a sanity check of public keys collected on the web and found that the vast majority works as intended. Our main goal was to test the validity of the assumption that different random choices are made each time keys are generated. We found that this is not always the case, resulting in public keys that offer no security. Our conclusion is that generating secure public keys in the real world is challenging. We did not study usage of public keys."
2379086,15510,20754,Directions in Incident Detection and Response,2011,Richard Bejtlich leads a conversation on how incident detection and response (IDR) teams' focus on detecting and preventing attacks has moved from targeting OSs to unauthorized-access-application functionality and data. He discusses why this makes IDR so much more difficult and what these new targets mean for IDR. Department editors Gunnar Peterson and John Steven respond with tactics on how application security teams can help.
2190120,15510,339,Secure cloud maintenance: protecting workloads against insider attacks,2012,"In recent years,  Cloud Computing  has gained remarkable popularity due to the economic and technical benefits provided by this new way of delivering computing resources. Businesses can offload their IT infrastructure into the cloud and benefit from rapid provisioning, scalability, and cost advantages. While cloud computing can be implemented on different abstraction levels, we focus on  Infrastructure Clouds  such as Amazon EC2 [1] that provide virtual machines, storage, and networks."
1529734,15510,20524,Automatically securing permission-based software by reducing the attack surface: an application to Android,2012,"In the permission-based security model (used e.g. in Android and Blackberry), applications can be granted more permissions than they actually need, what we call a &#x201C;permission gap&#x201D;. Malware can leverage the unused permissions for achieving their malicious goals, for instance using code injection. In this paper, we present an approach to detecting permission gaps using static analysis. Using our tool on a dataset of Android applications, we found out that a non negligible part of applications suffers from permission gaps, i.e. does not use all the permissions they declare."
1194048,15510,20754,Safety-Critical Systems: The Next Generation,2013,"Society is becoming increasingly dependent on the safe and secure operations of digital devices and software embedded in consumer, industrial, and military systems. This special issue features three outstanding articles that illustrate some of the advanced design and certification concepts using cyber-physical systems from the domains of medical devices, driverless cars, and avionics as well as the importance and difficulty of learning from experience."
912659,15510,20754,A Case Study in Malware Research Ethics Education: When Teaching Bad is Good,2014,There is a growing interest in the research of malware in the context of cyber-security. In this paper I will present a case study that will outline the curriculum used to teach malware ethics within the context of a computer science course that teaches students malware programing techniques. Issues from computer and information ethics that apply most closely to ethical malware research will be highlighted. The topics discussed in the course will be outlined and assessment techniques will be discussed.
711548,15510,339,A covert channel construction in a virtualized environment,2012,"Memory deduplication has been widely used in various commodity hypervisors. However, while this technique improves memory efficiency, it has an impact on system security. In particular, memory deduplication is usually implemented using a variant of copy-on-write techniques, for which, writing to a shared page would incur a longer access time than those non-shared. By exploiting this artifact, we demonstrate a new covert channel can be built in a virtualized environment."
1736805,15510,20754,Privacy and the System Life Cycle,2011,"Engineering long-lived systems is hard, and adding privacy considerations to such systems makes the work harder.The system life cycle and privacy implications of user-created code are beyond the current state of the art and merit significant attention in their own right. But experienced software engineers know very well that test datasets are generally way too clean and don't exercise the worst of the system."
1362811,15510,9475,Cost of fairness in disease spread control,2012,"This article studies the cost of fairness in designing controls (allocating resources) to mitigate disease spread, in the context of canonical network models for spread. Specifically, the performance of an optimal design in terms of the reduction in spread rate is compared with that of a fair one: an algebraic bound on the difference in performance (or cost of fairness) is obtained, and this bound is further characterized in the case that the spread topology is specially structured (e.g., a regular or random graph)."
944981,15510,20754,"Technology, Transparency, and Trust",2014,"Over time, device control and transparency have continued to decrease. As users and consumers, we have a responsibility to think about how technology fits in our lives and what we want it to accomplish. We also have a responsibility to think about secondary effects, such as when and whether allowing our devices to monitor and track us is acceptable. These are important questions to ask at a time when enthusiasm for functionality can lead to a rush to market before the security and privacy implications are fully realized, assessed, and addressed."
1872919,15510,8228,Unidirectional Identity-Based Proxy Re-Signature,2011,"To construct a suitable and secure proxy re-signature scheme is not an easy job, up to now, there exist only a few schemes. None of these schemes is unidirectional identity-based proxy re-signature, where a semi-trusted proxy can transform a signature under an identity to another signature under another identity on the same message, while the proxy cannot generate any signature on behalf of any of these two identities. In this paper, based on Schnorr's signature and Libert-Vergnaud proxy re-signature, we propose the first unidirectional identity-based proxy re-signature, which is existentially unforgeable in the random oracle model based on the extended computational Diffie-Hellman assumption."
2004784,15510,11470,Preventative steganalysis in wireless visual sensor networks: Challenges and solutions,2011,"The goal of preventative steganalysis is to offer a proactive solution against steganography by increasing the steganalyst's knowledge of the cover-media therefore emphasizing the presence of hidden messages. This paper presents the concept of preventative steganalysis applied to wireless visual sensor networks. By means of the entropy, the uncertainty of the data captured by the network's camera is reduced, hence reducing the potential embedding capacity and discouraging the use of steganography."
2042487,15510,20754,Federated Identity Management Systems: A Privacy-Based Characterization,2013,"Identity management systems store attributes associated with users and employ these attributes to facilitate authorization. The authors analyze existing systems and describe a privacy-driven taxonomy of design choices, which can help technical experts consulting on public policy relating to identity management. The US National Strategy for Trusted Identities in Cyberspace initiative is discussed to illustrate how this taxonomy helps analyze public policy options."
1558814,15510,339,Threshold ring signature without random oracles,2011,"In this paper, we present the notion and construction of threshold ring signature without random oracles. This is the  first scheme  in the literature that is proven secure in the standard model. Our scheme extends the Shacham-Waters signature from PKC 2007 in a non-trivial way. We note that our technique is specifically designed to achieve a threshold ring signature in the standard model. Interestingly, we can still maintain the signature size to be the same as the Shacham-Waters signature, while only a tiny computation cost is added."
942766,15510,20754,"Hardware-Anchored Security Based on SRAM PUFs, Part 1",2012,"Physical unclonable functions based on static RAM can help provide new approaches to such applications as secure key storage, secure boot for flash-memory-based embedded devices without on-chip nonvolatile memory, hardware-software binding, and generating true random numbers. Part 1 is available at http://doi.ieeecomputersociety.org/10.1109/MSP.2012.68."
2701126,15510,20754,Military Cybersomethings,2013,"You can hardly read the news without seeing dire warnings of national security problems lurking in our computers. If it isn't some country stealing some other country's commercial secrets&#x2014;just who's the victim and who's the thief varies with the teller, of course&#x2014;it's the threat of a cyber Pearl Harbor or cyberterrorism or cyberwarfare or cyberespionage or cyber disturbing the peace or cybersomething-or-other. What are all of these things? Are they real? And what should we&#x2014;one nation, or the whole world&#x2014;do about them?"
1295026,15510,20754,Filling Your Cyber Operations Training Toolbox,2012,This training article introduces readers to the specific tools and skills needed to best provide cyber operations education and training to university students at the undergraduate and graduate level. It isn't a curriculum-mapping exercise but rather a detailed listing of tools and techniques that can be included in existing and new courses to best align with the NSA's new Center of Academic Excellence in Cyber Operations (CAE-CO).
84861,15510,374,Socially constructed trust for distributed authorization,2011,We describe an approach for distributed access control that is based on the idea of using a community-constructed repository of expressions of propositional attitudes. We call this repository an oracle. Members of a community may consult the oracle and use the expressions of belief and disbelief in propositions that are expressed by community members about requesters for access to resources. Our conceptual model and access control policies are described in terms of a computational logic and we describe an implementation of the approach that we advocate.
1219984,15510,20754,Silver Bullet Talks with Gary Warzala,2013,"Gary McGraw interviews Gary Warzala, Visa's chief information security officer. He talks about the daily life of a CISO, how companies can attract and retain good security employees, and how to measure security and discuss the results with management. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
684574,15510,339,Poster: privacy-preserving profile similarity computation in online social networks,2011,"Currently, none of the existing online social networks (OSNs) enables its users to make new friends without revealing their private information. This leaves the users in a vulnerable position when searching for new friends. We propose a solution which enables a user to compute her profile similarity with another user in a privacy-preserving way. Our solution is designed for a realistic OSN environment, where a pair of users is unlikely to be online at the same time."
940758,15510,20754,Analysis of Unintentional Insider Threats Deriving from Social Engineering Exploits,2014,Organizations often suffer harm from individuals who bear no malice against them but whose actions unintentionally expose the organizations to risk-the unintentional insider threat (UIT). In this paper we examine UIT cases that derive from social engineering exploits. We report on our efforts to collect and analyze data from UIT social engineering incidents to identify possible behavioral and technical patterns and to inform future research and development of UIT mitigation strategies.
1632193,15510,8228,Out of the wild: On generating default policies in social ecosystems,2013,"Combining and incorporating rich semantics of user social data, which is currently fragmented and managed by proprietary applications, has the potential to more accurately represent a user's social ecosystems. However, social ecosystems raise even more serious privacy concerns than today's social networks. This paper proposes to model privacy as contextual integrity by using semantic web tools and focuses on defining default privacy policies, as they have the highest impact."
1531861,15510,339,Self-certified ring signatures,2011,"We present a new notion,  Self-certified Ring Signature  (SCRS), to provide an alternative solution to the certificate management problem in ring signatures and eliminate private key escrow problem in identity based ring signatures. Our scheme captures all features of ring signatures and exhibits the advantages such as low storage, communication and computation cost. The main contribution of this paper is a precise definition of self-certified ring signatures along with a concrete construction. We also provide a security model of SCRS and a security proof of our scheme."
648643,15510,8422,A Conference Management System with Verified Document Confidentiality,2014,"We present a case study in verified security for realistic systems: the implementation of a conference management system, whose functional kernel is faithfully represented in the Isabelle theorem prover, where we specify and verify confidentiality properties. The various theoretical and practical challenges posed by this development led to a novel security model and verification method generally applicable to systems describable as inputoutput automata."
992908,15510,21102,Clustering and visualization of fuzzy communities in social networks,2013,"We discuss a new formulation of a fuzzy validity index that generalizes the Newman-Girvan (NG) modularity function. The NG function serves as a cluster validity functional in community detection studies. The input data is an undirected graph G = (V, E) that represents a social network. Clusters in V correspond to socially similar substructures in the network. We compare our fuzzy modularity to an existing modularity function using the well-studied Karate Club data set."
1658258,15510,22260,Why it is Hard to Fight against Cyber Criminals,2012,"We are witnessing numerous cyber attacks every day, however, we do not see many cyber criminals are brought to justice. One reason is that it is technically hard to identify and trace cyber criminals. One reason for this passive situation is our limited or even inappropriate understanding of the cyber space. In this paper, we survey the challenges and opportunities in this research field for interested readers. We also list promising tools and directions based on our understanding."
910143,15510,20754,Pain Management for Entrepreneurs: Working with Venture Capital,2013,"Although information systems security is acknowledged as one of technology's most critical areas of need, there is a sizable gap between available technical approaches to security and the capabilities of current commercial products. This reflects acknowledged issues in technology transfer. The author, a veteran of both information security research and commercial security product venture capital organizations, provides a discussion of the motivations and considerations associated with this part of the technology transfer world."
1067332,15510,9856,A peel of onion,2011,"Onion routing  was invented more than fifteen years ago to separate identification from routing in network communication. Since that time there has been much design, analysis, and deployment of onion routing systems. This has been accompanied by much confusion about what these systems do, what security they provide, how they work, who built them, and even what they are called. Here I give an overview of onion routing from its earliest conception to some of the latest research, including the design and use of Tor, a global onion routing network with about a half million users on any given day."
721405,15510,20754,Trust Management in the Pervasive Computing Era,2011,"The study of trust should be multidisciplinary. This primarily means including computing and information science on one hand, and psychology on the other. Although some research projects have already employed multidisciplinary approaches, they've rarely included all the necessary ingredients. Furthermore, the core of the trust phenomenon is often overlooked. In addition, to complement current quantitative methodologies, we should develop methodologies that support a quantitative treatment by using qualitative assessments of trust."
1568599,15510,20754,Bandwidth Distributed Denial of Service: Attacks and Defenses,2014,"The Internet is vulnerable to bandwidth distributed denial-of-service (BW-DDoS) attacks, wherein many hosts send a huge number of packets to cause congestion and disrupt legitimate traffic. So far, BW-DDoS attacks have employed relatively crude, inefficient, brute force mechanisms; future attacks might be significantly more effective and harmful. To meet the increasing threats, we must deploy more advanced defenses."
1256958,15510,20754,"What Happened to the Crypto Dream?, Part 1",2013,"Despite privacy-preserving cryptography technologies' potential, they've largely failed to find commercial adoption. Reasons include people's unawareness of privacy-preserving cryptography, developers' lack of expertise, the field's complexity, economic constraints, and trust issues. View part 1 of this article (from the March/April 2013 issue) here: http://doi.ieeecomputersociety.org/10.1109/MSP.2013.45."
227689,15510,374,Deciding Epistemic and Strategic Properties of Cryptographic Protocols,2012,"We propose a new, widely applicable model for analyzing knowledge-based (epistemic) and strategic properties of cryptographic protocols. We prove that the corresponding model checking problem with respect to an expressive epistemic strategic logic is decidable. As corol- laries, we obtain decidability of complex security properties including coercion-resistance of voting protocols, accountability of protocols using a trusted third party, and abuse-freeness of contract signing protocols."
2129738,15510,517,Applying Security Assurance Techniques to a Mobile Phone Application: An Initial Approach,2011,"As users download applications to their mobile phones, security is a critical issue. In this paper we present a process for the security assurance of applications. It uses existing vulnerability databases and application development guidelines to identify potential security issues. The identified issues are then validated using a variety of techniques including black-box testing, unit testing code inspection and static analysis. This process is illustrated using an application for the Android platform."
1136146,15510,20754,Leaking Sensitive Information in Complex Document Files--and How to Prevent It,2014,"Complex document formats such as PDF and Microsoft's Compound File Binary Format can contain information that is hidden but recoverable, as a result of text highlighting, cropping, or the embedding of high-resolution JPEG images. Private information can be released inadvertently if these files are distributed in electronic form. Simple experiments involving the creation of test documents can determine whether a particular program embeds hidden information."
153009,15510,9766,Adaptive Password-Strength Meters from Markov Models,2012,"Measuring the strength of passwords is crucial to ensure the security of password-based authentication. However, current methods to measure password strength have limited accuracy, first, because they use rules that are too simple to capture the complexity of passwords, and second, because password frequencies widely differ from one application to another. In this paper, we present the concept of adaptive password strength meters that estimate password strength using Markov-models. We propose a secure implementation that greatly improves on the accuracy of current techniques."
2040169,15510,8228,Identity-Based Conditional Proxy Re-Encryption,2011,"This paper proposes a new cryptographic primitive, named identity-based conditional proxy re-encryption (IBCPRE). In this primitive, a proxy with some information (a.k.a. re-encryption key) is allowed to transform a subset of ciphertexts under an identity to other ciphertexts under another identity. Due to the specific transformation, IBCPRE is very useful in encrypted email forwarding. Furthermore, we propose a concrete IBCPRE scheme based on Boneh-Franklin identity-based encryption. The proposed IBCPRE scheme is secure against the chosen ciphertext and identity attack in the random oracle."
1867539,15510,339,Text-based CAPTCHA strengths and weaknesses,2011,"We carry out a systematic study of existing visual CAPTCHAs based on distorted characters that are augmented with anti-segmentation techniques. Applying a systematic evaluation methodology to 15 current CAPTCHA schemes from popular web sites, we find that 13 are vulnerable to automated attacks. Based on this evaluation, we identify a series of recommendations for CAPTCHA designers and attackers, and possible future directions for producing more reliable human/computer distinguishers."
2132994,15510,10286,Upper bound of the length of information embedd in RSA public key efficiently,2013,"Lenstra proposed a method by which information can be efficiently in a public key N in RSA encryption. Since then, many methods such as the additional key escrow function and a visible public key have been proposed. Lenstra made an assertion that the size of embeddable information is up to half the length of a public key, but he did not mention the strict upper bound of the size. In this paper, we analytially examine the Lenstra algorithm both in theory and implementation, and calcuate the upper bound of the size of information that can be efficiently embedded in an RSA public key."
647942,15510,9874,Constructing practical signcryption KEM from standard assumptions without random oracles,2013,"We present a direct construction for signcryption Key Encapsulation Mechanism (KEM) without random oracles under standard complexity assumptions. Chosen-ciphertext security is proven in the standard model under the DBDH assumption, and unforgeability is proven in the standard model under the CDH assumption. The proof technique allows us to achieve strong unforgeability from the weakly unforgeable Waters signature. The validity of the ciphertext of our signcryption KEM can be verified publicly, without knowledge of the decryption key."
879004,15510,8806,SPAD: software protection through anti-debugging using hardware virtualization,2011,"Debugging could be a threat to system security when adopted by malicious attackers. The major challenges of software-only anti-debugging are compromised strategy and lack of self-protection. Leveraging hardware virtualization, we proposes a strategy of software protection through anti-debugging which imperceptibly monitors the debug event on a higher privilege level than the conventional kernel space. Our prototype can effectively prohibit the debugging behavior from selected popular debuggers in the replication experiment."
2179463,15510,8235,Authentication of Data on Devices,2012,"Use of smart-phones and devices has proliferated almost all aspects of our lives. With that, each of us have become the producers and consumers of different types of data, of different levels of sensitivity, and of different levels of trustworthiness. One important aspect of managing such data on our devices and associated cloud (e.g., iCloud of Apple) is how to manage the authenticity such data. In this paper, we present a data model and a scheme towards assuring authenticity of the data. Our scheme is very efficient -- it computes only one signature."
1160728,15510,339,POSTER: Abusing URL Shortening Services for Stealthy and Resilient Message Transmitting,2014,"URL shortening services (USS) have been widely used on the Internet, but are currently prone to abuse. In this poster, we exploit the possibility of building a novel stealthy and robust message transmission channel through use of USS. A text string or binary file can be transmitted stealthily using this channel. Our preliminary results show that the proposed channel is feasible and affects many popular USS, thus posing a practical threat to attackers."
38626,15510,10286,On homomorphic encryption and chosen-ciphertext security,2012,"Chosen-Ciphertext (IND-CCA) security is generally considered the right notion of security for a cryptosystem. Because of its central importance much effort has been devoted to constructing IND-CCA secure cryptosystems.#R##N##R##N#In this work, we consider constructing IND-CCA secure cryptosystems from (group) homomorphic encryption. Our main results give natural and efficient constructions of IND-CCA secure cryptosystems from any homomorphic encryption scheme that satisfies weak cyclic properties, either in the plaintext, ciphertext or randomness space. Our results have the added benefit of being simple to describe and analyze."
1580836,15510,20754,A Knowledge-Based Approach to Intrusion Detection Modeling,2012,Current state of the art intrusion detection and prevention systems (IDPS) are signature-based systems that detect threats and vulnerabilities by cross-referencing the threat or vulnerability signatures in their databases. These systems are incapable of taking advantage of heterogeneous data sources for analysis of system activities for threat detection. This work presents a situation-aware intrusion detection model that integrates these heterogeneous data sources and build a semantically rich knowledge-base to detect cyber threats/vulnerabilities.
2193898,15510,22021,Multiplicative secret sharing schemes from Reed-Muller type codes,2012,Multiplicative linear secret sharing schemes are the building blocks for multiparty computation protocols. Such schemes can be defined in terms of linear codes with an additional algebraic structure. We show that Reed-Muller codes have the required additional structure and we introduce a more general class of Reed-Muller type codes suitable for linear secret sharing and multiparty computation. The codes have highly structured generator and parity check matrices that can be used for very efficient implementations over the binary field.
2725166,15510,20754,Lost Treasures,2012,"Is the computer security field really old enough to have lost treasures? Will a granite punch card with ancient Cobol contain some code fragment that produces a better firewall? Hardly. The computing environment changes so much and so radically that implementation details lose relevance quickly. However, concepts and key insights can serve modern developers just as well today as they did builders of ancient systems from the 1980s."
1093604,15510,11166,Integrity Verification of Outsourced Frequent Itemset Mining with Deterministic Guarantee,2013,"In this paper, we focus on the problem of result integrity verification for outsourcing of frequent item set mining. We design efficient cryptographic approaches that verify whether the returned frequent item set mining results are correct and complete with deterministic guarantee. The key of our solution is that the service provider constructs cryptographic proofs of the mining results. Both correctness and completeness of the mining results are measured against the proofs. We optimize the verification by minimizing the number of proofs. Our empirical study demonstrates the efficiency and effectiveness of the verification approaches."
180959,15510,293,A Needle in the Haystack - Delay Based User Identification in Cellular Networks,2014,"In this work, we discuss a technique for identifying users in cellular networks that exploits the effect that RRC state machine transitions have on the measured round-trip time of mobile devices. Our preliminary experiments performed in a controlled environment, show that it is possible to leverage popular real-time messaging apps, such as Facebook, WhatsApp and Viber, to trigger an observable delay pattern on a user's device, and use it to identify the device."
1448556,15510,20754,Reading: From Paper to Pixels,2011,"What, if anything, will be the role of publishers in a world in which books are formatted by their authors, distributed electronically, and read online? The success of e-books has spawned a boom in self-publishing, with the possibility that just as musicians now depend not on recording contracts but self-promotion for concert revenues, authors will depend on direct sales to readers rather than having their books packaged by publishers. Readers can expect more choice and lower prices, but writers will face a continued struggle."
1013862,15510,20754,The Curse of Cryptographic Numerology,2011,"The problem of cryptographic numerology has plagued modern cryptography throughout most of its life. The basic concept is that as long as your encryption keys are at least this big, you're fine, even if none of the surrounding infrastructure benefits from that size or even works at all. The application of cryptographic numerology conveniently directs attention from the difficult to the trivial, because choosing a key size is fantastically easy, whereas making the crypto work effectively is really hard."
1542586,15510,20754,A Doctrinal Thesis,2011,"Policy proposals are best made relative to a cybersecurity doctrine rather than suggested piecemeal as is being done today. A doctrine of deterrence through accountability, for example, would be a basis for rationalizing proposals that equate attacks with crimes and focus on network-wide authentication and identification mechanisms. A new doctrine of public cybersecurity is also discussed; its goals are producing cybersecurity and managing the remaining insecurity, where individual rights are balanced with public welfare."
839707,15510,20754,Security as if People Mattered,2011,"Computer security and usability are challenging problems that are often interrelated. In harmonizing security and usability, it isn't enough to consider how human factors can be leveraged in support of security. Instead, it's important to take a user-centered perspective, and consider how best to support people in attaining their goals when they use computer systems. This article approaches this problem by highlighting some of the psychological factors and human values that must be considered when creating effective security solutions."
895112,15510,20754,Everyday Security: Default to Decency,2013,"Sociological study of normal routine behavior informs us of the mechanisms through which safety and social order are maintained. From ethnographic studies of public sites such as the New York subway system, we learn how workers' routines fit or do not fit into official security-era policies coming from above. Suggestions are provided for concrete mechanisms likely to enhance security while providing collateral benefits of enhanced efficiency and pleasure to members of the public."
1606723,15510,20754,Silver Bullet Talks with W. Hord Tipton,2013,"Gary McGraw talks with W. Hord Tipton, executive director of (ISC)2, about how he got into science and engineering, the insights he's cultivated from being a nuclear and chemical engineer, whether or not certification can help advance software security, and the benefits of teaching software security to kids. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
2453025,15510,8228,Multi-Use Unidirectional Proxy Re-Encryption,2011,"This paper presents the first multi-use unidirectional proxy re-encryption scheme proven-secure against chosenciphertext attacks and collusion attacks in the standard model. Although our proposal features a linear ciphertext size and decryption time in the number of translations, we emphasize that it is the first multi-use and unidirectional realization of the primitive satisfying the chosen-ciphertext security and collusion resistance. The proposal gives an answer to the problem proposed by Canetti and Hohenberger at ACM CCS 2007."
1457870,15510,339,POSTER: T-IP: A Self-Trustworthy and Secure Internet Protocol with Full Compliance to TCP/IP,2014,"In this demo, we propose the self-trustworthy and secure Internet protocol (T-IP) for authenticated and encrypted network layer communications. T-IP has the following advantages: 1) Self-Trustworthy IP address. 2) Low connection latency and transmission overhead. 3) Reserving to be stateless (an important merit of IP). 4) Compatible with the existing TCP/IP architecture. We have implemented the protocol and deployed it in our campus network. Compared with IPsec, the evaluation shows that T-IP has a much lower transmission overhead and connection latency."
886969,15510,10192,The Impact of Evasion on the Generalization of Machine Learning Algorithms to Classify VoIP Traffic,2012,We propose a novel approach to generate well generalized signatures to classify Skype VoIP traffic using a machine learning based approach. Results show that the performance of the signatures did not degrade significantly when they were evaluated on traffic that was captured from different locations and at different times as well as employed against evasion attacks. Our results on the evasion of Skype classifier demonstrate that the performance of the signatures are very promising even if the user tries maliciously to alter the characteristics of Skype traffic to evade the classifier.
1487392,15510,8806,Formal analysis of device authentication applications in ubiquitous computing,2011,"Authentication between mobile devices in ad-hoc computing environments is a challenging problem. Without pre-shared knowledge, existing applications rely on additional communication methods, such as out-of-band or location-limited channels for device authentication. However, no formal analysis has been conducted to determine whether out-of-band channels are actually necessary. We answer this question through formal analysis, and use BAN logic to show that device authentication using a single channel is not possible."
2301295,15510,9874,Identity-based extractable hash proofs and their applications,2012,"In this paper, we introduce a general paradigm called identity-based extractable hash proof system (IB-EHPS), which is an extension of extractable hash proof system (EHPS) proposed by Wee (CRYPTO '10). We show how to construct identity-based encryption (IBE) scheme from IB-EHPS in a simple and modular fashion. Our construction provides a generic method of building and interpreting CCA-secure IBE schemes based on computational assumptions. As instantiations, we realize IB-EHPS from the bilinear Diffie-Hellman assumption and the modified bilinear Diffie-Hellman assumption, respectively."
105970,15510,10286,Public key encryption against related key attacks,2012,"In this work, we present efficient public-key encryption schemes resilient against linear related key attacks (RKA) under standard assumptions and in the standard model. Specifically, we obtain encryption schemes based on hardness of factoring, BDDH and LWE that remain secure even against an adversary that may query the decryption oracle on linear shifts of the actual secret key. Moreover, the ciphertext overhead is only an additive constant number of group elements."
716125,15510,20754,Authenticated Encryption: Toward Next-Generation Algorithms,2014,"Wondering whether researchers have a cryptographic tool able to provide both confidentiality (privacy) and integrity (authenticity) of a message? They do: authenticated encryption (AE), a symmetric-key mechanism that transforms a message into a ciphertext. This article discusses standard AE algorithms, classic security models' shortcomings for AE algorithms, and related attacks. Motivated by these attacks, the crypto community started CAESAR (Competition for Authenticated Encryption: Security, Applicability, and Robustness) to promote the development of next-generation AE algorithms."
742826,15510,23712,Heisenberg Groups as Platform for the AAG Key-Exchange Protocol,2014,"When the AAG protocol was first introduced, braid groups were proposed as platform group. However, there are studies that successful attack AAG with braid groups, one main attack method is the length-based attack. Searching for a new platform for AAG, Garber, Kahrobaei, and Lam studied polycyclic groups generated by number field and concluded that they are resistant against the length-based attack. Inspired by this result, we ask whether other type of polycyclic groups can be used as platform for AAG. In this paper, we discuss the use of Heisenberg groups, a type of polycyclic group, as a platform group for AAG by submitting them to one of AAG's major attacks, the length-based attack."
1445513,15510,10286,On the properties of public key encryption from group signatures,2013,"In this talk, we discuss properties of public key encryption schemes which are derived from group signatures. Abdalla and Warinschi (ICICS 2004) and Ohtake et al. (AFRICACRYPT 2009) already showed that it is possible to construct a chosen-ciphertext secure public key encryption from an arbitrary group signature scheme in a black-box manner. By extending these results, we further show that if the underlying group signature scheme has some special property, then its converted public key encryption scheme also yields a special property which is inherited from the underlying group signature."
163751,15510,9969,New Proof Methods for Attribute-Based Encryption: Achieving Full Security through Selective Techniques,2012,"We develop a new methodology for utilizing the prior techniques to prove selective security for functional encryption systems as a direct ingredient in devising proofs of full security. This deepens the relationship between the selective and full security models and provides a path for transferring the best qualities of selectively secure systems to fully secure systems. In particular, we present a Ciphertext-Policy Attribute-Based Encryption scheme that is proven fully secure while matching the efficiency of the state of the art selectively secure systems."
1196273,15510,9856,A building code for building code: putting what we know works to work,2013,"Systems of programs control more and more of our critical infrastructures. Forty years of system development and research have taught us many lessons in how to build software that is reliable, relatively free of vulnerabilities, and can enforce security policies. Those years of experience seem not to have taught us how to get these lessons put into practice, particularly with respect to security, except in a few specialized places. This essay suggests an approach to capturing what we know in a way that can make a difference in systems on which we all rely."
1286026,15510,8806,Information leakage analysis of database query languages,2014,"In this work, we extend language-based information-flow security analysis to the case of database applications embedding query languages. The analysis is performed by ( i ) computing an overapproximation of variables' dependences, in the form of propositional formula, occurred up to each program point, ( ii ) checking the satisfiability on assigning truth values to variables, ( iii ) analyzing the application over a  numerical abstract  domain, and finally, ( iv ) enhancing the analysis using the reduced product of the  propositional formulae domain  and the  numerical abstract domain."
1227595,15510,20754,Steganography in OFDM Symbols of Fast IEEE 802.11n Networks,2013,This paper presents a proposal of covert steganographic channels in high-speed IEEE 802.11n networks. The method is based on the modification of cyclic prefixes in OFDM (Orthogonal Frequency-Division Multiplexing) symbols. This proposal provides the highest hidden transmission known in the state of the art. This paper includes theoretical analysis and simulation results of the presented steganographic system performance. The simulation performance was compared with other known approaches in the literature.
646706,15510,11345,Solving LPN Using Covering Codes,2014,"We present a new algorithm for solving the LPN problem. The algorithm has a similar form as some previous methods, but includes a new key step that makes use of approximations of random words to a nearest codeword in a linear code. It outperforms previous methods for many parameter choices. In particular, we can now solve instances suggested for 80-bit security in cryptographic schemes like HB variants, LPN-C and Lapin, in less than 2(80) operations."
2156165,15510,8806,Generic support for RBAC break-glass policies in process-aware information systems,2013,"We present a break-glass extension for process-related role-based access control (RBAC) models. Our extension ensures the static (design-time) and dynamic (runtime) consistency of corresponding break-glass models. The extension is generic in the sense that it can, in principle, be used to extend arbitrary process-aware information systems or process modeling languages with support for process-related RBAC and corresponding break-glass policies. We implemented a library and runtime engine that provides full platform support for all properties of our approach."
1809994,15510,20754,Cloud Computing: A Records and Information Management Perspective,2011,"For many records and information management (RIM) professionals, cloud computing resembles a traditional hosting service: information storage or applications are outsourced to a third-party provider and accessed by the organization through a network connection. However, the information, applications, and processing power in a cloud infrastructure are distributed across many servers and stored along with other customers' information, separated only by logical isolation mechanisms. This presents both new RIM challenges and benefits."
2486374,15510,11345,"Cryptographic Schemes Based on the ASASA Structure: Black-Box, White-Box, and Public-Key (Extended Abstract)",2014,In this paper we pick up an old challenge to design public key or white-box constructions from symmetric cipher components. We design several encryption schemes based on the ASASA structure ranging from fast and generic symmetric ciphers to compact public key and white- box constructions based on generic affine transformations combined with specially designed low degree non-linear layers. While explaining our de- sign process we show several instructive attacks on the weaker variants of our schemes 1 .
1966815,15510,339,Poster: protecting information in systems of systems,2011,"Systems of Systems (SoS) are dynamic, distributed coalitions of autonomous and heterogeneous systems that collaborate to achieve a common goal. While offering several advantages in terms of scalability and flexibility, the SoS paradigm has a strong impact on system interoperability and on the security requirements of collaborating parties. In this demo we present a prototype implementation of POLIPO, a security framework that combines context-aware access control with trust management and ontology-based services to protect information in SoS."
906847,15510,339,Rethinking about guessing attacks,2011,"Although various past efforts have been made to characterize and detect guessing attacks, there is no consensus on the definition of guessing attacks. Such a lack of generic definition makes it extremely difficult to evaluate the resilience of security protocols to guessing attacks.   To overcome this hurdle, we seek a new definition in this paper to fully characterize the attacker's guessing capabilities (i.e., guessability). This provides a general framework to reason about guessing attacks in a symbolic setting, independent of specific intruder models. We show how the framework can be used to analyze both passive and active guessing attacks."
972991,15510,20754,Silver Bullet Talks with the IEEE Center for Secure Design,2014,"The IEEE Center for Secure Design (CSD), which launched in August 2014, gathers software security expertise from industry, academia, and government and provides guidance on recognizing design flaws and building security in. Three of the founding members of the CSD discuss the project and its future. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
1707456,15510,8912,A model for security analysis of smart meters,2012,"Smart grids are replacing traditional power grids and smart meters are one of the key components of smart grids. Rapid deployment of smart grids has resulted in development of advanced metering infrastructures (AMI) without adequate security planning. In this paper we propose a systematic method for modeling functionalities of smart meters and deriving attacks that can be mounted on them. We apply our method to a real open source meter, implement two of the derived attacks, and measure their performance/memory overheads."
942804,15510,10192,A Comprehensive Security Model for Networking Applications,2012,"The Internet is currently being used by millions of users for web browsing, data storage, social networks, communications, VOIP, e-commerce, and other applications that are enabled by wireless networks, cloud computing, distributed systems, and cellphone networks. The architecture for these applications is not secure as shown by all the recent widely-publicized attacks. We propose a comprehensive security model for networking applications that includes new key distribution and management techniques and a realistic trust model."
1640878,15510,20754,Silver Bullet Talks with Howard Schmidt,2012,"Gary McGraw interviews Howard Schmidt, former cybersecurity coordinator for the Obama administration. They discuss the differences between doing security work in the public and private sectors, the difficulties of establishing cybersecurity in the government, and how the actions of Anonymous and Wikileaks square with the notion of free speech. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
2474224,15510,20754,By Any Means Possible: How Intelligence Agencies Have Gotten Their Data,2014,"Amidst the many public discussions springing from the Edward Snowden documents, one has been about the perceived change in the NSA’s practices: they’re now hacking computers instead of tapping wires and listening to radio signals. Looked at narrowly—that is, in terms of only NSA’s mission—that may be true. Looked at more broadly, in terms of how intelligence agencies have always behaved, this is no surprise at all. They’ve long used only two criteria when evaluating a proposed tactic: does it work, and at what cost?"
1743792,15510,20754,Closing the Gap on Securing Energy Sector Control Systems [Guest editors' introduction],2014,"Control system operations staff are highly specialized. They're a healthy mix of deep, narrow experts--power engineers and petroleum engineers, for example--and less educated technicians who slowly evolve from field workers to supervisors. For an industry in which 50-year-old equipment remains commonplace, cybersecurity is a brand new requirement, and there's a shortage of qualified expertise available to address it. It will be up to our community to bridge the gap."
2334066,15510,23749,The Cloud: Requirements for a Better Service,2012,"Cloud computing has rapidly made it to the top of the list of considerations for IT strategies in various organizations. However, there are many unanswered requirements delaying the complete adoption of this paradigm. As a result, it is essential to identify the organizations' wish-list for Cloud services. In this paper, we define a set of requirements for Cloud computing. Then we highlight the level of importance of each one for government organizations' applications, large-scale computations, financial services, healthcare applications, and the online entertainment."
1096311,15510,339,Security Vulnerabilities of the Cisco IOS Implementation of the MPLS Transport Profile,2014,"We are interested in the security of the MPLS Transport Profile (MPLS-TP), in the context of smart-grid communication networks. The security guidelines of the MPLS-TP standards are written in a complex and indirect way, which led us to pose as hypothesis that vendor solutions might not implement them satisfactorily. To test this hypothesis, we investigated the Cisco implementation of two MPLS-TP OAM (Operations, Administration, and Maintenance) protocols: bidirectional forwarding detection (BFD), used to detect failures in label-switched paths (LSPs) and protection state coordination (PSC), used to coordinate protection switching. Critical smart grid applications, such as protection and control, rely on the protection switching feature controlled by BFD and PSC. We did find security issues with this implementation. We implemented a testbed with eight nodes that run the MPLS-TP enabled Cisco IOS; we demonstrated that an attacker who has access to only one cable (for two attacks) or two cables (for one attack) is able to harm the network at several points (e.g., disabling both working and protection LSPs). This occurred in spite of us implementing the security guidelines that are available from Cisco for IOS and MPLS-TP. The attacks use forged BFD or PSC messages, which induce a label-edge router (LER) into believing false information about an LSP. In one attack, the LER disables the operational LSP; in another attack, the LER continues to believe that a physically destroyed LSP is up and running; in yet another attack, both operational and backup LSPs are brought down. Our findings suggest that the MPLS-TP standard should be more explicit when it comes to security. For example, to thwart the attacks revealed here, it should mandate either hop by hop authentication (such as MACSec) at every node, or an ad-hoc authentication mechanism for BFD and PSC."
1070021,15510,339,The state and evolution of privacy by design,2012,"Privacy by design (PbD) represents a distinct philosophical movement and a shift away from the dominant legal-oriented approach to privacy and toward an approach that is more proactive, technical, and embedded. However, it suffers from the general absence of organized systematic techniques for carrying it out. In part, this gap reflects a failure to appropriately leverage and organize existing ideas and methods, but it also reflects the need to develop new methods capable of addressing the complexities of new socio-technical systems. This tutorial aims to survey the state of PbD and what will be required to move it into the realm of actionable and structured techniques."
136134,15510,374,Symbolic Probabilistic Analysis of Off-Line Guessing,2013,"We introduce a probabilistic framework for the automated analysis of security protocols. Our framework provides a general method for expressing properties of cryptographic primitives, modeling an at- tacker more powerful than conventional Dolev-Yao attackers. It allows modeling equational properties of cryptographic primitives as well as property statements about their weaknesses, e.g. primitives leaking par- tial information about messages or the use of weak random generation al- gorithms. These properties can be used to automatically find attacks and estimate their success probability. Existing symbolic methods can neither model such properties nor find such attacks. We show that the probabil- ity estimates we obtain are negligibly different from those yielded by a generalized random oracle model based on sampling terms into bitstrings while respecting the stipulated properties of cryptographic primitives. As case studies, we use a prototype implementation of our framework to model non-trivial properties of RSA encryption and automatically estimate the probability of off-line guessing attacks on the EKE protocol."
789424,15510,339,The robustness of hollow CAPTCHAs,2013,"CAPTCHA is now a standard security technology for differentiating between computers and humans, and the most widely deployed schemes are text-based. While many text schemes have been broken, hollow CAPTCHAs have emerged as one of the latest designs, and they have been deployed by major companies such as Yahoo!, Tencent, Sina, China Mobile and Baidu. A main feature of such schemes is to use contour lines to form connected hollow characters with the aim of improving security and usability simultaneously, as it is hard for standard techniques to segment and recognize such connected characters, which are however easy to human eyes. In this paper, we provide the first analysis of hollow CAPTCHAs' robustness. We show that with a simple but novel attack, we can successfully break a whole family of hollow CAPTCHAs, including those deployed by all the major companies. While our attack casts serious doubt on the viability of current designs, we offer lessons and guidelines for designing better hollow CAPTCHAs."
1501320,15510,339,Demonstrating the effectiveness of MOSES for separation of execution modes,2012,"In this paper, we describe a demo of a  light virtualisation  solution for Android phones. We named our solution  MOSES  (MOde-of-uses SEcurity Separation). MOSES is a policy-based framework for enforcing software isolation of applications and data. In MOSES, it is possible to define distinct  security profiles  within a single smartphone. Each security profile is associated with a set of policies that control the access to applications and data. One of the main characteristics of MOSES is the dynamic switching from one security profile to another. Each profile is associated with a context as well. Through the smartphones sensors, MOSES is able to detect changes in context and to dynamically switch to the security profile associated with the current context. Our current implementation of MOSES shows minimal overhead compared to standard Android in terms of latencies and battery consumption."
2453489,15510,339,iSpy: automatic reconstruction of typed input from compromising reflections,2011,"We investigate the implications of the ubiquity of personal mobile devices and reveal new techniques for compromising the privacy of users typing on virtual keyboards. Specifi- cally, we show that so-called compromising reflections (in, for example, a victim's sunglasses) of a device's screen are sufficient to enable automated reconstruction, from video, of text typed on a virtual keyboard. Despite our deliberate use of low cost commodity video cameras, we are able to compensate for variables such as arbitrary camera and device positioning and motion through the application of advanced computer vision and machine learning techniques. Using footage captured in realistic environments (e.g., on a bus), we show that we are able to reconstruct fluent translations of recorded data in almost all of the test cases, correcting users' typing mistakes at the same time. We believe these results highlight the importance of adjusting privacy expectations in response to emerging technologies."
616775,15510,374,Investigation of signal and message manipulations on the wireless channel,2011,"We explore the suitability of Dolev-Yao-based attacker models for the security analysis of wireless communication. The Dolev-Yao model is commonly used for wireline and wireless networks. It is defined on abstract messages exchanged between entities and includes arbitrary, real-time modification of messages by the attacker. In this work, we aim at understanding and evaluating the conditions under which these real-time, covert low-energy signal modifications can be successful. In particular, we focus on the following signal and message manipulation techniques: symbol flipping and signal annihilation. We analyze these techniques theoretically, by simulations, and experiments and show their feasibility for particular wireless channels and scenarios."
1765333,15510,20754,The Known Unknowns,2013,"Securing computer systems is an ongoing task that requires involvement of users, system administrators, and developers. There has been a lot of discussion of embedded computer security in the computer science curriculum, but that is insufficient. It's necessary to provide training to keep workers up to date, and to educate them. In this article, the authors discuss the workforce, and the fact that a majority of those working in computing fields don't have a formal computer science degree. What do they know, and what do employers need to know about the gaps in the employee's knowledge?"
890571,15510,20754,Silver Bullet Talks with Per-Olof Persson,2013,"Gary McGraw interviews Per-Olof Persson, currently head of global software security operations at Sony Mobile. Persson discusses the importance of working in different positions within the same company&#x2014;from directing the Sony Board to running in front of Android phones. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
2549382,15510,20754,Obfuscation: The Hidden Malware,2011,"A cyberwar exists between malware writers and antimalware researchers. At this war's heart rages a weapons race that originated in the 80s with the first computer virus. Obfuscation is one of the latest strategies to camouflage the telltale signs of malware, undermine antimalware software, and thwart malware analysis. Malware writers use packers, polymorphic techniques, and metamorphic techniques to evade intrusion detection systems. The need exists for new antimalware approaches that focus on what malware is doing rather than how it's doing it."
925296,15510,20754,A Method for Preventing Skipping Attacks,2012,"Until recently, known fault attacks against (non-CRT) exponentiation-based cryptosystems were supposed to be of rather theoretical nature, as they require a precise fault injection, e.g., a bit flip. However, Schmidt and Herbst (FDTC 2008) reported practical fault-attacks against RSA in standard mode using low-cost equipment. Although their attacks were described against RSA, they readily extend to any other exponentiation-based cryptosystem. This paper describes an efficient method to prevent those new attacks."
1261836,15510,343,Tor instead of IP,2011,"As the Internet has become more popular, it has increasingly been a target and medium for monitoring, censorship, content discrimination, and denial of service. Although anonymizing overlays such as Tor [2] provide some help to end users in combating these trends, the overlays themselves have become targets in turn. In this paper, we take a fresh approach: instead of running Tor on top of IP, we propose to run Tor instead of IP. We ask: what might the Internet look like if privacy and censorship resistance had been designed in from scratch? To be practical, any proposal also needs to be robust to failures, achieve reasonable efficiency compared to today's Internet, and be consistent with ISP economic concerns. Although preliminary, we argue that our design achieves these goals."
2529338,15510,339,Foundations of garbled circuits,2012,"Garbled circuits, a classical idea rooted in the work of Yao, have long been understood as a cryptographic  technique , not a cryptographic  goal . Here we cull out a primitive corresponding to this technique. We call it a  garbling scheme . We provide a provable-security treatment for garbling schemes, endowing them with a versatile syntax and multiple security definitions. The most basic of these,  privacy , suffices for two-party secure function evaluation (SFE) and private function evaluation (PFE). Starting from a PRF, we provide an efficient garbling scheme achieving privacy and we analyze its concrete security. We next consider  obliviousness  and  authenticity , properties needed for private and verifiable outsourcing of computation. We extend our scheme to achieve these ends. We provide highly efficient blockcipher-based instantiations of both schemes. Our treatment of garbling schemes presages more efficient garbling, more rigorous analyses, and more modularly designed higher-level protocols."
979501,15510,339,Defining verifiability in e-auction protocols,2013,"An electronic auction protocol will only be used by those who trust that it operates correctly. Therefore, e-auction protocols must be  verifiable : seller, buyer and losing bidders must all be able to determine that the result was correct. We pose that the importance of verifiability for e-auctions necessitates a formal analysis. Consequently, we identify notions of verifiability for each stakeholder. We formalize these and then use the developed framework to study the verifiability of two examples, the protocols due to Curtis et al. and Brandt, identifying several issues."
895717,15510,339,Proof of plaintext knowledge for code-based public-key encryption revisited,2013,"In a recent paper at Asiacrypt'2012, Jain et al point out that Veron code-based identification scheme is not perfect zero-knowledge. In particular, this creates a gap in security arguments of proof of plaintext knowledge (PPK) and verifiable encryption for the McEliece public key encryption (PKE) proposed by Morozov and Takagi at ACISP'2012. We fix the latter result by showing that PPK for the code-based Niederreiter and McEliece PKE's can be constructed using Stern zero-knowledge identification scheme, which is unaffected by the above mentioned problem. Since code-based verifiable encryption uses PPK as a main ingredient, our proposal presents a fix for the McEliece verifiable encryption as well. In addition, we present the Niederreiter verifiable encryption."
160620,15510,374,New Insight to Preserve Online Survey Accuracy and Privacy in Big Data Era,2014,"An online survey system provides a convenient way for people to conduct surveys. It removes the necessity of human resources to hold paper surveys or telephone interviews and hence reduces the cost significa ntly. Nevertheless, accuracy and privacy remain as the major obstacles that need additional att ention. To conduct an accurate survey, privacy maybe lost, and vice versa. In this paper, we provide new insight to preserve these two seeming contradictory issues in online survey systems especially suitable in big data era. We propose a secure system, which is shown to be effic ient and practical by simulation data. Our analysis further shows that the proposed solution is desirable not only in online survey systems but also in several potential applications, including E-Voting, Smart-Grid and Vehicular Ad Hoc Networks. 2014 Springer International Publishing Switzerland."
1352458,15510,8335,Security Enhanced Linux on embedded systems: A hardware-accelerated implementation,2012,"Security Enhanced Linux implements fine-grained mandatory access control. Despite its usefulness, the overhead of implementing it on embedded devices is prohibitive. Therefore, in the past it has been proposed to accelerate SELinux by means of dedicated hardware; in this work we demonstrate the feasibility of such an approach by implementing a hardware accelerator for SELinux on a FPGA-based platform. Our implementation obtains a huge reduction in the performance overhead and energy consumption of SELinux, yet employing a limited chip area."
1611586,15510,20754,Silver Bullet Talks with Wenyuan Xu,2013,"Wenyuan Xu, as associate professor at the University of South Carolina, talks about the differences between American and Chinese technical culture, her work on automatic meter reading systems, whether electrical engineering is more advanced in terms of design than computer science, and why there are so few women in engineering and computer science. Hear the full podcast at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet."
1518273,15510,339,Poster: Destabilizing BitTorrent's clusters to attack high bandwidth leechers,2011,BitTorrent protocol incentivizes sharing through its choking algorithm. BitTorrent choking algorithm creates clusters of leechers with similar upload capacity to achieve higher overall transfer rates. We show that a malicious peer can exploit BitTorrent's choking algorithm to reduce the upload utilization of high bandwidth leechers. We use a testbed comprising of 24 nodes to provide experimental evidence of a distributed attack in which the malicious peers increase the download time for high bandwidth leechers by up to 16% and increases average download time of the swarm by up to 15% by using distributed and loosely-coupled malicious peers which comprise only 4.7% of the swarm. The countermeasures of this attack are a part of our ongoing research work.
2345180,15510,339,ATRA: Address Translation Redirection Attack against Hardware-based External Monitors,2014,"Hardware-based external monitors have been proposed as a trustworthy method for protecting the kernel integrity. We introduce the design and implementation of Address Translation Redirection Attack (ATRA) that enables complete evasion of the hardware-based external monitor that anchors its trust on a separate processor. ATRA circumvents the external monitor by redirecting the memory access to critical kernel objects into a non-monitored region. Despite the seriousness of the ATRA issue, the address translation integrity has been assumed in many hardware-based external monitors and the possibility of its exploitation has been suggested yet many considered hypothetical. We explore the intricate details of ATRA, explain major challenges in realizing ATRA in practice, and address them with two types of ATRA called Memory-bound ATRA and Register-bound ATRA. Our evaluations with benchmarks show that ATRA does not introduce a noticeable performance degradation to the host system, proving practical applicability of the attack to alert the researchers to seriously address ATRA in designing future external monitors."
1324349,15510,339,OTO: online trust oracle for user-centric trust establishment,2012,"Malware continues to thrive on the Internet. Besides automated mechanisms for detecting malware, we provide users with trust evidence information to enable them to make informed trust decisions. To scope the problem, we study the challenge of assisting users with judging the trustworthiness of software downloaded from the Internet.   Through expert elicitation, we deduce indicators for trust evidence, then analyze these indicators with respect to scalability and robustness. We design OTO, a system for communicating these trust evidence indicators to users, and we demonstrate through a user study the effectiveness of OTO, even with respect to IE's SmartScreen Filter (SSF). The results from the between-subjects experiment with 58 participants confirm that the OTO interface helps people make correct trust decisions compared to the SSF interface regardless of their security knowledge, education level, occupation, age, or gender."
1433731,15510,339,Boolean symmetric searchable encryption,2013,"In this article we tackle the issue of searchable encryption with a generalized query model. Departing from many previous works that focused on queries consisting of a single keyword, we consider the the case of queries consisting of arbitrary boolean expressions on keywords, that is to say conjunctions and disjunctions of keywords and their complement. Our construction of boolean symmetric searchable encryption BSSE is mainly based on the orthogonalization of the keyword field according to the Gram-Schmidt process. Each document stored in an outsourced server is associated with a label which contains all the keywords corresponding to the document, and searches are performed by way of a simple inner product. Furthermore, the queries in the BSSE scheme are randomized. This randomization hides the search pattern of the user since the search results cannot be associated deterministically to queries. We formally define an adaptive security model for the BSSE scheme. In addition, the search complexity is in $O(n)$ where $n$ is the number of documents stored in the outsourced server."
2338234,15510,339,POSTER: Misuseablity Analysis for IT Infrastructure,2014,"Today, organizations have limited resources available to allocate to the detection of complex cyber-attacks. In order to optimize their resource allocation, organizations must conduct a thorough risk analysis process so as to focus their efforts and resources on the protection of the organization's important assets. In this study we propose a framework that automatically and dynamically derives a misuseability score for every IT component (e.g., PC, laptop, server, router, smartphone, and user). The misuseability score encapsulates the potential damage that can be caused to the organization when its assets are compromised and misused."
1438297,15510,339,On the invisibility of designated confirmer signatures,2011,"As an important cryptographic primitive, designated confirmer signatures are introduced to control the public verifiability of signatures. That is, only the signer or a semi-trusted party, called  designated confirmer , can interactively assist a verifier to check the validity of a designated confirmer signature. The central security property of a designated confirmer signature scheme is called  invisibility , which requires that even an adaptive adversary cannot determine the validity of an alleged signature without direct cooperation from either the signer or the designated confirmer. However, in the literature researchers have proposed two other related properties, called  impersonation  and  transcript simulatability , though the relations between them are not clear. In this paper, we first explore the relations among these three invisibility related concepts and conclude that invisibility, impersonation and transcript simulatability forms an increasing stronger order. After that, we turn to study the invisibility of two designated confirmer signature schemes recently presented by Zhang et al. and Wei et al. By demonstrating concrete and effective attacks, we show that both of those two scheme fail to meet invisibility, the central security property of designated confirmer signatures."
1294640,15510,339,POSTER: A Hybrid Botnet Ecological Environment,2014,"Research into defense against botnets, especially countermeasures against the command and control (CC however, they need a relatively closed and controllable environment designed by researchers to quantitatively evaluate the capabilities of these next-generation botnets. Consequently, we propose the Hybrid Botnet Ecological Environment (HBEE), which aims to make bots expose as many of their execution paths as possible, in order to mine the C&C protocol vulnerabilities of bots as well as to evaluate the capability of advanced botnets. Our design can also prevent bots from causing harm to the real Internet by malicious flow filtration and C&C server spoofing. Our preliminary results show that HBEE can observe communication actions and produce accurate and comprehensive data about botnet behaviors and advanced botnet capabilities."
1410207,15510,339,OAKE: a new family of implicitly authenticated diffie-hellman protocols,2013,"Cryptographic algorithm standards play an important role both to the practice of information security and to cryptography theory research. Among them, the KEA and OPACITY (KEA/OPACITY, in short) protocols, and the MQV and HMQV ((H)MQV, in short) protocols, are a family of implicitly authenticated Diffie-Hellman key-exchange (IA-DHKE) protocols that are among the most efficient authenticated key-exchange protocols known and are widely standardized. In this work, from some new design insights, we develop a new family of practical IA-DHKE protocols, referred to as OAKE (standing for optimal authenticated key-exchange in brief). We show that the OAKE protocol family combines, in essence, the advantages of both (H)MQV and KEA/OPACITY, while saving from or alleviating the disadvantages of them both."
877991,15510,339,Privacy-preserving alibi systems,2012,"An alibi provides evidence of a person's past location and can be critical in proving ones innocence. An alibi involves two parties: the  owner , who benefits from the alibi, and the  corroborator , who testifies for the owner. As mobile devices become ubiquitous, they can determine where we are and what we are doing, and help us to establish evidence of our location as they accompany us on our daily activities. Existing location-based services like Google Latitude can already track and record our every move, but these systems require us to reveal our identity when recording our location. This leaves our privacy at risk, and requires a trusted third party to maintain our location information."
941855,15510,339,Receipt-mode trust negotiation: efficient authorization through outsourced interactions,2011,"In trust negotiation approaches to authorization, previously unacquainted entities establish trust in one another gradually via the bilateral and iterative exchange of policies and digital credentials. Although this affords resource providers with an expressive means of access control for open systems, the trust negotiation process incurs non-trivial computational and communications costs. In this paper, we propose  Receipt-Mode Trust Negotiation  (RMTN) as a means of mitigating the performance penalties on servers that use trust negotiation. RMTN provides a means of off-loading the majority of the trust negotiation process to delegated receipt-generating  helper servers . RMTN ensures that helpers produce correct trust negotiation protocol receipts, and that the helpers are incapable of impersonating the resource server outside of the RMTN protocol. We describe an initial implementation of our RMTN protocol on a Linux testbed, discuss the security of this protocol, and present experimental results indicating that the receipt-mode protocol does indeed enhance the performance of resource servers that rely on trust negotiation approaches to authorization."
1020786,15510,339,Automatic verification of protocols with lists of unbounded length,2013,"We present a novel automatic technique for proving secrecy and authentication properties for security protocols that manipulate lists of unbounded length, for an unbounded number of sessions. This result is achieved by extending the Horn clause approach of the automatic protocol verifier ProVerif. We extend the Horn clauses to be able to represent lists of unbounded length. We adapt the resolution algorithm to handle the new class of Horn clauses, and prove the soundness of this new algorithm. We have implemented our algorithm and successfully tested it on several protocol examples, including XML protocols coming from web services."
1174254,15510,339,POSTER: Caching oblivious memory access: an extension to the HCRYPT virtual machine,2013,"Efficient homomorphic encryption enables the construction of an encrypted computer system. Previous work has shown how this can be achieved using only arithmetic representations of simple demultiplexer circuits. This poster extends the results by introducing a caching mechanism for oblivious memory access, by far the most time-consuming building block of a recently proposed sample machine architecture. The construction allows to significantly accelerate homomorphically encrypted machine operation while still preserving obliviousness of memory access, control unit operation and functional components."
1731449,15510,339,Vigilare: toward snoop-based kernel integrity monitor,2012,"In this paper, we present  Vigilare system , a kernel integrity monitor that is architected to snoop the bus traffic of the host system from a separate independent hardware. This  snoop-based monitoring  enabled by the Vigilare system, overcomes the limitations of the  snapshot-based monitoring  employed in previous kernel integrity monitoring solutions. Being based on inspecting snapshots collected over a certain interval, the previous hardware-based monitoring solutions cannot detect  transient attacks  that can occur in between snapshots. We implemented a prototype of the Vigilare system on Gaisler's grlib-based system-on-a-chip (SoC) by adding  Snooper  hardware connections module to the host system for bus snooping. To evaluate the benefit of snoop-based monitoring, we also implemented similar SoC with a snapshot-based monitor to be compared with. The Vigilare system detected all the transient attacks without performance degradation while the snapshot-based monitor could not detect all the attacks and induced considerable performance degradation as much as 10% in our tuned STREAM benchmark test."
2260071,15510,339,Towards measuring warning readability,2012,"Security systems frequently rely on warning messages to convey important information, especially when a machine is not able to assess a situation automatically. For a long time, researchers have investigated the effects of warning messages to optimise their reception by a user. Design guidelines and best practises help the developer or interaction designer to adequately channel urgent information. In this poster, we investigate the application of readability measures to assess the difficulty of the descriptive text in warning messages. Adapting such a measure to fit the needs of warning message design allows objective feedback on the quality of a warning's descriptive text. An automated process will be able to assist software developers and designers in creating more readable and hence more understandable security warning messages. We present an initial exploration of the use of readability measures on the descriptive text of warning messages. Existing measures were evaluated on warning messages extracted from current browsers using an experimental study with 15 undergrad students. While our data did not yield conclusive results yet, we argue that readability measures can provide valuable assistance when implementing security systems."
2230990,15510,122,ZOOMM: a parallel web browser engine for multicore mobile devices,2013,"We explore the challenges in expressing and managing concurrency in browsers on mobile devices. Browsers are complex applications that implement multiple standards, need to support legacy behavior, and are highly dynamic and interactive. We present ZOOMM, a highly concurrent web browser engine prototype and show how concurrency is effectively exploited at different levels: speed up computation performance, preload network resources, and preprocess resources outside the critical path of page loading. On a dual-core Android mobile device we demonstrate that ZOOMM is two times faster than the native WebKit based browser when loading the set of pages defined in the Vellamo benchmark."
1177669,15510,339,"A three-way investigation of a game-CAPTCHA: automated attacks, relay attacks and usability",2014,"Existing captcha solutions on the Internet are a major source of user frustration. Game captchas are an interesting and, to date, little-studied approach claiming to make captcha solving a fun activity for the users. One broad form of such captchas -- called Dynamic Cognitive Game (DCG) captchas -- challenge the user to perform a game-like cognitive task interacting with a series of dynamic images. We pursue a comprehensive analysis of a representative category of DCG captchas. We formalize, design and implement such captchas, and dissect them across: (1) fully automated attacks, (2) human-solver relay attacks, and (3) usability. Our results suggest that the studied DCG captchas exhibit high usability and, unlike other known captchas, offer some resistance to relay attacks, but they are also vulnerable to our novel dictionary-based automated attack."
756061,15510,339,Coercion resistance in authentication responsibility shifting,2012,"To meet the demand of scalability and usability, many real-world authentication systems have adopted the idea of responsibility shifting, explicitly or implicitly, where a user's responsibility of authentication is shifted to another entity, usually in case of failure of the primary authentication method. One example of responsibility shifting is in the fourth-factor authentication [1] whereby a user gets the crucial authentication assistance from a helper who takes over the responsibility. In the fourth-factor authentication system [1], subverting/coercing the helper (trustee) allows the adversary to log in without capturing the password of the user."
1486441,15510,339,POSTER: Secure authentication from facial attributeswith no privacy loss,2013,"Biometric authentication is more secure than using regular passwords, as biometrics cannot be forgotten and contain high entropy. Thus, many constructions rely on biometric features for authentication, and use them as a source for good cryptographic keys. At the same time, biometric systems carry with them many privacy concerns.   We describe a proof-of-concept (PoC) which transforms facial attributes from a single image into keys in a consistent, discriminative, and privacy-aware manner. The outcome is a user-specific string that cannot be guessed, and it reveals no information concerning the users of the system, even when the system's secrets are revealed."
1400494,15510,339,YourPassword: applying feedback loops to improve security behavior of managing multiple passwords,2014,"Various mechanisms exist to secure users' passwords, yet users continue to struggle with the complexity of multiple password management. We explore the effectiveness of a feedback loop to improve users' password management. We introduce YourPassword, a web-based application that uses feedback to inform users about the security of their password behavior. YourPassword has two main components: a password behavior checker that converts password strengths into numerical scores and a dashboard interface that visualizes users' overall password behavior and provides visual feedback in real time. YourPassword not only provides a total score on all passwords, but also visualizes when passwords are too similar to each other. To test the efficacy of YourPassword, we conducted a between-subjects experiment and think-aloud test with 48 participants. Participants either had access to YourPassword, an existing commercial password checker, or no password tool (control condition). YourPassword helped participants improve their password behavior as compared with the commercial tool or no tool."
898239,15510,339,Sufficient conditions for vertical composition of security protocols,2014,"Vertical composition of security protocols means that an application protocol (e.g., a banking service) runs over a channel established by another protocol (e.g., a secure channel provided by TLS). This naturally gives rise to a compositionality question: given a secure protocol P1 that provides a certain kind of channel as a goal and another secure protocol P2 that assumes this kind of channel, can we then derive that their vertical composition P2[P1] is secure? It is well known that protocol composition can lead to attacks even when the individual protocols are all secure in isolation. In this paper, we formalize seven easy-to-check static conditions that support a large class of channels and applications and that we prove to be sufficient for vertical security protocol composition."
826648,15510,339,4th cloud computing security workshop (CCSW 2012),2012,"Notwithstanding the latest buzzword (grid, cloud, utility computing, SaaS, etc.), large-scale computing and cloud-like infrastructures are here to stay. How exactly they will look like tomorrow is still for the markets to decide, yet one thing is certain: clouds bring with them new untested deployment and associated adversarial models and vulnerabilities. It is essential that our community becomes involved at this early stage. The CCSW workshop aims to bring together researchers and practitioners in all security aspects of cloud-centric and outsourced computing to act as a fertile ground for creative debate and interaction in security-sensitive areas of computing impacted by clouds."
1566741,15510,20754,StegTorrent: A Steganographic Method for the P2P File Sharing Service,2013,The paper proposes StegTorrent a new network steganographic method for the popular P2P file transfer service-BitTorrent. It is based on modifying the order of data packets in the peer-peer data exchange protocol. Unlike other existing steganographic methods that modify the packets' order it does not require any synchronization. Experimental results acquired from prototype implementation proved that it provides high steganographic bandwidth of up to 270 b/s while introducing little transmission distortion and providing difficult detectability.
1699317,15510,339,Leakage resilient eCK-secure key exchange protocol without random oracles,2011,"This paper presents the first formalization of partial key leakage security of a  two-pass  two-party authenticated key exchange (AKE) protocol on the extended Canetti-Krawczyk (eCK) security model. Our formalization, λ-leakage resilient eCK security, is a (stronger) generalization of the eCK security model with enhanced by the notion of λ-leakage resilient security recently introduced by Akavia, Goldwasser and Vaikuntanathan. We present a PKI-based two-pass key exchange protocol with Hash Proof System (HPS), that is λ-leakage resilient eCK secure without random oracles."
746355,15510,339,Priceless: the role of payments in abuse-advertised goods,2012,"Large-scale abusive advertising is a profit-driven endeavor. Without consumers purchasing spam-advertised Viagra, search-advertised counterfeit software or malware-advertised fake anti-virus, these campaigns could not be economically justified. Thus, in addition to the numerous efforts focused on identifying and blocking individual abusive advertising mechanisms, a parallel research direction has emerged focused on undermining the associated means of monetization: payment networks. In this paper we explain the complex role of payment processing in monetizing the modern affiliate program ecosystem and characterize the dynamics of these banking relationships over two years within the counterfeit pharmaceutical and software sectors. By opportunistically combining our own active purchasing data with contemporary disruption efforts by brand-holders and payment card networks, we gather the first empirical dataset concerning this approach. We discuss how well such payment interventions work, how abusive merchants respond in kind and the role that the payments ecosystem is likely to play in the future."
1396838,15510,339,DEMO: On the real-time masking of the sound of credit cards using hot patching,2013,"Phone based card payments utilize inband DTMF signaling to convey data. Since the DTMF signals are audible to a human ear, a call operator is in position to carry out a privacy attack. We investigate real-time techniques that can obfuscate the 'digit' values without deteriorating the voice quality. Furthermore, we consider a setting where the privacy solution is being provided by a third party which does not have the benefit of open interfaces to the communication application. Our experiments reveal the efficacy of binary interception to 'inject' the signal filtering. Meanwhile, we observe that several DTMF suppression techniques that have been proposed in literature can leave a residue that is sufficient for de-anonymizing the digit value. In light of these observations, we argue in favor of more modest privacy guarantees, which can be achieved by suppressing only the higher frequency. We show that margin crossings and peak variances can be used for fast pre-filtering of audio to detect the presence of a tone, thus reducing the computational needs."
2086597,15510,422,Compression for anti-adversarial learning,2011,"We investigate the susceptibility of compression-based learning algorithms to adversarial attacks. We demonstrate that compression-based algorithms are surprisingly resilient to carefully plotted attacks that can easily devastate standard learning algorithms. In the worst case where we assume the adversary has a full knowledge of training data, compression-based algorithms failed as expected. We tackle the worst case with a proposal of a new technique that analyzes subsequences strategically extracted from given data. We achieved near-zero performance loss in the worst case in the domain of spam filtering."
2166309,15510,339,On The Security of Mobile Cockpit Information Systems,2014,"Recent trends in aviation have led many general aviation pilots to adopt the use of iPads (or other tablets) in the cockpit. While initially used to display static charts and documents, uses have expanded to include live data such as weather and traffic information that is used to make flight decisions. Because the tablet and any connected devices are not a part of the onboard systems, they are not currently subject to the software reliability standards applied to avionics. In this paper, we create a risk model for electronic threats against mobile cockpit information systems and evaluate three such systems popular with general aviation pilots today: The Appareo Stratus 2 receiver with the ForeFlight app, the Garmin GDL~39 receiver with the Garmin Pilot app, and the SageTech Clarity CL01 with the WingX Pro7 app. We found all three to be vulnerable, allowing an attacker to manipulate information presented to the pilot, which in some scenarios would lead to catastrophic outcomes. Finally, we provide recommendations for securing such systems."
2071773,15510,339,APKLancet: tumor payload diagnosis and purification for android applications,2014,"A huge number of Android applications are bundled with relatively independent modules either during the development or by intentionally repackaging. Undesirable behaviors such as stealthily acquiring and distributing user's private information are frequently discovered in some bundled third-party modules, i.e., advertising libraries or malicious code (we call the module tumor payload in this work), which sabotage the integrity of the original app and lie as a threat to both the security of mobile system and the user's privacy.   In this paper, we discuss how to purify an Android APK by resecting the tumor payload. Our work is based on two observations: 1) the tumor payload has its own characteristics, so it could be spotted through program analysis, and 2) the tumor payload is a relatively independent module so it can be resected without affecting the original app's function.   We propose APKLancet, an automatic Android application diagnosis and purification system, to detect and resect the tumor payload. Relying on features extracting from ad libraries, analytics plugins and an approximately 8,000 malware samples, APKLancet is capable of diagnosing an APK and discovering unwelcome code fragment. Then it makes use of the code fragment as index to employ fine-grained program analysis and detaches the entire tumor payload. More precisely, it conducts an automatic app patching process to preserve the original normal functions while resecting tumor payload. We test APKLancet by the Android apps bundled with representative tumor payloads from online sandbox system. The result shows that the purification process is feasible to resect tumor payload and repair the apps. Moreover, all of the above do not require any Android system modification, and the purified app does not introduce any performance latency."
2181059,15510,339,Diesel: applying privilege separation to database access,2011,"Database-backed applications typically grant complete database access to every part of the application. In this scenario, a flaw in one module can expose data that the module never uses for legitimate purposes. Drawing parallels to traditional privilege separation, we argue that database data should be subject to limitations such that each section of code receives access to only the data it needs. We call this  data separation . Data separation defends against SQL-based errors including buggy queries and SQL injection attacks and facilitates code review, since a module's policy makes the extent of its database access explicit to programmers and code reviewers. We construct a system called Diesel, which implements data separation by intercepting database queries and applying modules' restrictions to the queries. We evaluate Diesel on three widely-used applications: Drupal, JForum, and WordPress."
1112851,15510,339,Monetizing spambot activity and understanding its relation with spambot traffic features,2012,"A myriad of studies are reporting an exponential increase in the number and size of worldwide botnets [1, 2, 15, 17, 20, 21]. For instance, it has been reported that the Storm botnet increased by a factor of three during the second quarter of 2008. The reason of such exponential growth is the financial gain that these spam botnets can generate [1, 2, 3]. Absent grounded empirical data, it is challenging to reconcile revenue estimates that can range from $2M/day for one spam botnet [4]. Paxson et. al [1] have documented 82,000 and 37,00 monthly orders for seven counterfeit pharmacies and counterfeit software stores, respectively. The spammers running all these spams generally purchase time from a bot master to launch a spam campaign with a single objective to increase their respective profit margins from such spam campaigns."
1462032,15510,339,Moving Targets: Security and Rapid-Release in Firefox,2014,"Software engineering practices strongly affect the security of the code produced. The increasingly popular Rapid Release Cycle (RRC) development methodology and easy network software distribution have enabled rapid feature introduction. RRC's defining characteristic of frequent software revisions would seem to conflict with traditional software engineering wisdom regarding code maturity, reliability and reuse, as well as security. Our investigation of the consequences of rapid release comprises a quantitative, data-driven study of the impact of rapid-release methodology on the security of the Mozilla Firefox browser. We correlate reported vulnerabilities in multiple rapid release versions of Firefox code against those in corresponding extended release versions of the same system; using a common software base with different release cycles eliminates many causes other than RRC for the observables. Surprisingly, the resulting data show that Firefox RRC does not result in higher vulnerability rates and, further, that it is exactly the unfamiliar, newly released software (the moving targets) that requires time to exploit. These provocative results suggest that a rethinking of the consequences of software engineering practices for security may be warranted."
689459,15510,293,A Closer Look at Third-Party OSN Applications: Are They Leaking Your Personal Information?,2014,"We examine third-party Online Social Network (OSN) applications for two major OSNs: Facebook and RenRen. These third-party applications typically gather, from the OSN, user personal information. We develop a measurement platform to study the interaction between OSN applications and fourth parties. We use this platform to study the behavior of 997 Facebook applications and 377 RenRen applications. We find that the Facebook and RenRen applications interact with hundreds of different fourth-party tracking entities. More worrisome, 22% of Facebook applications and 69% of RenRen applications provide users' personal information to one or more fourth-party tracking entities."
823971,15510,339,ReasONets: a fuzzy-based approach for reasoning on network incidents,2012,"We provide an approach for real-time analysis of ongoing events in a controlled network. We propose ReasONets, i.e. Reasoning on Networks, a distributed and lightweight system, able to process and reason about anomalies and incidents observed in closed net- works. To the best of our knowledge this is the first system combining detections and classification of network events with real-time reasoning. Our demo will show a running prototype of the ReasONets, demonstrating the power and accuracy of the reasoning process in presence of incidents of various nature."
1360305,15510,11330,Curtailing privilege escalation attacks over asynchronous channels on Android,2014,"Abstract—Recently we presented QuantDroid [7], a quantita-tive approach towards mitigating privilege escalation attacks onAndroid. By monitoring all synchronous IPC via overt channelson-the-ﬂy, a so called ﬂow-graph service detects an abnormalamount of tra\u000ec exchanged between DVMs running di erentApps to indicate a potential horizontal privilege escalation attack.However, although certainly a valuable ﬁrst step, our initialQuantDroid approach fails when dealing with asynchronous IPCvia persistent storage containers on the Android system. Toalso address this issue, in this work we extend QuantDroidto QuantDroid ++ by providing i) a central storage of taintswhen operating on system-internal databases of Android, ii) anextension of the SQL cursor object to preserve taints and linkrequested data with such taints, and, ﬁnally iii) an inspectionof the information ﬂow with such newly available taints for allrelevant database operations.Keywords—Android, IPC, Horizontal Privilege Escalation I. IntroductionVulnerability of mobile devices has recently attracted thenews, let it be due to the spying out of Mrs. Merkel’smobile phone, or, Android’s ﬂashlight-App which has beendownloaded more than 50 million times revealing the user’sposition and device identity. Whereas in case of the ﬂashlight-App, at installation time careless users equip the App evenwith permissions not required e.g. for the illumination ofthe mobile’s display, recently we observe more and moresophisticated attacks aiming at an escalation of privilegeson a mobile device. We will see that (horizontal) privilegeescalation is a common problem on mobile operating systems,which, foremost is true for the Android OS.Android is an open-source platform. Due to the tools andAPI provided by Google, one can implement applications(Apps) relatively easy. Thus, also relatively unexercised pro-grammers can create own Apps and publish them in Googleso\u000ecial App market (Google Play). Google does not checkthe qualiﬁcation of the developer. The only requirement isthat Apps are signed with the developers certiﬁcate. That waybug prone or malicious Apps frequently ﬁnd their way ontothe end-users’ mobile devices via Google Play or third partymarkets.Let us assume an App which formats text messages ac-cording to a given proﬁle and displays it in a sorted manner.This App may be used as an alternative approach for the coreShort Message Service (SMS) App. Naturally it would requirethe READ SMS or the RECEIVE SMS permission but not theINTERNET permission. However, as we will see, there are twopossibilities that the SMS Formatter App can pose a securityrisk.Firstly, it could have an exposed component which isnot secured against illegitimate access. A stand alone SMSFormatter widget, which displays the SMS sorted by the SMSFormatter on the home screen, would need access to the SMSdata. The task to verify correct permissions of the requestingApp is handed to the developer of the App. If such a permissioncheck is not executed, nearly any App can access SMS data.To sign an App for its publication, the keystore ﬁle andthe corresponding password are required. If an unauthorizeddeveloper gains access to the certiﬁcate and password, he couldbogusly sign his own Apps. Google explicitly advises to avoidpassing the private key to others since this compromises theidentity of the developer and the trust of the users. However,if the key is stored at an unsafe place, it can be stolen andreused. When using the command line options -storepass  and -keypass   of the keytool, thevalues inserted can be read in the shell history. Thus, anattacker can easily sign his own malicious App with theSMS FORMATTER key and use the same sharedUserId.Moreover we believe that the real threat is what we coinedinsidious trustfulness pretension. An attacker cancreate a useful and successfully operating App which is widelyaccepted and top-rated by the community. Therefore this Apphelps establishing the developer’s trust to the community.If a second, now malicious App is created by the sameApp developer, the attacker can insidiously proﬁt from hisreputation since the new App will at least tried out by thetrusting user base. This is also true for updates of previouslyinstalled and accepted Apps.Such an App could be a task scheduling App whichsynchronizes to a web server. It would only need INTERNETpermission. When this malicious App is also installed on thetarget device running the SMS FORMATTER, it can e ortlesslyaccess all data. If the formatter exchanges data with its stand-alone widget by using Intents, the task scheduler can requestSMS data by Intents too.Also other types of communication channels can be usedto e.g. fetch SMS data. Due to the sharedUserID, the ma-licious App can access the SMS FORMATTER database evenasynchronously at a later point in time without requiring theformatter to run simultaneously. This simple example impres-sively illustrates, how private data like contact information can"
1283644,15510,339,On the foundations of trust in networks of humans and computers,2012,"A general theory of trust in networks of humans and computers must be built on both a theory of behavioral trust and a theory of computational trust. 1  This argument is motivated by increased participation of people in online social networking, crowdsourcing, human computation, and socio-economic protocols; e.g., protocols modeled by trust and gift-exchange games, norms-establishing contracts, and scams/deception. We illustrate a class of interactive social protocols that relies both on trustworthy properties of commodity systems 2  (e.g., verifiable end-to-end trusted path) and participant trust, since on-line verification of protocol compliance is often impractical; e.g., it can lead to undecidable problems, co-NP complete test procedures, and user inconvenience. Trust is captured by participant preferences (i.e., risk and betrayal aversion) and beliefs in the trustworthiness of other protocol participants. Both preferences and beliefs can be enhanced whenever protocol non-compliance leads to punishment of untrustworthy participants; i.e., it seems natural that betrayal aversion can be decreased and belief in trustworthiness increased by properly defined punishment. Similarly, risk aversion can be decreased and trustworthiness increased by feasible recovery from participant non-compliance.   A general theory of trust which focuses on the establishment of new trust relations where none were possible before would help create new economic opportunities. New trust relations would increase the pool of services available to users, remove cooperation barriers, and enable the network effect where it really matters; i.e., at the application level. Hence, it seems important that security research should enable and promote trust-enhancement infrastructures in human and computer networks; e.g., trust networks. Finally, we argue that a general theory of trust should mirror human expectations and mental models without relying on false metaphors and analogies with the physical world.   Virgil D. Gligor received his B.Sc., M.Sc., and Ph.D. degrees from the University of California at Berkeley. He taught at the University of Maryland between 1976 and 2007, and is currently a Professor of Electrical and Computer Engineering at Carnegie Mellon University and co-Director of CyLab. Over the past thirty-five years, his research interests ranged from access control mechanisms, penetration analysis, and denial-of-service protection to cryptographic protocols and applied cryptography. Gligor was an editorial board member of several IEEE and ACM journals, and the Editor in Chief of the IEEE Transactions on Dependable and Secure Computing. He received the 2006 National Information Systems Security Award jointly given by NIST and NSA in the US, and the 2011 Outstanding Innovation Award given by the ACM Special Interest Group on Security, Audit and Control."
59027,15510,9874,Secure Multi-Party Sorting and Applications,2011,"Research within the area of cryptography constitutes the core of this the- sis. In addition to cryptography, we also present results in peer-assisted streaming and web security. We present results on two specific cryptographic problems: broadcast encryption and secure multi-party computation. Broad- cast encryption is the problem of efficiently and securely distributing content to a large and changing group of receivers. Secure multi-party computation is the subject of how a number of parties can collaborate securely. All in all, this thesis spans from systems work discussing the Spotify streaming system with millions of users, to more theoretic, foundational results. Streaming is among the largest applications of the Internet today. On- demand streaming services allow users to consume the media content they want, at their convenience. With the large catalogs offered by many services, users can access a wide selection of content. Live streaming provides the means for corporations as well as individuals to broadcast to the world. The power of such broadcasts was shown in the recent (early 2011) revolts in Tunisia and Egypt, where protesters streamed live from demonstrations. To stream media to a large global audience requires significant resources, in particular in terms of the bandwidth needed. One approach to reduce the requirements is to use peer-to-peer techniques, where clients assist in distributing the media. Spotify is a commercial music-on-demand streaming system, using peer-to-peer streaming. In this thesis, we discuss the Spotify protocol and measurements on its performance. In many streaming systems, it is important to restrict access to content. One approach is to use cryptographic solutions from the area of broadcast encryption. Within this area, we present two results. The first is a protocol which improves the efficiency of previous systems at the cost of lowered secu- rity guarantees. The second contains lower-bound proofs, showing that early protocols in the subset cover framework are essentially optimal. Many streaming systems are web-based, where the user accesses content in a web browser. Apart from this usage of the web, subscriptions for streaming services are bought using a web browser. This means that to provide a secure streaming service, we must understand web security. This thesis contains a result on a new type of attack, using an old history detection vulnerability to time the execution of a redirect of a victim’s browser. Within the area of secure multi-party computation, this thesis has three contributions. Firstly, we give efficient protocols for the basic functions of summation and disjunction which adapt to the network they run on. Secondly, we provide efficient protocols for sorting and aggregation, by using techniques from the area of sorting networks. Finally, we prove a dichotomy theorem, showing that all functions with three distinct outputs are either maximally easy or maximally difficult with regards to the security provided."
1837730,15510,9969,Key-evolution schemes resilient to space-bounded leakage,2011,"Much recent work in cryptography attempts to build secure schemes in the presence of side-channel leakage or leakage caused by malicious software, like computer viruses. In this setting, the adversary may obtain some additional information (beyond the control of the scheme designer) about the internal secret state of a cryptographic scheme. Here, we consider key-evolution schemes that allow a user to evolve a secret-key K1 via a deterministic function f, to get updated keysK2 = f(K1), K3 = f(K2), . . .. Such a scheme is leakage-resilient if an adversary that can leak on the first i steps of the evolution process does not get any useful information about any future keys. For such schemes, one must assume some restriction on the complexity of the leakage to prevent pre-computation attacks, where the leakage on a key Ki simply pre-computes a future key Ki+t and leaks even a single bit on it.#R##N##R##N#Much of the prior work on this problem, and the restrictions made therein, can be divided into two types. Theoretical work offers rigor and provable security, but at the cost of having to make strong restrictions on the type of leakage and designing complicated schemes to make standard reduction-based proof techniques go through (an example of such an assumption is the only computation leaks axiom). On the other hand, practical work focuses on simple and efficient schemes, often at the cost of only achieving an intuitive notion of security without formal well-specified guarantees.#R##N##R##N#In this paper, we complement the two tracks via a middle-of-the-road approach. On one hand, we rely on the random-oracle model. On the other hand, we show that even in the random-oracle model, designing secure leakage-resilient schemes is susceptible to pitfalls. For example, just assuming that leakage cannot evaluate the random oracle can be misleading. Instead, we define a new model in which we assume that the leakage can be any arbitrary space bounded computation that can make random oracle calls itself. We connect the spacecomplexity of a computation in the random-oracle modeling to the pebbling complexity on graphs. Using this connection, we derive meaningful guarantees for relatively simple key-evolution constructions.#R##N##R##N#Our scheme is secure also against a large and natural class of active attacks, where an attacker can leak as well as tamper with the internals of a device. This is especially important if the key evolution is performed on a PC that can be attacked by a virus, a setting considered by prior work in the bounded retrieval model (BRM)). This paper provides the first scheme were the adversary in the BRM can also modify the data stored on the machine."
2096869,15510,339,Constructive and destructive aspects of embedded security in the internet of things,2013,"Through the prevalence of interconnected embedded systems, the vision of pervasive computing has become reality over the last few years. More recently, this evolutionary development has become better known as the Internet of Things. As part of this development, embedded security has become an increasingly important issue in a multitude of applications. Examples include the Stuxnet virus, which has allegedly delayed the Iranian nuclear program, killer applications in the consumer area like iTunes or Amazon's Kindle (the business models of which rely on IP protection) and even medical implants like pace makers and insulin pumps that allow remote configuration. These examples show the destructive and constructive aspects of modern embedded security. In this tutorial we will address both the constructive and penetration testing aspect of embedded security.   In the area of destructive embedded security implementation attacks, also known as physical attacks, are of crucial importance. Whereas a network-borne attacker usually can't exploit the physical environment of an application, embedded devices often allow this. For instance, an attacker can monitor the power or timing behavior of a device. Also she can force the device to malfunction, e.g., through power spikes, and deduct information from faulty outputs. Many systems which are otherwise secure become vulnerable against implementation attacks. In this talk, we will focus on side-channel attacks, or SCA, which form arguably the most powerful method among physical attacks. After developing the mechanics of DPA (differential power analysis), we will look at recent case studies in which real-world implementation were broken using SCA. This includes successful attacks against contactless smart cards and FPGAs.   With respect to constructive aspects of embedded security, we will look at the field of lightweight cryptography. The goal here is to provide security at the lowest possible cost, e.g., measured in power consumption, code size or chip area. Over the last six years or so, this has become a very active area within symmetric cryptography. Very recently, even NSA released two lightweight ciphers, SIMON and SPECK. We will look at the motiviation for such ciphers, e.g., for passive RFID tags or anti-counterfeiting applications. We will then introduce several lightweight constructions and will compare them with AES."
806086,15510,339,Exciting Security Research Opportunity: Next-generation Internet,2014,"The Internet has been successful beyond even the most optimistic expectations. It permeates and intertwines with almost all aspects of our society and economy. The success of the Internet has created a dependency on communication as many of the processes underpinning the foundations of modern society would grind to a halt should communication become unavailable. However, much to our dismay, the current state of safety and availability of the Internet is not commensurate with its importance.   Although we cannot conclusively determine what the impact of a 1-minute, 1-hour, 1-day, or 1-week outage of Internet connectivity on our society would be, anecdotal evidence indicates that even short outages have a profound negative impact on governmental, economic, and societal operations. To make matters worse, the Internet has not been designed for high availability in the face of malicious actions by adversaries. Recent patches to improve Internet security and availability have been constrained by the current Internet architecture, business models, and legal aspects. Moreover, there are fundamental design decisions of the current Internet that inherently complicate secure operation. Given the diverse nature of constituents in today's Internet, another important challenge is how to scale authentication of entities (e.g., AS ownership for routing, name servers for DNS, or domains for TLS) to a global environment. Currently prevalent PKI models (monopoly and oligarchy) do not scale globally because mutually distrusting entities cannot agree on a single trust root, and because everyday users cannot evaluate the trustworthiness of each of the many root CAs in their browsers.   To address these issues, we study the design of a next-generation Internet that is secure, available, and offers privacy by design; that provides appropriate incentives for a transition to the new architecture; and that considers economic and policy issues at the design stage. Such a research environment offers a bonanza for security researchers: a critically important problem space with a medley of challenges to address, and unfettered freedom to think creatively in the absence of limiting constraints. Once we know how good a network could be, we can then engage in incorporating these ideas into the current Internet or study strategies for transition to a next-generation network."
1778391,15510,20754,Chip and Skim: Cloning EMV Cards with the Pre-play Attack,2014,"EMV, also known as Chip and PIN, is the leading system for card payments worldwide. It is used throughout Europe and much of Asia, and is starting to be introduced in North America too. Payment cards contain a chip so they can execute an authentication protocol. This protocol requires point-of-sale (POS) terminals or ATMs to generate a nonce, called the unpredictable number, for each transaction to ensure it is fresh. We have discovered two serious problems: a widespread implementation flaw and a deeper, more difficult to fix flaw with the EMV protocol itself. The first flaw is that some EMV implementers have merely used counters, timestamps or home-grown algorithms to supply this nonce. This exposes them to a pre-play attack which is indistinguishable from card cloning from the standpoint of the logs available to the card-issuing bank, and can be carried out even if it is impossible to clone a card physically. Card cloning is the very type of fraud that EMV was supposed to prevent. We describe how we detected the vulnerability, a survey methodology we developed to chart the scope of the weakness, evidence from ATM and terminal experiments in the field, and our implementation of proof-of-concept attacks. We found flaws in widely-used ATMs from the largest manufacturers. We can now explain at least some of the increasing number of frauds in which victims are refused refunds by banks which claim that EMV cards cannot be cloned and that a customer involved in a dispute must therefore be mistaken or complicit. The second problem was exposed by the above work. Independent of the random number quality, there is a protocol failure: the actual random number generated by the terminal can simply be replaced by one the attacker used earlier when capturing an authentication code from the card. This variant of the pre-play attack may be carried out by malware in an ATM or POS terminal, or by a man-in-the-middle between the terminal and the acquirer. We explore the design and implementation mistakes that enabled these flaws to evade detection until now: shortcomings of the EMV specification, of the EMV kernel certification process, of implementation testing, formal analysis, and monitoring customer complaints. Finally we discuss countermeasures. More than a year after our initial responsible disclosure of these flaws to the banks, action has only been taken to mitigate the first of them, while we have seen a likely case of the second in the wild, and the spread of ATM and POS malware is making it ever more of a threat."
816364,15510,20754,PUFs in Security Protocols: Attack Models and Security Evaluations,2013,"In recent years, PUF-based schemes have not only been suggested for the basic security tasks of tamper sensitive key storage or system identification, but also for more complex cryptographic protocols like oblivious transfer (OT), bit commitment (BC), or key exchange (KE). In these works, so-called Strong PUFs are regarded as a new, fundamental cryptographic primitive of their own, comparable to the bounded storage model, quantum cryptography, or noisebased cryptography. This paper continues this line of research, investigating the correct adversarial attack model and the actual security of such protocols. In its first part, we define and compare different attack models. They reach from a clean, first setting termed the stand-alone, good PUF model to stronger scenarios like the bad PUF model and the PUF re-use model. We argue why these attack models are realistic, and that existing protocols would be faced with them if used in practice. In the second part, we execute exemplary security analyses of existing schemes in the new attack models. The evaluated protocols include recent schemes from Brzuska et al. published at Crypto 2011 [1] and from Ostrovsky et al. [18]. While a number of protocols are certainly secure in their own, original attack models, the security of none of the considered protocols for OT, BC, or KE is maintained in all of the new, realistic scenarios. One consequence of our work is that the design of advanced cryptographic PUF protocols needs to be strongly reconsidered. Furthermore, it suggests that Strong PUFs require additional hardware properties in order to be broadly usable in such protocols: Firstly, they should ideally be erasable, meaning that single PUF-responses can be erased without affecting other responses. If the area efficient implementation of this feature turns out to be difficult, new forms of Controlled PUFs [8] (such as Logically Erasable and Logically Reconfigurable PUFs [13]) may suffice in certain applications. Secondly, PUFs should be certifiable, meaning that one can verify that the PUF has been produced faithfully and has not been manipulated in any way afterwards. The combined implementation of these features represents a pressing and challenging problem, which we pose to the PUF hardware community in this work."
1200138,15510,20754,"Upgrading Your Android, Elevating My Malware: Privilege Escalation through Mobile OS Updating",2014,"Android is a fast evolving system, with new updates coming out one after another. These updates often completely overhaul a running system, replacing and adding tens of thousands of files across Android's complex architecture, in the presence of critical user data and applications (apps for short). To avoid accidental damages to such data and existing apps, the upgrade process involves complicated program logic, whose security implications, however, are less known. In this paper, we report the first systematic study on the Android updating mechanism, focusing on its Package Management Service (PMS). Our research brought to light a new type of security-critical vulnerabilities, called Pileup flaws, through which a malicious app can strategically declare a set of privileges and attributes on a low-version operating system (OS) and wait until it is upgraded to escalate its privileges on the new system. Specifically, we found that by exploiting the Pileup vulnerabilities, the app can not only acquire a set of newly added system and signature permissions but also determine their settings (e.g., protection levels), and it can further substitute for new system apps, contaminate their data (e.g., cache, cookies of Android default browser) to steal sensitive user information or change security configurations, and prevent installation of critical system services. We systematically analyzed the source code of PMS using a program verification tool and confirmed the presence of those security flaws on all Android official versions and over 3000 customized versions. Our research also identified hundreds of exploit opportunities the adversary can leverage over thousands of devices across different device manufacturers, carriers and countries. To mitigate this threat without endangering user data and apps during an upgrade, we also developed a new detection service, called SecUP, which deploys a scanner on the user's device to capture the malicious apps designed to exploit Pileup vulnerabilities, based upon the vulnerability-related information automatically collected from newly released Android OS images."
2558749,15510,11345,"Multi-user Collisions: Applications to Discrete Logarithm, Even-Mansour and PRINCE",2014,"In this paper, we investigate the multi-user setting both in public and in secret-key cryptanalytic applications. In this setting, the adversary tries to recover keys of many users in parallel more efficiently than with classical attacks, i.e., the number of recovered keys multiplied by the time complexity to find a single key, by amortizing the cost among several users. One possible scenario is to recover a single key in a large set of users more efficiently than to recover a key in the classical model. Another possibility is, after some shared precomputation, to be able to learn individual keys very efficiently. This latter model is close to traditional time/memory tradeoff attacks with precomputation. With these goals in mind, we introduce two new algorithmic ideas to improve collision-based attacks in the multi-user setting. Both ideas are derived from the parallelizable collision search as proposed by van Oorschot and Wiener. This collision search uses precomputed chains obtained by iterating some basic function. In our cryptanalytic application, each pair of merging chains can be used to correlate the key of two distinct users. The first idea is to construct a graph, whose vertices are keys and whose edges are these correlations. When the graph becomes connected, we simultaneously recover all the keys. Thanks to random graph analysis techniques, we can show that the number of edges that are needed to make this event occurs is small enough to obtain some improved attacks. The second idea modifies the basic technique of van Oorschot and Wiener: instead of waiting for two chains to merge, we now require that they become parallel.#R##N##R##N#We first show that, using the first idea alone, we can recover the discrete logarithms of $L$ users in a group of size $N$ in time $\tilde{O}(\sqrt{NL})$. We put these two ideas together and we show that in the multi-user Even-Mansour scheme, all the keys of $L=N^{1/3}$ users can be found with $N^{1/3+\epsilon}$ queries for each user (where $N$ is the domain size). Finally, we consider the PRINCE block cipher (with 128-bit keys and 64-bit blocks) and find the keys of 2 users among a set of $2^{32}$ users in time $2^{65}$. We also describe a new generic attack in the classical model for PRINCE."
16210,15510,374,Third-Party Private DFA Evaluation on Encrypted Files in the Cloud,2012,"Motivated by the need to outsource file storage to untrusted clouds while still permitting limited use of that data by third parties, we present practical protocols by which a client (the third-party) can eval- uate a deterministic finite automaton (DFA) on an encrypted file stored at a server (the cloud), once authorized to do so by the file owner. Our protocols provably protect the privacy of the DFA and the file contents from a malicious server and the privacy of the file contents (except for the result of the evaluation) from an honest-but-curious client (and, heuris- tically, from a malicious client). We further present simple techniques to detect client or server misbehavior. Outsourcing file storage to storage service providers (SSPs) and clouds can provide significant savings to file owners in terms of management costs and capital investments. However, because cloud storage can heighten the risk of file disclosure, prudent file owners encrypt their cloud-resident files to protect their confidentiality. This encryption introduces difficulties in managing access to these files by partially trusted third parties, however. Third-party service providers who are contracted to analyze files stored in the cloud generally can- not do so if the files are encrypted. For example, periodically scanning files to detect new malware, as is common today for PC platforms, cannot presently be performed on encrypted files by a third party. Moreover, with some excep- tions (see §2), third-party customers generally cannot search the files if they are encrypted. Searches on genome datasets, pharmaceutical databases, document corpora, or network logs are critical for research in various fields, but the privacy constraints of these datasets may mandate their encryption, particularly when stored in the cloud. These difficulties are compounded when the third party views its queries on the files to be sensitive, as well. New malware signatures may be sensitive since releasing them enables attackers to design malware to evade them (e.g., (37)). Customers of datasets in numerous domains (e.g., pharmaceutical research) may view their research interests, and hence their queries, as private. As a step toward resolving this tension among file protection, search access by authorized third parties, and privacy for third-party queries, in this paper S. Foresti, M. Yung, and F. Martinelli (Eds.): ESORICS 2012, LNCS 7459, pp. 523-540, 2012."
1877199,15510,339,Sedic: privacy-aware data intensive computing on hybrid clouds,2011,"The emergence of cost-effective cloud services offers organizations great opportunity to reduce their cost and increase productivity. This development, however, is hampered by privacy concerns: a significant amount of organizational computing workload at least partially involves sensitive data and therefore cannot be directly outsourced to the public cloud. The scale of these computing tasks also renders existing secure outsourcing techniques less applicable. A natural solution is to split a task, keeping the computation on the private data within an organization's private cloud while moving the rest to the public commercial cloud. However, this hybrid cloud computing is not supported by today's data-intensive computing frameworks, MapReduce in particular, which forces the users to manually split their computing tasks. In this paper, we present a suite of new techniques that make such privacy-aware data-intensive computing possible. Our system, called Sedic, leverages the special features of MapReduce to automatically partition a computing job according to the security levels of the data it works on, and arrange the computation across a hybrid cloud. Specifically, we modified MapReduce's distributed file system to strategically replicate data, moving sanitized data blocks to the public cloud. Over this data placement, map tasks are carefully scheduled to outsource as much workload to the public cloud as possible, given sensitive data always stay on the private cloud. To minimize inter-cloud communication, our approach also automatically analyzes and transforms the reduction structure of a submitted job to aggregate the map outcomes within the public cloud before sending the result back to the private cloud for the final reduction. This also allows the users to interact with our system in the same way they work with MapReduce, and directly run their legacy code in our framework. We implemented Sedic on Hadoop and evaluated it using both real and synthesized computing jobs on a large-scale cloud test-bed. The study shows that our techniques effectively protect sensitive user data, offload a large amount of computation to the public cloud and also fully preserve the scalability of MapReduce."
1187174,15510,9836,An 8-bit AVR-Based Elliptic Curve Cryptographic RISC Processor for the Internet of Things,2012,"In recent years, a large body of research has been dedicated to the 'lightweight' implementation of Elliptic Curve Cryptography (ECC) for RFID tags, wireless sensor nodes, and other 'smart' devices that are supposed to become components of the Internet of Things (IoT). However, making ECC suitable for the IoT is far from trivial since many applications demand fast response times (i.e. high performance), but nonetheless call for small silicon area and low power consumption. We tackle this challenge through hardware/software co-design and introduce an 8-bit Application-Specific Instruction Set Processor (ASIP) that combines the efficiency of a dedicated hardware implementation with the flexibility and scalability of ECC software. Our ASIP is based on JAAVR ('Just Another AVR'), an ATmega128 clone into which we integrated a relatively small (32x4)-bit Multiply- Accumulate (MAC) unit optimized to speed up multi-precision arithmetic. To demonstrate the flexibility of our co-design, we implemented scalar multiplication over four families of elliptic curve, namely a Weierstrass curve, a twisted Edwards curve, a Montgomery curve, and a Gallant-Lambert-Vanstone curve. All curves use a 160-bit Optimal Prime Field (OPF) as underlying algebraic structure, which allows for particularly fast execution of the modular reduction on JAAVR. When using 'native' AVR instructions only, our fastest implementation of scalar multiplication reaches an execution time of less than 4M clock cycles on a conventional ATmega128 processor. Taking advantage of the MAC unit, the time for a full 160-bit scalar multiplication falls below 1M cycles, whereas a 'leakage-reducing' implementation that does not execute any security-critical conditional statements needs some 1.3M cycles. A low-memory variant of the extended JAAVR occupies an area of merely 21k gates, making it suitable for resource-constrained IoT devices like sensor nodes."
2179482,15510,9969,Constructing Confidential Channels from Authenticated Channels--Public-Key Encryption Revisited,2013,"The security of public-key encryption PKE, a widely-used cryptographic primitive, has received much attention in the cryptology literature. Many security notions for PKE have been proposed, including several versions of CPA-security, CCA-security, and non-malleability. These security notions are usually defined via a game that no efficient adversary can win with non-negligible probability or advantage.#R##N##R##N#If a PKE scheme is used in a larger protocol, then the security of this protocol is proved by showing a reduction of breaking a certain security property of the PKE scheme to breaking the security of the protocol. A major problem is that each protocol requires in principle its own tailor-made security reduction. Moreover, which security notion of the PKE scheme should be used in a given context is a priori not evident; the employed games model the use of the scheme abstractly through oracle access to its algorithms, and the sufficiency for specific applications is neither explicitly stated nor proven.#R##N##R##N#In this paper we propose a new approach to investigating the application of PKE, based on the constructive cryptography framework [24,25]. The basic use of PKE is to enable confidential communication from a sender A to a receiver B, assuming A is in possession of B's public key. One can distinguish two relevant cases: The non-confidential communication channel from A to B can be authenticated e.g., because messages are signed or non-authenticated. The application of PKE is shown to provide the construction of a secure channel from A to B from two assumed authenticated channels, one in each direction, or, alternatively, if the channel from A to B is completely insecure, the construction of a confidential channel without authenticity. Composition then means that the assumed channels can either be physically realized or can themselves be constructed cryptographically, and also that the resulting channels can directly be used in any applications that require such a channel. The composition theorem of constructive cryptography guarantees the soundness of this approach, which eliminates the need for separate reduction proofs.#R##N##R##N#We also revisit several popular game-based security notions and variants thereof and give them a constructive semantics by demonstrating which type of construction is achieved by a PKE scheme satisfying which notion. In particular, the necessary and sufficient security notions for the above two constructions to work are CPA-security and a variant of CCA-security, respectively."
2063016,15510,22260,Towards Secure and Effective Utilization over Encrypted Cloud Data,2011,"Cloud computing enables an economic paradigm of data service outsourcing, where individuals and enterprise customers can avoid committing large capital outlays in the purchase and management of both software and hardware and the operational overhead therein. Despite the tremendous benefits, outsourcing data management to the commercial public cloud is also depriving customers' direct control over the systems that manage their data, raising security and privacy as the primary obstacles to the adoption of cloud. Although data encryption helps protecting data confidentiality, it also obsoletes the traditional data utilization service based on plain text keyword search. Thus, enabling an encrypted cloud data search service with privacy-assurance is of paramount importance. Considering the large number of data users and huge amount of outsourced data files in cloud, this problem is particularly challenging as it is extremely difficult to meet also the practical requirements of performance, system usability, and high-level user searching experiences. This paper investigates these challenges and defines the problem of fuzzy keyword search over encrypted cloud data, which should be explored for effective data utilization in Cloud Computing. Fuzzy keyword search aims at accommodating various typos and representation inconsistencies in different user searching input for acceptable system usability and overall user searching experience, while protecting keyword privacy. In order to further enrich the spectrum of secure cloud data utilization services, we also study how the notion of fuzzy search naturally supports similarity search, a fundamental and powerful tool that is widely used in information retrieval. We describe the challenges that are not yet met by existing searchable encryption techniques and discuss the research directions and possible technical approaches for these new search functionalities to become a reality. The investigation of the proposed research can become the key for cloud service providers to securely and effectively deliver value from the cloud infrastructure to their enterprise and individual customers, and thus significantly encourage the adoption of Cloud Computing in a large scale."
645988,15510,9969,"Adaptive and Concurrent Secure Computation from New Adaptive, Non-malleable Commitments",2013,"We present a unified approach for obtaining general secure computation that achieves adaptive-Universally Composable UC-security. Using our approach we essentially obtain all previous results on adaptive concurrent secure computation, both in relaxed models e.g., quasi-polynomial time simulation, as well as trusted setup models e.g., the CRS model, the imperfect CRS model. This provides conceptual simplicity and insight into what is required for adaptive and concurrent security, as well as yielding improvements to set-up assumptions and/or computational assumptions in known models. Additionally, we provide the first constructions of concurrent secure computation protocols that are adaptively secure in the timing model, and the non-uniform simulation model. As a corollary we also obtain the first adaptively secure multiparty computation protocol in the plain model that is secure under bounded-concurrency.#R##N##R##N#Conceptually, our approach can be viewed as an adaptive analogue to the recent work of Lin, Pass and Venkitasubramaniam [STOC '09], who considered only non-adaptive adversaries. Their main insight was that the non-malleability requirement could be decoupled from the simulation requirement to achieve UC-security. A main conceptual contribution of this work is, quite surprisingly, that it is still the case even when considering adaptive security.#R##N##R##N#A key element in our construction is a commitment scheme that satisfies a strong definition of non-malleability. Our new primitive of concurrent equivocal non-malleable commitments, intuitively, guarantees that even when a man-in-the-middle adversary observes concurrent equivocal commitments and decommitments, the binding property of the commitments continues to hold for commitments made by the adversary. This definition is stronger than previous ones, and may be of independent interest. Previous constructions that satisfy our definition have been constructed in setup models, but either require existence of stronger encryption schemes such as CCA-secure encryption or require independent trapdoors provided by the setup for every pair of parties to ensure non-malleability. A main technical contribution of this work is to provide a construction that eliminates these requirements and requires only a single trapdoor."
1358253,15510,9766,Nazca: Detecting Malware Distribution in Large-Scale Networks,2014,"Malware remains one of the most significant secu- rity threats on the Internet. Antivirus solutions and blacklists, the main weapons of defense against these attacks, have only been (partially) successful. One reason is that cyber-criminals take active steps to bypass defenses, for example, by distribut- ing constantly changing (obfuscated) variants of their malware programs, and by quickly churning through domains and IP addresses that are used for distributing exploit code and botnet commands. We analyze one of the core tasks that malware authors have to achieve to be successful: They must distribute and install malware programs onto as many victim machines as possible. A main vec- tor to accomplish this is through drive-by download attacks where victims are lured onto web pages that launch exploits against the users' web browsers and their components. Once an exploit is successful, the injected shellcode automatically downloads and launches the malware program. While a significant amount of previous work has focused on detecting the drive-by exploit step and the subsequent network traffic produced by malware programs, little attention has been paid to the intermediate step where the malware binary is downloaded. In this paper, we study how clients in real-world networks download and install malware, and present Nazca, a system that detects infections in large scale networks. Nazca does not operate on individual connections, nor looks at properties of the downloaded programs or the reputation of the servers hosting them. Instead, it looks at the telltale signs of the malicious network infrastructures that orchestrate these malware installa- tion that become apparent when looking at the collective traffic produced and becomes apparent when looking at the collective traffic produced by many users in a large network. Being content agnostic, Nazca does not suffer from coverage gaps in reputation databases (blacklists), and is not susceptible to code obfuscation. We have run Nazca on seven days of traffic from a large Internet Service Provider, where it has detected previously-unseen malware with very low false positive rates"
2366328,15510,339,AmazonIA: when elasticity snaps back,2011,"Cloud Computing is an emerging technology promising new business opportunities and easy deployment of web services. Much has been written about the risks and benefits of cloud computing in the last years. The literature on clouds often points out security and privacy challenges as the main obstacles, and proposes solutions and guidelines to avoid them. However, most of these works deal with either malicious cloud providers or customers, but ignore the severe threats caused by unaware users.   In this paper we consider security and privacy aspects of real-life cloud deployments, independently from malicious cloud providers or customers. We focus on the popular Amazon Elastic Compute Cloud (EC2) and give a detailed and systematic analysis of various crucial vulnerabilities in publicly available and widely used Amazon Machine Images (AMIs) and show how to eliminate them.   Our Amazon Image Attacks (AmazonIA) deploy an automated tool that uses only publicly available interfaces and makes no assumptions on the underlying cloud infrastructure. We were able to extract highly sensitive information (including passwords, keys, and credentials) from a variety of publicly available AMIs. The extracted information allows to (i) start (botnet) instances worth thousands of dollars per day, (ii) provide backdoors into the running machines, (iii) launch impersonation attacks, or (iv) access the source code of the entire web service. Our attacks can be used to completely compromise several real web services offered by companies (including IT-security companies), e.g., for website statistics/user tracking, two-factor authentication, or price comparison. Further, we show mechanisms to identify the AMI of certain running instances.   Following the maxim security and privacy by design we show how our automated tools together with changes to the user interface can be used to mitigate our attacks."
1812239,15510,20754,Don't Trust Satellite Phones: A Security Analysis of Two Satphone Standards,2012,"There is a rich body of work related to the security aspects of cellular mobile phones, in particular with respect to the GSM and UMTS systems. To the best of our knowledge, however, there has been no investigation of the security of satellite phones (abbr. sat phones). Even though a niche market compared to the G2 and G3 mobile systems, there are several 100,000 sat phone subscribers worldwide. Given the sensitive nature of some of their application domains (e.g., natural disaster areas or military campaigns), security plays a particularly important role for sat phones. In this paper, we analyze the encryption systems used in the two existing (and competing) sat phone standards, GMR-1 and GMR-2. The first main contribution is that we were able to completely reverse engineer the encryption algorithms employed. Both ciphers had not been publicly known previously. We describe the details of the recovery of the two algorithms from freely available DSP-firmware updates for sat phones, which included the development of a custom disassembler and tools to analyze the code, and extending prior work on binary analysis to efficiently identify cryptographic code. We note that these steps had to be repeated for both systems, because the available binaries were from two entirely different DSP processors. Perhaps somewhat surprisingly, we found that the GMR-1 cipher can be considered a proprietary variant of the GSM A5/2 algorithm, whereas the GMR-2 cipher is an entirely new design. The second main contribution lies in the cryptanalysis of the two proprietary stream ciphers. We were able to adopt known A5/2 cipher text-only attacks to the GMR-1 algorithm with an average case complexity of 2 32  steps. With respect to the GMR-2 cipher, we developed a new attack which is powerful in a known-plaintext setting. In this situation, the encryption key for one session, i.e., one phone call, can be recovered with approximately 50-65 bytes of key stream and a moderate computational complexity. A major finding of our work is that the stream ciphers of the two existing satellite phone systems are considerably weaker than what is state-of-the-art in symmetric cryptography."
704848,15510,339,Workshop Summary of AISec'14: 2014 Workshop on Artificial Intelligent and Security,2014,"It is our great pleasure to welcome you to the 2014 ACM Workshop Artificial Intelligence and Security (AISec 2014) -- the seventh annual workshop addressing technologies that fuse intelligent systems into computer security applications and the implications of these approaches. The workshop's aim is to advance research at the intersection of artificial intelligence, machine learning, privacy and security. In particular, AISec gives researchers and practitioners working within one or more of those fields a platform for interdisciplinary discussion, which would otherwise be lacking. Hopefully, the workshop will lead to the initiation of knew col- laborations between groups working across these areas. The papers to be presented in this year's program include topics such as the analysis of privacy, adversarial learning models, intrusion detection and automatic advertisement filtering. We are delighted to again be co-located with the premier ACM Computer and Communication Security (CCS 2014) conference. This year we had 23 submissions from Asia, Europe and North America. This year, the workshop also includes a presentation-only track, for papers appearing elsewhere. After a rigorous reviewing process, 11 original papers were accepted for presentation at the workshop, while one paper was accepted for peresentation only.   Organizing AISec 2014 was a team effort made possible by colleagues from institutions around the world. We sincerely thank the AISec program committee and external reviewers for their invaluable efforts towards guaranteeing a strong program, and the authors of papers who provided us with such excellent material. Their high caliber submissions and the thoughtful feedback from the reviewers continue to ensure the success of the ACM AISec workshop series. Finally, we wish to thank the ACM CCS organizers, for providing us with a suitable forum and for their continued support of this workshop. We believe that the workshop program will be interesting not only for researchers working in the field, but also for practitioners and academics in other areas in security. We look forward to seeing you all in Scottsdale, Arizona this year."
925420,15510,339,Cryptographic primitives for building secure and privacy respecting protocols,2011,"Using the Internet and other electronic media for our daily tasks has become common. Thereby a lot of sensitive information is exchanged, processed, and stored at many different laces. Once released, controlling the dispersal of this information is virtually impossible. Worse, the press reports daily on incidents where sensitive information has been lost, stolen, or misused - often involving large and reputable organizations. Privacy-enhancing technologies can help to minimize the amount of information that needs to be revealed in transactions, on the one hand, and to limit the dispersal, on the other hand. Many of these technologies build on common cryptographic primitives that allow for data to be authenticated and encrypted in such a way that it is possible to efficiently prove possession and/or properties of data revealing the data or side-information about it. Proving such statements is of course possible for any signature and encryption scheme. However, if the result is to be practical, special cryptographic primitives and proof protocols are needed.   In this talk we will first consider a few example scenarios and motivate the need for such cryptograph building block before we then present and discuss these. We start with efficient discrete logarithms based proof protocols often referred to as generalized Schnorr proofs. They allow one to prove knowledge of different discrete logarithms (exponents) and relations among them. Now, to be able to prove possession of a (valid) signature and a message with generalized Schnorr proofs, it is necessary that the signature and the message signed are exponents and that no hash-function is used in the signature verification. Similarly, for encryption schemes, the plain text needs to be an exponent. We will present and discuss a number of such signature and encryption schemes.   To show the power of these building blocks, we will consider a couple of example protocols such as anonymous access control and anonymous polling. We then conclude with a discussion on security definition and proofs. We hope that the presented building blocks will enable many new privacy-preserving protocols and and applications in the future."
2302124,15510,339,How to Use Bitcoin to Incentivize Correct Computations,2014,"We study a model of incentivizing correct computations in a variety of cryptographic tasks. For each of these tasks we propose a formal model and design protocols satisfying our model's constraints in a hybrid model where parties have access to special ideal functionalities that enable monetary transactions. We summarize our results:    Verifiable computation.  We consider a setting where a delegator outsources computation to a worker who expects to get paid in return for delivering correct outputs. We design protocols that compile both public and private verification schemes to support incentivizations described above.    Secure computation with restricted leakage.  Building on the recent work of Huang et al. (Security and Privacy 2012), we show an efficient secure computation protocol that monetarily penalizes an adversary that attempts to learn one bit of information but gets detected in the process.     Fair secure computation.  Inspired by recent work, we consider a model of secure computation where a party that aborts after learning the output is monetarily penalized. We then propose an ideal transaction functionality  F  ML  and show a constant-round realization on the Bitcoin network. Then, in the  F  ML -hybrid world we design a constant round protocol for secure computation in this model.     Noninteractive bounties.  We provide formal definitions and candidate realizations of noninteractive bounty mechanisms on the Bitcoin network which (1) allow a bounty maker to place a bounty for the solution of a hard problem by sending a single message, and (2) allow a bounty collector (unknown at the time of bounty creation) with the solution to claim the bounty, while (3) ensuring that the bounty maker can learn the solution whenever its bounty is collected, and (4) preventing malicious eavesdropping parties from both claiming the bounty as well as learning the solution.     All our protocol realizations (except those realizing fair secure computation) rely on a special ideal functionality that is not currently supported in Bitcoin due to limitations imposed on Bitcoin scripts. Motivated by this, we propose validation complexity of a protocol, a formal complexity measure that captures the amount of computational effort required to validate Bitcoin transactions required to implement it in Bitcoin. Our protocols are also designed to take advantage of optimistic scenarios where participating parties behave honestly."
1016257,15510,339,"The science, engineering and business of cyber security",2013,"I will use the rare opportunity of this keynote talk to give my perspective on the general state and future prospects for cyber security, and the consequences of this perspective with respect to cyber security research and education. The ambiguous status of computer science in modern academia has persisted through the thirty plus years of my career. Does it belong in the College of Science or the College of Engineering? How about the College of Business? Is it worthy of a separate College of its own? I believe this ambiguity is a manifestation of the fundamental difference between computer science relative to traditional sciences and engineering disciplines. The forces of science, engineering and business come together and reconcile in a particularly unique way in computer science, and within computer science cyber security brings additional peculiarities to this reconciliation.   My outlook on cyber security is generally optimistic. I believe at the consumer level market and social forces will drive developed societies to a relatively low assurance of security and privacy analogous to the current state of internet security. The large-scale adoption of internet services across diverse global populations is one indicator that the average consumer is reasonably comfortable with the collateral risks. But nothing is automatic, so social organization will be required to compensate for the intrusions of big government and big business which may turn out to be the much bigger problem than big crime. At the same time I share the concern of many senior national security officials and thought leaders on the increasingly grave threat of cyberwar and cyberterrorism. The US Department of Defense has publicly recognized cyberspace as a man-made domain on par with land, sea, air and space within which wars will be conducted and facilitated. Many other nations and militaries are preparing offensive and defensive cyber capabilities.   My talk will elaborate on these notions and seek to glean some lessons for cyber security researchers."
1729931,15510,339,Towards mechanisms for detection and prevention of data exfiltration by insiders: keynote talk paper,2011,"Data represent an extremely important asset for any organization. Confidential data such as military secrets or intellectual property must never be disclosed outside the organization. Therefore, one of the most severe threats in the case of cyber-insider attacks is the loss of confidential data due to  exfiltration . A malicious insider who has the proper credentials to access the organization databases may, over time, send data outside the organization network through a variety of channels, such as email, crafted HTTP requests that encapsulate data, etc. Existing security tools for detection of cyber-attacks focus on protecting the boundary between the organization and the outside world. Numerous network-level intrusion detection systems (IDS) exist, which monitor the traffic pattern and attempt to infer anomalous behavior. While such tools may be effective in protecting against external attacks, they are less suitable when the data exfiltration is performed by an insider who has the proper credentials and authorization to access resources within the organization. In this paper, we argue that DBMS-layer detection and prevention systems are the best alternative to defend against data exfiltration because: (1) DBMS access is performed through a standard, unique language (SQL) with well-understood semantics; (2) monitoring the potential disclosure of confidential data is more effective if done as close as possible to the data source; and (3) the DBMS layer already has in place a thorough mechanism for enforcing access control based on subject credentials. By analyzing the pattern of interaction between subjects and the DBMS, it is possible to detect anomalous activity that is indicative of early signs of exfiltration. In the paper, we outline a taxonomy of cyber-insider dimensions of activities that are indicative of data exfiltration, and we discuss a high-level architecture and mechanisms for early detection of exfiltration by insiders. We also outline a virtualization-based mechanism that prevents insiders from exfiltrating data, even in the case when they manage to gain control over the network. The protection mechanism relies on explicit authorization of data transfers that cross the organizational boundary."
1544957,15510,9766,Breaking and Fixing Origin-Based Access Control in Hybrid Web/Mobile Application Frameworks.,2014,"Hybrid mobile applications (apps) combine the features of Web applications and “native” mobile apps. Like Web applications, they are implemented in portable, platform-independent languages such as HTML and JavaScript. Like native apps, they have direct access to local device resources—file system, location, camera, contacts, etc.#R##N##R##N#Hybrid apps are typically developed using hybrid application frameworks such as PhoneGap. The purpose of the framework is twofold. First, it provides an embedded Web browser (for example, WebView on Android) that executes the app's Web code. Second, it supplies “bridges” that allow Web code to escape the browser and access local resources on the device.#R##N##R##N#We analyze the software stack created by hybrid frameworks and demonstrate that it does not properly compose the access-control policies governing Web code and local code, respectively. Web code is governed by the same origin policy, whereas local code is governed by the access-control policy of the operating system (for example, user-granted permissions in Android). The bridges added by the framework to the browser have the same local access rights as the entire application, but are not correctly protected by the same origin policy. This opens the door to fracking attacks, which allow foreign-origin Web content included into a hybrid app (e.g., ads confined in iframes) to drill through the layers and directly access device resources. Fracking vulnerabilities are generic: they affect all hybrid frameworks, all embedded Web browsers, all bridge mechanisms, and all platforms on which these frameworks are deployed.#R##N##R##N#We study the prevalence of fracking vulnerabilities in free Android apps based on the PhoneGap framework. Each vulnerability exposes sensitive local resources—the ability to read and write contacts list, local files, etc.—to dozens of potentially malicious Web domains. We also analyze the defenses deployed by hybrid frameworks to prevent resource access by foreign-origin Web content and explain why they are ineffectual.#R##N##R##N#We then present NoFrak, a capability-based defense against fracking attacks. NoFrak is platform-independent, compatible with any framework and embedded browser, requires no changes to the code of the existing hybrid apps, and does not break their advertising-supported business model."
2583506,15510,20592,Mimesis aegis: a mimicry privacy shield a system's approach to data privacy on public cloud,2014,"Users are increasingly storing, accessing, and exchanging data through public cloud services such as those provided by Google, Facebook, Apple, and Microsoft. Although users may want to have faith in cloud providers to provide good security protection, the confidentiality of any data in public clouds can be violated, and consequently, while providers may not be doing evil, we can not and should not trust them with data confidentiality.#R##N##R##N#To better protect the privacy of user data stored in the cloud, in this paper we propose a privacy-preserving system called Mimesis Aegis (M-Aegis) that is suitable for mobile platforms. M-Aegis is a new approach to user data privacy that not only provides isolation but also preserves the user experience through the creation of a conceptual layer called Layer 7.5 (L-7.5), which is interposed between the application (OSI Layer 7) and the user (Layer 8). This approach allows M-Aegis to implement true end-to-end encryption of user data with three goals in mind: 1) complete data and logic isolation from untrusted entities; 2) the preservation of original user experience with target apps; and 3) applicable to a large number of apps and resilient to app updates.#R##N##R##N#In order to preserve the exact application workflow and look-and-feel, M-Aegis uses L-7.5 to put a transparent window on top of existing application GUIs to both intercept plaintext user input before transforming the input and feeding it to the underlying app, and to reverse-transform the output data from the app before displaying the plaintext data to the user. This technique allows M-Aegis to transparently integrate with most cloud services without hindering usability and without the need for reverse engineering. We implemented a prototype of M-Aegis on Android and show that it can support a number of popular cloud services, e.g. Gmail, Facebook Messenger, WhatsApp, etc.#R##N##R##N#Our performance evaluation and user study show that users incur minimal overhead when adopting M-Aegis on Android: imperceptible encryption/decryption latency and a low and adjustable false positive rate when searching over encrypted data."
2164935,15510,9856,CPS: beyond usability: applying value sensitive design based methods to investigate domain characteristics for security for implantable cardiac devices,2014,"Wireless implantable medical devices (IMDs) are cyber-physical systems that deliver life-saving treatments to cardiac patients with dangerous heart conditions. Current access control models for these systems are insufficient; more security is necessary. In response to this problem, the technical security community has investigated new directions for improving security on these resource-constrained devices. Defenses, however, must not only be technically secure; in order to be deployable, defenses must be designed to work within the needs and constraints of their relevant application spaces. Designing for an application space---particularly a specialized one---requires a deep understanding of the stakeholders, their values, and the contexts of technology usage. Grounding our work in value sensitive design (VSD), we collaborated as an interdisciplinary team to conduct three workshops with medical providers for the purpose of gathering their values and perspectives. The structure of our workshop builds on known workshop structures within the human-computer interaction (HCI) community, and the number of participants in our workshops (N=24) is compatible with current practices for inductive, exploratory studies. We present results on: what the participants find important with respect to providing care and performing their jobs; their reactions to potential security system concepts; and their views on what security system properties should be sought or avoided due to side effects within the context of their work practice. We synthesize these results, use the results to articulate design considerations for future technical security systems, and suggest directions for further research. Our research not only provides a contribution to security research for an important class of cyber-physical systems (IMDs); it also provides an example of leveraging techniques from other communities to better explore the landscape of security designs for technologies."
1584543,15510,339,Scanner hunter: understanding HTTP scanning traffic,2014,"This paper focuses on detecting and studying HTTP scanners, which are malicious entities that explore a website selectively for opportunities that can potentially be used for subsequent intrusion attempts. Interestingly, there is practically no prior work on the detection of these entities, which are different from web crawlers or machines performing network-level reconnaissance activities such as port scanning. Detecting HTTP scanners is challenging as they are stealthy and often only probe a few key places on a website, so finding them is a needle-in-the-haystack problem. At the same time, they pose serious risk because they perform the first, exploratory step to provide the seed information that may allow hackers to compromise a website. Our work makes two main contributions. First, we propose Scanner Hunter, arguably the first method to detect HTTP scanners efficiently. The novelty and success of the method lies in the use of community structure, in an appropriately constructed bipartite graph, in order to expose groups of HTTP scanners. The rationale is that the aggregated behavior makes identifying groups of scanners easier than attempting to profile and label IP addresses individually. Scanner Hunter achieves an impressive 96.5% detection precision, which is roughly twice as high as the precision of the Machine Learning-based methods that we use as reference. Second, we provide an extensive study of HTTP scanners in an effort to understand: (a) their spatial and temporal properties, (b) the techniques and tools used by the scanners, and (c) the types of resources they are looking for, which can provides hints as to what the subsequent penetration attempt may target. We use six months worth of web traffic logs collected in 2012 from a University campus, the websites hosted by which received over 1.9 billion requests from 12.8 million IPs. We found that the number of HTTP scanners is non-trivial with roughly 4,000 IPs engaging in this type of activity per week. Our work will hopefully raise the awareness of the community regarding this problem while at the same time provide a promising detection technique that can provide the basis for mitigating the risk posed by HTTP scanners."
1072527,15510,339,"Poster: fast, automatic iPhone shoulder surfing",2011,"Touchscreen devices increase the risk of shoulder surfing to such an extent that attackers could steal sensitive information by simply following the victim and observe his or her portable device. We underline this concern by proposing an automatic shoulder surfing attack against modern touchscreen keyboards that display magnified keys in predictable positions. We demonstrate this attack against the Apple iPhone - although it can work with other layouts and different devices - and show that it recognizes up to 97.07% (91.03% on average) of the keystrokes, with only 1.15% of errors, at 37 to 51 keystrokes per minute: About eight times faster than a human analyzing a recorded video. Our attack, described thoroughly in [2], accurately recovers the sequence of keystrokes input by the user. The attack described in [1], which targeted desktop scenarios and thus worked with very restrictive settings, is similar in spirit to ours. However, as it assumes that camera and target keyboard are both in fixed, perpendicular position, it cannot suite mobile settings, characterized by moving target and skewed, rotated viewpoints. Our attack, instead, requires no particular settings and even allows for natural movements of both target device and shoulder surfer's camera. In addition, our attack yields accurate output without any grammar or syntax checks, so that it can detect large context-free text or non-dictionary words.   In summary: - We are the first studying the practical risks brought forth by mainstream touchscreen keyboards. - We design a practical attack that detects keystrokes on modern touchscreen keyboards: The attacker requires not to stand exactly behind the victim nor to observe the screen perpendicularly. Our attack is robust to occlusions (eg, typing fingers), thanks to our efficient filtering technique that validates detected keys and reconstructs keystroke sequences accurately."
2483354,15510,9969,Order-preserving encryption revisited: improved security analysis and alternative solutions,2011,"We further the study of order-preserving symmetric encryption (OPE), a primitive for allowing efficient range queries on encrypted data, recently initiated (from a cryptographic perspective) by Boldyreva et al. (Eurocrypt'09). First, we address the open problem of characterizing what encryption via a random order-preserving function (ROPF) leaks about underlying data (ROPF being the ideal object in the security definition, POPF, satisfied by their scheme.) In particular, we show that, for a database of randomly distributed plaintexts and appropriate choice of parameters, ROPF encryption leaks neither the precise value of any plaintext nor the precise distance between any two of them. The analysis here is quite technically non-trivial and introduces useful new techniques. On the other hand, we also show that ROPF encryption does leak both the value of any plaintext as well as the distance between any two plaintexts to within a range of possibilities roughly the square root of the domain size. We then study schemes that are not order-preserving, but which nevertheless allow efficient range queries and achieve security notions stronger than POPF. In a setting where the entire database is known in advance of key-generation (considered in several prior works), we show that recent constructions of monotone minimal perfect hash functions allow to efficiently achieve (an adaptation of) the notion of IND-O(rdered) CPA also considered by Boldyreva et al., which asks that only the order relations among the plaintexts is leaked. Finally, we introduce modular order-preserving encryption (MOPE), in which the scheme of Boldyreva et al. is prepended with a shift cipher. MOPE improves the security of OPE in a sense, as it does not leak any information about plaintext location. We clarify that our work should not be interpreted as saying the original scheme of Boldyreva et al., or the variants that we introduce, are secure or insecure. Rather, the goal of this line of research is to help practitioners decide whether the options provide a suitable security-functionality tradeoff for a given application."
1387118,15510,20754,The Science of Guessing: Analyzing an Anonymized Corpus of 70 Million Passwords,2012,"We report on the largest corpus of user-chosen passwords ever studied, consisting of anonymized password histograms representing almost 70 million Yahoo! users, mitigating privacy concerns while enabling analysis of dozens of subpopulations based on demographic factors and site usage characteristics. This large data set motivates a thorough statistical treatment of estimating guessing difficulty by sampling from a secret distribution. In place of previously used metrics such as Shannon entropy and guessing entropy, which cannot be estimated with any realistically sized sample, we develop partial guessing metrics including a new variant of guesswork parameterized by an attacker's desired success rate. Our new metric is comparatively easy to approximate and directly relevant for security engineering. By comparing password distributions with a uniform distribution which would provide equivalent security against different forms of guessing attack, we estimate that passwords provide fewer than 10 bits of security against an online, trawling attack, and only about 20 bits of security against an optimal offline dictionary attack. We find surprisingly little variation in guessing difficulty; every identifiable group of users generated a comparably weak password distribution. Security motivations such as the registration of a payment card have no greater impact than demographic factors such as age and nationality. Even proactive efforts to nudge users towards better password choices with graphical feedback make little difference. More surprisingly, even seemingly distant language communities choose the same weak passwords and an attacker never gains more than a factor of 2 efficiency gain by switching from the globally optimal dictionary to a population-specific lists."
1167335,15510,20754,Framing Signals - A Return to Portable Shellcode,2014,"Signal handling has been an integral part of UNIX systems since the earliest implementation in the 1970s. Nowadays, we find signals in all common flavors of UNIX systems, including BSD, Linux, Solaris, Android, and Mac OS. While each flavor handles signals in slightly different ways, the implementations are very similar. In this paper, we show that signal handling can be used as an attack method in exploits and backdoors. The problem has been a part of UNIX from the beginning, and now that advanced security measures like ASLR, DEP and stack cookies have made simple exploitation much harder, our technique is among the lowest hanging fruit available to an attacker. Specifically, we describe Sigreturn Oriented Programming (SROP), a novel technique for exploits and backdoors in UNIX-like systems. Like return-oriented programming (ROP), sigreturn oriented programming constructs what is known as a 'weird machine' that can be programmed by attackers to change the behavior of a process. To program the machine, attackers set up fake signal frames and initiate returns from signals that the kernel never really delivered. This is possible, because UNIX stores signal frames on the process' stack. Sigreturn oriented programming is interesting for attackers, OS developers and academics. For attackers, the technique is very versatile, with pre-conditions that are different from those of existing exploitation techniques like ROP. Moreover, unlike ROP, sigreturn oriented programming programs are portable. For OS developers, the technique presents a problem that has been present in one of the two main operating system families from its inception, while the fixes (which we also present) are non-trivial. From a more academic viewpoint, it is also interesting because we show that sigreturn oriented programming is Turing complete. We demonstrate the usefulness of the technique in three applications. First, we describe the exploitation of a vulnerable web server on different Linux distributions. Second, we build a very stealthy proof-of-concept backdoor. Third, we use SROP to bypass Apple's code signing and security vetting process by building an app that can execute arbitrary system calls. Finally, we discuss mitigation techniques."
2805793,15510,9969,"Substitution-Permutation Networks, Pseudorandom Functions, and Natural Proofs",2012,"This paper takes a new step towards closing the troubling gap between pseudorandom functions PRF and their popular, bounded-input-length counterparts. This gap is both quantitative, because these counterparts are more efficient than PRF in various ways, and methodological, because these counterparts usually fit in the substitution-permutation network paradigm SPN which has not been used to construct PRF.#R##N##R##N#We give several candidate PRF $$\mathcal {F}_i$$ that are inspired by the SPN paradigm. This paradigm involves a substitution function S-box. Our main candidates are:#R##N##R##N#$$\mathcal {F}_1 : \{0, 1\}^n \rightarrow \{0, 1\}^n$$ is an SPN whose S-box is a random function on b bits given as part of the seed. We prove unconditionally that $$\mathcal {F}_1$$ resists attacks that run in time $$\le 2^{\epsilon b}$$. Setting $$b = \omega \lg n$$ we obtain an inefficient PRF, which however seems to be the first such construction using the SPN paradigm.#R##N##R##N#$$\mathcal {F}_2 : \{0, 1\}^n \rightarrow \{0, 1\}^n$$ is an SPN where the S-box is patched field inversion, a common choice in practical constructions. $$\mathcal {F}_2$$ is computable with Boolean circuits of size $$n \cdot \log ^{O1} n$$, and in particular with seed length $$n \cdot \log ^{O1} n$$. We prove that this candidate has exponential security $$2^{\Omega n}$$ against linear and differential cryptanalysis.#R##N##R##N#$$\mathcal {F}_3 : \{0, 1\}^n \rightarrow \{0, 1\}$$ is a non-standard variant on the SPN paradigm, where states grow in length. $$\mathcal {F}_3$$ is computable with size $$n^{1+\epsilon }$$, for any $$\epsilon > 0$$, in the restricted circuit class $$\mathrm {TC}^0$$ of unbounded fan-in majority circuits of constant-depth. We prove that $$\mathcal {F}_3$$ is almost 3-wise independent.#R##N##R##N#$$\mathcal {F}_4 : \{0, 1\}^n \rightarrow \{0, 1\}$$ uses an extreme setting of the SPN parameters one round, one S-box, no diffusion matrix. The S-box is again patched field inversion. We prove that this candidate fools all parity tests that look at $$\le 2^{0.9n}$$ outputs.#R##N##R##N#Assuming the security of our candidates, our work also narrows the gap between the Natural Proofs barrier [Razborov & Rudich; JCSS '97] and existing lower bounds, in three models: unbounded-depth circuits, $$\mathrm {TC}^0$$ circuits, and Turing machines. In particular, the efficiency of the circuits computing $$\mathcal {F}_3$$ is related to a result by Allender and Koucky [JACM '10] who show that a lower bound for such circuits would imply a lower bound for $$\mathrm {TC}^0$$."
406623,15510,20592,From throw-away traffic to bots: detecting the rise of DGA-based malware,2012,"Many botnet detection systems employ a blacklist of known command and control (C&C) domains to detect bots and block their traffic. Similar to signature-based virus detection, such a botnet detection approach is static because the blacklist is updated only after running an external (and often manual) process of domain discovery. As a response, botmasters have begun employing domain generation algorithms (DGAs) to dynamically produce a large number of random domain names and select a small subset for actual C&C use. That is, a C&C domain is randomly generated and used for a very short period of time, thus rendering detection approaches that rely on static domain lists ineffective. Naturally, if we know how a domain generation algorithm works, we can generate the domains ahead of time and still identify and block bot-net C&C traffic. The existing solutions are largely based on reverse engineering of the bot malware executables, which is not always feasible.#R##N##R##N#In this paper we present a new technique to detect randomly generated domains without reversing. Our insight is that most of the DGA-generated (random) domains that a bot queries would result in Non-Existent Domain (NXDomain) responses, and that bots from the same bot-net (with the same DGA algorithm) would generate similar NXDomain traffic. Our approach uses a combination of clustering and classification algorithms. The clustering algorithm clusters domains based on the similarity in the make-ups of domain names as well as the groups of machines that queried these domains. The classification algorithm is used to assign the generated clusters to models of known DGAs. If a cluster cannot be assigned to a known model, then a new model is produced, indicating a new DGA variant or family. We implemented a prototype system and evaluated it on real-world DNS traffic obtained from large ISPs in North America. We report the discovery of twelve DGAs. Half of them are variants of known (botnet) DGAs, and the other half are brand new DGAs that have never been reported before."
917462,15510,20754,Blind Seer: A Scalable Private DBMS,2014,"Query privacy in secure DBMS is an important feature, although rarely formally considered outside the theoretical community. Because of the high overheads of guaranteeing privacy in complex queries, almost all previous works addressing practical applications consider limited queries (e.g., just keyword search), or provide a weak guarantee of privacy. In this work, we address a major open problem in private DB: efficient sub linear search for arbitrary Boolean queries. We consider scalable DBMS with provable security for all parties, including protection of the data from both server (who stores encrypted data) and client (who searches it), as well as protection of the query, and access control for the query. We design, build, and evaluate the performance of a rich DBMS system, suitable for real-world deployment on today medium-to large-scale DBs. On a modern server, we are able to query a formula over 10TB, 100M-record DB, with 70 searchable index terms per DB row, in time comparable to (insecure) MySQL (many practical queries can be privately executed with work 1.2-3 times slower than MySQL, although some queries are costlier). We support a rich query set, including searching on arbitrary boolean formulas on keywords and ranges, support for stemming, and free keyword searches over text fields. We identify and permit a reasonable and controlled amount of leakage, proving that no further leakage is possible. In particular, we allow leakage of some search pattern information, but protect the query and data, provide a high level of privacy for individual terms in the executed search formula, and hide the difference between a query that returned no results and a query that returned a very small result set. We also support private and complex access policies, integrated in the search process so that a query with empty result set and a query that fails the policy are hard to tell apart."
1205385,15510,23634,Stateless Cryptographic Protocols,2011,"Secure computation protocols inherently involve multiple rounds of interaction among the parties where, typically a party has to keep a state about what has happened in the protocol so far and then \emph{wait} for the other party to respond. We study if this is inherent. In particular, we study the possibility of designing cryptographic protocols where the parties can be completely stateless and compute the outgoing message by applying a single fixed function to the incoming message (independent of any state). The problem of designing stateless secure computation protocols can be reduced to the problem of designing protocols satisfying the notion of reset table computation introduced by Canetti, Goldreich, Gold wasser and Micali (FOCS'01) and widely studied thereafter. The current start of art in reset table computation allows for construction of protocols which provide security only when a \emph{single predetermined} party is reset table \cite{GoyalSa09}. An exception is for the case of the zero-knowledge functionality for which a protocol in which both parties are reset table was recently obtained by Deng, Goyal and Sahai (FOCS'09). The fundamental question left open in this sequence of works is, whether fully-reset table computation is possible, when:\begin{enumerate}\item An adversary can corrupt any number of parties, and\item The adversary can reset any party to its original state during the execution of the protocol and can restart the protocol. \end{enumerate}In this paper, we resolve the above problem by constructing secure protocols realizing \emph{any} efficiently computable multi-party functionality in the plain model under standard cryptographic assumptions. First, we construct a Fully-Reset table Simulation Sound Zero-Knowledge (ss-rs-rZK) protocol. Next, based on these ss-rs-rZK protocols, we show how to compile any semi-honest secure protocol into a protocol secure against fully resetting adversaries. Next, we study a seemingly unrelated open question: ``Does there exist a functionality which, in the concurrent setting, is impossible to securely realize using BB simulation but can be realized using NBB simulation ? & quot;. We resolve the above question in the affirmative by giving an example of such a (reactive) functionality. Somewhat surprisingly, this is done by making a connection to the existence of a fully reset table simulation sound zero-knowledge protocol."
1596020,15510,339,Reflections on the evolution of internet threats: the growing imperative for a cyber secure society,2011,"Critical infrastructure, including the Internet, plays a vital role in the economic, political, and social fabric of society. This interdependency leaves society vulnerable to a wide range of threats that impact the security, reliability, availability, and overall trustworthiness of information technology resources. Assuring these properties in the face of adversarial behavior and an Internet that has changed dramatically in size, complexity, and diversity over the last decade has proven to be a critical challenge. In this talk, I will reflect on the evolution of Internet threats - from early threats, such as viruses and worms, to modern botnets. I will explore how changing attacker's technological means (e.g., resilient infrastructure, covert communication) have intertwined with attacker's changing social, behavioral, and economic motives (e.g., vandalism, crime, activism) to create today's large, complex, and diverse ecosystem of threats. I will also touch on how future innovation in the threat landscape will likely be driven by Internet adoption patterns such as the explosive growth of on-line data, the proliferation of mobile devices, and the emergence of the cloud computing paradigm.   In response to these challenges, I will discuss the need for sustained, long-term research investments in a spectrum of scientific and technical areas with particular emphasis on calls to develop the scientific foundations of cyber-security and to accelerate the transition of knowledge into practice. I will articulate a vision in which a cyber secure society is necessary if we are to achieve the promise of computing to address a wide range of national priorities including health, energy, transportation, education and life-long learning, and public safety/emergency preparedness."
1228270,15510,22260,ImageElves: Rapid and Reliable System Updates in the Cloud,2013,"Virtualization has significantly reduced the cost of creating a new virtual machine and cheap storage allows VMs to be turned down when unused. This has led to a rapid proliferation of virtual machine images, both active and dormant, in the data center. System management technologies have not been able to keep pace with this growth and the management cost of keeping all virtual machines images, active as well as dormant, updated is significant. In this work, we present ImageElves, a system to rapidly, reliably and automatically propagate updates (e.g., patches, software installs, compliance checks) in a data center. ImageElves analyses all target images and creates reliable image patches using a very small number of online updates. Traditionally, updates are applied by taking the application offline, applying updates, and then restoring the application, a process that is unreliable and has an unpredictable downtime. With ImageElves, we propose a two phase process. In the first phase, images are analyzed to create an update signature and update manifest. In the second phase, downtime is taken and the manifest is applied offline on virtual images in a parallel, reliable and automated manner. This has two main advantages, (i) spontaneously apply updates to already dormant VMs, and (ii) all updates following this process are guaranteed to work reliably leading to reduced and predictable downtimes. ImageElves uses three key ideas: (i) a novel per-update profiling mechanism to divide VMs into equivalence classes, (ii) a background logging mechanism to convert updates on live instances into patches for dormant images, and (iii) a cross-difference mechanism to filter system-specific or random information (e.g., host name, IP address), while creating equivalence classes. We evaluated the ability of ImageElves to speed up mix of popular system management activities and observed upto 80% smaller update times for active instances and upto 90% reduction in update time for dormant instances."
1305111,15510,8228,Using multiscale traffic analysis to detect WPS attacks,2013,"The worldwide adoption of the IEEE 802.11 standard as the solution to provide efficient network coverage with high data-rates raised several security concerns. In a first stage, Wired Equivalent Privacy (WEP) was used to protect wireless networks from intrusions, whose main motivations ranged from simply getting free Internet access to the perpetration of complex attacks in order to retrieve confidential information. However, due to multiple technical flaws, this approach was not sufficient, leading to the emergence of the Wi-Fi Protected Access (WPA) and WPA2 technologies, which provided more secure mechanisms at the cost of requiring more complicated configuration tasks. In order to create a simple configuration interface, the Wi-Fi Alliance proposed a simple configuration approach: the Wi-Fi Protected Setup (WPS), which is used by major network products manufacturers and provides a much easier configuration setup, although in a less efficient security environment. Actually, this implementation is vulnerable to brute force attacks, which are very quick to execute, have little complexity and are difficult to detect. After cracking WPS, attackers can access to WPA/WPA2 login information and illicitly connect to the target wireless network. There are several technical requirements and legal constrains that limit access to the contents of wireless frames, thus preventing their deep analysis. This paper presents a method to detect attacks over WPA-enabled routers with Wi-Fi Protected Setup, based only on the amount of generated traffic. The detection methodology uses a monitoring station that exclusively analyzes traffic flows from the router: by monitoring traffic and using a multiscale analysis procedure, the approach is able to accurately identify each intrusion attempt."
50673,15510,9969,Succinct Arguments from Multi-prover Interactive Proofs and Their Efficiency Benefits,2012,"Succinct arguments of knowledge are computationally-sound proofs of knowledge for NP where the verifier's running time is independent of the time complexity of the NP nondeterministic machine for the considered language.#R##N##R##N#Existing succinct argument constructions are, typically, based on techniques that combine cryptographic hashing and probabilistically-checkable proofs PCPs, and thus, in light of today's state-of-the-art PCP technology, are quite inefficient: either one uses long PCP proofs with lots of redundancy to make the verifier fast but at the cost of making the prover slow, or one uses short PCP proofs to make the prover fast but at the cost of making the verifier slow.#R##N##R##N#To obtain better efficiency, we propose to investigate the alternative approach of constructing succinct arguments based on multi-prover interactive proofs MIPs and stronger cryptographic techniques:#R##N##R##N#1 We construct a one-round succinct MIP of knowledge protocol where i each prover is highly efficient in terms of time AND space, and ALSO ii the verifier is highly efficient.#R##N##R##N#2 We show how to transform any one round MIP protocol to a succinct four-message argument with a single prover, while preserving the time and space efficiency of the original MIP protocol.#R##N##R##N#As a main tool for this transformation, we construct a succinct multi-function commitment that a allows the sender to commit to a vector of functions in time and space complexity that are essentially the same as those needed for a single evaluation of the functions, and b ensures that the receiver's running time is essentially independent of the function. The scheme is based on fully-homomorphic encryption and no additional assumptions are needed for our succinct argument.#R##N##R##N#3 In addition, we revisit the problem of non-interactive succinct arguments of knowledge SNARKs, where known impossibilities rule out solutions based on black-box reductions to standard assumptions. We formulate a natural though non-standard variant of homomorphic encryption that has a homomorphism-extraction property. We then show that his primitive essentially allows to squash our interactive protocol, while again preserving time and space efficiency. We further show that this variant is, in fact, implied by the existence of SNARKs."
1120635,15510,339,The impact of vendor customizations on android security,2013,"The smartphone market has grown explosively in recent years, as more and more consumers are attracted to the sensor-studded multipurpose devices. Android is particularly ascendant; as an open platform, smartphone manufacturers are free to extend and modify it, allowing them to differentiate themselves from their competitors. However, vendor customizations will inherently impact overall Android security and such impact is still largely unknown.   In this paper, we analyze ten representative stock Android images from five popular smartphone vendors (with two models from each vendor). Our goal is to assess the extent of security issues that may be introduced from vendor customizations and further determine how the situation is evolving over time. In particular, we take a three-stage process: First, given a smartphone's stock image, we perform provenance analysis to classify each app in the image into three categories: apps originating from the AOSP, apps customized or written by the vendor, and third-party apps that are simply bundled into the stock image. Such provenance analysis allows for proper attribution of detected security issues in the examined Android images. Second, we analyze permission usages of pre-loaded apps to identify overprivileged ones that unnecessarily request more Android permissions than they actually use. Finally, in vulnerability analysis, we detect buggy pre-loaded apps that can be exploited to mount permission re-delegation attacks or leak private information.   Our evaluation results are worrisome: vendor customizations are significant on stock Android devices and on the whole responsible for the bulk of the security problems we detected in each device. Specifically, our results show that on average 85.78% of all pre-loaded apps in examined stock images are overprivileged with a majority of them directly from vendor customizations. In addition, 64.71% to 85.00% of vulnerabilities we detected in examined images from every vendor (except for Sony) arose from vendor customizations. In general, this pattern held over time -- newer smartphones, we found, are not necessarily more secure than older ones."
1685540,15510,20754,Hunting the Red Fox Online: Understanding and Detection of Mass Redirect-Script Injections,2014,"Compromised websites that redirect web traffic to malicious hosts play a critical role in organized web crimes, serving as doorways to all kinds of malicious web activities (e.g., drive-by downloads, phishing etc.). They are also among the most elusive components of a malicious web infrastructure and extremely difficult to hunt down, due to the simplicity of redirect operations, which also happen on legitimate sites, and extensive use of cloaking techniques. Making the detection even more challenging is the recent trend of injecting redirect scripts into JavaScript (JS) files, as those files are not indexed by search engines and their infections are therefore more difficult to catch. In our research, we look at the problem from a unique angle: the adversary's strategy and constraints for deploying redirect scripts quickly and stealthily. Specifically, we found that such scripts are often blindly injected into both JS and HTML files for a rapid deployment, changes to the infected JS files are often made minimum to evade detection and also many JS files are actually JS libraries (JS-libs) whose uninfected versions are publicly available. Based upon those observations, we developed JsRED, a new technique for the automatic detection of unknown redirect-script injections. Our approach analyzes the difference between a suspicious JS-lib file and its clean counterpart to identify malicious redirect scripts and further searches for similar scripts in other JS and HTML files. This simple, lightweight approach is found to work effectively against redirect injection campaigns: our evaluation shows that JsRED captured most of compromised websites with almost no false positives, significantly outperforming a commercial detection service in terms of finding unknown JS infections. Based upon the compromised websites reported by JsRED, we further conducted a measurement study that reveals interesting features of redirect payloads and a new Peer-to-Peer network the adversary constructed to evade detection."
2404528,15510,20358,Prophiler: a fast filter for the large-scale detection of malicious web pages,2011,"Malicious web pages that host drive-by-download exploits have become a popular means for compromising hosts on the Internet and, subsequently, for creating large-scale botnets. In a drive-by-download exploit, an attacker embeds a malicious script (typically written in JavaScript) into a web page. When a victim visits this page, the script is executed and attempts to compromise the browser or one of its plugins. To detect drive-by-download exploits, researchers have developed a number of systems that analyze web pages for the presence of malicious code. Most of these systems use dynamic analysis. That is, they run the scripts associated with a web page either directly in a real browser (running in a virtualized environment) or in an emulated browser, and they monitor the scripts' executions for malicious activity. While the tools are quite precise, the analysis process is costly, often requiring in the order of tens of seconds for a single page. Therefore, performing this analysis on a large set of web pages containing hundreds of millions of samples can be prohibitive.   One approach to reduce the resources required for performing large-scale analysis of malicious web pages is to develop a fast and reliable filter that can quickly discard pages that are benign, forwarding to the costly analysis tools only the pages that are likely to contain malicious code. In this paper, we describe the design and implementation of such a filter. Our filter, called  Prophiler , uses static analysis techniques to quickly examine a web page for malicious content. This analysis takes into account features derived from the HTML contents of a page, from the associated JavaScript code, and from the corresponding URL. We automatically derive detection models that use these features using machine-learning techniques applied to labeled datasets.   To demonstrate the effectiveness and efficiency of  Prophiler , we crawled and collected millions of pages, which we analyzed for malicious behavior. Our results show that our filter is able to reduce the load on a more costly dynamic analysis tools by more than 85%, with a negligible amount of missed malicious pages."
1793548,15510,339,Wiretapping via Mimicry: Short Voice Imitation Man-in-the-Middle Attacks on Crypto Phones,2014,"Establishing secure voice, video and text over Internet (VoIP) communications is a crucial task necessary to prevent eavesdropping and man-in-the-middle attacks. The traditional means of secure session establishment (e.g., those relying upon PKI or KDC) require a dedicated infrastructure and may impose unwanted trust onto third-parties. Crypto Phones (popular instances such as PGPfone and Zfone), in contrast, provide a purely peer-to-peer user-centric secure mechanism claiming to completely address the problem of wiretapping. The secure association mechanism in Crypto Phones is based on cryptographic protocols employing Short Authenticated Strings (SAS) validated by end users over the voice medium. The security of Crypto Phones crucially relies on the assumption that the voice channel, over which SAS is validated by the users, provides the properties of integrity and source authentication. In this paper, we challenge this assumption, and report on automated SAS voice imitation man-in-the-middle attacks} that can compromise the security of Crypto Phones in both two-party and multi-party settings, even if users pay due diligence. The first attack, called the short voice reordering attack, builds arbitrary SAS strings in a victim's voice by reordering previously eavesdropped SAS strings spoken by the victim. The second attack, called the short voice morphing attack, builds arbitrary SAS strings in a victim's voice from a few previously eavesdropped sentences (less than 3 minutes) spoken by the victim. We design and implement our attacks using off-the-shelf speech recognition/synthesis tools, and comprehensively evaluate them with respect to both manual detection (via a user study with 30 participants) and automated detection. The results demonstrate the effectiveness of our attacks against three prominent forms of SAS encodings: numbers, PGP word Lists and Madlib sentences. These attacks can be used by a wiretapper to compromise the confidentiality and privacy of Crypto Phones voice, video and text communications (plus authenticity in case of text conversations)."
1393579,15510,8335,ScanPUF: Robust ultralow-overhead PUF using scan chain,2013,"Physical Unclonable Functions (PUFs) have emerged as an attractive primitive to address diverse hardware security issues, such as chip authentication, intellectual property (IP) protection and cryptographic key generation. Existing PUFs, typically acquired and integrated in a design as a commodity, often incur considerable hardware overhead. Many of these PUFs also suffer from insufficient challenge-response pairs. In this paper, we propose ScanPUF, a novel PUF implementation using a common on-chip structure used for improving circuit testability, namely scan chain. It exploits path delay variations between the scan flip-flops in a scan chain to create high-quality (in terms of uniqueness and robustness) secret keys. Furthermore, since a scan chain provides large pool of scan paths to create a signature, we can achieve high volume of secret keys from each chip. Since it uses a prevalent on-chip structure, the overhead is extremely small (2.3% area of the RO-PUF), primarily contributed by small additional logic in the signature-generation cycle controller. Circuit-level simulation results with 1000 chips under inter- and intra-die process variations show high uniqueness of 49.9% average inter-die Hamming distance and good reproducibility of 5% intra-die Hamming distance below 85 °C. The temporal variations due to device aging effect e.g. bias temperature instability (BTI) lead to only 4% unstable bits for ten-year usage. The experimental evaluation on FPGA (Altera Cyclone-III) exhibits 47.1% average inter-Hamming distance, as well as 3.2% unstable bits at room temperature."
1704510,15510,9766,"Neural Signatures of User-Centered Security: An fMRI Study of Phishing, and Malware Warnings.",2014,"The security of computer systems often relies upon decisions and actions of end users. In this paper, we set out to investigate user-centered security by concentrating at the most fundamental component governing user behavior - the human brain. We introduce a novel neuroscience-based study methodology to inform the design of user-centered security systems. Specifically, we report on an fMRI study measuring users' security performance and the underlying neural activity with respect to two critical security tasks: (1) distinguishing between a legitimate and a phishing website, and (2) heeding security (malware) warnings. At a higher level, we identify neural markers that might be controlling users' performance in these tasks, and establish relationships between brain activity and behavioral performance as well as between users' personality traits and security behavior. Our results provide a largely positive perspective towards users' capability and performance vis-a-vis these crucial security tasks. First , we show that users exhibit significant brain activity in key regions associated with decision-making, attention, and problem-solving (phishing and malware warnings) as well as language comprehension and reading (malware warnings), which means that users are actively engaged in these security tasks. Second , we demonstrate that certain individual traits, such as impulsivity measured via an established questionnaire, can have a significant negative effect on brain activation in these tasks. Third , we discover a high degree of correlation in brain activity (in decision-making regions) across phishing detection and malware warnings tasks, which implies that users' behavior in one task may potentially be predicted by their behavior in the other task. Finally , we discuss the broader impacts and implications of our work on the field of user-centered security, including the domain of security education, targeted security training, and security screening."
1572201,15510,22164,User authentication through biometric sensors and decision fusion,2013,"The interaction between humans and most desktop and laptop computers is often performed through two input devices: the keyboard and the mouse. Continuous tracking of these devices provides an opportunity to verify the identity of a user, based on a profile of behavioral biometrics from the user's previous interaction with these devices. We propose a bank of sensors, each feeding a binary detector (trying to distinguish the authentic user from all others). In this study the detectors use features derived from the keyboard and the mouse, and their decisions are fused to develop a global authentication decision. The binary classification of the individual features is developed using Naive Bayes Classifiers which play the role of local detectors in a parallel binary decision fusion architecture. The conclusion of each classifier ('authentic user' or 'other') is sent to a Decision Fusion Center (DFC) where we use the Neyman-Pearson criterion to maximize the probability of detection under an upper bound on the probability of false alarms. We compute the receiver operating characteristic (ROC) of the resulting detection scheme, and use the ROC to assess the contribution of each individual sensor to the quality of the global decision on user authenticity. In this manner we identify the characteristics (and local detectors) that are most significant to the development of correct user authentication. While the false accept rate (FAR) and false reject rate (FRR) are fixed for the local sensors, the fusion center provides trade-off between the two global error rates, and allows the designer to fix an operating point based on hislher tolerance level of false alarms. We test our approach on a real-world dataset collected from 10 office workers, who worked for a week in an office environment as we tracked their keyboard dynamics and"
1571850,15510,8235,A Game-Theoretic Approach for High-Assurance of Data Trustworthiness in Sensor Networks,2012,"Sensor networks are being increasingly deployed in many application domains ranging from environment monitoring to supervising critical infrastructure systems (e.g., the power grid). Due to their ability to continuously collect large amounts of data, sensor networks represent a key component in decision-making, enabling timely situation assessment and response. However, sensors deployed in hostile environments may be subject to attacks by adversaries who intend to inject false data into the system. In this context, {\em data trustworthiness} is an important concern, as false readings may result in wrong decisions with serious consequences (e.g., large-scale power outages). To defend against this threat, it is important to establish trust levels for sensor nodes and adjust node trustworthiness scores to account for malicious interferences. In this paper, we develop a game-theoretic defense strategy to protect sensor nodes from attacks and to guarantee a high level of trustworthiness for sensed data. We use a discrete time model, and we consider that there is a limited attack budget that bounds the capability of the attacker in each round. The defense strategy objective is to ensure that sufficient sensor nodes are protected in each round such that the discrepancy between the value accepted and the truthful sensed value is below a certain threshold. We model the attack-defense interaction as a Stackel berg game, and we derive the Nash equilibrium condition that is sufficient to ensure that the sensed data are truthful within a nominal error bound. We implement a prototype of the proposed strategy and we show through extensive experiments that our solution provides an effective and efficient way of protecting sensor networks from attacks."
1999785,15510,9969,Bi-deniable public-key encryption,2011,"In 1997, Canetti et al. (CRYPTO 1997) put forward the intruiging notion of deniable encryption, which (informally) allows a sender and/or receiver, having already performed some encrypted communication, to produce 'fake' (but legitimate-looking) random coins that open the ciphertext to another message. Deniability is a powerful notion for both practice and theory: apart from its inherent utility for resisting coercion, a deniable scheme is also noncommitting (a useful property in constructing adaptively secure protocols) and secure under selectiveopening attacks on whichever parties can equivocate. To date, however, known constructions have achieved only limited forms of deniability, requiring at least one party to withhold its randomness, and in some cases using an interactive protocol or external parties.#R##N##R##N#In this work we construct bi-deniable public-key cryptosystems, in which both the sender and receiver can simultaneously equivocate; we stress that the schemes are noninteractive and involve no third parties. One of our systems is based generically on simulatable encryption as defined by Damgard and Nielsen (CRYPTO 2000), while the other is lattice-based and builds upon the results of Gentry, Peikert and Vaikuntanathan (STOC 2008) with techniques that may be of independent interest. Both schemes work in the so-called multi-distributional model, in which the parties run alternative key-generation and encryption algorithms for equivocable communication, but claim under coercion to have run the prescribed algorithms. Although multi-distributional deniability has not attracted much attention, we argue that it is meaningful and useful because it provides credible coercion resistance in certain settings, and suffices for all of the related properties mentioned above."
1434090,15510,339,"Hey, NSA: Stay Away from my Market! Future Proofing App Markets against Powerful Attackers",2014,"Mobile devices are evolving as the dominant computing platform and consequently application repositories and app markets are becoming the prevalent paradigm for deploying software. Due to their central and trusted position in the software ecosystem, coerced, hacked or malicious app markets pose a serious threat to user security. Currently, there is little that hinders a nation state adversary (NSA) or other powerful attackers from using such central and trusted points of software distribution to deploy customized (malicious) versions of apps to specific users. Due to intransparencies in the current app installation paradigm, this kind of attack is extremely hard to detect.   In this paper, we evaluate the risks and drawbacks of current app deployment in the face of powerful attackers. We assess the app signing practices of 97% of all free Google Play apps and find that the current practices make targeted attacks unnecessarily easy and almost impossible to detect for users and app developers alike. We show that high profile Android apps employ intransparent and unaccountable strategies when they publish apps to (multiple) alternative markets. We then present and evaluate Application Transparency (AT), a new framework that can defend against ``targeted-and-stealthy'' attacks, mount by malicious markets.    We deployed AT in the wild and conducted an extensive field study in which we analyzed app installations on 253,819 real world Android devices that participate in a popular anti-virus app's telemetry program. We find that AT can effectively protect users against malicious targeted attack apps and furthermore adds transparency and accountability to the current intransparent signing and packaging strategies employed by many app developers."
2551342,15510,9856,Security through amnesia: a software-based solution to the cold boot attack on disk encryption,2011,"Disk encryption has become an important security measure for a multitude of clients, including governments, corporations, activists, security-conscious professionals, and privacy-conscious individuals. Unfortunately, recent research has discovered an effective side channel attack against any disk mounted by a running machine [23]. This attack, known as the cold boot attack, is effective against any mounted volume using state-of-the-art disk encryption, is relatively simple to perform for an attacker with even rudimentary technical knowledge and training, and is applicable to exactly the scenario against which disk encryption is primarily supposed to defend: an adversary with physical access.   While there has been some previous work in defending against this attack [27], the only currently available solution suffers from the twin problems of disabling access to the SSE registers and supporting only a single encrypted volume, hindering its usefulness for such common encryption scenarios as data and swap partitions encrypted with different keys (the swap key being a randomly generated throw-away key). We present Loop-Amnesia, a kernel-based disk encryption mechanism implementing a novel technique to eliminate vulnerability to the cold boot attack. We contribute a novel technique for shielding multiple encryption keys from RAM and a mechanism for storing encryption keys inside the CPU that does not interfere with the use of SSE. We offer theoretical justification of Loop-Amnesia's invulnerability to the attack, verify that our implementation is not vulnerable in practice, and present measurements showing our impact on I/O accesses to the encrypted disk is limited to a slowdown of approximately 2x. Loop-Amnesia is written for x86-64, but our technique is applicable to other register-based architectures. We base our work on loop-AES, a state-of-the-art open source disk encryption package for Linux."
1941728,15510,339,Practical PIR for electronic commerce,2011,"We extend Goldberg's multi-server information-theoretic private information retrieval (PIR) with a suite of protocols for privacy-preserving e-commerce. Our first protocol adds support for single-payee tiered pricing, wherein users purchase database records without revealing the indices or prices of those records. Tiered pricing lets the seller set prices based on each user's status within the system; e.g., non-members may pay full price while members may receive a discounted rate. We then extend tiered pricing to support group-based access control lists with record-level granularity; this allows the servers to set access rights based on users' price tiers. Next, we show how to do some basic bookkeeping to implement a novel top-K replication strategy that enables the servers to construct bestsellers lists, which facilitate faster retrieval for these most popular records. Finally, we build on our bookkeeping functionality to support multiple payees, thus enabling several sellers to offer their digital goods through a common database while enabling the database servers to determine to what portion of revenues each seller is entitled. Our protocols maintain user anonymity in addition to query privacy; that is, queries do not leak information about the index or price of the record a user purchases, the price tier according to which the user pays, the user's remaining balance, or even whether the user has ever queried the database before. No other priced PIR or oblivious transfer protocol supports tiered pricing, access control lists, multiple payees, or top-K replication, whereas ours supports all of these features while preserving PIR's sublinear communication complexity. We have implemented our protocols as an add-on to Percy++, an open source implementation of Goldberg's PIR scheme. Measurements indicate that our protocols are practical for deployment in real-world e-commerce applications."
2048077,15510,339,After we knew it: empirical study and modeling of cost-effectiveness of exploiting prevalent known vulnerabilities across IaaS cloud,2014,"Infrastructure as a Service (IaaS) cloud has been attracting more and more customers as it provides the highest level of flexibility by offering configurable virtual machines (VMs) and computing infrastructures. Public VM images are usually available for customers to customize and launch. However, the 1 to N mapping between VM images and running instances in IaaS makes vulnerabilities propagate rapidly across the entire public cloud. Besides, IaaS cloud naturally comes with a larger and more stable attack surface and more concentrated target resources than traditional surroundings. In this paper, we first identify the threat of exploiting prevalent vulnerabilities over public IaaS cloud with an empirical study in Amazon EC2. We find that attackers can compromise a considerable number of VMs with trivial cost. We then do a qualitative cost-effectiveness analysis of this threat. Our main result is a two-fold observation: in IaaS cloud, exploiting prevalent vulnerabilities is much more cost-effective than traditional in-house computing environment, therefore attackers have stronger incentive; Fortunately, on the other hand, cloud defenders (cloud providers and customers) also have much lower cost-loss ratio than in traditional environment, therefore they can be more effective for defending attacks. We then build a game-theoretic model and conduct a risk-gain analysis to compare exploiting and patching strategies under cloud and traditional computing environments. Our modeling indicates that under cloud environment, both attack and defense become less cost-effective as time goes by, and the earlier actioner can be more rewarding. We propose countermeasures against such threat in order to bridge the gap between current security situation and defending mechanisms. To our best knowledge, we are the first to analyze and model the threat with prevalent known-vulnerabilities in public cloud."
448773,15510,10286,Multi-location leakage resilient cryptography,2012,"Understanding and modeling leakage in the context of cryptographic systems (connecting physical protection of keys and cryptographic operation) is an emerging area with many missing issues and hard to understand aspects. In this work we initiate the study of leakage out of cryptographic devices when the operation is inherently replicated in  multiple locations  . This setting (allowing the adversary access to leakage at different locations) arises naturally in cases like protocols, where different parties activate the same cryptographic function, or in the case of a global service providers (like cloud operators) which need to replicate the cryptographic function to allow for accessible and responsive services. We specifically deal with the theoretical setting of leakage resilient cryptography, (modeling leakage as a bound associated with algorithmic steps), and in the most general model of continual leakage on memory, randomness (and thus computation) with periods of operation and refresh of private keys between them.#R##N##R##N#We first investigate public-key cryptography, and construct a multi-location leakage resilient signature scheme (with unbounded number of locations) with optimal (i.e., total  n  (1− o  (1)) leakage) in a period, and  O  (log n  ) leakage during updates ( n  is the key size). The new crucial issue behind our scheme is how to maintain leakage at each location at the level of key leakage in the single location variant, even under parallel adaptive leakage at the different locations. We then construct a shared-symmetric-key authenticated session protocol that is resilient to leakage on both the sender and the receiver, and tolerates  O  (log n  ) bits of leakage per computation. We construct and utilize a single-location pseudorandom generator which is the first to tolerate continual leakage with only an efficient pseudorandom function as a primitive component. This protocol highlights the importance of protocol level per message synchronization against leakage adversaries. Interestingly, the construction is secure in spite of the entire randomness used in the refresh processes being publicly available."
1756123,15510,20754,Signing Me onto Your Accounts through Facebook and Google: A Traffic-Guided Security Study of Commercially Deployed Single-Sign-On Web Services,2012,"With the boom of software-as-a-service and social networking, web-based single sign-on (SSO) schemes are being deployed by more and more commercial websites to safeguard many web resources. Despite prior research in formal verification, little has been done to analyze the security quality of SSO schemes that are commercially deployed in the real world. Such an analysis faces unique technical challenges, including lack of access to well-documented protocols and code, and the complexity brought in by the rich browser elements (script, Flash, etc.). In this paper, we report the first field study on popular web SSO systems. In every studied case, we focused on the actual web traffic going through the browser, and used an algorithm to recover important semantic information and identify potential exploit opportunities. Such opportunities guided us to the discoveries of real flaws. In this study, we discovered 8 serious logic flaws in high-profile ID providers and relying party websites, such as Open ID (including Google ID and Pay Pal Access), Face book, Jan Rain, Freelancer, Farm Ville, Sears.com, etc. Every flaw allows an attacker to sign in as the victim user. We reported our findings to affected companies, and received their acknowledgements in various ways. All the reported flaws, except those discovered very recently, have been fixed. This study shows that the overall security quality of SSO deployments seems worrisome. We hope that the SSO community conducts a study similar to ours, but in a larger scale, to better understand to what extent SSO is insecurely deployed and how to respond to the situation."
137330,15510,10286,Achieving Privacy in Verifiable Computation with Multiple Servers --- Without FHE and without Pre-processing,2014,"Cloud services provide a powerful resource to which weak clients may outsource their computation. While tremendously useful, they come with their own security challenges. One of the fundamental issues in cloud computation is: how does a client efficiently verify the correctness of computation performed on an untrusted server? Furthermore, how can the client be assured that the server learns nothing about its private inputs? In recent years, a number of proposals have been made for constructing verifiable computation protocols. Unfortunately, solutions that guarantee privacy of inputs in addition to the correctness of computation rely on the use of fully homomorphic encryption FHE. An unfortunate consequence of this dependence on FHE, is that all hope of making verifiable computation implementable in practice hinges on the challenge of making FHE deployable in practice. This brings us to the following question: do we need fully homomorphic encryption to obtain privacy in verifiable computation protocol which achieves input privacy?#R##N##R##N#Another drawback of existing protocols is that they require the client to run a pre-processing stage, in which the work done by the client is proportional to the function being outsourced and hence the outsourcing benefit is obtained only in an amortized sense. This brings us to our next question: can we build verifiable computation protocols that allow the client to efficiently outsource even a computation that it wishes to execute just once?#R##N##R##N#In this paper, we consider a model in which the client outsources his computation to multiple say ni¾?2 servers. In this model, we construct verifiable computation protocols that do not make use of FHE and that do not have a pre-processing stage. In the two-server setting, we present an extremely practical protocol based only on one-way functions. We also present a solution, based on the DDH assumption, for the multi-server model for any arbitrary n. All these protocols are secure as long as at least one server is honest. Finally, even in the n-server model, we present a solution based solely on one-way functions. This protocol tolerates up to a constant fraction of corrupted servers."
2202669,15510,9589,Cachet: a decentralized architecture for privacy preserving social networking with caching,2012,"Online social networks (OSNs) such as Facebook and Google+ have transformed the way our society communicates. However, this success has come at the cost of user privacy; in today's OSNs, users are not in control of their own data, and depend on OSN operators to enforce access control policies. A multitude of privacy breaches has spurred research into privacy-preserving alternatives for social networking, exploring a number of techniques for storing, disseminating, and controlling access to data in a decentralized fashion. In this paper, we argue that a combination of techniques is necessary to efficiently support the complex functionality requirements of OSNs.   We propose Cachet, an architecture that provides strong security and privacy guarantees while preserving the main functionality of online social networks. In particular, Cachet protects the confidentiality, integrity and availability of user content, as well as the privacy of user relationships. Cachet uses a distributed pool of nodes to store user data and ensure availability. Storage nodes in Cachet are untrusted; we leverage cryptographic techniques such as attribute based encryption to protect the confidentiality of data. For efficient dissemination and retrieval of data, Cachet uses a hybrid structured-unstructured overlay paradigm in which a conventional distributed hash table is augmented with social links between users. Social contacts in our system act as caches to store recent updates in the social network, and help reduce the cryptographic as well as the communication overhead in the network.   We built a prototype implementation of Cachet in the FreePastry simulator. To demonstrate the functionality of existing OSNs we implemented the newsfeed application. Our evaluation demonstrates that (a) decentralized architectures for privacy preserving social networking are feasible, and (b) use of social contacts for object caching results in significant performance improvements."
631401,15510,9969,Group Signatures with Almost-for-Free Revocation,2012,"Group signatures are a central cryptographic primitive where users can anonymously and accountably sign messages in the name of a group they belong to. Several efficient constructions with security proofs in the standard model i.e., without the random oracle idealization appeared in the recent years. However, like standard PKIs, group signatures need an efficient revocation system to be practical. Despite years of research, membership revocation remains a non-trivial problem: many existing solutions do not scale well due to either high overhead or constraining operational requirements like the need for all users to update their keys after each revocation. Only recently, Libert, Peters and Yung Eurocrypt'12 suggested a new scalable revocation method, based on the Naor-Naor-Lotspiech NNL broadcast encryption framework, that interacts nicely with techniques for building group signatures in the standard model. While promising, their mechanism introduces important storage requirements at group members. Namely, membership certificates, which used to have constant size in existing standard model constructions, now have polylog size in the maximal cardinality of the group NNL, after all, is a tree-based technique and such dependency is naturally expected. In this paper we show how to obtain private keys of constant size. To this end, we introduce a new technique to leverage the NNL subset cover framework in the context of group signatures but, perhaps surprisingly, without logarithmic relationship between the size of private keys and the group cardinality. Namely, we provide a way for users to efficiently prove their membership of one of the generic subsets in the NNL subset cover framework. This technique makes our revocable group signatures competitive with ordinary group signatures i.e., without revocation in the standard model. Moreover, unrevoked members as in PKIs still do not need to update their keys at each revocation."
2243090,15510,9969,"Leftover Hash Lemma, revisited",2011,"The famous Leftover Hash Lemma (LHL) states that (almost) universal hash functions are good randomness extractors. Despite its numerous applications, LHL-based extractors suffer from the following two limitations: - Large Entropy Loss: to extract v bits from distribution X of minentropy m which are e-close to uniform, one must set v ≤ m - 2 log (1/e), meaning that the entropy loss L = m - v ≥ 2 log (1/e). For many applications, such entropy loss is too large. - Large Seed Length: the seed length n of (almost) universal hash function required by the LHL must be at least n ≥ min(u - v, v + 2 log (1/e) - O(1), where u is the length of the source, and must grow with the number of extracted bits.#R##N##R##N#Quite surprisingly, we show that both limitations of the LHL - large entropy loss and large seed - can be overcome (or, at least, mitigated) in various important scenarios. First, we show that entropy loss could be reduced to L = log(1/e) for the setting of deriving secret keys for a wide range of cryptographic applications. Specifically, the security of these schemes with an LHL-derived key gracefully degrades from e to at most e + √e2-L. (Notice that, unlike standard LHL, this bound is meaningful even when one extracts more bits than the min-entropy we have!) Based on these results we build a general computational extractor that enjoys low entropy loss and can be used to instantiate a generic key derivation function for any cryptographic application.#R##N##R##N#Second, we study the soundness of the natural expand-then-extract approach, where one uses a pseudorandom generator (PRG) to expand a short input seed S into a longer output seed S', and then use the resulting S' as the seed required by the LHL (or, more generally, by any randomness extractor). We show that, in general, the expandthen-extract approach is not sound if the Decisional Diffie-Hellman assumption is true. Despite that, we show that it is sound either: (1) when extracting a small (logarithmic in the security of the PRG) number of bits; or (2) in minicrypt. Implication (2) suggests that the expandthen-extract approach is likely secure when used with practical PRGs, despite lacking a reductionist proof of security!"
227822,15510,10286,On Minimal Assumptions for Sender-Deniable Public Key Encryption,2014,"The primitive of deniable encryption was introduced by Canetti et al. CRYPTO, 1997. Deniable encryption is an encryption scheme with the added feature that after transmitting a message m, both sender and receiver may produce random coins showing that the transmitted ciphertext was an encryption of any message m' in the message space. Deniable encryption is a key tool for constructing incoercible protocols, since it allows a party to send one message and later provide apparent evidence to a coercer that a different message was sent. In addition, deniable encryption may be used to obtain adaptively-secure multiparty computation MPC protocols and is secure under selective-opening attacks. Different flavors such as sender-deniable and receiver-deniable encryption, where only the sender or receiver produce fake random coins, have been considered.#R##N##R##N#Recently, over 15 years after the primitive was first introduced, Sahai and Waters IACR Cryptology ePrint Archive, 2013, gave the first construction of sender-deniable encryption schemes with super-polynomial security, where an adversary has negligible advantage in distinguishing real and fake openings. Their construction is based on the construction of an indistinguishability obfuscator for general programs recently introduced in a breakthrough result of Garg et al. FOCS, 2013. Although feasibility has now been demonstrated, the question of determining the minimal assumptions necessary for sender-deniable encryption with super-polynomial security remains open.#R##N##R##N#The primitive of simulatable public key encryption PKE, introduced by Damgard and Nielsen CRYPTO, 2000, is a public key encryption scheme with additional properties that allow oblivious sampling of public keys and ciphertexts. It is one of the low-level primitives used to construct adaptively-secure MPC protocols and was used by O'Neill et al. in their construction of bi-deniable encryption in the multi-distributional model CRYPTO, 2011. Moreover, the original construction of sender-deniable encryption with polynomial security given by Canetti et al. can be instantiated with simulatable PKE. Thus, a natural question to ask is whether it is possible to construct sender-deniable encryption with super-polynomial security from simulatable PKE.#R##N##R##N#In this work, we investigate the possibility of constructing sender-deniable public key encryption from simulatable PKE in a black-box manner. We show that there is no black-box construction of sender-deniable public key encryption with super-polynomial security from simulatable PKE. This indicates that improving on the original construction of Canetti et al. requires the use of non-black-box techniques, stronger assumptions, or interaction, thus giving some evidence that strong assumptions such as those used by Sahai and Waters are necessary."
40085,15510,9969,Secure Database Commitments and Universal Arguments of Quasi Knowledge,2012,"In this work we focus on a simple database commitment functionality where besides the standard security properties, one would like to hide the size of the input of the sender. Hiding the size of the input of a player is a critical requirement in some applications, and relatively few works have considered it. Notable exceptions are the work on zero-knowledge sets introduced ini¾?[14], and recent work on size-hiding private set intersectioni¾?[1]. However, neither of these achieves a secure computation i.e., a reduction of a real-world attack of a malicious adversary into an ideal-world attack of the proposed functionality.#R##N##R##N#The first result of this submission consists in defining secure database commitment and in observing that previous constructions do not satisfy this definition. This leaves open the question of whether there is any way this functionality can be achieved.#R##N##R##N#We then provide an affirmative answer to this question by using new techniques that combined together achieve secure database commitment. Our construction is in particular optimized to require only a constant number of rounds, to provide non-interactive proofs on the content of the database, and to rely on the existence of a family of CRHFs. This is the first result where input-size hiding secure computation is achieved for an interesting functionality and moreover we obtain this result with standard security i.e., simulation in expected polynomial time against fully malicious adversaries, without random oracles, without non-black-box extraction assumptions, without hardness assumptions against super-polynomial time adversaries.#R##N##R##N#A key building block in our construction is a universal argument enjoying an improved proof of knowledge property, that we call quasi-knowledge. This property is significantly closer to the standard proof of knowledge property than the weak proof of knowledge property satisfied by previous constructions."
858074,15510,9856,FORECAST: skimming off the malware cream,2011,"To handle the large number of malware samples appearing in the wild each day, security analysts and vendors employ automated tools to detect, classify and analyze malicious code. Because malware is typically resistant to static analysis, automated dynamic analysis is widely used for this purpose. Executing malicious software in a controlled environment while observing its behavior can provide rich information on a malware's capabilities. However, running each malware sample even for a few minutes is expensive. For this reason, malware analysis efforts need to select a subset of samples for analysis. To date, this selection has been performed either randomly or using techniques focused on avoiding re-analysis of polymorphic malware variants [41, 23].   In this paper, we present a novel approach to sample selection that attempts to maximize the total value of the information obtained from analysis, according to an application-dependent scoring function. To this end, we leverage previous work on behavioral malware clustering [14] and introduce a machine-learning-based system that uses all statically-available information to predict into which behavioral class a sample will fall,  before  the sample is actually executed. We discuss scoring functions tailored at two practical applications of large-scale dynamic analysis: the compilation of network blacklists of command and control servers and the generation of remediation procedures for malware infections. We implement these techniques in a tool called ForeCast. Large-scale evaluation on over 600,000 malware samples shows that our prototype can increase the amount of potential command and control servers detected by up to 137% over a random selection strategy and 54% over a selection strategy based on sample diversity."
2702174,15510,11345,Sequential Aggregate Signatures with Lazy Verification from Trapdoor Permutations - (Extended Abstract).,2012,"Sequential aggregate signature schemes allow n signers, in order, to sign a message each, at a lower total cost than the cost of n in- dividual signatures. We present a sequential aggregate signature scheme based on trapdoor permutations (e.g., RSA). Unlike prior such propos- als, our scheme does not require a signer to retrieve the keys of other signers and verify the aggregate-so-far before adding its own signature. Indeed, we do not even require a signer to know the public keys of other signers! Moreover, for applications that require signers to verify the aggregate anyway, our schemes support lazy verification :as igner can add its own signature to an unverified aggregate and forward it along immediately, postponing verification until load permits or the necessary public keys are obtained. This is especially important for applications where signers must access a large, secure, and current cache of public keys in order to verify messages. The price we pay is that our signature grows slightly with the number of signers. We report a technical analysis of our scheme (which is provably se- cure in the random oracle model), a detailed implementation-level spec- ification, and implementation results based on RSA and OpenSSL. To evaluate the performance of our scheme, we focus on the target applica- tion of BGPsec (formerly known as Secure BGP), a protocol designed for securing the global Internet routing system. There is a particular need for lazy verification with BGPsec, since it is run on routers that must process signatures extremely quickly, while being able to access tens of thousands of public keys. We compare our scheme to the algorithms currently proposed for use in BGPsec, and find that our signatures are considerably shorter nonaggregate RSA (with the same sign and verify times) and have an order of magnitude faster verification than nonaggre- gate ECDSA, although ECDSA has shorter signatures when the number of signers is small."
2574669,15510,9969,Cryptography with tamperable and leaky memory,2011,"A large and growing body of research has sought to secure cryptographic systems against physical attacks. Motivated by a large variety of real-world physical attacks on memory, an important line of work was initiated by Akavia, Goldwasser, and Vaikuntanathan [1] where security is sought under the assumptions that: (1) all memory is leaky, and (2) leakage can be an arbitrarily chosen (efficient) function of the memory.#R##N##R##N#However, physical attacks onmemory are not limited to leakagethrough side-channels, but can also include active tampering attacks through a variety of physical attacks, including heat and EM radiation. Nevertheless, protection against the analogous model for tampering - where (1) all memory is tamperable, and (2) where the tampering can be an arbitrarily chosen (efficient) function applied to the memory - has remained an elusive target, despite significant effort on tampering-related questions.#R##N##R##N#In this work, we tackle this question by considering a model where we assume that both of these pairs of statements are true - that all memory is both leaky and (arbitrarily) tamperable. Furthermore, we assume that this leakage and tampering can happen repeatedly and continually (extending the model of [10,7] in the context of leakage). We construct a signature scheme and an encryption scheme that are provably secure against such attacks, assuming that memory can be updated in a randomized fashion between episodes of tampering and leakage. In both schemes we rely on the linear assumption over bilinear groups.#R##N##R##N#We also separately consider a model where only continual and repeated tampering (but only bounded leakage) is allowed, and we are able to obtain positive results assuming only that self-destruct is possible, without the need for memory updates.#R##N##R##N#Our results also improve previous results in the continual leakage regime without tampering [10,7]. Whereas previous schemes secure against continual leakage (of arbitrary bounded functions of the secret key), could tolerate only 1/2-e leakage-rate between key updates under the linear assumption over bilinear groups, our schemes can tolerate 1-e leakage-rate between key updates, under the same assumption."
371936,15510,20592,Secure outsourced garbled circuit evaluation for mobile devices,2013,"Garbled circuits provide a powerful tool for jointly evaluating functions while preserving the privacy of each user's inputs. While recent research has made the use of this primitive more practical, such solutions generally assume that participants are symmetrically provisioned with massive computing resources. In reality, most people on the planet only have access to the comparatively sparse computational resources associated with their mobile phones, and those willing and able to pay for access to public cloud computing infrastructure cannot be assured that their data will remain unexposed. We address this problem by creating a new SFE protocol that allows mobile devices to securely outsource the majority of computation required to evaluate a garbled circuit. Our protocol, which builds on the most efficient garbled circuit evaluation techniques, includes a new out-sourced oblivious transfer primitive that requires significantly less bandwidth and computation than standard OT primitives and outsourced input validation techniques that force the cloud to prove that it is executing all protocols correctly. After showing that our extensions are secure in the malicious model, we conduct an extensive performance evaluation for a number of standard SFE test applications as well as a privacy-preserving navigation application designed specifically for the mobile usecase. Our system reduces execution time by 98.92% and bandwidth by 99.95% for the edit distance problem of size 128 compared to non-outsourced evaluation. These results show that even the least capable devices are capable of evaluating some of the largest garbled circuits generated for any platform."
1872374,15510,11345,A Simplified Representation of AES,2014,"We show that the so-called super S-box representation of AES - that provides a simplified view of two consecutive AES rounds - can be further simplified. In the untwisted representation of AES pre- sented here, two consecutive AES rounds are viewed as the composition of a non-linear transformation S and an af fi ne transformationR that re- spectively operate on the four 32-bit columns and on the four 32-bit rows of their 128-bit input. To illustrate that this representation can be helpful for analysing the resistance of AES-like ciphers or AES-based hash func- tions against some structural attacks, we present some improvements of the known-key distinguisher for the 7-round variant of AES presented by Knudsen and Rijmen at ASIACRYPT 2007. We first introduce a known-key distinguisher for the 8-round variant of AES which constructs a2 64 -tuple of (input,output) pairs satisfying a simple integral property. While this new 8-round known-key distinguisher is outperformed for 8 AES rounds by known-key differential distinguishers of time complex- ity 2 48 and 2 44 presented by Gilbert and Peyrin at FSE 2010 and Jean, Naya-Plasencia, and Peyrin at SAC 2013, we show that one can take advantage of its specific features to mount a known-key distinguisher for the 10-round AES with independent subkeys and the full AES-128. The obtained 10-round distinguisher has the same time complexity 2 64 as the 8-round distinguisher it is derived from, but the highlighted input- output correlation property is more intricate and therefore its impact on the security of the 10-round AES when used as a known key primitive, e.g. in a hash function construction, is questionable. The new known-key distinguishers do not affect at all the security of AES when used as a keyed primitive, for instance for encryption or message authentication purposes. In this paper we present an alternative representation of AES. More precisely we show that AES can be viewed as the composition of other elementary trans- formations than those originally used for the specification of its round function. While one might wonder whether selecting any of the equivalent descriptions of a cipher is more than an arbitrary convention, numerous examples illustrate that the choice of an appropriate description may be very useful for highlighting some"
2636330,15510,20592,A Bayesian approach to privacy enforcement in smartphones,2014,"Mobile apps often require access to private data, such as the device ID or location. At the same time, popular platforms like Android and iOS have limited support for user privacy. This frequently leads to unauthorized disclosure of private information by mobile apps, e.g. for advertising and analytics purposes. This paper addresses the problem of privacy enforcement in mobile systems, which we formulate as a classification problem: When arriving at a privacy sink (e.g., database update or outgoing web message), the runtime system must classify the sink's behavior as either legitimate or illegitimate. The traditional approach of information-flow (or taint) tracking applies binary classification, whereby information release is legitimate iff there is no data flow from a privacy source to sink arguments. While this is a useful heuristic, it also leads to false alarms.#R##N##R##N#We propose to address privacy enforcement as a learning problem, relaxing binary judgments into a quantitative/ probabilistic mode of reasoning. Specifically, we propose a Bayesian notion of statistical classification, which conditions the judgment whether a release point is legitimate on the evidence arising at that point. In our concrete approach, implemented as the BAYESDROID system that is soon to be featured in a commercial product, the evidence refers to the similarity between the data values about to be released and the private data stored on the device. Compared to TaintDroid, a state-of-the-art taint-based tool for privacy enforcement, BAYESDROID is substantially more accurate. Applied to 54 top-popular Google Play apps, BAYESDROID is able to detect 27 privacy violations with only 1 false alarm."
1394753,15510,23712,Anti-jamming communication in cognitive radio networks with unknown channel statistics,2011,"Recently, many opportunistic spectrum sensing and access protocols have been proposed for cognitive radio networks (CRNs). For achieving optimized spectrum usage, existing solutions model the spectrum sensing and access problem as a partially observed Markov decision process (POMDP) and assume that the information states and/or the primary users' (PUs) traffic statistics are known a priori to the secondary users (SUs). While theoretically sound, these existing approaches may not be effective in practice due to two main concerns. First, the assumptions they made are not practical, as before the communication starts, PUs' traffic statistics may not be readily available to the SUs. Secondly and more seriously, existing approaches are extremely vulnerable to malicious jamming attacks. A cognitive attacker can always jam the channels to be accessed by leveraging the same statistic information and stochastic dynamic decision making process that the SUs would follow. To address the above concerns, we formulate the problem of anti-jamming multichannel access in CRNs and solve it as a non-stochastic multi-armed bandit (NS-MAB) problem, where the secondary sender and receiver adaptively choose their arms (i.e., sending and receiving channels) to operate. The proposed protocol enables them to hop to the same set of channels with high probability in the presence of jamming. We analytically show the convergence of the learning algorithms, i.e., the performance difference between the secondary sende and receiver's optimal strategies is no more than O(20k/√e √Tn ln n). Extensive simulations are conducted to validate the theoretical analysis and show that the proposed protocol is highly resilient to various jamming attacks."
2552893,15510,9969,Better security for deterministic public-key encryption: the auxiliary-input setting,2011,"Deterministic public-key encryption, introduced by Bellare, Boldyreva, and O'Neill (CRYPTO '07), provides an alternative to randomized public-key encryption in various scenarios where the latter exhibits inherent drawbacks. A deterministic encryption algorithm, however, cannot satisfy any meaningful notion of security when the plaintext is distributed over a small set. Bellare et al. addressed this difficulty by requiring semantic security to hold only when the plaintext has high min-entropy from the adversary's point of view.#R##N##R##N#In many applications, however, an adversary may obtain auxiliary information that is related to the plaintext. Specifically, when deterministic encryption is used as a building block of a larger system, it is rather likely that plaintexts do not have high min-entropy from the adversary's point of view. In such cases, the framework of Bellare et al. might fall short from providing robust security guarantees.#R##N##R##N#We formalize a framework for studying the security of deterministic public-key encryption schemes with respect to auxiliary inputs. Given the trivial requirement that the plaintext should not be efficiently recoverable from the auxiliary input, we focus on hard-to-invert auxiliary inputs. Within this framework, we propose two schemes: the first is based on the decisional Diffie-Hellman (and, more generally, on the d-linear) assumption, and the second is based on a rather general class of subgroup indistinguishability assumptions (including, in particular, quadratic residuosity and Paillier's composite residuosity). Our schemes are secure with respect to any auxiliary input that is subexponentially hard to invert (assuming the standard hardness of the underlying computational assumptions). In addition, our first scheme is secure even in the multi-user setting where related plaintexts may be encrypted under multiple public keys. Constructing a scheme that is secure in the multi-user setting (even without considering auxiliary inputs) was identified by Bellare et al. as an important open problem."
548435,15510,9766,Pisces: Anonymous Communication Using Social Networks,2012,"The architectures of deployed anonymity systems such as Tor suffer from two key problems that limit user's trust in these systems. First, paths for anonymous communication are built without considering trust relationships between users and relays in the system. Second, the network architecture relies on a set of centralized servers. In this paper, we propose Pisces, a decentralized protocol for anonymous communications that leverages users' social links to build circuits for onion routing. We argue that such an approach greatly improves the system's resilience to attackers. #R##N#A fundamental challenge in this setting is the design of a secure process to discover peers for use in a user's circuit. All existing solutions for secure peer discovery leverage structured topologies and cannot be applied to unstructured social network topologies. In Pisces, we discover peers by using random walks in the social network graph with a bias away from highly connected nodes to prevent a few nodes from dominating the circuit creation process. To secure the random walks, we leverage the reciprocal neighbor policy: if malicious nodes try to exclude honest nodes during peer discovery so as to improve the chance of being selected, then honest nodes can use a tit-for-tat approach and reciprocally exclude the malicious nodes from their routing tables. We describe a fully decentralized protocol for enforcing this policy, and use it to build the Pisces anonymity system. #R##N#Using theoretical modeling and experiments on real-world social network topologies, we show that (a) the reciprocal neighbor policy mitigates active attacks that an adversary can perform, (b) our decentralized protocol to enforce this policy is secure and has low overhead, and (c) the overall anonymity provided by our system significantly outperforms existing approaches."
589107,15510,20349,Koi: a location-privacy platform for smartphone apps,2012,"With mobile phones becoming first-class citizens in the online world, the rich location data they bring to the table is set to revolutionize all aspects of online life including content delivery, recommendation systems, and advertising. However, user-tracking is a concern with such location-based services, not only because location data can be linked uniquely to individuals, but because the low-level nature of current location APIs and the resulting dependence on the cloud to synthesize useful representations virtually guarantees such tracking.#R##N##R##N#In this paper, we propose privacy-preserving location-based matching as a fundamental platform primitive and as an alternative to exposing low-level, latitude-longitude (lat-long) coordinates to applications. Applications set rich location-based triggers and have these be fired based on location updates either from the local device or from a remote device (e.g., a friend's phone). Our Koi platform, comprising a privacy-preserving matching service in the cloud and a phone-based agent, realizes this primitive across multiple phone and browser platforms. By masking low-level lat-long information from applications, Koi not only avoids leaking privacy-sensitive information, it also eases the task of programmers by providing a higher-level abstraction that is easier for applications to build upon. Koi's privacy-preserving protocol prevents the cloud service from tracking users. We verify the non-tracking properties of Koi using a theorem prover, illustrate how privacy guarantees can easily be added to a wide range of location-based applications, and show that our public deployment is performant, being able to perform 12K matches per second on a single core."
1080716,15510,20338,Rise of the planet of the apps: a systematic study of the mobile app ecosystem,2013,"Mobile applications (apps) have been gaining rising popularity due to the advances in mobile technologies and the large increase in the number of mobile users. Consequently, several app distribution platforms, which provide a new way for developing, downloading, and updating software applications in modern mobile devices, have recently emerged. To better understand the download patterns, popularity trends, and development strategies in this rapidly evolving mobile app ecosystem, we systematically monitored and analyzed four popular third-party Android app marketplaces. Our study focuses on measuring, analyzing, and modeling the app popularity distribution, and explores how pricing and revenue strategies affect app popularity and developers' income. Our results indicate that unlike web and peer-to-peer file sharing workloads, the app popularity distribution deviates from commonly observed Zipf-like models. We verify that these deviations can be mainly attributed to a new download pattern, to which we refer as the clustering effect. We validate the existence of this effect by revealing a strong temporal affinity of user downloads to app categories. Based on these observations, we propose a new formal clustering model for the distribution of app downloads, and demonstrate that it closely fits measured data. Moreover, we observe that paid apps follow a different popularity distribution than free apps, and show how free apps with an ad-based revenue strategy may result in higher financial benefits than paid apps. We believe that this study can be useful to appstore designers for improving content delivery and recommendation systems, as well as to app developers for selecting proper pricing policies to increase their income."
1119570,15510,20754,The Peril of Fragmentation: Security Hazards in Android Device Driver Customizations,2014,"Android phone manufacturers are under the perpetual pressure to move quickly on their new models, continuously customizing Android to fit their hardware. However, the security implications of this practice are less known, particularly when it comes to the changes made to Android's Linux device drivers, e.g., those for camera, GPS, NFC etc. In this paper, we report the first study aimed at a better understanding of the security risks in this customization process. Our study is based on ADDICTED, a new tool we built for automatically detecting some types of flaws in customized driver protection. Specifically, on a customized phone, ADDICTED performs dynamic analysis to correlate the operations on a security-sensitive device to its related Linux files, and then determines whether those files are under-protected on the Linux layer by comparing them with their counterparts on an official Android OS. In this way, we can detect a set of likely security flaws on the phone. Using the tool, we analyzed three popular phones from Samsung, identified their likely flaws and built end-to-end attacks that allow an unprivileged app to take pictures and screenshots, and even log the keys the user enters through touch screen. Some of those flaws are found to exist on over a hundred phone models and affect millions of users. We reported the flaws and helped the manufacturers fix those problems. We further studied the security settings of device files on 2423 factory images from major phone manufacturers, discovered over 1,000 vulnerable images and also gained insights about how they are distributed across different Android versions, carriers and countries."
2334985,15510,20754,A Formalization of the Security Features of Physical Functions,2011,"Physical attacks against cryptographic devices typically take advantage of information leakage (e.g., side-channels attacks) or erroneous computations (e.g., fault injection attacks). Preventing or detecting these attacks has become a challenging task in modern cryptographic research. In this context intrinsic physical properties of integrated circuits, such as Physical(ly) Unclonable Functions~(PUFs), can be used to complement classical cryptographic constructions, and to enhance the security of cryptographic devices. PUFs have recently been proposed for various applications, including anti-counterfeiting schemes, key generation algorithms, and in the design of block ciphers. However, currently only rudimentary security models for PUFs exist, limiting the confidence in the security claims of PUF-based security primitives. A useful model should at the same time (i) define the security properties of PUFs abstractly and naturally, allowing to design and formally analyze PUF-based security solutions, and (ii) provide practical quantification tools allowing engineers to evaluate PUF instantiations. In this paper, we present a formal foundation for security primitives based on PUFs. Our approach requires as little as possible from the physics and focuses more on the main properties at the heart of most published works on PUFs: robustness (generation of stable answers), unclonability (not provided by algorithmic solutions), and unpredictability. We first formally define these properties and then show that they can be achieved by previously introduced PUF instantiations. We stress that such a consolidating work allows for a meaningful security analysis of security primitives taking advantage of physical properties, becoming increasingly important in the development of the next generation secure information systems."
588818,15510,20358,The role of web hosting providers in detecting compromised websites,2013,"Compromised websites are often used by attackers to deliver malicious content or to host phishing pages designed to steal private information from their victims. Unfortunately, most of the targeted websites are managed by users with little security background - often unable to detect this kind of threats or to afford an external professional security service.   In this paper we test the ability of web hosting providers to detect compromised websites and react to user complaints. We also test six specialized services that provide security monitoring of web pages for a small fee.   During a period of 30 days, we hosted our own vulnerable websites on 22 shared hosting providers, including 12 of the most popular ones. We repeatedly ran five different attacks against each of them. Our tests included a bot-like infection, a drive-by download, the upload of malicious files, an SQL injection stealing credit card numbers, and a phishing kit for a famous American bank. In addition, we also generated traffic from seemingly valid victims of phishing and drive-by download sites. We show that most of these attacks could have been detected by free network or file analysis tools. After 25 days, if no malicious activity was detected, we started to file abuse complaints to the providers. This allowed us to study the reaction of the web hosting providers to both real and bogus complaints.   The general picture we drew from our study is quite alarming. The vast majority of the providers, or add-on security monitoring services, are unable to detect the most simple signs of malicious activity on hosted websites."
2216750,15510,339,Mayhem in the Push Clouds: Understanding and Mitigating Security Hazards in Mobile Push-Messaging Services,2014,"Push messaging is among the most important mobile-cloud services, offering critical supports to a wide spectrum of mobile apps. This service needs to coordinate complicated interactions between developer servers and their apps in a large scale, making it error prone. With its importance, little has been done, however, to understand the security risks of the service. In this paper, we report the first security analysis on those push-messaging services, which reveals the pervasiveness of subtle yet significant security flaws in them, affecting billions of mobile users. Through even the most reputable services like Google Cloud Messaging (GCM) and Amazon Device Messaging (ADM), the adversary running carefully-crafted exploits can steal sensitive messages from a target device, stealthily install or uninstall any apps on it, remotely lock out its legitimate user or even completely wipe out her data. This is made possible by the vulnerabilities in those services' protection of device-to-cloud interactions and the communication between their clients and subscriber apps on the same devices. Our study further brings to light questionable practices in those services, including weak cloud-side access control and extensive use of PendingIntent, as well as the impacts of the problems, which cause popular apps or system services like Android Device Manager, Facebook, Google+, Skype, PayPal etc. to leak out sensitive user data or unwittingly act on the adversary's command. To mitigate this threat, we developed a technique that helps the app developers establish end-to-end protection of the communication with their apps, over the vulnerable messaging services they use."
2491390,15510,11058,"FlowDroid: precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for Android apps",2014,"Today's smartphones are a ubiquitous source of private and confidential data. At the same time, smartphone users are plagued by carelessly programmed apps that leak important data by accident, and by malicious apps that exploit their given privileges to copy such data intentionally. While existing static taint-analysis approaches have the potential of detecting such data leaks ahead of time, all approaches for Android use a number of coarse-grain approximations that can yield high numbers of missed leaks and false alarms.   In this work we thus present FlowDroid, a novel and highly precise static taint analysis for Android applications. A precise model of Android's lifecycle allows the analysis to properly handle callbacks invoked by the Android framework, while context, flow, field and object-sensitivity allows the analysis to reduce the number of false alarms. Novel on-demand algorithms help FlowDroid maintain high efficiency and precision at the same time.   We also propose DroidBench, an open test suite for evaluating the effectiveness and accuracy of taint-analysis tools specifically for Android apps. As we show through a set of experiments using SecuriBench Micro, DroidBench, and a set of well-known Android test applications, FlowDroid finds a very high fraction of data leaks while keeping the rate of false positives low. On DroidBench, FlowDroid achieves 93% recall and 86% precision, greatly outperforming the commercial tools IBM AppScan Source and Fortify SCA. FlowDroid successfully finds leaks in a subset of 500 apps from Google Play and about 1,000 malware apps from the VirusShare project."
2253242,15510,9969,Must You Know the Code of f to Securely Compute f,2012,"When Alice and Bob want to securely evaluate a function of their shared inputs, they typically first express the function as a boolean or arithmetic circuit and then securely evaluate that circuit, gate-by-gate. In other words, a secure protocol for evaluating f is typically obtained in a non-black-box-way from f itself. Consequently, secure computation protocols have high overhead in communication & computation that is directly linked to the circuit-description complexity of f.#R##N##R##N#In other settings throughout cryptography, black-box constructions invariably lead to better practical efficiency than comparable non-black-box constructions. Could secure computation protocols similarly be made more practical by eliminating their dependence on a circuit representation of the target function? Or, in other words, must one know the code of f to securely evaluate f?#R##N##R##N#In this work we initiate the theoretical study of this question. We show the following:1.A complete characterization of the 2-party tasks which admit such security against semi-honest adversaries. The characterization is inspired by notions of autoreducibility from computational complexity theory. From this characterization, we show a class of pseudorandom functions that cannot be securely evaluated when one party holds the seed and the other holds the input without knowing the code of the function in question. On the positive side, we show a class of functions related to blind signatures that can indeed be securely computed without knowing the code of the function.2.Sufficient conditions for such security against malicious adversaries, also based on autoreducibility. We show that it is not possible to prove membership in the image of a one-way function in zero-knowledge, without knowing the code of the one-way function. We also describe a variant of the GMW compiler for transforming semi-honest to malicious security while preserving the specific black-box property considered here."
587346,15510,20592,Dynamic hooks: hiding control flow changes within non-control data,2014,"Generally speaking, malicious code leverages hooks within a system to divert the control flow. Without them, an attacker is blind to the events occurring in the system, rendering her unable to perform malicious activities (e.g., hiding of files or capturing of keystrokes). However, while hooks are an integral part of modern attacks, they are at the same time one of their biggest weaknesses: Even the most sophisticated attack can be easily identified if one of its hooks is found. In spite of this fact, hooking mechanisms have remained almost unchanged over the last years and still rely on the persistent modification of code or control data to divert the control flow. As a consequence, hooks represent an abnormality within the system that is permanently evident and can in many cases easily be detected as the hook detection mechanisms of recent years amply demonstrated.#R##N##R##N#In this paper, we propose a novel hooking concept that we refer to as dynamic hooking. Instead of modifying persistent control data permanently, this hooking mechanisms targets transient control data such as return addresses at run-time. The hook itself will thereby reside within non-control data and remains hidden until it is triggered. As a result, there is no evident connection between the hook and the actual control flow change, which enables dynamic hooks to successfully evade existing detection mechanisms. To realize this idea, dynamic hooks make use of exploitation techniques to trigger vulnerabilities at run-time. Due to this approach, dynamic hooks cannot only be used to arbitrarily modify the control flow, but can also be applied to conduct noncontrol data attacks, which makes them more powerful than their predecessors. We implemented a prototype that makes uses of static program slicing and symbolic execution to automatically extract paths for dynamic hooks that can then be used by a human expert for their realization. To demonstrate this, we used the output provided by our prototype to implement concrete examples of dynamic hooks for both modern Linux and Windows kernels."
907617,15510,339,Sound and precise malware analysis for android via pushdown reachability and entry-point saturation,2013,"Sound malware analysis of Android applications is challenging. First, object-oriented programs exhibit highly interprocedural, dynamically dispatched control structure. Second, the Android programming paradigm relies heavily on the asynchronous execution of multiple entry points. Existing analysis techniques focus more on the second challenge, while relying on traditional analytic techniques that suffer from inherent imprecision or unsoundness to solve the first.   We present Anadroid, a static malware analysis framework for Android apps. Anadroid exploits two techniques to soundly raise precision: (1) it uses a pushdown system to precisely model dynamically dispatched interprocedural and exception-driven control-flow; (2) it uses Entry-Point Saturation (EPS) to soundly approximate all possible interleavings of asynchronous entry points in Android applications. (It also integrates static taint-flow analysis and least permissions analysis to expand the class of malicious behaviors which it can catch.) Anadroid provides rich user interface support for human analysts which must ultimately rule on the maliciousness of a behavior.   To demonstrate the effectiveness of Anadroid's malware analysis, we had teams of analysts analyze a challenge suite of 52 Android applications released as part of the Automated Program Analysis for Cybersecurity (APAC) DARPA program. The first team analyzed the apps using a version of Anadroid that uses traditional (finite-state-machine-based) control-flow-analysis found in existing malware analysis tools; the second team analyzed the apps using a version of Anadroid that uses our enhanced pushdown-based control-flow-analysis. We measured machine analysis time, human analyst time, and their accuracy in flagging malicious applications. With pushdown analysis, we found statistically significant (p"
2334619,15510,8306,"Crafting a usable microkernel, processor, and I/O system with strict and provable information flow security",2011,"High assurance systems used in avionics, medical implants, and cryptographic devices often rely on a small trusted base of hardware and software to manage the rest of the system. Crafting the core of such a system in a way that achieves flexibility, security, and performance requires a careful balancing act. Simple static primitives with hard partitions of space and time are easier to analyze formally, but strict approaches to the problem at the hardware level have been extremely restrictive, failing to allow even the simplest of dynamic behaviors to be expressed.   Our approach to this problem is to construct a minimal but configurable  architectural skeleton . This skeleton couples a critical slice of the low level hardware implementation with a microkernel in a way that allows information flow properties of the entire construction to be statically verified all the way down to its gate-level implementation. This strict structure is then made usable by a runtime system that delivers more traditional services (e.g. communication interfaces and long-living contexts) in a way that is decoupled from the information flow properties of the skeleton. To test the viability of this approach we design, test, and statically verify the information-flow security of a hardware/software system complete with support for unbounded operation, inter-process communication, pipelined operation, and I/O with traditional devices. The resulting system is provably sound even when adversaries are allowed to execute arbitrary code on the machine, yet is flexible enough to allow caching, pipelining, and other common case optimizations."
823734,15510,8912,An independent verification of errors and vulnerabilities in SaaS cloud,2012,"Software-as-a-Service (SaaS) offers immense advantages to a subscriber, as the SaaS subscriber pays for the amount of service he has consumed. This pay-per-use model offered by the SaaS provider is supported by the underlying virtualization technology, which allows sharing of the physical infrastructure among several clients who subscribe to the SaaS cloud to optimize the cost of usage. However, with this cost-benefit come several risks related to reliability, security and availability (RAS). Consequently, a potential subscriber of a SaaS offering wants to perform several reviews and validations related to RAS before the subscription. In fact, the subscriber often prefers an independent validation of these QoS aspects, as an on-going basis. In this work, we propose a validation methodology and a tool iCirrus-Val for a SaaS subscriber, to perform an independent analysis and verification of functional errors and vulnerabilities of a SaaS cloud from its weblogs. iCirrus-Val groups the logged URLs into whitelist and suspect categories. A whitelisted URL belonging to a business process, is analyzed for permanent and transient faults. A suspect URL is further analyzed to check if it falls into an “attempt to an attack category”. Our approach is lightweight and does not require data from other parts of the system that is typically unavailable to a SaaS subscriber. It is restricted to a study of RAS from the subscribers entry point. However, we believe that our approach has a potential to identify a large number of the vulnerabilities. Our belief, though not empirically validated here, rests upon recent research findings which indicate that vulnerabilities are increasingly targeted at the entry point such as the web server, as attackers find it difficult to hack the core server.We illustrate our approach using a real-life data of an organization that has adopted a SaaS public cloud."
2611080,15510,11345,Four-Dimensional gallant-lambert-vanstone scalar multiplication,2012,"The GLV method of Gallant, Lambert and Vanstone (CRYPTO 2001) computes any multiple kP of a point P of prime order n lying on an elliptic curve with a low-degree endomorphism Φ (called GLV curve) over $\mathbb{F}_p$ as $kP = k_1P + k_2\Phi(P), \text{with } \max\{|k_1|,|k_2|\}\leq C_1\sqrt n$, for some explicit constant C1>0. Recently, Galbraith, Lin and Scott (EUROCRYPT 2009) extended this method to all curves over $\mathbb{F}_{p^2}$ which are twists of curves defined over $\mathbb{F}_p$. We show in this work how to merge the two approaches in order to get, for twists of any GLV curve over $\mathbb{F}_{p^2}$, a four-dimensional decomposition together with fast endomorphisms Φ, &Ψ over $\mathbb{F}_{p^2}$ acting on the group generated by a point P of prime order n, resulting in a proven decomposition for any scalar k∈[1,n] given by kP=k1P+k2Φ(P)+k3&Ψ(P)+k4&ΨΦ(P) with max i (|ki|) 0. Remarkably, taking the best C1, C2, we obtain C2/C1<412, independently of the curve, ensuring in theory an almost constant relative speedup. In practice, our experiments reveal that the use of the merged GLV-GLS approach supports a scalar multiplication that runs up to 50% times faster than the original GLV method. We then improve this performance even further by exploiting the Twisted Edwards model and show that curves originally slower may become extremely efficient on this model. In addition, we analyze the performance of the method on a multicore setting and describe how to efficiently protect GLV-based scalar multiplication against several side-channel attacks. Our implementations improve the state-of-the-art performance of point multiplication for a variety of scenarios including side-channel protected and unprotected cases with sequential and multicore execution."
2266633,15510,11345,"Secure Two-Party Computation with Reusable Bit-Commitments, via a Cut-and-Choose with Forge-and-Lose Technique",2013,"A secure two-party computation (S2PC) protocol allows two parties to compute over their combined private inputs, as if intermediated by a trusted third party. In the active model, security is maintained even if one party is malicious, deviating from the protocol specification. For example, a honest party retains privacy of its input and is ensured a correct output. This can be achieved with a cut-and-choose of garbled circuits (C&C-GCs), where some GCs are verified for correctness and the remaining are evaluated to determine the circuit output. This paper presents a new C&C-GCs-based S2PC protocol, with significant advantages in eciency and applicability. First, in contrast with prior protocols that require a majority of evaluated GCs to be correct, the new protocol only requires that at least one evaluated GC is correct. In practice this reduces the total number of GCs to approximately one third, for the same statistical security goal. This is accomplished by augmenting the C&C with a new forge-and-lose technique based on bit commitments with trapdoor. Second, the output of the new protocol includes reusable XOR-homomorphic bit commitments of all circuit input and output bits, thereby enabling ecient linkage of several S2PCs in a reactive manner. The protocol has additional interesting characteristics (which may allow new comparison tradeos). The number of exponentiations is only linear with the number of input and output wires and a statistical parameter - this is an improvement over protocols whose number of exponentiations is proportional to the number of GCs multiplied by the number of input and output wires. It uses unconditionally hiding bit commitments with trapdoor as the basis of oblivious transfers, with the circuit evaluator choosing a single value and the circuit constructor receiving two (a sort of 2-out-of-1 oblivious transfer, instead of the typical 1-out-of-2). The verification of consistency of circuit input and output keys across dierent GCs is embedded in the C&C structure."
2588625,15510,20592,From the aether to the ethernet: attacking the internet using broadcast digital television,2014,"In the attempt to bring modern broadband Internet features to traditional broadcast television, the Digital Video Broadcasting (DVB) consortium introduced a specification called Hybrid Broadcast-Broadband Television (HbbTV), which allows broadcast streams to include embedded HTML content which is rendered by the television. This system is already in very wide deployment in Europe, and has recently been adopted as part of the American digital television standard.#R##N##R##N#Our analyses of the specifications, and of real systems implementing them, show that the broadband and broadcast systems are combined insecurely. This enables a large-scale exploitation technique with a localized geographical footprint based on radio frequency (RF) injection, which requires a minimal budget and infrastructure and is remarkably difficult to detect. Despite our responsible disclosure to the standards body, our attack was viewed as too expensive and with limited pay-off to the attackers.#R##N##R##N#In this paper, we present the attack methodology and a number of follow-on exploitation techniques that provide significant flexibility to attackers. Furthermore, we demonstrate that the technical complexity and required budget are low, making this attack practical and realistic, especially in areas with high population density - in a dense urban area, an attacker with a budget of about $450 can target more than 20,000 devices in a single attack. A unique aspect of this attack is that, in contrast to most Internet of Things/Cyber-Physical System threat scenarios where the attack comes from the data network side and affects the physical world, our attack uses the physical broadcast network to attack the data network."
1153425,15510,339,ShadowReplica: efficient parallelization of dynamic data flow tracking,2013,"Dynamic data flow tracking (DFT) is a technique broadly used in a variety of security applications that, unfortunately, exhibits poor performance, preventing its adoption in production systems. We present ShadowReplica, a new and efficient approach for accelerating DFT and other shadow memory-based analyses, by decoupling analysis from execution and utilizing spare CPU cores to run them in parallel. Our approach enables us to run a heavyweight technique, like dynamic taint analysis (DTA), twice as fast, while concurrently consuming fewer CPU cycles than when applying it in-line. DFT is run in parallel by a second shadow thread that is spawned for each application thread, and the two communicate using a shared data structure. We avoid the problems suffered by previous approaches, by introducing an off-line application analysis phase that utilizes both static and dynamic analysis methodologies to generate optimized code for decoupling execution and implementing DFT, while it also minimizes the amount of information that needs to be communicated between the two threads. Furthermore, we use a lock-free ring buffer structure and an N-way buffering scheme to efficiently exchange data between threads and maintain high cache-hit rates on multi-core CPUs. Our evaluation shows that ShadowReplica is on average ~2.3× faster than in-line DFT (~2.75× slowdown over native execution) when running the SPEC CPU2006 benchmark, while similar speed ups were observed with command-line utilities and popular server software. Astoundingly, ShadowReplica also reduces the CPU cycles used up to 30%."
2315030,15510,9856,BareBox: efficient malware analysis on bare-metal,2011,"Present-day malware analysis techniques use both virtualized and emulated environments to analyze malware. The reason is that such environments provide isolation and system restoring capabilities, which facilitate automated analysis of malware samples. However, there exists a class of malware, called VM-aware malware, which is capable of detecting such environments and then hide its malicious behavior to foil the analysis. Because of the artifacts introduced by virtualization or emulation layers, it has always been and will always be possible for malware to detect virtual environments.   The definitive way to observe the actual behavior of VM-aware malware is to execute them in a system running on real hardware, which is called a bare-metal system. However, after each analysis, the system must be restored back to the previous clean state. This is because running a malware program can leave the system in an instable/insecure state and/or interfere with the results of a subsequent analysis run. Most of the available state-of-the-art system restore solutions are based on disk restoring and require a system reboot. This results in a significant downtime between each analysis. Because of this limitation, efficient automation of malware analysis in bare-metal systems has been a challenge.   This paper presents the design, implementation, and evaluation of a malware analysis framework for bare-metal systems that is based on a fast and rebootless system restore technique. Live system restore is accomplished by restoring the entire physical memory of the analysis operating system from another, small operating system that runs outside of the target OS. By using this technique, we were able to perform a rebootless restore of a live Windows system, running on commodity hardware, within four seconds. We also analyzed 42 malware samples from seven different malware families, that are known to be silent in a virtualized or emulated environments, and all of them showed their true malicious behavior within our bare-metal analysis environment."
1132099,15510,9856,A comprehensive black-box methodology for testing the forensic characteristics of solid-state drives,2013,"Solid-state drives (SSDs) are inherently different from traditional drives, as they incorporate data-optimization mechanisms to overcome their limitations (such as a limited number of program-erase cycles, or the need of blanking a block before writing). The most common optimizations are wear leveling, trimming, compression, and garbage collection, which operate transparently to the host OS and, in certain cases, even when the disks are disconnected from a computer (but still powered up). In simple words, SSD controllers are designed to hide these internals completely, rendering them inaccessible if not through direct acquisition of the memory cells.   These optimizations have a significant impact on the forensic analysis of SSDs. The main cause is that memory cells could be pre-emptively blanked, whereas a traditional drive sector would need to be explicitly rewritten to physically wipe off the data. Unfortunately, the existing literature on this subject is sparse and the conclusions are seemingly contradictory.   In this paper we propose a generic, practical, test-driven methodology that guides researchers and forensics analysts through a series of steps that assess the forensic friendliness of a SSD. Given a drive of the same brand and model of the one under analysis, our methodology produces a decision that helps an analyst to determine whether or not an expensive direct acquisition of the memory cells is worth the effort, because the extreme optimizations may have rendered the data unreadable or useless. We apply our methodology to three SSDs produced by top vendors (Samsung, Corsair, and Crucial), and provide a detailed description of how each step should be conducted."
1975365,15510,20592,Enhanced operating system security through efficient and fine-grained address space randomization,2012,"In recent years, the deployment of many application-level countermeasures against memory errors and the increasing number of vulnerabilities discovered in the kernel has fostered a renewed interest in kernel-level exploitation. Unfortunately, no comprehensive and well-established mechanism exists to protect the operating system from arbitrary attacks, due to the relatively new development of the area and the challenges involved.#R##N##R##N#In this paper, we propose the first design for fine-grained address space randomization (ASR) inside the operating system (OS), providing an efficient and comprehensive countermeasure against classic and emerging attacks, such as return-oriented programming. To motivate our design, we investigate the differences with application-level ASR and find that some of the well-established assumptions in existing solutions are no longer valid inside the OS; above all, perhaps, that information leakage becomes a major concern in the new context. We show that our ASR strategy outperforms state-of-the-art solutions in terms of both performance and security without affecting the software distribution model. Finally, we present the first comprehensive live rerandomization strategy, which we found to be particularly important inside the OS. Experimental results demonstrate that our techniques yield low run-time performance overhead (less than 5% on average on both SPEC and syscall-intensive benchmarks) and limited run-time memory footprint increase (around 15% during the execution of our benchmarks). We believe our techniques can greatly enhance the level of OS security without compromising the performance and reliability of the OS."
915114,15510,339,Blackbox traceable CP-ABE: how to catch people leaking their keys by selling decryption devices on ebay,2013,"In the context of Ciphertext-Policy Attribute-Based Encryption (CP-ABE), if a decryption device associated with an attribute set S_D appears on eBay, and is alleged to be able to decrypt any ciphertexts with policies satisfied by S_D, no one including the CP-ABE authorities can identify the malicious user(s) who build such a decryption device using their key(s). This has been known as a major practicality concern in CP-ABE applications, for example, providing fine-grained access control on encrypted data. Due to the nature of CP-ABE, users get decryption keys from authorities associated with attribute sets. If there exists two or more users with attribute sets being the supersets of S_D, existing CP-ABE schemes cannot distinguish which user is the malicious one who builds and sells such a decryption device. In this paper, we extend the notion of CP-ABE to support Blackbox Traceability and propose a concrete scheme which is able to identify a user whose key has been used in building a decryption device from multiple users whose keys associated with the attribute sets which are all the supersets of S_D. The scheme is efficient with sub-linear overhead and when compared with the very recent (non-traceable) CP-ABE scheme due to Lewko and Waters in Crypto 2012, we can consider this new scheme as an extension with the property of fully collusion-resistant blackbox traceability added, i.e. an adversary can access an arbitrary number of keys when building a decryption device while the new tracing algorithm can still identify at least one particular key which must have been used for building the underlying decryption device. We show that this new scheme is secure against adaptive adversaries in the standard model, and is highly expressive by supporting any monotonic access structures. Its additional traceability property is also proven against adaptive adversaries in the standard model.   As of independent interest, in this paper, we also consider another scenario which we call it found-in-the-wild. In this scenario, a decryption device is found, for example, from a black market, and reported to an authority (e.g. a law enforcement agency). The decryption device is found to be able to decrypt ciphertexts with certain policy, say A, while the associated attribute set S_D is missing. In this found-in-the-wild scenario, we show that the Blackbox Traceable CP-ABE scheme proposed in this paper can still be able to find the malicious users whose keys have been used for building the decryption device, and our scheme can achieve selective traceability in the standard model under this scenario."
1987024,15510,339,Unauthorized origin crossing on mobile platforms: threats and mitigation,2013,"With the progress in mobile computing, web services are increasingly delivered to their users through mobile apps, instead of web browsers. However, unlike the browser, which enforces origin-based security policies to mediate the interactions between the web content from different sources, today's mobile OSes do not have a comparable security mechanism to control the cross-origin communications between apps, as well as those between an app and the web. As a result, a mobile user's sensitive web resources could be exposed to the harms from a malicious origin. In this paper, we report the first systematic study on this mobile cross-origin risk. Our study inspects the main cross-origin channels on Android and iOS, including intent, scheme and web-accessing utility classes, and further analyzes the ways popular web services (e.g., Facebook, Dropbox, etc.) and their apps utilize those channels to serve other apps. The research shows that lack of origin-based protection opens the door to a wide spectrum of cross-origin attacks. These attacks are unique to mobile platforms, and their consequences are serious: for example, using carefully designed techniques for mobile cross-site scripting and request forgery, an unauthorized party can obtain a mobile user's Facebook/Dropbox authentication credentials and record her text input. We report our findings to related software vendors, who all acknowledged their importance. To address this threat, we designed an origin-based protection mechanism, called Morbs, for mobile OSes. Morbs labels every message with its origin information, lets developers easily specify security policies, and enforce the policies on the mobile channels based on origins. Our evaluation demonstrates the effectiveness of our new technique in defeating unauthorized origin crossing, its efficiency and the convenience for the developers to use such protection."
1491468,15510,9856,It's the psychology stupid: how heuristics explain software vulnerabilities and how priming can illuminate developer's blind spots,2014,"Despite the security community's emphasis on the importance of building secure software, the number of new vulnerabilities found in our systems is increasing. In addition, vulnerabilities that have been studied for years are still commonly reported in vulnerability databases. This paper investigates a new hypothesis that software vulnerabilities are blind spots in developer's heuristic-based decision-making processes. Heuristics are simple computational models to solve problems without considering all the information available. They are an adaptive response to our short working memory because they require less cognitive effort. Our hypothesis is that as software vulnerabilities represent corner cases that exercise unusual information flows, they tend to be left out from the repertoire of heuristics used by developers during their programming tasks.   To validate this hypothesis we conducted a study with 47 developers using psychological manipulation. In this study each developer worked for approximately one hour on six vulnerable programming scenarios. The sessions progressed from providing no information about the possibility of vulnerabilities, to priming developers about unexpected results, and explicitly mentioning the existence of vulnerabilities in the code. The results show that (i) security is not a priority in software development environments, (ii) security is not part of developer's mindset while coding, (iii) developers assume common cases for their code, (iv) security thinking requires cognitive effort, (v) security education helps, but developers can have difficulties correlating a particular learned vulnerability or security information with their current working task, and (vi) priming or explicitly cueing about vulnerabilities  on-the-spot  is a powerful mechanism to make developers aware about potential vulnerabilities."
2579923,15510,9969,Leakage-Tolerant Computation with Input-Independent Preprocessing,2014,"Following a rich line of research on leakage-resilient cryptog- raphy, (Garg, Jain, and Sahai, CRYPTO11) and (Bitansky, Canetti, and Halevi, TCC12) initiated the study of secure interactive protocols in the presence of arbitrary leakage. They put forth notions of leakage tolerance for zero-knowledge and general secure multi-party computation that aim at capturing the best-possible security when the private inputs of honest parties are exposed to direct leakage. So far, only a handful of specific two-party functionalities have been successfully realized under the no- tion. General functionalities were only realized under weaker security notions (Boyle, Garg, Jain, Kalai, and Sahai, Crypto13), or relying on leakage-immune input-processing, which needs to be repeated for each and every execution (Boyle, Goldwasser, Jain, Kalai, STOC12). We construct leakage-tolerant multi-party computation protocols for general functions ,r elying oninput-independent preprocessing that is per- formed once and for-all. The protocols tolerate continualleakage, through- out an unboundednumberof executions, providedthat leakage is bounded within any particular execution. In the malicious setting, we also require a common reference string, and a constant fraction of honest parties. At the core of our construction, is a tight connection between secure compilers in the Only-Computation-Leaks (OCL) model and leakage- tolerant protocols. In particular, we show that two-party leakage-tolerant protocols with input-independent preprocessing are essentially equivalent to two-component OCL compilers satisfying certain strong properties. We then show how to construct such strong OCL compilers in the plain model, with the help of O(1) auxliary components."
1078953,15510,20338,"Detecting, validating and characterizing computer infections in the wild",2011,"Although network intrusion detection systems (IDSs) have been studied for several years, their operators are still overwhelmed by a large number of false-positive alerts. In this work we study the following problem: from a large archive of intrusion alerts collected in a production network, we want to detect with a small number of false positives hosts within the network that have been infected by malware. Solving this problem is essential not only for reducing the false-positive rate of IDSs, but also for labeling traces collected in the wild with information about validated security incidents. We use a 9-month long dataset of IDS alerts and we first build a novel heuristic to detect infected hosts from the on average 3 million alerts we observe per day. Our heuristic uses a statistical measure to find hosts that exhibit a repeated multi-stage malicious footprint involving specific classes of alerts. A significant part of our work is devoted to the validation of our heuristic. We conduct a complex experiment to assess the security of suspected infected systems in a production environment using data from several independent sources, including intrusion alerts, blacklists, host scanning logs, vulnerability reports, and search engine queries. We find that the false positive rate of our heuristic is 15% and analyze in-depth the root causes of the false positives. Having validated our heuristic, we apply it to our entire trace, and characterize various important properties of 9 thousand infected hosts in total. For example, we find that among the infected hosts, a small number of heavy hitters originate most outbound attacks and that future infections are more likely to occur close to already infected hosts."
628422,15510,9969,Time-Optimal Interactive Proofs for Circuit Evaluation,2013,"Recently, researchers have been working toward the development of practical general-purpose protocols for verifiable computation. These protocols enable a computationally weak verifier to offload computations to a powerful but untrusted prover, while providing the verifier with a guarantee that the prover performed the computations correctly. Despite substantial progress, existing implementations are not yet practical. The main bottleneck is typically the extra effort required by the prover to return an answer with a guarantee of correctness, compared to returning an answer with no guarantee. #R##N#We describe a refinement of a powerful interactive proof protocol originally due to Goldwasser, Kalai, and Rothblum. Cormode, Mitzenmacher, and Thaler show how to implement the prover in this protocol in time O(S log S), where S is the size of an arithmetic circuit computing the function of interest. Our refinements apply to circuits whose wiring pattern is sufficiently regular; for these circuits, we bring the runtime of the prover down to O(S). That is, our prover can evaluate the circuit with a guarantee of correctness, with only a constant-factor blowup in work compared to evaluating the circuit with no guarantee. #R##N#We argue that our refinements capture a large class of circuits, and prove some theorems formalizing this. Experimentally, our refinements yield a 200x speedup for the prover over the implementation of Cormode et al., and our prover is less than 10x slower than a C++ program that simply evaluates the circuit. Along the way, we describe a special-purpose protocol for matrix multiplication that is of interest in its own right. #R##N#Our final contribution is a protocol targeted at general data parallel computation. Compared to prior work, this protocol can more efficiently verify complicated computations as long as that computation is applied independently to many pieces of data."
1074876,15510,20754,Smashing the Gadgets: Hindering Return-Oriented Programming Using In-place Code Randomization,2012,"The wide adoption of non-executable page protections in recent versions of popular operating systems has given rise to attacks that employ return-oriented programming (ROP) to achieve arbitrary code execution without the injection of any code. Existing defenses against ROP exploits either require source code or symbolic debugging information, or impose a significant runtime overhead, which limits their applicability for the protection of third-party applications. In this paper we present in-place code randomization, a practical mitigation technique against ROP attacks that can be applied directly on third-party software. Our method uses various narrow-scope code transformations that can be applied statically, without changing the location of basic blocks, allowing the safe randomization of stripped binaries even with partial disassembly coverage. These transformations effectively eliminate about 10%, and probabilistically break about 80% of the useful instruction sequences found in a large set of PE files. Since no additional code is inserted, in-place code randomization does not incur any measurable runtime overhead, enabling it to be easily used in tandem with existing exploit mitigations such as address space layout randomization. Our evaluation using publicly available ROP exploits and two ROP code generation toolkits demonstrates that our technique prevents the exploitation of the tested vulnerable Windows 7 applications, including Adobe Reader, as well as the automated construction of alternative ROP payloads that aim to circumvent in-place code randomization using solely any remaining unaffected instruction sequences."
59420,15510,9969,The PHOTON family of lightweight Hash functions,2011,"RFID security is currently one of the major challenges cryptography has to face, often solved by protocols assuming that an ontag hash function is available. In this article we present the PHOTON lightweight hash-function family, available in many different flavors and suitable for extremely constrained devices such as passive RFID tags. Our proposal uses a sponge-like construction as domain extension algorithm and an AES-like primitive as internal unkeyed permutation. This allows us to obtain the most compact hash function known so far (about 1120 GE for 64-bit collision resistance security), reaching areas very close to the theoretical optimum (derived from the minimal internal state memory size). Moreover, the speed achieved by PHOTON also compares quite favorably to its competitors. This is mostly due to the fact that unlike for previously proposed schemes, our proposal is very simple to analyze and one can derive tight AES-like bounds on the number of active Sboxes. This kind of AES-like primitive is usually not well suited for ultra constrained environments, but we describe in this paper a new method for generating the column mixing layer in a serial way, lowering drastically the area required. Finally, we slightly extend the sponge framework in order to offer interesting trade-offs between speed and preimage security for small messages, the classical use-case in hardware."
2263972,15510,10192,Securing Mobile Devices with Biotelemetry,2011,"As the value of information placed on mobile devices increases, so does the risk that the information will be lost or stolen. In dire scenarios, such as soldiers on the battlefield, there is a tension between accessing critical information quickly and protecting that information from unauthorized viewers. Lightweight body sensors that detect and process physiological information can provide an unconventional means for simultaneously securing data on a mobile device and making pertinent health information available to authorized remote viewers. In this paper we present the design, implementation, and evaluation of our three-tier Secure Mobile Computing (SMC) system. Tier one consists of a physiological sensor (initially an electrocardiograph), microcontroller, and radio (initially Bluetooth) with the form factor of a bandage, collectively termed the patch. The patch prototype collects and processes electrocardiograph (ECG) data and transmits the processed information over the wireless channel either continuously or periodically. The primary processing functionality, the heartbeat detection algorithm, has an average accuracy of over 99.5%. Tier two is the mobile device (e.g., cell phone, PDA, or laptop). SMC makes the utility of the mobile device dependent upon receipt of the patch's telemetry signal. SMC supports a number of programmable security policies that can either lock (e.g., encrypt) or erase data if the user is incapacitated or the mobile device loses proximity to the patch. Tier three is a web service that allows authorized viewers to view the sensor information remotely. We explore how SMC manages the interfaces between the tiers to implement security policies on the mobile device."
2323233,15510,339,A11y Attacks: Exploiting Accessibility in Operating Systems,2014,"Driven in part by federal law, accessibility (a11y) support for disabled users is becoming ubiquitous in commodity OSs. Some assistive technologies such as natural language user interfaces in mobile devices are welcomed by the general user population. Unfortunately, adding new features in modern, complex OSs usually introduces new security vulnerabilities. Accessibility support is no exception. Assistive technologies can be defined as computing subsystems that either transform user input into interaction requests for other applications and the underlying OS, or transform application and OS output for display on alternative devices. Inadequate security checks on these new I/O paths make it possible to launch attacks from accessibility interfaces. In this paper, we present the first security evaluation of accessibility support for four of the most popular computing platforms: Microsoft Windows, Ubuntu Linux, iOS, and Android. We identify twelve attacks that can bypass state-of-the-art defense mechanisms deployed on these OSs, including UAC, the Yama security module, the iOS sandbox, and the Android sandbox. Further analysis of the identified vulnerabilities shows that their root cause is that the design and implementation of accessibility support involves inevitable trade-offs among compatibility, usability, security, and (economic) cost. These trade-offs make it difficult to secure a system against misuse of accessibility support. Based on our findings, we propose a number of recommendations to either make the implementation of all necessary security checks easier and more intuitive, or to alleviate the impact of missing/incorrect checks. We also point out open problems and challenges in automatically analyzing accessibility support and identifying security vulnerabilities."
1992481,15510,20754,SoK: Eternal War in Memory,2013,"Memory corruption bugs in software written in low-level languages like C or C++ are one of the oldest problems in computer security. The lack of safety in these languages allows attackers to alter the program's behavior or take full control over it by hijacking its control flow. This problem has existed for more than 30 years and a vast number of potential solutions have been proposed, yet memory corruption attacks continue to pose a serious threat. Real world exploits show that all currently deployed protections can be defeated. This paper sheds light on the primary reasons for this by describing attacks that succeed on today's systems. We systematize the current knowledge about various protection techniques by setting up a general model for memory corruption attacks. Using this model we show what policies can stop which attacks. The model identifies weaknesses of currently deployed techniques, as well as other proposed protections enforcing stricter policies. We analyze the reasons why protection mechanisms implementing stricter polices are not deployed. To achieve wide adoption, protection mechanisms must support a multitude of features and must satisfy a host of requirements. Especially important is performance, as experience shows that only solutions whose overhead is in reasonable bounds get deployed. A comparison of different enforceable policies helps designers of new protection mechanisms in finding the balance between effectiveness (security) and efficiency. We identify some open research problems, and provide suggestions on improving the adoption of newer techniques."
587586,15510,11345,Naturally Rehearsing Passwords,2013,"We introduce quantitative usability and security models to guide the design of password management schemes — systematic strate- gies to help users create and remember multiple passwords. In the same way that security proofs in cryptography are based on complexity- theoretic assumptions (e.g., hardness of factoring and discrete loga- rithm), we quantify usability by introducing usability assumptions .I n particular, password management relies on assumptions about human memory, e.g., that a user who follows a particular rehearsal schedule will successfully maintain the corresponding memory. These assumptions are informed by research in cognitive science and can be tested empirically. Given rehearsal requirements and a user's visitation schedule for each account, we use the total number of extra rehearsals that the user would have to do to remember all of his passwords as a measure of the usability of the password scheme. Our usability model leads us to a key observa- tion: password reuse benefits users not only by reducing the number of passwords that the user has to memorize, but more importantly by in- creasing the natural rehearsal rate for each password. We also present a security model which accounts for the complexity of password man- agement with multiple accounts and associated threats, including online, offline, and plaintext password leak attacks. Observing that current pass- word management schemes are either insecure or unusable, we present Shared Cues — a new scheme in which the underlying secret is strategi- cally shared across accounts to ensure that most rehearsal requirements are satisfied naturally while simultaneously providing strong security. The construction uses the Chinese Remainder Theorem to achieve these competing goals."
2514984,15510,20592,Enabling fine-grained permissions for augmented reality applications with recognizers,2013,"Augmented reality (AR) applications sense the environment, then render virtual objects on human senses. Examples include smartphone applications that annotate storefronts with reviews and XBox Kinect games that show avatars mimicking human movements. No current OS has special support for such applications. As a result, permissions for AR applications are necessarily coarse-grained: applications must ask for access to raw sensor feeds, such as video and audio. These raw feeds expose significant additional information beyond what applications need, including sensitive information such as the user's location, face, or surroundings.#R##N##R##N#Instead of exposing raw sensor data to applications directly, we introduce a new OS abstraction: the recognizer. A recognizer takes raw sensor data as input and exposes higher-level objects, such as a skeleton or a face, to applications. We propose a fine-grained permission system where applications request permissions at the granularity of recognizer objects. We analyze 87 shipping AR applications and find that a set of four core recognizers covers almost all current apps. We also introduce privacy goggles, a visualization of sensitive data exposed to an application. Surveys of 962 people establish a clear privacy ordering over recognizers and demonstrate that privacy goggles are effective at communicating application capabilities. We build a prototype on Windows that exposes nine recognizers to applications, including the Kinect skeleton tracker. Our prototype incurs negligible overhead for single applications, while improving performance of concurrent applications and enabling secure offloading of heavyweight recognizer computation."
2181921,15510,20754,ILR: Where'd My Gadgets Go?,2012,"Through randomization of the memory space and the confinement of code to non-data pages, computer security researchers have made a wide range of attacks against program binaries more difficult. However, attacks have evolved to exploit weaknesses in these defenses. To thwart these attacks, we introduce a novel technique called Instruction Location Randomization (ILR). Conceptually, ILR randomizes the location of every instruction in a program, thwarting an attacker's ability to re-use program functionality (e.g., arc-injection attacks and return-oriented programming attacks). ILR operates on arbitrary executable programs, requires no compiler support, and requires no user interaction. Thus, it can be automatically applied post-deployment, allowing easy and frequent re-randomization. Our preliminary prototype, working on 32-bit x86 Linux ELF binaries, provides a high degree of entropy. Individual instructions are randomly placed within a 31-bit address space. Thus, attacks that rely on a priori knowledge of the location of code or derandomization are not feasible. We demonstrated ILR's defensive capabilities by defeating attacks against programs with vulnerabilities, including Adobe's PDF viewer, acroread, which had an in-the-wild vulnerability. Additionally, using an industry-standard CPU performance benchmark suite, we compared the run time of prototype ILR-protected executables to that of native executables. The average run-time overhead of ILR was 13% with more than half the programs having effectively no overhead (15 out of 29), indicating that ILR is a realistic and cost-effective mitigation technique."
27824,15510,10286,Chosen Ciphertext Security via UCE,2014,"Bellare, Hoang, and Keelveedhi CRYPTO'13 introduced a security notion for a family of hash functions called universal computational extractor UCE, and showed how it can be used to realize various kinds of cryptographic primitives in the standard model whose efficient constructions were only known in the random oracle model. Although the results of Bellare et al. have shown that UCEs are quite powerful and useful, the notion of UCE is new, and its potential power and limitation do not seem to have been clarified well. To further widen and deepen our understanding of UCE, in this paper we study the construction of chosen ciphertext secure CCA secure public key encryption PKE, one of the most important primitives in the area of cryptography to which inapplicability of UCEs was not covered by the work of Bellare et al.#R##N##R##N#We concretely consider the setting in which other than a UCE, we only use chosen plaintext secure CPA secure PKE as an additional building block, and obtain several negative and positive results. As our negative results, we show difficulties of instantiating the random oracle in the Fujisaki-Okamoto FO construction PKC'99 with a UCE, by exhibiting pairs of CPA secure PKE and a UCE for which the FO construction instantiated with these pairs becomes insecure assuming that CPA secure PKE and a UCE exist at all. Then, as our main positive result, we show how to construct a CCA secure PKE scheme using only CPA secure PKE and a UCE as building blocks. Furthermore, we also show how to extend this result to a CCA secure deterministic PKE scheme for block sources with some constraint on the running time of the sources. Our positive results employ the ideas and techniques from the Dolev-Dwork-Naor DDN construction STOC'91, and for convenience we abstract and formalize the ''core structure of the DDN construction as a stand-alone primitive that we call puncturable tag-based encryption, which might be of independent interest."
135787,15510,9874,Contextual OTP: mitigating emerging man-in-the-middle attacks with wireless hardware tokens,2012,"OTP (One Time Password) devices are highly deployed trust enhancing (password entropy increasing) devices which are used to authenticate a user with a second factor (a pseudorandom sequence of digits produced by a device the user owns) and to cope with off-line phishing of password information. Wireless connection adds usability to OTP protocols in an obvious way: instead of the person copying the information between machines, the wireless (say, Bluetooth) mechanism can transfer the value directly. Indeed, OTP devices implemented in a smartphone and communicating with the browser over Bluetooth can act in usable fashion (and this extension was implemented in our organization and got very positive usability feedback). What we then noticed as a key observation is that this mode of OTP wireless transfer has turned the man to machine nature of the OTP tokens to a (mobile) device to machine (the browser on the computer) method, so we can now employ protocols between the two interacting computers. Thus, we asked what can this new mode contribute to security (rather than to usability only) and cope with increased set of attacks. Specifically, the question we are dealing with is whether wireless OTP devices (i.e., smartphones) can be hardened at a reasonable cost (i.e., without costly OTP infrastructural changes, public-key infrastructure/ operations, and with small modification to browsers) so as to be useful against one type of interesting and currently growing and highly publicized Man in the Middle (MITM) attacks. The work herein summarizes our study which is based on our proposed new notion of Contextual OTP (XOTP for short), which exploits session contexts to break the symmetry between the user-MITM and the MITM-server sessions."
1377332,15510,20754,Finding the Linchpins of the Dark Web: a Study on Topologically Dedicated Hosts on Malicious Web Infrastructures,2013,"Malicious Web activities continue to be a major threat to the safety of online Web users. Despite the plethora forms of attacks and the diversity of their delivery channels, in the back end, they are all orchestrated through malicious Web infrastructures, which enable miscreants to do business with each other and utilize others' resources. Identifying the linchpins of the dark infrastructures and distinguishing those valuable to the adversaries from those disposable are critical for gaining an upper hand in the battle against them. In this paper, using nearly 4 million malicious URL paths crawled from different attack channels, we perform a large-scale study on the topological relations among hosts in the malicious Web infrastructure. Our study reveals the existence of a set of topologically dedicated malicious hosts that play orchestrating roles in malicious activities. They are well connected to other malicious hosts and do not receive traffic from legitimate sites. Motivated by their distinctive features in topology, we develop a graph-based approach that relies on a small set of known malicious hosts as seeds to detect dedicate malicious hosts in a large scale. Our method is general across the use of different types of seed data, and results in an expansion rate of over 12 times in detection with a low false detection rate of 2%. Many of the detected hosts operate as redirectors, in particular Traffic Distribution Systems (TDSes) that are long-lived and receive traffic from new attack campaigns over time. These TDSes play critical roles in managing malicious traffic flows. Detecting and taking down these dedicated malicious hosts can therefore have more impact on the malicious Web infrastructures than aiming at short-lived doorways or exploit sites."
201794,15510,9969,Behind the Scene of Side Channel Attacks,2013,"Since the introduction of side channel attacks in the nineties, a large amount of work has been devoted to their effectiveness and efficiency improvements. On the one side, general results and conclusions are drawn in theoretical frameworks, but the latter ones are often set in a too ideal context to capture the full complexity of an attack performed in real conditions. On the other side, practical improvements are proposed for specific contexts but the big picture is often put aside, which makes them difficult to adapt to different contexts. This paper tries to bridge the gap between both worlds. We specifically investigate which kind of issues is faced by a security evaluator when performing a state of the art attack. This analysis leads us to focus on the very common situation where the exact time of the sensitive processing is drown in a large number of leakage points. In this context we propose new ideas to improve the effectiveness and/or efficiency of the three considered attacks. In the particular case of stochastic attacks, we show that the existing literature, essentially developed under the assumption that the exact sensitive time is known, cannot be directly applied when the latter assumption is relaxed. To deal with this issue, we propose an improvement which makes stochastic attack a real alternative to the classical correlation power analysis. Our study is illustrated by various attack experiments performed on several copies of three micro-controllers with different CMOS technologies respectively 350, 130 and 90 nanometers."
72217,15510,11345,Authenticating Computation on Groups: New Homomorphic Primitives and Applications,2014,"In this paper we introduce new primitives to authenticate computation on data expressed as elements in (cryptographic) groups. As for the case of homomorphic authenticators, our primitives allow to verify the correctness of the computation without having to know of the original data set. More precisely, our contributions are two-fold. First, we introduce the notion of linearly homomorphic authenticated encryption with public verifiability and show how to instantiate this prim- itive (in the random oracle model) to support Paillier's ciphertexts. This immediately yields a very simple and efficient (publicly) verifiable com- putation mechanism for encrypted (outsourced) data based on Paillier's cryptosystem. As a second result, we show how to construct linearly homomorphic signature schemes to sign elements in bilinear groups (LHSG for short). Such type of signatures are very similar to (linearly homomorphic) struc- ture preserving ones, but they allow for more flexibility, as the signature is explicitly allowed to contain components which are not group ele- ments. In this sense our contributions are as follows. First we show a very simple construction of LHSG that is secure against weak random message attack (RMA). Next we give evidence that RMA secure LHSG are interesting on their own right by showing applications in the con- text of on-line/off-line homomorphic and network coding signatures. This notably provides what seems to be the first instantiations of homomor- phic signatures achieving on-line/off-line efficiency trade-offs. Finally, we present a generic transform that converts RMA-secure LHSG into ones that achieve full security guarantees."
1438254,15510,339,"Attacks against process control systems: risk assessment, detection, and response",2011,"In the last years there has been an increasing interest in the security of process control and SCADA systems. Furthermore, recent computer attacks such as the Stuxnet worm, have shown there are parties with the motivation and resources to effectively attack control systems.   While previous work has proposed new security mechanisms for control systems, few of them have explored new and fundamentally different research problems for securing control systems when compared to securing traditional information technology (IT) systems. In particular, the sophistication of new malware attacking control systems--malware including zero-days attacks, rootkits created for control systems, and software signed by trusted certificate authorities--has shown that it is very difficult to prevent and detect these attacks based solely on IT system information.   In this paper we show how, by incorporating knowledge of the physical system under control, we are able to detect computer attacks that change the behavior of the targeted control system. By using knowledge of the physical system we are able to focus on the final objective of the attack, and not on the particular mechanisms of how vulnerabilities are exploited, and how the attack is hidden. We analyze the security and safety of our mechanisms by exploring the effects of stealthy attacks, and by ensuring that automatic attack-response mechanisms will not drive the system to an unsafe state.   A secondary goal of this paper is to initiate the discussion between control and security practitioners--two areas that have had little interaction in the past. We believe that control engineers can leverage security engineering to design--based on a combination of their best practices--control algorithms that go beyond safety and fault tolerance, and include considerations to survive targeted attacks."
1633016,15510,9856,Mitigating code-reuse attacks with control-flow locking,2011,"Code-reuse attacks are software exploits in which an attacker directs control flow through existing code with a malicious result. One such technique, return-oriented programming, is based on gadgets (short pre-existing sequences of code ending in a ret instruction) being executed in arbitrary order as a result of a stack corruption exploit. Many existing codereuse defenses have relied upon a particular attribute of the attack in question (e.g., the frequency of ret instructions in a return-oriented attack), which leads to an incomplete protection, while a smaller number of efforts in protecting  all  exploitable control flow transfers suffer from limited deploy-ability due to high performance overhead. In this paper, we present a novel cost-effective defense technique called  control flow locking , which allows for effective enforcement of control flow integrity with a small performance overhead. Specifically, instead of immediately determining whether a control flow violation happens before the control flow transfer takes place, control flow locking lazily detects the violation after the transfer. To still restrict attackers' capability, our scheme guarantees that the deviation of the normal control flow graph will only occur  at most  once. Further, our scheme ensures that this deviation cannot be used to craft a malicious system call, which denies any potential gains an attacker might obtain from what is permitted in the threat model. We have developed a proof-of-concept prototype in Linux and our evaluation demonstrates desirable effectiveness and competitive performance overhead with existing techniques. In several benchmarks, our scheme is able to achieve significant gains."
1873640,15510,339,Forgery-resilience for digital signature schemes,2012,"We introduce the notion of forgery-resilience for digital signature schemes, a new paradigm exhibiting desirable legislative properties. It evolves around the idea that, for any message, there can only be a unique  valid  signature, and exponentially many  acceptable  signatures, all but one of them being  spurious .   This primitive enables a judge to verify whether an alleged forged signature is indeed a forgery. In particular, the scheme considers an adversary who has access to a signing oracle and an oracle that solves a hard problem, and who tries to produce a signature that appears to be acceptable from a verifier's point of view. However, a judge can tell apart such a spurious signature from a legitimate signature. This property is referred to as  validatibility . Moreover, the scheme provides  undeniability  against malicious signers who try to fabricate spurious signatures and deny them later by showing that they are not valid. Last but not least,  trustability  refers to the inability of a malicious judge trying to forge a valid signature.   This notion for signature schemes improves upon the notion of fail-stop signatures in different ways. For example, it is possible to sign more than one messages with forgery-resilient signatures and once a forgery is found, the credibility of a previously signed signature is not under question.   A concrete instance of a forgery-resilient signature scheme is constructed based on the hardness of extracting roots of higher residues, which we show to be equivalent to the factoring assumption. In particular, using collision-free accumulators, we present a tight reduction from malicious signers to adversaries against the factoring problem. Meanwhile, a secure pseudorandom function ensures that no  polynomially-bounded cheating verifier , who can still solve hard problems, is able to forge valid signatures. Security against malicious judges is based on the RSA assumption."
614848,15510,20592,TRUESET: faster verifiable set computations,2014,"Verifiable computation (VC) enables thin clients to efficiently verify the computational results produced by a powerful server. Although VC was initially considered to be mainly of theoretical interest, over the last two years impressive progress has been made on implementing VC. Specifically, we now have open-source implementations of VC systems that handle all classes of computations expressed either as circuits or in the RAM model. Despite this very encouraging progress, new enhancements in the design and implementation of VC protocols are required to achieve truly practical VC for real-world applications.#R##N##R##N#In this work, we show that for functions that can be expressed efficiently in terms of set operations (e.g., a subset of SQL queries) VC can be enhanced to become drastically more practical: We present the design and prototype implementation of a novel VC scheme that achieves orders of magnitude speed-up in comparison with the state of the art. Specifically, we build and evaluate TRUESET, a system that can verifiably compute any polynomial-time function expressed as a circuit consisting of set gates such as union, intersection, difference and set cardinality. Moreover, TRUESET supports hybrid circuits consisting of both set gates and traditional arithmetic gates. Therefore, it does not lose any of the expressiveness of previous schemes--this also allows the user to choose the most efficient way to represent different parts of a computation. By expressing set computations as polynomial operations and introducing a novel Quadratic Polynomial Program technique, our experiments show that TRUESET achieves prover performance speed-up ranging from 30x to 150x and up to 97% evaluation key size reduction compared to the state-of-the-art."
971145,15510,339,PCTCP: per-circuit TCP-over-IPsec transport for anonymous communication overlay networks,2013,"Recently, there have been several research efforts to design a transport layer that meets the security requirements of anonymous communications while maximizing the network performance experienced by users. In this work, we argue that existing proposals suffer from several performance and deployment issues and we introduce PCTCP, a novel anonymous communication transport design for overlay networks that addresses the shortcomings of the previous proposals. In PCTCP, every overlay path, or circuit, is assigned a separate kernel-level TCP connection that is protected by IPsec, the standard security layer for IP.   To evaluate our work, we focus on the Tor network, the most popular low-latency anonymity network, which is notorious for its performance problems that can potentially deter its wider adoption and thereby impact its anonymity. Previous research showed that the current transport layer design of Tor, in which several circuits are multiplexed in a single TCP connection between any pair of routers, is a key contributor to Tor's performance issues.   We implemented, experimentally evaluated, and confirmed the potential gains provided by PCTCP in an isolated testbed and on the live Tor network. We ascertained that significant performance benefits can be obtained using our approach for web clients, while maintaining the same level of anonymity provided by the network today. Our realistic large-scale experimental evaluation of PCTCP shows improvements of more than 60% for response times and approximately 30% for download times compared to Tor. Finally, PCTCP only requires minimal changes to Tor and is easily deployable, as it does not require all routers on a circuit to upgrade."
663482,15510,20349,Header space analysis: static checking for networks,2012,"Today's networks typically carry or deploy dozens of protocols and mechanisms simultaneously such as MPLS, NAT, ACLs and route redistribution. Even when individual protocols function correctly, failures can arise from the complex interactions of their aggregate, requiring network administrators to be masters of detail. Our goal is to automatically find an important class of failures, regardless of the protocols running, for both operational and experimental networks.#R##N##R##N#To this end we developed a general and protocol-agnostic framework, called Header Space Analysis (HSA). Our formalism allows us to statically check network specifications and configurations to identify an important class of failures such as Reachability Failures, Forwarding Loops and Traffic Isolation and Leakage problems. In HSA, protocol header fields are not first class entities; instead we look at the entire packet header as a concatenation of bits without any associated meaning. Each packet is a point in the {0,1}L space where L is the maximum length of a packet header, and networking boxes transform packets from one point in the space to another point or set of points (multicast).#R##N##R##N#We created a library of tools, called Hassel, to implement our framework, and used it to analyze a variety of networks and protocols. Hassel was used to analyze the Stanford University backbone network, and found all the forwarding loops in less than 10 minutes, and verified reachability constraints between two subnets in 13 seconds. It also found a large and complex loop in an experimental loose source routing protocol in 4 minutes."
728786,15510,339,Librando: transparent code randomization for just-in-time compilers,2013,"Just-in-time compilers (JITs) are here to stay. Unfortunately, they also provide new capabilities to cyber attackers, namely the ability to supply input programs (in languages such as JavaScript) that will then be compiled to executable code. Once this code is placed and marked as executable, it can then be leveraged by the attacker.   Randomization techniques such as constant blinding raise the cost to the attacker, but they significantly add to the burden of implementing a JIT. There are a great many JITs in use today, but not even all of the most commonly used ones randomize their outputs.   We present librando, the first comprehensive technique to harden JIT compilers in a completely generic manner by randomizing their output transparently ex post facto. We implement this approach as a system-wide service that can simultaneously harden multiple running JITs. It hooks into the memory protections of the target OS and randomizes newly generated code on the fly when marked as executable.   In order to provide black box JIT hardening, librando needs to be extremely conservative. For example, it completely preserves the contents of the calling stack, presenting each JIT with the illusion that it is executing its own generated code. Yet in spite of the heavy lifting that librando performs behind the scenes, the performance impact is surprisingly low. For Java (HotSpot), we measured slowdowns by a factor of 1.15x, and for compute-intensive JavaScript (V8) benchmarks, a slowdown of 3.5x.   For many applications, this overhead is low enough to be practical for general use today."
1901566,15510,339,Designing leakage-resilient password entry on touchscreen mobile devices,2013,"Touchscreen mobile devices are becoming commodities as the wide adoption of pervasive computing. These devices allow users to access various services at anytime and anywhere. In order to prevent unauthorized access to these services, passwords have been pervasively used in user authentication. However, password-based authentication has intrinsic weakness in password leakage. This threat could be more serious on mobile devices, as mobile devices are widely used in public places.   Most prior research on improving leakage resilience of password entry focuses on desktop computers, where specific restrictions on mobile devices such as small screen size are usually not addressed. Meanwhile, additional features of mobile devices such as touch screen are not utilized, as they are not available in the traditional settings with only physical keyboard and mouse. In this paper, we propose a user authentication scheme named CoverPad for password entry on touchscreen mobile devices. CoverPad improves leakage resilience by safely delivering hidden messages, which break the correlation between the underlying password and the interaction information observable to an adversary. It is also designed to retain most benefits of legacy passwords, which is critical to a scheme intended for practical use. The usability of CoverPad is evaluated with an extended user study which includes additional test conditions related to time pressure, distraction, and mental workload. These test conditions simulate common situations for a password entry scheme used on a daily basis, which have not been evaluated in the prior literature. The results of our user study show the impacts of these test conditions on user performance as well as the practicability of the proposed scheme."
1287194,15510,339,POSTER: When and How to Implicitly Authenticate Smartphone Users,2014,"Possession of modern smartphones is becoming increasingly ubiquitous, and with this rise in usage comes a rise in the amount of sensitive data being stored on them. Despite this, the high-frequency, low-duration nature of the average smartphone session makes passwords or PIN-locks even less usable than in the desktop context. To combat these issues, implicit authentication (IA) schemes can be developed and deployed to smartphones. IA schemes continuously authenticate users by profiling their behaviour using the variety of sensors prevalent on the phones, such as touchscreens and accelerometers. When a non-owner acquires the device and attempts to access sensitive data on it, the IA scheme recognizes the difference in behaviour and automatically ejects the attacker from the system. In particularly sensitive contexts, IA schemes can also be deployed as a secondary defence mechanism on top of explicit authentication, providing layered security in the event of, for example, a shoulder-surfing attack compromising the device's PIN or an operating system vulnerability allowing its bypass. In this work, we evaluate existing proposals for IA schemes using different behavioural feature sets, and evaluate them against real-world data to show when they are (and are not) useful. We have implemented them in an easily extensible open source framework for the Android operating system called Itus, which allows other researchers to iteratively improve on the existing mechanisms for performing IA. Itus performs IA at the app level, which we have shown allows app developers to selectively protect sensitive data while decreasing the impact on battery life and device performance, and at the same time obtaining better detection accuracy for the IA scheme being invoked."
1794878,15510,9856,IMSI-catch me if you can: IMSI-catcher-catchers,2014,"IMSI Catchers  are used in mobile networks to identify and eavesdrop on phones. When, the number of vendors increased and prices dropped, the device became available to much larger audiences. Self-made devices based on open source software are available for about US$ 1,500.   In this paper, we identify and describe multiple methods of detecting artifacts in the mobile network produced by such devices. We present two independent novel implementations of an  IMSI Catcher Catcher  (ICC) to detect this threat against everyone's privacy. The first one employs a network of stationary (sICC) measurement units installed in a geographical area and constantly scanning all frequency bands for cell announcements and fingerprinting the cell network parameters. These rooftop-mounted devices can cover large areas. The second implementation is an app for standard consumer grade mobile phones (mICC), without the need to  root  or  jailbreak  them. Its core principle is based upon geographical network topology correlation, facilitating the ubiquitous built-in GPS receiver in today's phones and a network cell capabilities fingerprinting technique. The latter works for the vicinity of the phone by first learning the cell landscape and than matching it against the learned data. We implemented and evaluated both solutions for digital self-defense and deployed several of the stationary units for a long term field-test. Finally, we describe how to detect recently published denial of service attacks."
833484,15510,339,CHEX: statically vetting Android apps for component hijacking vulnerabilities,2012,"An enormous number of apps have been developed for Android in recent years, making it one of the most popular mobile operating systems. However, the quality of the booming apps can be a concern [4]. Poorly engineered apps may contain security vulnerabilities that can severally undermine users' security and privacy. In this paper, we study a general category of vulnerabilities found in Android apps, namely the component hijacking vulnerabilities. Several types of previously reported app vulnerabilities, such as permission leakage, unauthorized data access, intent spoofing, and etc., belong to this category.   We propose CHEX, a static analysis method to automatically vet Android apps for component hijacking vulnerabilities. Modeling these vulnerabilities from a data-flow analysis perspective, CHEX analyzes Android apps and detects possible hijack-enabling flows by conducting low-overhead reachability tests on customized system dependence graphs. To tackle analysis challenges imposed by Android's special programming paradigm, we employ a novel technique to discover component entry points in their completeness and introduce app splitting to model the asynchronous executions of multiple entry points in an app.   We prototyped CHEX based on Dalysis, a generic static analysis framework that we built to support many types of analysis on Android app bytecode. We evaluated CHEX with 5,486 real Android apps and found 254 potential component hijacking vulnerabilities. The median execution time of CHEX on an app is 37.02 seconds, which is fast enough to be used in very high volume app vetting and testing scenarios."
1014414,15510,339,Practical secret key agreement for full-duplex near field communications,2014,"Near Field Communication (NFC) is a promising short distance radio communication technology for many useful applications. Although its communication range is short, NFC alone does not guarantee secure communication and is subject to security attacks, such as eavesdropping attack. Generating a shared key and using symmetric key cryptography to secure the communication between NFC devices is a feasible solution to prevent various attacks. However, conventional Diffie-Hellman key agreement protocol is not preferable for resource constrained NFC devices due to its extensive computational overhead and energy consumption. In this paper, we propose a practical, fast and energy-efficient key agreement scheme, called RIWA (Random bIts transmission with Waveform shAking), for NFC devices by exploiting its full-duplex capability. In RIWA, two devices send random bits to each other simultaneously without strict synchronization or perfect match of amplitude and phase. On the contrary, RIWA randomly introduces synchronization offset and mismatch of amplitude and phase for each bit transmission in order to prevent a passive attacker from determining the generated key. A shared bit can be established when two devices send different bits. We conduct theoretical analysis on the correctness and security strength of RIWA, and extensive simulations to evaluate its effectiveness. We build a testbed based on USRP software defined radio and conduct proof-of-concept experiments to evaluate RIWA in a real-world environment. It shows that RIWA achieves a high key generation rate about 26kbps and is immune to eavesdropping attack even when the attacker is within several centimeters away from the legitimate devices. RIWA is a practical, fast, energy-efficient, and secure key agreement scheme for resource-constrained NFC devices."
2446445,15510,9856,GPU and CPU parallelization of honest-but-curious secure two-party computation,2013,"Recent work demonstrates the feasibility and practical use of secure two-party computation [5, 9, 15, 23]. In this work, we present the first Graphical Processing Unit (GPU)-optimized implementation of an optimized Yao's garbled-circuit protocol for two-party secure computation in the honest-but-curious and 1-bit-leaked malicious models. We implement nearly all of the modern protocol advancements, such as Free-XOR, Pipelining, and OT extension. Our implementation is the first allowing entire circuits to be generated concurrently, and makes use of a modification of the XOR technique so that circuit generation is optimized for implementation on SIMD architectures of GPUs. In our best cases we generate about 75 million gates per second and we exceed the state of the art performance metrics on modern CPU systems by a factor of about 200, and GPU systems by about a factor of 2.3. While many recent works on garbled circuits exploit the embarrassingly parallel nature of many tasks that are part of a secure computation protocol, we show that there are still various forms and levels of parallelization that may yet improve the performance of these protocols. In particular, we highlight that implementations on the SIMD architecture of modern GPUs require significantly different approaches than the general purpose MIMD architecture of multi-core CPUs, which again differ from the needs of parallelizing on compute clusters. Additionally, modifications to the security models for many common protocols have large effects on reasonable parallel architectures for implementation."
1777168,15510,20338,Suspended accounts in retrospect: an analysis of twitter spam,2011,"In this study, we examine the abuse of online social networks at the hands of spammers through the lens of the tools, techniques, and support infrastructure they rely upon. To perform our analysis, we identify over 1.1 million accounts suspended by Twitter for disruptive activities over the course of seven months. In the process, we collect a dataset of 1.8 billion tweets, 80 million of which belong to spam accounts. We use our dataset to characterize the behavior and lifetime of spam accounts, the campaigns they execute, and the wide-spread abuse of legitimate web services such as URL shorteners and free web hosting. We also identify an emerging marketplace of illegitimate programs operated by spammers that include Twitter account sellers, ad-based URL shorteners, and spam affiliate programs that help enable underground market diversification.   Our results show that 77% of spam accounts identified by Twitter are suspended within on day of their first tweet. Because of these pressures, less than 9% of accounts form social relationships with regular Twitter users. Instead, 17% of accounts rely on hijacking trends, while 52% of accounts use unsolicited mentions to reach an audience. In spite of daily account attrition, we show how five spam campaigns controlling 145 thousand accounts combined are able to persist for months at a time, with each campaign enacting a unique spamming strategy. Surprisingly, three of these campaigns send spam directing visitors to reputable store fronts, blurring the line regarding what constitutes spam on social networks."
1476540,15510,9836,"Continuous, Low Overhead, Run-Time Validation of Program Executions",2014,"The construction of trustworthy systems demands that the execution of every piece of code is validated as genuine, that is, the executed codes do exactly what they are supposed to do. Pre-execution validations of code integrity fail to detect run time compromises like code injection, return and jump-oriented programming, and illegal dynamic linking of program modules. We propose and evaluate a generalized mechanism called REV (for Run-time Execution Validator) that can be easily integrated into a contemporary out-of-order processor to validate, as the program executes, the control flow path and instructions executed along the control flow path. To prevent memory from being tainted by compromised code, REV also prevents updates to the memory from a basic block until its execution has been authenticated. Although control flow signature based authentication of an execution has been suggested before for software testing and for restricted cases of embedded systems, their extensions to out-of-order cores is a non-incremental effort from a micro architectural standpoint. Unlike REV, the existing solutions do not scale with binary sizes, require binaries to be altered or require new ISA support and also fail to contain errors and, in general, impose a heavy performance penalty. We show, using a detailed cycle-accurate micro architectural simulator for an out-of-order pipeline implementing the X86 ISA that the performance overhead of REV is limited to 1.87% on the average across the SPEC 2006 benchmarks."
1314528,15510,339,Using SMT solvers to automate design tasks for encryption and signature schemes,2013,"Cryptographic design tasks are primarily performed by hand today. Shifting more of this burden to computers could make the design process faster, more accurate and less expensive. In this work, we investigate tools for programmatically altering existing cryptographic constructions to reflect particular design goals. Our techniques enhance both security and efficiency with the assistance of advanced tools including Satisfiability Modulo Theories (SMT) solvers.   Specifically, we propose two complementary tools, AutoGroup and AutoStrong. AutoGroup converts a pairing-based encryption or signature scheme written in (simple) symmetric group notation into a specific instantiation in the more efficient, asymmetric setting. Some existing symmetric schemes have hundreds of possible asymmetric translations, and this tool allows the user to optimize the construction according to a variety of metrics, such as ciphertext size, key size or computation time. The AutoStrong tool focuses on the security of digital signature schemes by automatically converting an existentially unforgeable signature scheme into a strongly unforgeable one. The main technical challenge here is to automate the partitioned check, which allows a highly-efficient transformation.   These tools integrate with and complement the AutoBatch tool (ACM CCS 2012), but also push forward on the complexity of the automation tasks by harnessing the power of SMT solvers. Our experiments demonstrate that the two design tasks studied can be performed automatically in a matter of seconds."
2706713,15510,339,Deniable Liaisons,2014,"People sometimes need to communicate directly with one another while concealing the communication itself. Existing systems can allow users to achieve this level of privacy in the wide-area Internet, but parties who are in close proximity (e.g., a public square or coffee shop) may want a lightweight communications channel with similar properties. Today, covert exchanges in local settings typically require the exchange of physical media or involve other forms of direct communication (e.g., conversations, blind drops); most, if not all, of these exchanges are observable: in other words, even if the message exchanges are confidential, they are not covert or deniable. We construct a local communications channel that is unobservable to everyone except the parties exchanging messages. To do so, we take advantage of the ubiquitous phenomenon of packet corruption in wireless networks, which provide deniable cover for message exchange between parties within radio range. The communicating parties use a shared secret to differentiate truly corrupted frames from those that hide messages; to other parties, messages appear as corrupted wireless frames. We tackle the challenge of designing the observable corruption patterns to ensure that an observer can neither link sender and receiver of a hidden message(unlinkability), nor determine so much as the existence of any hidden message (deniability). We present the design and implementation of a prototype system that achieves these properties using off-the-shelf 802.11 hardware, evaluate its performance, and assess its resilience to various attacks."
445216,15510,20592,BOTMAGNIFIER: locating spambots on the internet,2011,"Unsolicited bulk email (spam) is used by cybercriminals to lure users into scams and to spread malware infections. Most of these unwanted messages are sent by spam botnets, which are networks of compromised machines under the control of a single (malicious) entity. Often, these botnets are rented out to particular groups to carry out spam campaigns, in which similar mail messages are sent to a large group of Internet users in a short amount of time. Tracking the bot-infected hosts that participate in spam campaigns, and attributing these hosts to spam botnets that are active on the Internet, are challenging but important tasks. In particular, this information can improve blacklist-based spam defenses and guide botnet mitigation efforts.#R##N##R##N#In this paper, we present a novel technique to support the identification and tracking of bots that send spam. Our technique takes as input an initial set of IP addresses that are known to be associated with spam bots, and learns their spamming behavior. This initial set is then magnified by analyzing large-scale mail delivery logs to identify other hosts on the Internet whose behavior is similar to the behavior previously modeled. We implemented our technique in a tool, called BOTMAGNIFIER, and applied it to several data streams related to the delivery of email traffic. Our results show that it is possible to identify and track a substantial number of spam bots by using our magnification technique. We also perform attribution of the identified spam hosts and track the evolution and activity of well-known spamming botnets over time. Moreover, we show that our results can help to improve state-of-the-art spam blacklists."
1160467,15510,339,Towards automated protocol reverse engineering using semantic information,2014,"Network security products, such as NIDS or application firewalls, tend to focus on application level communication flows. However, adding support for new proprietary and often undocumented protocols, implies the reverse engineering of these protocols. Currently, this task is performed manually. Considering the difficulty and time needed for manual reverse engineering of protocols, one can easily understand the importance of automating this task. This is even given more significance in today's cybersecurity context where reaction time and automated adaptation become a priority. Several studies were carried out to infer protocol's specifications from traces. As shown in this article, they do not provide accurate results on complex protocols and are often not applicable in an operational context to provide parsers or traffic generators, some key indicators of the quality of obtained specifications. In addition, too few previous works have resulted in the publication of tools that would allow the scientific community to experimentally validate and compare the different approaches.   In this paper, we infer the specifications out of complex protocols by means of an automated approach and novel techniques. Based on communication traces, we reverse the vocabulary of a protocol by considering embedded contextual information. We also use this information to improve message clustering and to enhance the identification of fields boundaries. We then show the viability of our approach through a comparative study including our reimplementation of three other state-of-the-art approaches (ASAP, Discoverer and ScriptGen)."
1288115,15510,339,Heart-to-heart (H2H): authentication for implanted medical devices,2013,"We present Heart-to-Heart (H2H), a system to authenticate external medical device controllers and programmers to Implantable Medical Devices (IMDs). IMDs, which include pacemakers and cardiac defibrillators, are therapeutic medical devices partially or wholly embedded in the human body. They often have built-in radio communication to facilitate non-invasive reprogramming and data readout. Many IMDs, though, lack well designed authentication protocols, exposing patients to over-the-air attack and physical harm.   H2H makes use of ECG (heartbeat data) as an authentication mechanism, ensuring access only by a medical instrument in physical contact with an IMD-bearing patient. Based on statistical analysis of real-world data, we propose and analyze new techniques for extracting time-varying randomness from ECG signals for use in H2H. We introduce a novel cryptographic device pairing protocol that uses this randomness to protect against attacks by active adversaries, while meeting the practical challenges of lightweight implementation and noise tolerance in ECG readings. Finally, we describe an end-to-end implementation in an ARM-Cortex M-3 microcontroller that demonstrates the practicality of H2H in current IMD hardware.   Previous schemes have had goals much like those of H2H, but with serious limitations making them unfit for deployment---such as naively designed cryptographic pairing protocols (some of them recently broken). In addition to its novel analysis and use of ECG entropy, H2H is the first physiologically-based IMD device pairing protocol with a rigorous adversarial model and protocol analysis."
188735,15510,293,One-way traffic monitoring with iatmon,2012,"During the last decade, unsolicited one-way Internet traffic has been used to study malicious activity on the Internet. Researchers usually observe such traffic using network telescopes deployed on darkspace (unused address space). When darkspace observations began ten years ago, one-way traffic was minimal. Over the last five years, however, traffic levels have risen so that they are now high enough to require more subtle differentiation --- raw packet and byte or even port counts make it hard to discern and distinguish new activities.#R##N##R##N#To make changes in composition of one-way traffic aggregates more detectable, we have developed iatmon (Inter-Arrival Time Monitor), a freely available measurement and analysis tool that allows one to separate one-way traffic into clearly-defined subsets. Initially we have implemented two subsetting schemes; source types, based on the schema proposed in [12]; and inter-arrival-time (IAT) groups that summarise source behaviour over time.#R##N##R##N#We use 14 types and 10 groups, giving us a matrix of 140 type+group subsets. Each subset constitutes only a fraction of the total traffic, so changes within the subsets are easily observable when changes in total traffic levels might not even be noticeable.#R##N##R##N#We report on our experience with this tool to observe changes in one-way traffic at the UCSD network telescope over the first half of 2011. Daily average plots of source numbers and their traffic volumes show clear long-term changes in several of our types and groups."
1016019,15510,9856,Discovery of emergent malicious campaigns in cellular networks,2013,"The growth of Smartphones has bridged the telephony/SMS and the IP worlds, and this has resulted in new opportunities for financially motivated attackers. For example, some malicious campaigns in the cellular network aimed at extracting money fraudulently can do so even without any malware. Detecting and mitigating the variety of attacks in cellular network is difficult because they do not necessarily have a fixed 'signature', and new  types  of campaigns appear frequently. Further complicating matters, detecting a single malicious entity (a domain name, a phone number, or a short code) that is part of a malicious campaign, is usually not very effective, because the attacker simply moves to using another entity in its place. An effective strategy requires detecting all/most elements involved in the campaign at once. In this paper, we describe a system, based on ideas from anomaly detection and clustering, that aims to detect many different families of widespread malicious campaigns in cellular networks. The system reveals an entire campaign as a graph cluster which includes the various entities involved in the campaign and their relationship, such as malware download websites, C&C servers, spammers, etc. Using logs from both SMS and IP portions of the network for millions of users, we detect newly popular entities and cluster them to discover how they are related. By looking for cues of possible malicious behavior from any of the entities in a cluster, we attempt to ascertain whether a detected campaign might be malicious, providing valuable leads to a human analyst. Our system is live and generates daily clusters for human analysts. We provide detailed case studies of real, previously unseen families of malicious campaigns that this system has successfully brought to light."
2022198,15510,9856,Transforming commodity security policies to enforce Clark-Wilson integrity,2012,"Modern distributed systems are composed from several off-the-shelf components, including operating systems, virtualization infrastructure, and application packages, upon which some custom application software (e.g., web application) is often deployed. While several commodity systems now include mandatory access control (MAC) enforcement to protect the individual components, the complexity of such MAC policies and the myriad of possible interactions among individual hosts in distributed systems makes it difficult to identify the attack paths available to adversaries. As a result, security practitioners  react  to vulnerabilities as adversaries uncover them, rather than  proactively protecting  the system's data integrity. In this paper, we develop a mostly-automated method to transform a set of commodity MAC policies into a system-wide policy that proactively protects system integrity, approximating the Clark-Wilson integrity model. The method uses the insights from the Clark-Wilson model, which requires integrity verification of security-critical data and mediation at program entrypoints, to extend existing MAC policies with the proactive mediation necessary to protect system integrity. We demonstrate the practicality of producing Clark-Wilson policies for distributed systems on a web application running on virtualized Ubuntu SELinux hosts, where our method finds: (1) that only 27 additional entrypoint mediators are sufficient to mediate the threats of remote adversaries over the entire distributed system and (2) and only 20 additional local threats require mediation to approximate Clark-Wilson integrity comprehensively. As a result, available security policies can be used as a foundation for proactive integrity protection from both local and remote threats."
1072624,15510,22260,Storing Shared Data on the Cloud via Security-Mediator,2013,"Nowadays, many organizations outsource data storage to the cloud such that a member (owner) of an organization can easily share data with other members (users). Due to the existence of security concerns in the cloud, both owners and users are suggested to verify the integrity of cloud data with Provable Data Possession (PDP) before further utilization on data. However, previous methods either unnecessarily reveal the identity of a data owner to the untrusted cloud or any public verifiers, or introduce significant overheads on verification metadata to preserve anonymity. In this paper, we propose a simple and efficient publicly verifiable approach to ensure cloud data integrity without sacrificing the anonymity of data owners nor requiring significant verification metadata. Specifically, we introduce a security-mediator (SEM), which is able to generate verification metadata (i.e., signatures) on outsourced data for data owners. Our approach decouples the anonymity protection mechanism from the PDP. Thus, an organization can employ its own anonymous authentication mechanism, and the cloud is oblivious to that since it only deals with typical PDP-metadata, Consequently, there is no extra storage overhead when compared with existing non-anonymous PDP solutions. The distinctive features of our scheme also include data privacy, such that the SEM does not learn anything about the data to be uploaded to the cloud at all, which is able to minimize the requirement of trust on the SEM. In addition, we can also extend our scheme to work with the multi-SEM model, which can avoid the potential single point of failure existing in the single-SEM scenario. Security analyses prove our scheme is secure, and experiment results demonstrate our scheme is efficient."
2458324,15510,20649,RESP: a robust physical unclonable function retrofitted into embedded SRAM array,2013,"Physical Unclonable Functions (PUFs) have emerged as an attractive primitive to address diverse hardware security issues in Integrated Circuits (ICs). A majority of existing PUFs rely on a dedicated circuit structure for generating chip-specific signatures, which often imposes concerns due to area/power overhead and extra design efforts. Furthermore, existing PUF-based signature generation cannot be employed to authenticate chips already in the market. In this paper, we propose RESP, a novel PUF structure realized in embedded SRAM array, a prevalent component in processors and system-on-chips (SOCs), with virtually no design modification. RESP leverages on voltage-depend memory access failures (during write) to produce large volume of high-quality challenge-response pairs. Since many modern ICs integrate SRAM array of varying size with isolated power grid, RESP can be easily retrofitted into these chips. Circuit-level simulation of 1000 chips using realistic process variation model shows high uniqueness of 49.2% average inter-die Hamming distance and good reproducibility of 2.88% intra-die Hamming distance under temperature <; 85°C. The device aging effect, e.g. bias temperature instability (BTI), results in only 4.95% estimated unstable bits for ten-year usage."
712838,15510,11345,"Pairing-Based cryptography: past, present, and future",2012,"While pairings were first introduced in cryptography as a tool to attack the discrete-log problem on certain elliptic curves, they have since found numerous applications in the construction of cryptographic systems. To this day many problems can only be solved using pairings. A few examples include collusion-resistant broadcast encryption and traitor tracing with short keys, 3-way Diffie-Hellman, and short signatures.#R##N##R##N#In this talk we survey some of the existing applications of pairings to cryptography, but mostly focus on open problems that cannot currently be solved using pairings. In particular we explain where the current techniques fail and outline a few potential directions for future progress.#R##N##R##N#One of the central applications of pairings is identity-based encryption and its generalization to functional encryption. While identity-based encryption can be built using arithmetic modulo composites and using lattices, constructions based on pairings currently provide the most expressive functional encryption systems. Constructing comparable functional encryption systems from lattices and composite arithmetic is a wonderful open problem. Again we survey the state of the art and outline a few potential directions for further progress.#R##N##R##N#Going beyond pairings (a.k.a bi-linear maps), a central open problem in public-key cryptography is constructing a secure tri-linear or more generally a secure n-linear map. That is, construct groups G and $G_{\scriptscriptstyle\mathrm{T}}$ where discrete-log in G is intractable and yet there is an efficiently computable non-degenerate n-linear map $e:G^n \to G_{\scriptscriptstyle\mathrm{T}}$. Such a construct can lead to powerful solutions to the problems mentioned in the first paragraph as well as to new functional encryption and homomorphic encryption systems. Currently, no such construct is known and we hope this talk will encourage further research on this problem."
1655136,15510,9856,Malicious PDF detection using metadata and structural features,2012,"Owed to their versatile functionality and widespread adoption, PDF documents have become a popular avenue for user exploitation ranging from large-scale phishing attacks to targeted attacks. In this paper, we present a framework for robust detection of malicious documents through machine learning. Our approach is based on features extracted from document metadata and structure. Using real-world datasets, we demonstrate the the adequacy of these document properties for malware detection and the durability of these features across new malware variants. Our analysis shows that the Random Forests classification method, an ensemble classifier that randomly selects features for each individual classification tree, yields the best detection rates, even on previously unseen malware.   Indeed, using multiple datasets containing an aggregate of over 5,000 unique malicious documents and over 100,000 benign ones, our classification rates remain well above 99% while maintaining low false positives of 0.2% or less for different classification parameters and experimental scenarios. Moreover, the classifier has the ability to detect documents crafted for targeted attacks and separate them from broadly distributed malicious PDF documents. Remarkably, we also discovered that by artificially reducing the influence of the top features in the classifier, we can still achieve a high rate of detection in an adversarial setting where the attacker is aware of both the top features utilized in the classifier and our normality model. Thus, the classifier is resilient against mimicry attacks even with knowledge of the document features, classification method, and training set."
848573,15510,9475,Effectiveness of IP address randomization in decoy-based moving target defense,2013,"In a decoy-based moving target defense (MTD), a computer network introduces a large number of virtual decoy nodes in order to prevent the adversary from locating and targeting real nodes. Since the decoys can eventually be identified and their Internet Protocol (IP) addresses blacklisted by the adversary, current MTD approaches suggest that the IP addresses of the real and decoy nodes should be randomly refreshed and reassigned over time. Refreshing and reassigning the IP addresses, however, disrupts services such as TCP/IP that rely on the IP address. We introduce an analytical approach to MTD and choosing the optimal randomization policy in order to minimize disruptions to system performance. Our approach consists of two components. First, we model the interaction between the adversary and a virtual node as a sequential detection process, in which the adversary attempts to determine whether the node is real or a decoy in the minimum possible time. We compute the optimal strategy for the adversary to decide whether the node is real or a decoy, and derive closed-form expressions for the expected time to identify the real node using this strategy. Second, we formulate the problem of deciding when to randomize the IP addresses, based on a trade-off between reducing the probability of detecting the real node and minimizing the disruption to network services, as an optimal stopping problem. We derive the optimal randomization policy for the network and analyze the detection probability, expected number of connections lost due to IP randomization, and expected time between randomizations under the proposed policy. Our results are illustrated via a simulation study using real-world data from NMAP, a software tool used to identify decoy nodes. Our simulation study indicates that our IP randomization policy reduces the probability of detection while minimizing the number of connections that are disrupted by the randomization."
1767701,15510,339,Confidentiality-preserving proof theories for distributed proof systems,2011,"A distributed proof system is an effective way for deriving useful information by combining data from knowledge bases managed by multiple different principals across different administrative domains. As such, many researchers have proposed using these types of systems as a foundation for distributed authorization and trust management in decentralized systems. However, to account for the potentially sensitive nature of the underlying information, it is important that such proof systems be able to protect the confidentiality of the logical facts and statements.   In this paper, we explore the design space of sound and safe confidentiality-preserving distributed proof systems. Specifically, we develop a framework to analyze the theoretical best-case proving power of these types of systems by analyzing confidentiality-preserving proof theories for Datalog-like languages within the context of a trusted third party evaluation model. We then develop a notion of safety based on the concept of non-deducibility and analyze the safety of several confidentiality-enforcing proof theories from the literature. The results in this paper show that the types of discretionary access control enforced by most systems on a principal-to-principal basis are indeed safe, but lack proving power when compared to other systems. Specifically, we show that a version of the Minami-Kotz (MK) proof system can prove more facts than the simple DAC system while retaining the safety property of the simple system. We further show that a seemingly-useful modification of the MK to support commutative encryption breaks the safety of the system without violating soundness."
2459870,15510,9704,Multi agent system for network attack classification using flow-based intrusion detection,2011,"Intrusion Detection (ID) is essential for protecting contemporary computer networks from a range of threats. Modern ID techniques must cope with increasingly sophisticated attacks as well as rapidly rising network line speeds. Signature-based ID is forced to sample sparsely, increasing the likelihood of malicious traffic entering the network without scrutiny. Consequently, flow-based ID is gaining attention as an effective complement. ID systems are furthermore often characterized as either network-based or host-based. The autonomous multi agent design paradigm is a scalable, attractive alternative for its potential to leverage the strengths of both architectures: the broad perspective and visibility into distributed malicious activity provided by network-based ID, and the comprehensive view of the local node provided by host-based ID. This paper therefore develops an architecture for a new multi agent, flow-based intrusion detection sysem. The architecture is designed in two iterations of increasing complexity. These innovative ID designs use a “repuation” system to permit agents to dynamically find nodes that are most effective for classifying malicious network activity. Furthermore, each system design includes the development of an innovative classifier that uses multi objective evolutionary algorithms to aid in the search for effective operational parameter values. Evaluation using an extensive agent simulation framework highlights the conditions under which the reputation system provides a significant classification benefit."
106300,15510,9874,Secure authenticated comparisons,2011,"In the third-party model for the distribution of data, the data owner provides a third party (referred to as the dealer) with data as well as integrity verification information for that data, in the form of digital signatures that the dealer can use to convince a user of the data's integrity (the dealer is not trusted with the owner's signature keys, which is why it receives pre-signed items). The user's interactions are with the dealer, who is in charge of enforcing access control and confidentiality for the data (i.e., no user should learn more than the outcome of their authorized query). This kind of outsourcing is becoming increasingly important because of its advantageous economics - a dealer who acts as a repository for many owners can achieve economies of scale that are not feasible for the individual owners, and the model allows the data owners to focus on what they do best (the creation and/or acquisition of high-quality data). A problem that arises in the context of outsourced databases (particularly for XML data) is the following: There is a total order Π on n items stored with the dealer, and a user query consists of a pair of items whose relative ordering should be revealed along with a proof that the result is correct. The proof is generated using the dealer's local data (i.e., without bothering the data owner). The main difficulty is achieving efficient storage and query-processing while achieving the desiderata (that the user should learn nothing other than the answer to their query, and that a misbehaving dealer should not be able to convince a user of a wrong ordering). This paper gives a solution that is provably secure under a new assumption and can efficiently generate a very short proof. Furthermore, this scheme is generalized to partial orders that can be decomposed into d total orders. In this case, a user either learns the ordering of the queried items, or learns that they are incomparable."
2045107,15510,20754,Quantifying Location Privacy,2011,"It is a well-known fact that the progress of personal communication devices leads to serious concerns about privacy in general, and location privacy in particular. As a response to these issues, a number of Location-Privacy Protection Mechanisms (LPPMs) have been proposed during the last decade. However, their assessment and comparison remains problematic because of the absence of a systematic method to quantify them. In particular, the assumptions about the attacker's model tend to be incomplete, with the risk of a possibly wrong estimation of the users' location privacy. In this paper, we address these issues by providing a formal framework for the analysis of LPPMs, it captures, in particular, the prior information that might be available to the attacker, and various attacks that he can perform. The privacy of users and the success of the adversary in his location-inference attacks are two sides of the same coin. We revise location privacy by giving a simple, yet comprehensive, model to formulate all types of location-information disclosure attacks. Thus, by formalizing the adversary's performance, we propose and justify the right metric to quantify location privacy. We clarify the difference between three aspects of the adversary's inference attacks, namely their accuracy, certainty, and correctness. We show that correctness determines the privacy of users. In other words, the expected estimation error of the adversary is the metric of users' location privacy. We rely on well-established statistical methods to formalize and implement the attacks in a tool: the Location-Privacy Meter that measures the location privacy of mobile users, given various LPPMs. In addition to evaluating some example LPPMs, by using our tool, we assess the appropriateness of some popular metrics for location privacy: entropy and k-anonymity. The results show a lack of satisfactory correlation between these two metrics and the success of the adversary in inferring the users' actual locations."
1057604,15510,8912,Social Puzzles: Context-Based Access Control in Online Social Networks,2014,"The increasing popularity of online social networks (OSNs) is spawning new security and privacy concerns. Currently, a majority of OSNs offer very naive access control mechanisms that are primarily based on static access control lists (ACL) or policies. But as the number of social connections grow, static ACL based approaches become ineffective and unappealing to OSN users. There is an increased need in social-networking and data-sharing applications to control access to data based on the associated context (e.g., event, location, and users involved), rather than solely on data ownership and social connections. Surveillance is another critical concern for OSN users, as the service provider may further scrutinize data posted or shared by users for personal gains (e.g., targeted advertisements), for use by corporate partners or to comply with legal orders. In this paper, we introduce a novel paradigm of context-based access control in OSNs, where users are able to access the shared data only if they have knowledge of the context associated with it. We propose two constructions for context-based access control in OSNs: the first is based on a novel application of Shamir's secret sharing scheme, whereas the second makes use of an attribute-based encryption scheme. For both constructions, we analyze their security properties, implement proof-of-concept applications for Facebook and empirically evaluate their functionality and performance. Our empirical measurements show that the proposed constructions execute efficiently on standard computing hardware, as well as, on portable mobile devices."
702680,15510,8806,Slicing droids: program slicing for smali code,2013,"The popularity of mobile devices like smartphones and tablets has increased significantly in the last few years with many millions of sold devices. This growth also has its drawbacks: attackers have realized that smartphones are an attractive target and in the last months many different kinds of malicious software (short:  malware ) for such devices have emerged. This worrisome development has the potential to hamper the prospering ecosystem of mobile devices and the potential for damage is huge.   Considering these aspects, it is evident that malicious apps need to be detected early on in order to prevent further distribution and infections. This implies that it is necessary to develop techniques capable of detecting malicious apps in an automated way. In this paper, we present SAAF, a Static Android Analysis Framework for Android apps. SAAF analyzes smali code, a disassembled version of the DEX format used by Android's Java VM implementation. Our goal is to create program slices in order to perform data-flow analyses to backtrack parameters used by a given method. This helps us to identify suspicious code regions in an automated way. Several other analysis techniques such as visualization of control flow graphs or identification of ad-related code are also implemented in SAAF. In this paper, we report on program slicing for Android and present results obtained by using this technique to analyze more than 136,000 benign and about 6,100 malicious apps."
1370914,15510,339,The UNIX Process Identity Crisis: A Standards-Driven Approach to Setuid,2014,"We revisit the setuid family of calls for privilege management that is implemented in several widely-used operating systems. Three of the four commonly used calls in the family are standardized by POSIX. We investigate the current status of setuid, and in the process, challenge some assertions in prior work. We address three sets of questions with regards to the setuid family. (1) Is the POSIX standard indeed broken as prior work suggests? (2) Are implementations POSIX-compliant as claimed? (3) Are the wrapper functions that prior work proposes to circumvent issues with setuid calls correct and usable? Towards (1), we express the standards in a precise syntax that allows us to assess whether they are unambiguous, logically consistent descriptions of well-formed functions. We have discovered that two of the three functions that are standardized fit these criteria, thereby challenging assertions in prior work regarding the quality of the standard. In cases wherein the standard is broken, we give a clear characterization, and suggest that the standard can be fixed easily, but at the cost of backwards-compatibility. Towards (2), we perform a state-space enumeration as in prior work, report on our discoveries, and discuss the implications of non-conformance and differences in implementation. Towards (3), we discuss some issues that we have discovered with prior wrappers. We then propose a new suite of wrapper functions which are designed with a different mindset from prior work, and provide both stronger guarantees with respect to atomicity and a clearer semantics for permanent and temporary changes in process identity. With a fresh approach, our work is a contribution to a well-established approach to privilege management."
2063531,15510,9969,Leakage-resilient zero knowledge,2011,"In this paper, we initiate a study of zero knowledge proof systems in the presence of side-channel attacks. Specifically, we consider a setting where a cheating verifier is allowed to obtain arbitrary bounded leakage on the entire state (including the witness and the random coins) of the prover during the entire protocol execution. We formalize a meaningful definition of leakage-resilient zero knowledge (LR-ZK) proof system, that intuitively guarantees that the protocol does not yield anything beyond the validity of the statement and the leakage obtained by the verifier.#R##N##R##N#We give a construction of LR-ZK interactive proof system based on standard general assumptions. To the best of our knowledge, this is the first instance of a cryptographic interactive protocol where the adversary is allowed to perform leakage attacks during the protocol execution on the entire state of honest party (in contrast, prior work only considered leakage prior to the protocol execution, or very limited leakage during the protocol execution). Next, we give an LR-NIZK proof system based on standard number-theoretic assumptions.#R##N##R##N#Finally, we demonstrate the usefulness of our notions by giving two concrete applications: - We initiate a new line of research to relax the assumption on the tamper-proofness of hardware tokens used in the design of various cryptographic protocols. In particular, we give a construction of a universally composable multiparty computation protocol in the leaky token model (where an adversary in possession of a token is allowed to obtain arbitrary bounded leakage on the entire state of the token) based on standard general assumptions. - Next, we give simple, generic constructions of fully leakage-resilient signatures in the bounded leakage model as well as the continual leakage model. Unlike the recent constructions of such schemes, we also obtain security in the noisy leakage model."
971388,15510,9856,PhorceField: a phish-proof password ceremony,2011,"Many widely deployed phishing defense schemes, such as SiteKey, use client-side secrets to help users confirm that they are visiting the correct website before entering their passwords. Unfortunately, studies have demonstrated that up to 92% of users can be convinced to ignore missing client-side secrets and enter their passwords into phishing pages. However, since client-side secrets have already achieved industry acceptance, they are an attractive building block for creating better phishing defenses. We present PhorceField, a phishing resistant password ceremony that combines client-side secrets and graphical passwords in a novel way that provides phishing resistance that neither achieves on its own. PhorceField enables users to login easily, but forces phishers to present victims with a fundamentally unfamiliar and onerous user interface. Victims that try to use the phisher's interface to enter their password find the task so difficult that they give up without revealing their password. We have evaluated PhorceField's phishing resistance in a user study in which 21 participants used PhorceField for a week and were then subjected to a simulated phishing attack. On average, participants were only able to reveal 20% of the entropy in their password, and none of them revealed their entire password. This is a substantial improvement over previous research that demonstrated that 92% of users would reveal their entire password to a phisher, even if important security indicators were missing[27].   PhorceField is easy to deploy in sites that already use client-side secrets for phishing defense -- it requires no client-side software and can be implemented entirely in javascript. Banks and other high value websites could therefore deploy it as a drop-in replacement for existing defenses, or deploy it on an opt-in basis, as Google has done with its phone-based 2-step verification system."
571698,15510,9969,1/p-Secure multiparty computation without honest majority and the best of both worlds,2011,"A protocol for computing a functionality is secure if an adversary in this protocol cannot cause more harm than in an ideal computation, where parties give their inputs to a trusted party which returns the output of the functionality to all parties. In particular, in the ideal model such computation is fair - all parties get the output. Cleve (STOC 1986) proved that, in general, fairness is not possible without an honest majority. To overcome this impossibility, Gordon and Katz (Eurocrypt 2010) suggested a relaxed definition - 1/p-secure computation - which guarantees partial fairness. For two parties, they construct 1/p-secure protocols for functionalities for which the size of either their domain or their range is polynomial (in the security parameter). Gordon and Katz ask whether their results can be extended to multiparty protocols.#R##N##R##N#We study 1/p-secure protocols in the multiparty setting for general functionalities. Our main result is constructions of 1/p-secure protocols that are resilient against any number of corrupt parties provided that the number of parties is constant and the size of the range of the functionality is at most polynomial (in the security parameter n). If less than 2/3 of the parties are corrupt, the size of the domain is constant, and the functionality is deterministic, then our protocols are efficient even when the number of parties is log log n. On the negative side, we show that when the number of parties is super-constant, 1/p-secure protocols are not possible when the size of the domain is polynomial. Thus, our feasibility results for 1/p-secure computation are essentially tight.#R##N##R##N#We further motivate our results by constructing protocols with stronger guarantees: If in the execution of the protocol there is a majority of honest parties, then our protocols provide full security. However, if only a minority of the parties are honest, then our protocols are 1/psecure. Thus, our protocols provide the best of both worlds, where the 1/p-security is only a fall-back option if there is no honest majority."
2959399,15510,9836,From Cryptography to Hardware: Analyzing Embedded Xilinx BRAM for Cryptographic Applications,2012,"Design of cryptographic applications need special care. For instance, physical attacks like Side-Channel Analysis (SCA) are able to recover the secret key, just by observing the activity of the computation, even for mathematically robust algorithms like AES. SCA considers the leakage of a well chosen intermediate variable correlated with the secret. Field programmable gate-arrays (FPGA) are often used for hardware implementations for low to medium volume productions or when flexibility is needed. They offer many possibilities for the computation, like small Look-Up Tables (LUT) and embedded block memories (BRAM). Certain countermeasures can be deployed, like dual-rail logic or masking, to resist SCA on FPGA. However to design an effective countermeasure, it is of prime importance for a designer to know the main leakage sources of the device. In this article, we analyze the leakage source of a Xilinx Virtex V FPGA by studying 3 different AES architectures. The analysis is based on real measurements by using specific leakage models of the sensitive variable, adapted to each architecture. Our results demonstrate that, BRAM which were considered to leak less traditionally, are found to be equally vulnerable if we change the attack target from address register to output latch. Hence by providing important clues about the leakage, this study allows the designers to enhance the robustness of their implementation in FPGA."
347713,15510,20592,JACKSTRAWS: picking command and control connections from bot traffic,2011,"A distinguishing characteristic of bots is their ability to establish a command and control (C&C) channel. The typical approach to build detection models for C&C traffic and to identify C&C endpoints (IP addresses and domains of C&C servers) is to execute a bot in a controlled environment and monitor its outgoing network connections. Using the bot traffic, one can then craft signatures that match C&C connections or blacklist the IP addresses or domains that the packets are sent to. Unfortunately, this process is not as easy as it seems. For example, bots often open a large number of additional connections to legitimate sites (to perform click fraud or query for the current time), and bots can deliberately produce noise - bogus connections that make the analysis more difficult. Thus, before one can build a model for C&C traffic or blacklist IP addresses and domains, one first has to pick the C&C connections among all the network traffic that a bot produces.#R##N##R##N#In this paper, we present JACKSTRAWS, a system that accurately identifies C&C connections. To this end, we leverage host-based information that provides insights into which data is sent over each network connection as well as the ways in which a bot processes the information that it receives. More precisely, we associate with each network connection a behavior graph that captures the system calls that lead to this connection, as well as the system calls that operate on data that is returned. By using machine learning techniques and a training set of graphs that are associated with known C&C connections, we automatically extract and generalize graph templates that capture the core of different types of C&C activity. Later, we use these C&C templates to match against behavior graphs produced by other bots. Our results show that JACKSTRAWS can accurately detect C&C connections, even for novel bot families that were not used for template generation."
311661,15510,9969,Efficient Padding Oracle Attacks on Cryptographic Hardware,2012,"We show how to exploit the encrypted key import functions of a variety of different cryptographic devices to reveal the imported key. The attacks are padding oracle attacks, where error messages resulting from incorrectly padded plaintexts are used as a side channel. In the asymmetric encryption case, we modify and improve Bleichenbacher's attack on RSA PKCS#1v1.5 padding, giving new cryptanalysis that allows us to carry out the 'million message attack' in a mean of 49 000 and median of 14 500 oracle calls in the case of cracking an unknown valid ciphertext under a 1024 bit key the original algorithm takes a mean of 215 000 and a median of 163 000 in the same case. We show how implementation details of certain devices admit an attack that requires only 9 400 operations on average 3 800 median. For the symmetric case, we adapt Vaudenay's CBC attack, which is already highly efficient. We demonstrate the vulnerabilities on a number of commercially available cryptographic devices, including security tokens, smartcards and the Estonian electronic ID card. The attacks are efficient enough to be practical: we give timing details for all the devices found to be vulnerable, showing how our optimisations make a qualitative difference to the practicality of the attack. We give mathematical analysis of the effectiveness of the attacks, extensive empirical results, and a discussion of countermeasures."
928442,15510,339,Enhancing Tor's performance using real-time traffic classification,2012,"Tor is a low-latency anonymity-preserving network that enables its users to protect their privacy online. It consists of volunteer-operated routers from all around the world that serve hundreds of thousands of users every day. Due to congestion and a low relay-to-client ratio, Tor suffers from performance issues that can potentially discourage its wider adoption, and result in an overall weaker anonymity to all users.   We seek to improve the performance of Tor by defining different classes of service for its traffic. We recognize that although the majority of Tor traffic is interactive web browsing, a relatively small amount of bulk downloading consumes an unfair amount of Tor's scarce bandwidth. Furthermore, these traffic classes have different time and bandwidth constraints; therefore, they should not be given the same Quality of Service (QoS), which Tor offers them today.   We propose and evaluate DiffTor, a machine-learning-based approach that classifies Tor's encrypted circuits by application in real time and subsequently assigns distinct classes of service to each application. Our experiments confirm that we are able to classify circuits we generated on the live Tor network with an extremely high accuracy that exceeds 95%. We show that our real-time classification in combination with QoS can considerably improve the experience of Tor clients, as our simple techniques result in a 75% improvement in responsiveness and an 86% reduction in download times at the median for interactive users."
1160811,15510,10162,Comparing and fusing different sensor modalities for relay attack resistance in Zero-Interaction Authentication,2014,"Zero-Interaction Authentication (ZIA) refers to approaches that authenticate a user to a verifier (terminal) without any user interaction. Currently deployed ZIA solutions are predominantly based on the terminal detecting the proximity of the user's personal device, or a security token, by running an authentication protocol over a short-range wireless communication channel. Unfortunately, this simple approach is highly vulnerable to low-cost and practical relay attacks which completely offset the usability benefits of ZIA. The use of contextual information, gathered via on-board sensors, to detect the co-presence of the user and the verifier is a recently proposed mechanism to resist relay attacks. In this paper, we systematically investigate the performance of different sensor modalities for co-presence detection with respect to a standard Dolev-Yao adversary. First, using a common data collection framework run in realistic everyday settings, we compare the performance of four commonly available sensor modalities (WiFi, Bluetooth, GPS, and Audio) in resisting ZIA relay attacks, and find that WiFi is better than the rest. Second, we show that, compared to any single modality, fusing multiple modalities improves resilience against ZIA relay attacks while retaining a high level of usability. Third, we motivate the need for a stronger adversarial model to characterize an attacker who can compromise the integrity of context sensing itself. We show that in the presence of such a powerful attacker, each individual sensor modality offers very low security. Positively, the use of multiple sensor modalities improves security against such an attacker if the attacker cannot compromise multiple modalities simultaneously."
2020744,15510,8806,Extracting probable command and control signatures for detecting botnets,2014,"Botnets, which are networks of compromised machines under the control of a single malicious entity, are a serious threat to online security. The fact that botnets, by definition, receive their commands from a single entity can be leveraged to fight them. To this end, one requires techniques that can detect command and control (C&C) traffic, as well as the servers that host C&C services. Given the knowledge of a C&C server's IP address, one can use this information to detect all hosts that attempt to contact such a server, and subsequently disinfect, disable, or block the infected machines. This information can also be used by law enforcement to take down the C&C server.   In this paper, we present a new botnet C&C signature extraction approach that can be used to find C&C communication in traffic generated by executing malware samples in a dynamic analysis system. This approach works in two steps. First, we extract all frequent strings seen in the network traffic. Second, we use a function that assigns a score to each string. This score represents the likelihood that the string is indicative of C&C traffic. This function allows us to rank strings and focus our attention on those that likely represent good C&C signatures. We apply our technique to almost 2.6 million network connections produced by running more than 1.4 million malware samples. Using our technique, we were able to automatically extract a set of signatures that are able to identify C&C traffic. Furthermore, we compared our signatures with those used by existing tools, such as Snort and BotHunter."
1600975,15510,10162,Combined heat and privacy: Preventing occupancy detection from smart meters,2014,"Electric utilities are rapidly deploying smart meters that record and transmit electricity usage in real-time. As prior research shows, smart meter data indirectly leaks sensitive, and potentially valuable, information about a home's activities. An important example of the sensitive information smart meters reveal is occupancy—whether or not someone is home and when. As prior work also shows, occupancy is surprisingly easy to detect, since it highly correlates with simple statistical metrics, such as power's mean, variance, and range. Unfortunately, prior research that uses chemical energy storage, e.g., batteries, to prevent appliance power signature detection is prohibitively expensive when applied to occupancy detection. To address this problem, we propose preventing occupancy detection using the thermal energy storage of large elastic heating loads already present in many homes, such as electric water and space heaters. In essence, our approach, which we call Combined Heat and Privacy (CHPr), controls the power usage of these large loads to make it look like someone is always home. We design a CHPr-enabled water heater that regulates its energy usage to mask occupancy without violating its objective, e.g., to provide hot water on demand, and evaluate it in simulation and using a prototype. Our results show that a 50-gallon CHPr-enabled water heater decreases the Matthews Correlation Coefficient (a standard measure of a binary classifier's performance) of a threshold-based occupancy detection attack in a representative home by 10x (from 0.44 to 0.045), effectively preventing occupancy detection at no extra cost."
2441308,15510,11345,Black-Box Separations for Differentially Private Protocols,2014,"We study the maximal achievable accuracy of distributed dierentially private protocols for a large natural class of boolean functions, in the computational setting. In the information theoretic model, McGregor et al. [FOCS 2010] and Goyal et al. [CRYPTO 2013] have demonstrated several functionalities whose dierentially private computation results in much lower accuracies in the distributed setting, as compared to the client-server setting. We explore lower bounds on the computational assumptions under which this particular accuracy gap can possibly be reduced for general two-party boolean output functions. In the distributed setting, it is possible to achieve optimal accuracy, i.e. the maximal achievable accuracy in the client-server setting, for any function, if a semi-honest secure protocol for oblivious transfer exists. However, we show the following strong impossibility results: For any boolean function and fixed level of privacy, the maximal achievable accuracy of any (fully) black-box construction based on existence of key-agreement protocols is at least a constant smaller than optimal achievable accuracy. Since key-agreement protocols imply the existence of one-way functions, this separation also extends to one-way functions. Our results are tight for the AND and XOR functions. For AND, there exists an accuracy threshold such that any accuracy up to the threshold can be information theoretically achieved; while no (fully) black-box construction based on existence of key-agreement can achieve accuracy beyond this threshold. An analogous statement is also true for XOR (albeit with a dierent accuracy threshold). Our results build on recent developments in black-box separation techniques for functions with private input [BM09, HOZ13, MMP14a, MMP14b]; and consequently translate information theoretic impossibilities into black-box separation results."
1522709,15510,20338,Detecting prefix hijackings in the internet with argus,2012,"Border Gateway Protocol (BGP) plays a critical role in the Internet inter-domain routing reliability. Invalid routes generated by mis-configurations or forged by malicious attacks may hijack the traffic and devastate the Internet routing system, but it is unlikely that a secure BGP can be deployed in the near future to completely prevent them. Although many hijacking detection systems have been developed, they more or less have weaknesses such as long detection delay, high false alarm rate and deployment difficulty, and no systematic detection results have been studied.   This paper proposes  Argus , an agile system that can accurately detect prefix hijackings and deduce the underlying cause of route anomalies in a very fast way.  Argus  is based on correlating the control and data plane information closely and pervasively, and has been continuously monitoring the Internet for more than one year. During this period, around 40K routing anomalies were detected, from which 220 stable prefix hijackings were identified. Our analysis on these events shows that, hijackings that have only been theoretically studied before do exist in the Internet. Although the frequency of new hijackings is nearly stable, more specific prefixes are hijacked more frequently. Around 20% of the hijackings last less than ten minutes, and some can pollute 90% of the Internet in less than two minutes. These characteristics make \emph{Argus} especially useful in practice. We further analyze some representative cases in detail to help increase the understanding of prefix hijackings in the Internet."
2437308,15510,21102,Dynamic window with fuzzy controller in wireless sensor networks for elliptic curve cryptography,2011,"Elliptic curve cryptosystem (ECC) was proposed by Miller [10] and Koblitz [9] which relies on the difficulty of elliptic curve discrete logarithmic problem (ECDLP). It is gaining wide acceptance as an alternative to the conventional public key cryptosystem such as RSA [24], DSA [25], DH [26]. Also it is noted that the wireless sensor networks (WSN) based on the rapid progress of wireless communications and embedded micro electro mechanical systems technologies are becoming important part in our daily life. The security of the WSN becomes one of the major concerns in its applications. Even ECC prominently offers great potential benefits for WSN security there is still a lot of work needs to be done due to WSN has very restraint running conditions such as limited energy source, capability of computing, etc. It is well known that scalar multiplication operation in ECC accounts for about 80% of key calculation time on wireless sensor network motes. In this paper we present an optimized dynamic window based on our previous research works. The whole quality of service (QoS) has been improved under this algorism in particularly the power consuming is more efficiently. The simulation results showed that the average calculation time, due to fuzzy conditions decreased from previous 26 to current 9 as a whole the calculation time, decreased by approximately 18% in comparison to our previous algorithms in an ECC wireless sensor network [23]."
210400,15510,20592,ret2dir: rethinking kernel isolation,2014,"Return-to-user (ret2usr) attacks redirect corrupted kernel pointers to data residing in user space. In response, several kernel-hardening approaches have been proposed to enforce a more strict address space separation, by preventing arbitrary control flow transfers and dereferences from kernel to user space. Intel and ARM also recently introduced hardware support for this purpose in the form of the SMEP, SMAP, and PXN processor features. Unfortunately, although mechanisms like the above prevent the explicit sharing of the virtual address space among user processes and the kernel, conditions of implicit sharing still exist due to fundamental design choices that trade stronger isolation for performance.#R##N##R##N#In this work, we demonstrate how implicit page frame sharing can be leveraged for the complete circumvention of software and hardware kernel isolation protections. We introduce a new kernel exploitation technique, called return-to-direct-mapped memory (ret2dir), which bypasses all existing ret2usr defenses, namely SMEP, SMAP, PXN, KERNEXEC, UDEREF, and kGuard. We also discuss techniques for constructing reliable ret2dir exploits against x86, x86-64, AArch32, and AArch64 Linux targets. Finally, to defend against ret2dir attacks, we present the design and implementation of an exclusive page frame ownership scheme for the Linux kernel that prevents the implicit sharing of physical memory pages with minimal runtime overhead."
1540046,15510,9856,All your face are belong to us: breaking Facebook's social authentication,2012,"Two-factor authentication is widely used by high-value services to prevent adversaries from compromising accounts using stolen credentials. Facebook has recently released a two-factor authentication mechanism, referred to as Social Authentication, which requires users to identify some of their friends in randomly selected photos. A recent study has provided a formal analysis of social authentication weaknesses against attackers inside the victim's social circles. In this paper, we extend the threat model and study the attack surface of social authentication in practice, and show how any attacker can obtain the information needed to solve the challenges presented by Facebook. We implement a proof-of-concept system that utilizes widely available face recognition software and cloud services, and evaluate it using real public data collected from Facebook. Under the assumptions of Facebook's threat model, our results show that an attacker can obtain access to (sensitive) information for at least 42% of a user's friends that Facebook uses to generate social authentication challenges. By relying solely on publicly accessible information, a casual attacker can solve 22% of the social authentication tests in an automated fashion, and gain a significant advantage for an additional 56% of the tests, as opposed to just guessing. Additionally, we simulate the scenario of a determined attacker placing himself inside the victim's social circle by employing dummy accounts. In this case, the accuracy of our attack greatly increases and reaches 100% when 120 faces per friend are accessible by the attacker, even though it is very accurate with as little as 10 faces."
2441721,15510,10286,"Identity-Based Lossy Trapdoor Functions: New Definitions, Hierarchical Extensions, and Implications",2014,"Lossy trapdoor functions, introduced by Peikert and Waters STOC'08, have received a lot of attention in the last years, because of their wide range of applications. The notion has been recently extended to the identity-based setting by Bellare et al. Eurocrypt'12. An identity-based trapdoor function IB-TDF satisfying the lossy property introduced by Bellare et al. can be used to construct other cryptographic primitives in the identity-based setting: encryption schemes with semantic security under chosen-plaintext attacks, deterministic encryption schemes, and hedged encryption schemes that maintain some security when messages are encrypted using randomness of poor quality. However, the constructed primitives can be proved secure only against selective adversaries who select the target identity upfront.#R##N##R##N#Our first contribution is an alternative definition for the lossiness of an identity-based trapdoor function. We prove that an IB-TDF satisfying the new property can be used to construct all the aforementioned primitives, in the identity-based setting, with security against adaptive adversaries. We further consider the new definition and its implications in the more general scenario of hierarchical identity-based cryptography, which has proved very useful both for practical applications and to establish theoretical relations with other cryptographic primitives including encryption with chosen-ciphertext security or with forward-security.#R##N##R##N#As a second contribution, we describe a pairing-based hierarchical IB-TDF satisfying the new definition of lossiness against either selective or, for hierarchies of constant depth, adaptive adversaries. This is also the first example of hierarchical trapdoor functions based on traditional i.e., non-lattice-related number theoretic assumptions. As a direct consequence of our two contributions, we obtain a hierarchical identity-based HIB encryption scheme with chosen-plaintext security, a HIB deterministic encryption scheme and a HIB hedged encryption scheme, all of them with security against adaptive adversaries."
1379221,15510,339,Quantifying the security of graphical passwords: the case of android unlock patterns,2013,"Graphical passwords were proposed as an alternative to overcome the inherent limitations of text-based passwords, inspired by research that shows that the graphical memory of humans is particularly well developed. A graphical password scheme that has been widely adopted is the Android Unlock Pattern, a special case of the Pass-Go scheme with grid size restricted to 3x3 points and restricted stroke count.   In this paper, we study the security of Android unlock patterns. By performing a large-scale user study, we measure actual user choices of patterns instead of theoretical considerations on password spaces. From this data we construct a model based on Markov chains that enables us to quantify the strength of Android unlock patterns. We found empirically that there is a high bias in the pattern selection process, e.g., the upper left corner and three-point long straight lines are very typical selection strategies. Consequently, the entropy of patterns is rather low, and our results indicate that the security offered by the scheme is less than the security of only three digit randomly-assigned PINs for guessing 20% of all passwords (i.e., we estimate a partial guessing entropy G_0.2 of 9.10 bit).   Based on these insights, we systematically improve the scheme by finding a small, but still effective change in the pattern layout that makes graphical user logins substantially more secure. By means of another user study, we show that some changes improve the security by more than doubling the space of actually used passwords (i.e., increasing the partial guessing entropy G_0.2 to 10.81 bit)."
664010,15510,9969,New Techniques for SPHFs and Efficient One-Round PAKE Protocols,2013,"Password-authenticated key exchange (PAKE) protocols allow two players to agree on a shared high entropy secret key, that depends on their own passwords only. Following the Gennaro and Lindell's approach, with a new kind of smooth-projective hash functions (SPHFs), Katz and Vaikuntanathan recently came up with the first concrete one-round PAKE protocols, where the two players just have to send simultaneous flows to each other. The first one is secure in the Bellare-Pointcheval-Rogaway (BPR) model and the second one in the Canetti's UC framework, but at the cost of simulation-sound non-interactive zero-knowledge (SSNIZK) proofs (one for the BPR-secure protocol and two for the UC-secure one), which make the overall constructions not really efficient.#R##N#This paper follows their path with, first, a new efficient instantiation of SPHF on Cramer-Shoup ciphertexts, which allows to get rid of the SSNIZK proof and leads to the design of the most efficient one-round PAKE known so far, in the BPR model, and in addition without pairings.#R##N#In the UC framework, the security proof required the simulator to be able to extract the hashing key of the SPHF, hence the additional SSNIZK proof. We improve the way the latter extractability is obtained by introducing the notion of trapdoor smooth projective hash functions (TSPHFs). Our concrete instantiation leads to the most efficient one-round PAKE UC-secure against static corruptions to date.#R##N#We additionally show how these SPHFs and TSPHFs can be used for blind signatures and zero-knowledge proofs with straight-line extractability."
819015,15510,9856,k-subscription: privacy-preserving microblogging browsing through obfuscation,2013,"Over the past few years, microblogging social networking services have become a popular means for information sharing and communication. Besides sharing information among friends, such services are currently being used by artists, politicians, news channels, and information providers to easily communicate with their constituency. Even though following specific channels on a microblogging service enables users to receive interesting information in a timely manner, it may raise significant privacy concerns as well. For example, the microblogging service is able to observe all the channels that a particular user follows. This way, it can infer all the subjects a user might be interested in and generate a detailed profile of this user. This knowledge can be used for a variety of purposes that are usually beyond the control of the users.   To address these privacy concerns, we propose  k-subscription : an obfuscation-based approach that enables users to follow privacy-sensitive channels, while, at the same time, making it difficult for the microblogging service to find out their actual interests. Our method relies on obfuscation: in addition to each privacy-sensitive channel, users are encouraged to randomly follow  k  -- 1 other channels they are not interested in. In this way (i) their actual interests are hidden in random selections, and (ii) each user contributes in hiding the real interests of other users. Our analysis indicates that  k-subscription  makes it difficult for attackers to pinpoint a user's interests with significant confidence. We show that this confidence can be made predictably small by slightly adjusting  k  while adding a reasonably low overhead on the user's system."
1163573,15510,10192,DoS and DDoS in Named Data Networking,2013,"With the growing realization that current Internet protocols are reaching the limits of their senescence, several on-going research efforts aim to design potential next-generation Internet architectures. Although they vary in maturity and scope, in order to avoid past pitfalls, these efforts seek to treat security and privacy as fundamental requirements. Resilience to Denial-of-Service (DoS) attacks that plague today's Internet is a major issue for any new architecture and deserves full attention. In this paper, we focus on DoS in Named Data Networking (NDN) - a specific candidate for next-generation Internet architecture designs. By naming data instead of its locations, NDN transforms data into a first-class entity and makes itself an attractive and viable approach to meet the needs for many current and emerging applications. It also incorporates some basic security features that mitigate classes of attacks that are commonly seen today. However, NDN's resilience to DoS attacks has not been analyzed to-date. This paper represents a first step towards assessment and possible mitigation of DoS in NDN. After identifying and analyzing several new types of attacks, it investigates their variations, effects and counter-measures. This paper also sheds some light on the debate about relative virtues of self-certifying, as opposed to human-readable, names in the context of content-centric networking."
2297710,15510,23653,Local connectivity tests to identify wormholes in wireless networks,2011,"A wormhole attack places two radio transceivers connected by a high capacity link and retransmits wireless signals from one antenna at the other. This creates a set of shortcut paths in the network, and may attract a lot of traffic to the wormhole link. The link thus gains control of a large fraction of network traffic which opens the door for more dangerous attacks afterwards. In this paper we introduce a wormhole detection and removal algorithm based on local connectivity tests.   The basic idea is that the neighborhood of a wormhole contains two sets of nodes corresponding to two sides of the wormhole. The distance between these two sets is small when using paths that pass through the wormhole link, but is large when only regular network paths are considered. Thus we remove a small neighborhood that will contain potential wormhole links and check if a slightly larger neighborhood falls apart to multiple connected components. To accommodate spatial and temporal unpredictability of wireless communication links we abstract the network connectivity as an arbitrary graph so that the method does  not  assume any idealistic models (such as unit disk graph model). The algorithm uses purely local connectivity information, handles multiple wormhole attacks and generalizes to wireless networks deployed in 3D. It does not suffer from typical limitations in previous work such as the requirements of special hardware, communication models, synchronization, node density etc. In simulations, our method is seen to beat the state of the art solutions, in particular for cases where previous solutions experience poor performance."
2541765,15510,20338,Analysis of country-wide internet outages caused by censorship,2011,"In the first months of 2011, Internet communications were disrupted in several North African countries in response to civilian protests and threats of civil war. In this paper we analyze episodes of these disruptions in two countries: Egypt and Libya. Our analysis relies on multiple sources of large-scale data already available to academic researchers: BGP interdomain routing control plane data; unsolicited data plane traffic to unassigned address space; active macroscopic traceroute measurements; RIR delegation files; and MaxMind's geolocation database. We used the latter two data sets to determine which IP address ranges were allocated to entities within each country, and then mapped these IP addresses of interest to BGP-announced address ranges (prefixes) and origin ASes using publicly available BGP data repositories in the U.S. and Europe. We then analyzed observable activity related to these sets of prefixes and ASes throughout the censorship episodes. Using both control plane and data plane data sets in combination allowed us to narrow down which forms of Internet access disruption were implemented in a given region over time. Among other insights, we detected what we believe were Libya's attempts to test firewall-based blocking before they executed more aggressive BGP-based disconnection. Our methodology could be used, and automated, to detect outages or similar macroscopically disruptive events in other geographic or topological regions."
950720,15510,9856,Beehive: large-scale log analysis for detecting suspicious activity in enterprise networks,2013,"As more and more Internet-based attacks arise, organizations are responding by deploying an assortment of security products that generate situational intelligence in the form of logs. These logs often contain high volumes of interesting and useful information about activities in the network, and are among the first data sources that information security specialists consult when they suspect that an attack has taken place. However, security products often come from a patchwork of vendors, and are inconsistently installed and administered. They generate logs whose formats differ widely and that are often incomplete, mutually contradictory, and very large in volume. Hence, although this collected information is useful, it is often  dirty .   We present a novel system, Beehive, that attacks the problem of automatically mining and extracting knowledge from the dirty log data produced by a wide variety of security products in a large enterprise. We improve on signature-based approaches to detecting security incidents and instead identify suspicious host behaviors that Beehive reports as potential security incidents. These incidents can then be further analyzed by incident response teams to determine whether a policy violation or attack has occurred. We have evaluated Beehive on the log data collected in a large enterprise, EMC, over a period of two weeks. We compare the incidents identified by Beehive against enterprise Security Operations Center reports, antivirus software alerts, and feedback from enterprise security specialists. We show that Beehive is able to identify malicious events and policy violations which would otherwise go undetected."
1061078,15510,339,Tracer: enforcing mandatory access control in commodity OS with the support of light-weight intrusion detection and tracing,2011,"Enforcing a practical Mandatory Access Control (MAC) in a commercial operating system to tackle malware problem is a grand challenge but also a promising approach. The firmest barriers to apply MAC to defeat malware programs are the incompatible and unusable problems in existing MAC systems. To address these issues, we start our work by analyzing the technical details of 2,600 malware samples one by one and performing experiments over two types of MAC enforced operating systems. Based on the preliminary studies, we design a novel MAC model incorporating intrusion detection and tracing in a commercial operating system, named Tracer, in order to disable malware on hosts while offering good compatibility to existing software and good usability to common users who are not system experts. The model conceptually consists of three actions: detecting, tracing and restricting suspected intruders. One novelty is that it leverages light-weight intrusion detection and tracing techniques to automate security label configuration that is widely acknowledged as a tough issue when applying a MAC system in practice. The other is that, rather than restricting information flow as a traditional MAC does, it traces intruders and restricts only their critical malware behaviors, where intruders represent processes and executables that are potential agents of a remote attacker. Our prototyping and experiments on Windows show that Tracer can effectively defeat all malware samples tested via blocking malware behaviors while not causing a significant compatibility problem."
944139,15510,339,PSiOS: bring your own privacy & security to iOS devices,2013,"Apple iOS is one of the most popular mobile operating systems. As its core security technology, iOS provides  application sandboxing  but assigns a generic sandboxing profile to every third-party application. However, recent attacks and incidents with benign applications demonstrate that this design decision is vulnerable to crucial privacy and security breaches, allowing applications (either benign or malicious) to access contacts, photos, and device IDs. Moreover, the dynamic character of iOS apps written in Objective-C renders the currently proposed static analysis tools less useful.   In this paper, we aim to address the open problem of  preventing  (not only detecting) privacy leaks and simultaneously strengthening security against runtime attacks on iOS. Compared to similar research work on the open Android, realizing such a system for the closed-source iOS is highly involved.   We present the design and implementation of  PSiOS , a tool that features a novel policy enforcement framework for iOS. It provides fine-grained, application-specific, and user/administrator defined sandboxing for each third-party application  without  requiring access to the application source code. Our reference implementation deploys control-flow integrity based on the recently proposed MoCFI (Mobile CFI) framework that only protects applications against runtime attacks. We evaluated several popular iOS applications (e.g., Facebook, WhatsApp) to demonstrate the efficiency and effectiveness of  PSiOS ."
1665612,15510,20796,Privacy preserving indexing for eHealth information networks,2011,"The past few years have witnessed an increasing demand for the next generation health information networks (e.g., NHIN[1]), which hold the promise of supporting large-scale information sharing across a network formed by autonomous healthcare providers. One fundamental capability of such information network is to support efficient, privacy-preserving (for both users and providers) search over the distributed, access controlled healthcare documents. In this paper we focus on addressing the privacy concerns of content providers; that is, the search should not reveal the specific association between contents and providers (a.k.a. content privacy). We propose SS-PPI, a novel privacy-preserving index abstraction, which, in conjunction of distributed access control-enforced search protocols, provides theoretically guaranteed protection of content privacy. Compared with existing proposals (e.g., flipping privacy-preserving index[2]), our solution highlights with a series of distinct features: (a) it incorporates access control policies in the privacy-preserving index, which improves both search efficiency and attack resilience; (b) it employs a fast index construction protocol via a novel use of the secrete-sharing scheme in a fully distributed manner (without trusted third party), requiring only constant (typically two) round of communication; (c) it provides information-theoretic security against colluding adversaries during index construction as well as query answering. We conduct both formal analysis and experimental evaluation of SS-PPI and show that it outperforms the state-of-the-art solutions in terms of both privacy protection and execution efficiency."
27256,15510,10286,Cross-Domain Secure Computation,2014,"Consider the setting of two mutually distrustful parties Alice and Bob communicating over the Internet, who want to securely evaluate desired functions on their private inputs. In this setting all known protocols for securely evaluating general functions either require honest parties to trust an external party or provide only weaker notions of security. Thus, the question of minimizing or removing trusted set-up assumptions remains open. In this work, we introduce the cross-domain model CD for secure computation as a means to reducing the level of required trust. In this model, each domain consists of a set of mutually trusting parties along with a key-registration authority, where we would like parties from distinct domains to be able to perform multiple secure computation tasks concurrently. In this setting, we show the followings:#R##N##R##N#Positive Construction for 2 domains: We give a multiparty-party protocol that concurrently and securely evaluates any function in the CD model with two domains, using only a constant number of rounds and relying only on standard assumptions.Impossibility Results for 3 or more domains: Consider a deterministic function e.g., 1-out-of-2 bit OT that Alice and Bob in the standalone setting cannot evaluate trivially and which allows only Bob to receive the output. In this setting if besides Alice and Bob there is a third party such that all three are from distinct domains then they cannot securely compute any such function in the CD model in concurrent setting even when their inputs are pre-specified.#R##N##R##N#These results extend to the setting of multiple parties as well. In particular, there exists an n-party concurrently secure protocol in the CD model of n domains if and only if there are exactly n domains in the system."
1100666,15510,20754,Proactive Insider Threat Detection through Graph Learning and Psychological Context,2012,"The annual incidence of insider attacks continues to grow, and there are indications this trend will continue. While there are a number of existing tools that can accurately identify known attacks, these are reactive (as opposed to proactive) in their enforcement, and may be eluded by previously unseen, adversarial behaviors. This paper proposes an approach that combines Structural Anomaly Detection (SA) from social and information networks and Psychological Profiling (PP) of individuals. SA uses technologies including graph analysis, dynamic tracking, and machine learning to detect structural anomalies in large-scale information network data, while PP constructs dynamic psychological profiles from behavioral patterns. Threats are finally identified through a fusion and ranking of outcomes from SA and PP. The proposed approach is illustrated by applying it to a large data set from a massively multi-player online game, World of War craft (WoW). The data set contains behavior traces from over 350,000 characters observed over a period of 6 months. SA is used to predict if and when characters quit their guild (a player association with similarities to a club or workgroup in non-gaming contexts), possibly causing damage to these social groups. PP serves to estimate the five-factor personality model for all characters. Both threads show good results on the gaming data set and thus validate the proposed approach."
1524769,15510,339,Enforcing system-wide control flow integrity for exploit detection and diagnosis,2013,"Modern malware like Stuxnet is complex and exploits multiple vulnerabilites in not only the user level processes but also the OS kernel to compromise a system. A main trait of such exploits is manipulation of control flow. There is a pressing need to diagnose such exploits. Existing solutions that monitor control flow either have large overhead or high false positives and false negatives, hence making their deployment impractical. In this paper, we present Total-CFI, an efficient and practical tool built on a software emulator, capable of exploit detection by enforcing system-wide Control Flow Integrity (CFI). Total-CFI performs punctual guest OS view reconstruction to identify key guest kernel semantics like processes, code modules and threads. It incorporates a novel thread stack identification algorithm that identifies the stack boundaries for different threads in the system. Furthermore, Total-CFI enforces a CFI policy - a combination of whitelist based and shadow call stack based approaches to monitor indirect control flows and detect exploits. We provide a proof-of-concept implementation of Total-CFI on DECAF, built on top of Qemu. We tested 25 commonly used programs and 7 recent real world exploits on Windows OS and found 0 false positives and 0 false negatives respectively. The boot time overhead was found to be no more than 64.1% and the average memory overhead was found to be 7.46KB per loaded module, making it feasible for hardware integration."
524227,15510,20592,STEALTHMEM: system-level protection against cache-based side channel attacks in the cloud,2012,"Cloud services are rapidly gaining adoption due to the promises of cost efficiency, availability, and on-demand scaling. To achieve these promises, cloud providers share physical resources to support multi-tenancy of cloud platforms. However, the possibility of sharing the same hardware with potential attackers makes users reluctant to offload sensitive data into the cloud. Worse yet, researchers have demonstrated side channel attacks via shared memory caches to break full encryption keys of AES, DES, and RSA.#R##N##R##N#We present STEALTHMEM, a system-level protection mechanism against cache-based side channel attacks in the cloud. STEALTHMEM manages a set of locked cache lines per core, which are never evicted from the cache, and efficiently multiplexes them so that each VM can load its own sensitive data into the locked cache lines. Thus, any VM can hide memory access patterns on confidential data from other VMs. Unlike existing state-of-the-art mitigation methods, STEALTHMEM works with existing commodity hardware and does not require profound changes to application software. We also present a novel idea and prototype for isolating cache lines while fully utilizing memory by exploiting architectural properties of set-associative caches. STEALTHMEM imposes 5.9% of performance overhead on the SPEC 2006 CPU benchmark, and between 2% and 5% overhead on secured AES, DES and Blowfish, requiring only between 3 and 34 lines of code changes from the original implementations."
2352466,15510,9766,FRESCO: Modular Composable Security Services for Software-Defined Networks,2013,"OpenFlow is an open standard that has gained tremendous interest in the last few years within the network community. It is an embodiment of the software-defined networking paradigm, in which higher-level flow routing decisions are derived from a control layer that, unlike classic network switch implementations, is separated from the data handling layer. The central attraction to this paradigm is that by decoupling the control logic from the closed and proprietary implementations of traditional network switch infrastructure, researchers can more easily design and distribute innovative flow handling and network control algorithms. Indeed, we also believe that OpenFlow can, in time, prove to be one of the more impactful technologies to drive a variety of innovations in network security. OpenFlow could offer a dramatic simplification to the way we design and integrate complex network security applications into large networks. However, to date there remains a stark paucity of compelling OpenFlow security applications. In this paper, we introduce FRESCO, an OpenFlow security application development framework designed to facilitate the rapid design, and modular composition of OF-enabled detection and mitigation modules. FRESCO, which is itself an OpenFlow application, offers a Click-inspired [19] programming framework that enables security researchers to implement, share, and compose together, many different security detection and mitigation modules. We demonstrate the utility of FRESCO through the implementation of several well-known security defenses as OpenFlow security services, and use them to examine various performance and efficiency aspects of our proposed framework."
115386,15510,9969,Lattice Signatures and Bimodal Gaussians,2013,"Our main result is a construction of a lattice-based digital signature scheme that represents an improvement, both in theory and in practice, over today's most efficient lattice schemes. The novel scheme is obtained as a result of a modification of the rejection sampling algorithm that is at the heart of Lyubashevsky's signature scheme (Eurocrypt, 2012) and several other lattice primitives. Our new rejection sampling algorithm which samples from a bimodal Gaussian distribution, combined with a modified scheme instantiation, ends up reducing the standard deviation of the resulting signatures by a factor that is asymptotically square root in the security parameter. The implementations of our signature scheme for security levels of 128, 160, and 192 bits compare very favorably to existing schemes such as RSA and ECDSA in terms of efficiency. In addition, the new scheme has shorter signature and public key sizes than all previously proposed lattice signature schemes. As part of our implementation, we also designed several novel algorithms which could be of independent interest. Of particular note, is a new algorithm for efficiently generating discrete Gaussian samples over ℤ n . Current algorithms either require many high-precision floating point exponentiations or the storage of very large pre-computed tables, which makes them completely inappropriate for usage in constrained devices. Our sampling algorithm reduces the hard-coded table sizes from linear to logarithmic as compared to the time-optimal implementations, at the cost of being only a small factor slower."
1878435,15510,339,Re 3 : relay reliability reputation for anonymity systems,2014,"To conceal user identities, Tor, a popular anonymity system, forwards traffic through multiple relays. These relays, however, are often unreliable, leading to a degraded user experience. Worse yet, malicious relays may strategically introduce deliberate failures to increase their chance of compromising anonymity. In this paper we propose a reputation system that profiles the reliability of relays in an anonymity system based on users' past experience. A particular challenge is that an observed failure in an anonymous communication cannot be uniquely attributed to a single relay. This enables an attack where malicious relays can target a set of honest relays in order to drive down their reputation. Our system defends against this attack in two ways. Firstly, we use an adaptive exponentially-weighted moving average (EWMA) that ensures malicious relays adopting time-varying strategic behavior obtain low reputation scores over time. Secondly, we propose a filtering scheme based on the evaluated reputation score that can effectively discard relays involved in such attacks. We use probabilistic analysis, simulations, and real-world experiments to validate our reputation system. We show that the dominant strategy for an attacker is to not perform deliberate failures, but rather maintain a high quality of service. Our reputation system also significantly improves the reliability of path construction even in the absence of attacks. Finally, we show that the benefits of our reputation system can be realized with a moderate number of observations, making it feasible for individual clients to perform their own profiling, rather than relying on an external entity."
1640589,15510,20754,ZEBRA: Zero-Effort Bilateral Recurring Authentication,2014,"Common authentication methods based on passwords, tokens, or fingerprints perform one-time authentication and rely on users to log out from the computer terminal when they leave. Users often do not log out, however, which is a security risk. The most common solution, inactivity timeouts, inevitably fail security (too long a timeout) or usability (too short a timeout) goals. One solution is to authenticate users continuously while they are using the terminal and automatically log them out when they leave. Several solutions are based on user proximity, but these are not sufficient: they only confirm whether the user is nearby but not whether the user is actually using the terminal. Proposed solutions based on behavioral biometric authentication (e.g., keystroke dynamics) may not be reliable, as a recent study suggests. To address this problem we propose Zero-Effort Bilateral Recurring Authentication (ZEBRA). In ZEBRA, a user wears a bracelet (with a built-in accelerometer, gyroscope, and radio) on her dominant wrist. When the user interacts with a computer terminal, the bracelet records the wrist movement, processes it, and sends it to the terminal. The terminal compares the wrist movement with the inputs it receives from the user (via keyboard and mouse), and confirms the continued presence of the user only if they correlate. Because the bracelet is on the same hand that provides inputs to the terminal, the accelerometer and gyroscope data and input events received by the terminal should correlate because their source is the same - the user's hand movement. In our experiments ZEBRA performed continuous authentication with 85% accuracy in verifying the correct user and identified all adversaries within 11s. For a different threshold that trades security for usability, ZEBRA correctly verified 90% of users and identified all adversaries within 50s."
622299,15510,9969,Self-Updatable Encryption: Time Constrained Access Control with Hidden Attributes and Better Efficiency,2013,"Revocation and key evolving paradigms are central issues in cryptography, and in PKI in particular. A novel concern related to these areas was raised in the recent work of Sahai, Seyalioglu, and Waters Crypto 2012 who noticed that revoking past keys should at times e.g., the scenario of cloud storage be accompanied by revocation of past ciphertexts to prevent unread ciphertexts from being read by revoked users. They introduced revocable-storage attribute-based encryption RS-ABE as a good access control mechanism for cloud storage. RS-ABE protects against the revoked users not only the future data by supporting key-revocation but also the past data by supporting ciphertext-update, through which a ciphertext at time T can be updated to a new ciphertext at time Ti¾?+i¾?1 using only the public key. Motivated by this pioneering work, we ask whether it is possible to have a modular approach, which includes a primitive for time managed ciphertext update as a primitive. We call encryption which supports this primitive a self-updatable encryption SUE. We then suggest a modular cryptosystems design methodology based on three sub-components: a primary encryption scheme, a key-revocation mechanism, and a time-evolution mechanism which controls the ciphertext self-updating via an SUE method, coordinated with the revocation when needed. Our goal in this is to allow the self-updating ciphertext component to take part in the design of new and improved cryptosystems and protocols in a flexible fashion. Specifically, we achieve the following results:"
1885552,15510,339,Breaking Integrated Circuit Device Security through Test Mode Silicon Reverse Engineering,2014,"Integrated Circuit (IC) device manufacturing is a challenging task and often results in subtle defects that can render a chip unusable. To detect these defects at multiple stages during the IC production process, test modes are inserted (Design For Testability). On the downside, attackers can use these test modes to break IC device security and extract sensitive information such as the firmware implementation or secret key material. While in high security smart cards the testing circuits are physically removed during production for this reason, in the majority of digital ICs the testing modes remain intact. Often they are undocumented, well-hidden and contain secret test commands. Utilizing search algorithms and/or side channel information, several attacks on secret testing modes have been presented lately. Accordingly, countermeasures that frequently rely on obfuscation techniques have been proposed as more advanced cryptographic methods would require significantly more space on the die and thus cause higher production costs. In this work, we show that limited effort silicon reverse engineering can be effectively used to discover secret testing modes and that proposed obfuscation based countermeasures can be circumvented without altering the analysis technique. We describe our approach in detail at the example of a proprietary cryptographic game authentication chip of a well known gaming console and present an FPGA implementation of the previously secret authentication algorithm."
96327,15510,9874,BackRef: Accountability in Anonymous Communication Networks,2014,"Many anonymous communication networks (ACNs) rely on routing traffic through a sequence of proxy nodes to obfuscate the orig- inator of the traffic. Without an accountability mechanism, exit proxy nodes may become embroiled in a criminal investigation if originators commit criminal actions through the ACN. We present BackRef ,a generic mechanism for ACNs that provides practical repudiation for the proxy nodes by tracing back the selected outbound traffic to the predeces- sor node (but not in the forward direction) through a cryptographically verifiable chain. It also provides an option for full (or partial) traceabil- ity back to the entry node or even to the corresponding originator when all intermediate nodes are cooperating. Moreover, to maintain a good balance between anonymity and accountability, the protocol incorpo- rates whitelist directories at exit proxy nodes. BackRef offers improved deployability over the related work, and introduces a novel concept of pseudonymous signatures that may be of independent interest. We exemplify the utility of BackRef by integrating it into the onion routing (OR) protocol, and examine its deployability by considering sev- eral system-level aspects. We also present the security definitions for the BackRef system (namely, anonymity, backward traceability, no for- ward traceability, and no false accusation) and conduct a formal security analysis of the OR protocol with BackRef using ProVerif, an automated cryptographic protocol verifier, establishing the aforementioned security properties against a strong adversarial model."
1906836,15510,23836,Securing Boot of an Embedded Linux on FPGA,2011,"The growing complexity of embedded systems makes reconfiguration and embedded OSs (Operating Systems) more and more interesting. FPGAs (Field-Programmable Gate Arrays) are able to perform such a feature with success. With most of the FPGAs, the OS is stored into an external memory (usually Flash) and running on a processor embedded into the FPGA. We consider that FPGA embedded processor is able to process the OS update through, for instance, an insecure network. However, these features may give rise to security flaws affecting the system integrity or freshness. Integrity can be altered by spoofing or modifying data in order to introduce malicious code. In the same way, freshness can be affected by replaying an old configuration in order to downgrade the system. This work proposes a trusted computing mechanism taking into account the whole security chain from bit stream-to-kernel-boot ensuring, both hardware and software, integrity while preventing replay attacks. This paper summarizes the current counter-measures ensuring integrity, confidentiality and freshness of the bit stream. Then we propose a solution to protect OS kernel against malicious modifications thanks to already trusted bit stream power-up. We also evaluate the area and performance overhead of the proposed architecture and its improvement using asymmetric cryptography. Adding security and increasing performances, this solution generates between 0 and 40% of area overhead depending on the re-usability consideration."
1981748,15510,9856,Disclosure: detecting botnet command and control servers through large-scale NetFlow analysis,2012,"Botnets continue to be a significant problem on the Internet. Accordingly, a great deal of research has focused on methods for detecting and mitigating the effects of botnets. Two of the primary factors preventing the development of effective large-scale, wide-area botnet detection systems are seemingly contradictory. On the one hand, technical and administrative restrictions result in a general unavailability of raw network data that would facilitate botnet detection on a large scale. On the other hand, were this data available, real-time processing at that scale would be a formidable challenge. In contrast to raw network data, NetFlow data is widely available. However, NetFlow data imposes several challenges for performing accurate botnet detection.   In this paper, we present Disclosure, a large-scale, wide-area botnet detection system that incorporates a combination of novel techniques to overcome the challenges imposed by the use of NetFlow data. In particular, we identify several groups of features that allow Disclosure to reliably distinguish C&C channels from benign traffic using NetFlow records (i.e., flow sizes, client access patterns, and temporal behavior). To reduce Disclosure's false positive rate, we incorporate a number of external reputation scores into our system's detection procedure. Finally, we provide an extensive evaluation of Disclosure over two large, real-world networks. Our evaluation demonstrates that Disclosure is able to perform real-time detection of botnet C&C channels over datasets on the order of billions of flows per day."
2644522,15510,20754,Hacking Blind,2014,"We show that it is possible to write remote stack buffer overflow exploits without possessing a copy of the target binary or source code, against services that restart after a crash. This makes it possible to hack proprietary closed-binary services, or open-source servers manually compiled and installed from source where the binary remains unknown to the attacker. Traditional techniques are usually paired against a particular binary and distribution where the hacker knows the location of useful gadgets for Return Oriented Programming (ROP). Our Blind ROP (BROP) attack instead remotely finds enough ROP gadgets to perform a write system call and transfers the vulnerable binary over the network, after which an exploit can be completed using known techniques. This is accomplished by leaking a single bit of information based on whether a process crashed or not when given a particular input string. BROP requires a stack vulnerability and a service that restarts after a crash. We implemented Braille, a fully automated exploit that yielded a shell in under 4,000 requests (20 minutes) against a contemporary nginx vulnerability, yaSSL + MySQL, and a toy proprietary server written by a colleague. The attack works against modern 64-bit Linux with address space layout randomization (ASLR), no-execute page protection (NX) and stack canaries."
2219525,15510,8228,Reorganized and Compact DFA for Efficient Regular Expression Matching,2011,"Regular expression matching has become a critical yet challenging technique in content-aware network processing, such as application identification and deep inspection. To meet the requirement for processing heavy network traffic at line rate, Deterministic Finite Automata (DFA) is widely used to accelerate regular expression matching at the expense of large memory usage. In this paper, we propose a DFA-based algorithm named RCDFA (Reorganized and Compact DFA), which dramatically reduces the memory usage while maintaining fast and deterministic lookup speed. Based on the dissection of real-life DFA tables, we observe that almost every state has multiple similar states, i.e. they share identical next-state transitions for most input characters. However, these similar states often distribute at nonadjacent positions in the original DFA table. RCDFA aims at reorganizing all similar states into adjacent entries, so that identical transitions become consecutive along the state dimension, then compresses the reorganized DFA table utilizing bitmap technique. Coupled with mapping along the character dimension, RCDFA is not only efficient in DFA compression, but also effective for hardware implementation. Experiment results show, RCDFA has superior performance in terms of high processing speed, low memory usage and short preprocessing time. RCDFA consistently achieves over 95% compression ratio for existing real-life rule sets. Implemented in a single Xilinx Virtex-6 FPGA platform, RCDFA matching engine achieved 12Gbps throughput."
1731625,15510,20754,Lost in Translation: Improving Decoy Documents via Automated Translation,2012,"Detecting insider attacks continues to prove to be one of the most difficult challenges in securing sensitive data. Decoy information and documents represent a promising approach to detecting malicious masqueraders, however, false positives can interfere with legitimate work and take up user time. We propose generating foreign language decoy documents that are sprinkled with untranslatable enticing proper nouns such as company names, hot topics, or apparent login information. Our goal is for this type of decoy to serve three main purposes. First, using a language that is not used in normal business practice gives real users a clear signal that the document is fake, so they waste less time examining it. Second, an attacker, if enticed, will need to exfiltrate the document's contents in order to translate it, providing a cleaner signal of malicious activity. Third, we consume significant adversarial resources as they must still read the document and decide if it contains valuable information, which is made more difficult as it will be somewhat scrambled through translation. In this paper, we expand upon the rationale behind using foreign language decoys. We present a preliminary evaluation which shows how they significantly increase the cost to attackers in terms of the amount of time that it takes to determine if a document is real and potentially contains valuable information or is entirely bogus, confounding their goal of exfiltrating important sensitive information."
1196193,15510,22260,No NAT'd User Left Behind: Fingerprinting Users behind NAT from NetFlow Records Alone,2014,"It is generally recognized that the network traffic generated by an individual acts as his biometric signature. Several tools exploit this fact to fingerprint and monitor users. Often, though, these tools access the entire traffic, including IP addresses and payloads. In general, this is not feasible on the grounds that both performance and privacy would be negatively affected. In reality, most ISPs convert user traffic into Net Flow records for a concise representation that does not include the payload. More importantly, a single IP address belonging to a large and distributed network is usually masked using Network Address Translation techniques, thus a few IP addresses may be associated to thousands of individuals (NAT'd IPs). We devised a new fingerprinting framework that overcomes these hurdles. Our system is able to analyze a huge amount of network traffic represented as Net Flows, with the intent to track people. It does so by accurately inferring when users are connected to the network and which IP addresses they are using, even though thousands of users are hidden behind NAT. Our prototype implementation was deployed and tested within an existing large metropolitan WiFi network serving about 200,000 users, with an average load of more than 1,000 users simultaneously connected behind 2 NAT'd IP addresses only. Our solution turned out to be very effective, with an accuracy greater than 90%. We also devised new tools and refined existing ones that may be applied to other contexts related to Net Flow analysis."
1272922,15510,22288,Game Theoretic Modeling of Security and Interdependency in a Public Cloud,2014,"As cloud computing thrives, many small organizations are joining a public cloud to take advantage of its multiple benefits. Cloud computing is cost efficient, i.e., cloud user can reduce spending on technology infrastructure and have easy access to their information without up-front or long-term commitment of resources. Moreover, a cloud user can dynamically grow and shrink the resources provisioned to an application on demand. Despite those benefits, cyber security concern is the main reason many large organizations with sensitive information such as the Department of Defense have been reluctant to join a public cloud. This is because different public cloud users share a common platform such as the hypervisor. A common platform intensifies the well-known problem of cyber security interdependency. In fact, an attacker can compromise a virtual machine (VM) to launch an attack on the hypervisor which if compromised can instantly yield the compromising of all the VMs running on top of that hypervisor. Therefore, a user that does not invest in cyber security imposes a negative externality on others. This research uses the mathematical framework of game theory to analyze the cause and effect of interdependency in a public cloud platform. This work shows that there are multiple possible Nash equilibria of the public cloud security game. However, the players use a specific Nash equilibrium profile depending on the probability that the hypervisor is compromised given a successful attack on a user and the total expense required to invest in security. Finally, there is no Nash equilibrium in which all the users in a public cloud will fully invest in security."
67280,15510,20592,Efficient and scalable socware detection in online social networks,2012,"Online social networks (OSNs) have become the new vector for cybercrime, and hackers are finding new ways to propagate spam and malware on these platforms, which we refer to as socware. As we show here, socware cannot be identified with existing security mechanisms (e.g., URL blacklists), because it exploits different weaknesses and often has different intentions.#R##N##R##N#In this paper, we present MyPageKeeper, a Facebook application that we have developed to protect Facebook users from socware. Here, we present results from the perspective of over 12K users who have installed MyPageKeeper and their roughly 2.4 million friends. Our work makes three main contributions. First, to enable protection of users at scale, we design an efficient socware detection method which takes advantage of the social context of posts. We find that our classifier is both accurate (97% of posts flagged by it are indeed socware and it incorrectly flags only 0.005% of benign posts) and efficient (it requires 46 ms on average to classify a post). Second, we show that socware significantly differs from traditional email spam or web-based malware. For example, website blacklists identify only 3% of the posts flagged by MyPageKeeper, while 26% of flagged posts point to malicious apps and pages hosted on Facebook (which no current antivirus or blacklist is designed to detect). Third, we quantify the prevalence of socware by analyzing roughly 40 million posts over four months; 49% of our users were exposed to at least one socware post in this period. Finally, we identify a new type of parasitic behavior, which we refer to as Like-as-a-Service, whose goal is to artificially boost the number of Likes of a Facebook page."
2008390,15510,20754,Safe Loading - A Foundation for Secure Execution of Untrusted Programs,2012,"The standard loader (ld.so) is a common target of attacks. The loader is a trusted component of the application, and faults in the loader are problematic, e.g., they may lead to local privilege escalation for SUID binaries. Software-based fault isolation (SFI) provides a framework to execute arbitrary code while protecting the host system. A problem of current approaches to SFI is that fault isolation is decoupled from the dynamic loader, which is treated as a black box. The sandbox has no information about the (expected) execution behavior of the application and the connections between different shared objects. As a consequence, SFI is limited in its ability to identify devious application behavior. This paper presents a new approach to run untrusted code in a user-space sandbox. The approach replaces the standard loader with a security-aware trusted loader. The secure loader and the sandbox together cooperate to allow controlled execution of untrusted programs. A secure loader makes security a first class concept and ensures that the SFI system does not allow any unchecked code to be executed. The user-space sandbox builds on the secure loader and subsequently dynamically checks for malicious code and ensures that all control flow instructions of the application adhere to an execution model. The combination of the secure loader and the user-space sandbox enables the safe execution of untrusted code in user-space. Code injection attacks are stopped before any unintended code is executed. Furthermore, additional information provided by the loader can be used to support additional security properties, e.g., in lining of Procedure Linkage Table calls reduces the number of indirect control flow transfers and therefore limits jump-oriented attacks. This approach implements a secure platform for privileged applications and applications reachable over the network that anticipates and confines security threats from the beginning."
113382,15510,9969,Shorter Quasi-Adaptive NIZK Proofs for Linear Subspaces,2013,"We define a novel notion of quasi-adaptive non-interactive zero knowledge NIZK proofs for probability distributions on parametri- zed languages. It is quasi-adaptive in the sense that the common reference string CRS generator can generate the CRS depending on the language parameters. However, the simulation is required to be uniform, i.e., a single efficient simulator should work for the whole class of parametrized languages. For distributions on languages that are linear subspaces of vector spaces over bilinear groups, we give quasi-adaptive computationally sound NIZKs that are shorter and more efficient than Groth-Sahai NIZKs. For many cryptographic applications quasi-adaptive NIZKs suffice, and our constructions can lead to significant improvements in the standard model. Our construction can be based on any k-linear assumption, and in particular under the eXternal Diffie Hellman XDH assumption our proofs are even competitive with Random-Oracle based Σ-protocol NIZK proofs.#R##N##R##N#We also show that our system can be extended to include integer tags in the defining equations, where the tags are provided adaptively by the adversary. This leads to applicability of our system to many applications that use tags, e.g. applications using Cramer-Shoup projective hash proofs. Our techniques also lead to the shortest known ciphertext fully secure identity based encryption IBE scheme under standard static assumptions SXDH. Further, we also get a short publicly-verifiable CCA2-secure IBE scheme."
2158064,15510,339,WebPatrol: automated collection and replay of web-based malware scenarios,2011,"Traditional remote-server-exploiting malware is quickly evolving and adapting to the new web-centric computing paradigm. By leveraging the large population of (insecure) web sites and exploiting the vulnerabilities at client-side modern (complex) browsers (and their extensions), web-based malware becomes one of the most severe and common infection vectors nowadays. While traditional malware collection and analysis are mainly focusing on binaries, it is important to develop new techniques and tools for collecting and analyzing web-based malware, which should include a complete web-based malicious logic to reflect the dynamic, distributed, multi-step, and multi-path web infection trails, instead of just the binaries executed at end hosts. This paper is a first attempt in this direction to automatically collect web-based malware scenarios (including complete web infection trails) to enable fine-grained analysis. Based on the collections, we provide the capability for offline live replay, i.e., an end user (e.g., an analyst) can faithfully experience the original infection trail based on her current client environment, even when the original malicious web pages are not available or already cleaned. Our evaluation shows that WebPatrol can collect/cover much more complete infection trails than state-of-the-art honeypot systems such as PHoneyC [11] and Capture-HPC [1]. We also provide several case studies on the analysis of web-based malware scenarios we have collected from a large national education and research network, which contains around 35,000 web sites."
2680645,15510,10286,Variants of Waters' Dual System Primitives Using Asymmetric Pairings (Extended Abstract),2012,"Waters, in 2009, introduced an important technique, called dual system encryption, to construct identity-based encryption (IBE) and related schemes. The resulting IBE scheme was described in the setting of symmetric pairing. A key feature of the construction is the presence of random tags in the ciphertext and decryption key. Later work by Lewko and Waters removed the tags and proceeding through composite-order pairings led to a more efficient dual system IBE scheme using asymmetric pairings whose security is based on non-standard but static assumptions. In this work, we have systematically simplified Wa- ters 2009 IBE scheme in the setting of asymmetric pairing. The simplifi- cations retain tags used in the original description. This leads to several variants, the first one of which is based on standard assumptions and in comparison to Waters' original scheme reduces ciphertexts and keys by two elements each. Going through several stages of simplifications, we finally obtain a simple scheme whose security can be based on two standard assumptions and a natural and minimal extension of the deci- sion Diffie-Hellman problem for asymmetric pairing groups. The scheme itself is also minimal in the sense that apart from the tags, both en- cryption and key generation use exactly one randomiser each. This final scheme is more efficient than both the previous dual system IBE scheme in the asymmetric setting due to Lewko and Waters and the more recent dual system IBE scheme due to Lewko. We extend the IBE scheme to hierarchical IBE (HIBE) and broadcast encryption (BE) schemes. Both primitives are secure in their respective full models and have better ef- ficiencies compared to previously known schemes offering the same level and type of security."
955266,15510,9856,A taste of tweets: reverse engineering Twitter spammers,2014,"In this paper, through reverse engineering Twitter spammers' tastes (their preferred targets to spam), we aim at providing guidelines for building more effective social honeypots, and generating new insights to defend against social spammers. Specifically, we first perform a measurement study by deploying benchmark social honeypots on Twitter with diverse and fine-grained social behavior patterns to trap spammers. After five months' data collection, we make a deep analysis on how Twitter spammers find their targets. Based on the analysis, we evaluate our new guidelines for building effective social honeypots by implementing advanced honeypots. Particularly, within the same time period, using those advanced honeypots can trap spammers around 26 times faster than using traditional honeypots.   In the second part of our study, we investigate new  active  collection approaches to complement the fundamentally  passive  procedure of using honeypots to slowly attract spammers. Our goal is that, given limited resources/time, instead of blindly crawling all possible (or randomly sampling) Twitter accounts at the first place (for later spammer analysis), we need a lightweight strategy to prioritize the  active  crawling/sampling of  more likely  spam accounts from the huge Twittersphere. Applying what we have learned about the tastes of spammers, we design two new,  active and guided  sampling approaches for collecting most likely spammer accounts during the crawling. According to our evaluation, our strategies could efficiently crawl/sample over 17,000 spam accounts within a short time with a considerably high Hit Ratio, i.e., collecting 6 correct spam accounts in every 10 sampled accounts."
1240464,15510,8235,Efficient Similarity Search over Encrypted Data,2012,"In recent years, due to the appealing features of cloud computing, large amount of data have been stored in the cloud. Although cloud based services offer many advantages, privacy and security of the sensitive data is a big concern. To mitigate the concerns, it is desirable to outsource sensitive data in encrypted form. Encrypted storage protects the data against illegal access, but it complicates some basic, yet important functionality such as the search on the data. To achieve search over encrypted data without compromising the privacy, considerable amount of searchable encryption schemes have been proposed in the literature. However, almost all of them handle exact query matching but not similarity matching, a crucial requirement for real world applications. Although some sophisticated secure multi-party computation based cryptographic techniques are available for similarity tests, they are computationally intensive and do not scale for large data sources. In this paper, we propose an efficient scheme for similarity search over encrypted data. To do so, we utilize a state-of-the-art algorithm for fast near neighbor search in high dimensional spaces called locality sensitive hashing. To ensure the confidentiality of the sensitive data, we provide a rigorous security definition and prove the security of the proposed scheme under the provided definition. In addition, we provide a real world application of the proposed scheme and verify the theoretical results with empirical observations on a real dataset."
706109,15510,9856,Implementation and implications of a stealth hard-drive backdoor,2013,"Modern workstations and servers implicitly trust hard disks to act as well-behaved block devices. This paper analyzes the catastrophic loss of security that occurs when hard disks are not trustworthy. First, we show that it is possible to compromise the firmware of a commercial off-the-shelf hard drive, by resorting only to public information and reverse engineering. Using such a compromised firmware, we present a stealth rootkit that replaces arbitrary blocks from the disk while they are written, providing a  data replacement back-door . The measured performance overhead of the compromised disk drive is less than 1% compared with a normal, non-malicious disk drive. We then demonstrate that a remote attacker can even establish a communication channel with a compromised disk to infiltrate commands and to ex-filtrate data. In our example, this channel is established over the Internet to an unmodified web server that relies on the compromised drive for its storage, passing through the original webserver, database server, database storage engine, filesystem driver, and block device driver. Additional experiments, performed in an emulated disk-drive environment, could automatically extract sensitive data such as  /etc/shadow  (or a secret key file) in less than a minute. This paper claims that the difficulty of implementing such an attack is not limited to the area of government cyber-warfare; rather, it is well within the reach of moderately funded criminals, botnet herders and academic researchers."
810028,15510,339,Demo: a comprehensive framework enabling data-minimizing authentication,2011,"Authentication is an all-embracing mechanism in today's (digital) society. While current systems require users to provide much personal data and offer many attack vectors due to using a username/passwords combination, systems that allow for minimizing the data released during authentication exist. Implementing such data-minimizing authentication reduces the number of attack vectors, enables enterprises to reduce the risk associated with possession of sensitive user data, and realizes better privacy for users. Our prototype demonstrates the use of data-minimizing authentication using the scenario of accessing a teenage chat room in a privacy-preserving way. The prototype allows a user to retrieve credentials, which may be seen as the digital equivalent of the plastic cards we carry in our wallets today. It also implements a service provider who requires authentication with respect to a service-specific policy. The prototype determines whether and how the user can fulfill the policy with her credentials, which typically results in various options. A graphical user interface then allows the user to select one of these options. Based on the user's input, the prototype generates an Identity Mixer proof that shows fulfillment of the service provider's policy without revealing unnecessary information. Finally, this proof is sent to the service provider for verification. Our prototype is the first implementation of such far-reaching data-minimizing authentication, where we provide the building blocks of our implementation as open-source software."
988564,15510,9856,Twitter games: how successful spammers pick targets,2012,"Online social networks, such as Twitter, have soared in popularity and in turn have become attractive targets of spam. In fact, spammers have evolved their strategies to stay ahead of Twitter's anti-spam measures in this short period of time. In this paper, we investigate the strategies Twitter spammers employ to reach relevant target audiences. Due to their targeted approaches to send spam, we see evidence of a large number of the spam accounts forming relationships with other Twitter users, thereby becoming deeply embedded in the social network.   We analyze nearly 20 million tweets from about 7 million Twitter accounts over a period of five days. We identify a set of 14,230 spam accounts that manage to live longer than the other 73% of other spam accounts in our data set. We characterize their behavior, types of tweets they use, and how they target their audience. We find that though spam campaigns changed little from a recent work by Thomas et al., spammer strategies evolved much in the same short time span, causing us to sometimes find contradictory spammer behavior from what was noted in Thomas et al.'s work. Specifically, we identify four major strategies used by 2/3rd of the spammers in our data. The most popular of these was one where spammers targeted their own followers. The availability of various kinds of services that help garner followers only increases the popularity of this strategy. The evolution in spammer strategies we observed in our work suggests that studies like ours should be undertaken frequently to keep up with spammer evolution."
157559,15510,374,DroidMiner: Automated Mining and Characterization of Fine-grained Malicious Behaviors in Android Applications,2014,"Most existing malicious Android app detection approaches rely on manually selected detection heuristics, features, and models. In this paper, we describe a new, complementary system, called DroidMiner, which uses static analysis to automatically mine malicious program logic from known Android malware, abstracts this logic into a sequence of threat modalities, and then seeks out these threat modality patterns in other unknown (or newly published) An- droid apps. We formalize a two-level behavioral graph representation used to capture Android app program logic, and design new techniques to identify and label elements of the graph that capture malicious behavioral patterns (or ma- licious modalities). After the automatic learning of these malicious behavioral models, DroidMiner can scan a new Android app to (i) determine whether it con- tains malicious modalities, (ii) diagnose the malware family to which it is most closely associated, (iii) and provide further evidence as to why the app is con- sidered to be malicious by including a concise description of identified malicious behaviors. We evaluate DroidMiner using 2,466 malicious apps, identified from a corpus of over 67,000 third-party market Android apps, plus an additional set of over 10,000 official market Android apps. Using this set of real-world apps, we demonstrate that DroidMiner achieves a 95.3% detection rate, with only a 0.4% false positive rate. We further evaluate DroidMiner's ability to classify malicious apps under their proper family labels, and measure its label accuracy at 92%."
1730746,15510,10192,Classification of Malicious Web Sessions,2012,"The ever increasing number of vulnerabilities and reported attacks on Web systems clearly illustrate the need for better understanding of malicious cyber activities, which will allow better protection, detection, and service recovery in the cyberspace. In this paper we use three supervised machine learning methods, Support Vector Machines (SVM), and decision trees based J48 and PART, to classify attacker activities aimed at Web systems. The empirical analysis is based on four datasets, each in duration of four to five months, collected by high-interaction honeypots. Malicious Web sessions are characterized with forty three different features (i.e., session attributes) extracted from Web server logs. Our results show that the supervised learning methods can be used to efficiently distinguish attack sessions from vulnerability scan sessions, with very high probability of detection and very low probability of false alarms. Furthermore, we follow the principle of Occam's razor, that is, we seek for the simplest possible model that can successfully classify malicious Web sessions. Our results show that attacks differ from vulnerability scans only in a small number of features (i.e., session attributes). In particular, depending on the data set, classification of malicious activities can be performed using from four to six features without significantly affecting learners' performance compared to when all 43 features are used. Decision tree based methods J48 and PART perform better than SVM across all datasets."
858407,15510,339,CCS'12 co-located workshop summary for SPSM 2012,2012,"Mobile devices such as smartphones and Internet-capable tablets have achieved computing and networking capabilities comparable to traditional personal computers. Their successful consumerization has also become a source of pain for adopting users and organizations. The operating systems supporting these new devices have both advantages and disadvantages with respect to offered security. On one hand, they use application sandboxing to contain exploits and limit privileges given to malware. On the other hand, they collect and organize many forms of security- and privacy-sensitive information simply as a matter of operation, and make that information easily accessible to downloaded third-party applications.   Recognizing smartphone security and privacy as the emerging area, this workshop intends to provide a venue for interested researchers and practitioners to get together and exchange ideas, thus to deepen our understanding to various security and privacy issues on smartphones, specifically the platforms such as iOS and Android. To this end, the workshop solicits both technical and position paper submissions with a variety of relevant topics and further strongly encourages novel paradigms and controversial ideas. With strong engagement from our community, the workshop emerges as a vibrant venue for creative debate and interaction in security- and privacy-sensitive areas of computing and communication broadly impacted by smartphones and mobile devices."
1470743,15510,9856,Analysis of the communication between colluding applications on modern smartphones,2012,"Modern smartphones that implement permission-based security mechanisms suffer from attacks by colluding applications. Users are not made aware of possible implications of application collusion attacks---quite the contrary---on existing platforms, users are implicitly led to believe that by approving the installation of each application independently, they can limit the damage that an application can cause.   We implement and analyze a number of covert and overt communication channels that enable applications to collude and therefore indirectly escalate their permissions. Furthermore, we present and implement a covert channel between an installed application and a web page loaded in the system browser. We measure the throughput of all these channels as well as their bit-error rate and required synchronization for successful data transmission. The measured throughput of covert channels ranges from 3.7 bps to 3.27 kbps on a Nexus One phone and from 0.47 bps to 4.22 kbps on a Samsung Galaxy S phone; such throughputs are sufficient to efficiently exchange users' sensitive information (e.g., GPS coordinates or contacts). We test two popular research tools that track information flow or detect communication channels on mobile platforms, and confirm that even if they detect some channels, they still do not detect all the channels and therefore fail to fully prevent application collusion. Attacks using covert communication channels remain, therefore, a real threat to smartphone security and an open problem for the research community."
2066168,15510,339,Improved anonymous proxy re-encryption with CCA security,2014,"Outsourcing private data and heavy computation tasks to the cloud may lead to privacy breach as attackers (e.g., malicious outsiders or cloud administrators) may correlate any relevant information to penetrate information of their interests. Therefore, how to preserve cloud users' privacy has been a top concern when adopting cloud solutions. In this paper, we investigate the identity privacy problem for the proxy re-encryption, which allows any third party (e.g., cloud) to re-encrypt ciphertexts in order to delegate the decryption right from one to another user. The relevant identity information, e.g., whose ciphertext was re-encrypted to the ciphertext under whose public key, may leak because re-encryption keys and ciphertexts (before and after re-encryption) are known to the third party. We review prior anonymity (identity privacy) notions, and find that these notions are either impractical or too weak. To address this problem thoroughly, we rigorously define the anonymity notion that not only embraces the prior anonymity notions but also captures the necessary anonymity requirement for practical applications. In addition, we propose a new and efficient proxy re-encryption scheme. The scheme satisfies the proposed anonymity notion under the Squared Decisional Bilinear Diffie-Hellman assumption and achieves security against chosen ciphertext attack under the Decisional Bilinear Diffie-Hellman assumption in the random oracle model. To the best of our knowledge, it is the first proxy re-encryption scheme attaining both chosen-ciphertext security and anonymity simultaneously.   We implement a prototype based on the proposed proxy re-encryption scheme and the performance study shows that it is efficient."
1060126,15510,9766,The Sniper Attack: Anonymously Deanonymizing and Disabling the Tor Network,2014,"Abstract : Tor is a distributed onion-routing network used for achieving anonymity and resisting censorship online. Because of Tor's growing popularity, it is attracting increasingly larger threats against which it was not securely designed. In this paper we present the Sniper Attack, an extremely low cost but highly destructive denial of service attack against Tor that an adversary may use to anonymously disable arbitrary Tor relays. The attack utilizes valid protocol messages to boundlessly consume memory by exploiting Tor's end-to-end reliable data transport. We design and evaluate a prototype of the attack to show its feasibility and efficiency: our experiments show that an adversary may consume a victim relay's memory by as much as 2187 KiB/s while using at most only 92 KiB/s of upstream bandwidth. We extend our experimental results to estimate the threat against the live Tor network and find that a strategic adversary could disable all of the top 20 exit relays in only 29 minutes, thereby reducing Tor's bandwidth capacity by 35 percent. We also show how the attack enables the deanonymization of hidden services through selective denial of service by forcing them to choose guard nodes in control of the adversary. Finally, we discuss defenses against the Sniper Attack that provably render the attack ineffective, and suggest defenses against deanonymization by denial-of-service attacks in general that significantly mitigate the threat."
1606270,15510,9856,From prey to hunter: transforming legacy embedded devices into exploitation sensor grids,2011,"Our global communication infrastructures are powered by large numbers of legacy embedded devices. Recent advances in offensive technologies targeting embedded systems have shown that the stealthy exploitation of high-value embedded devices such as router and firewalls is indeed feasible. However, little to no host-based defensive technology is available to monitor and protect these devices, leaving large numbers of critical devices defenseless against exploitation. We devised a method of augmenting legacy embedded devices, like Cisco routers, with host-based defenses in order to create a stealthy, embedded sensor-grid capable of monitoring and capturing real-world attacks against the devices which constitute the bulk of the Internet substrate. Using a software mechanism which we call the Symbiote, a white-list based code modification detector is automatically injected  in situ  into Cisco IOS, producing a fully functional router firmware capable of detecting and capturing successful attacks against itself for analysis. Using the Symbiote-protected router as the main component, we designed a sensor system which requires no modification to existing hardware, fully preserves the functionality of the original firmware, and detects unauthorized modification of memory within 450 ms. We believe that it is feasible to use the techniques described in this paper to inject monitoring and defensive capability into existing routers to create an  early attack warning system  to protect the Internet substrate."
2100485,15510,339,On the effectiveness of risk prediction based on users browsing behavior,2014,"Users are typically the final target of web attacks: criminals are interested in stealing their money, their personal information, or in infecting their machines with malicious code. However, while many aspects of web attacks have been carefully studied by researchers and security companies, the reasons that make certain users more at risk than others are still unknown. Why do certain users never encounter malicious pages while others seem to end up on them on a daily basis?   To answer this question, in this paper we present a comprehensive study on the effectiveness of risk prediction based only on the web browsing behavior of users. Our analysis is based on a telemetry dataset collected by a major AntiVirus vendor, comprising millions of URLs visited by more than 100,000 users during a period of three months. For each user, we extract detailed usage statistics, and distill this information in 74 unique features that model different aspects of the user's behavior.   After the features are extracted, we perform a correlation analysis to see if any of them is correlated with the probability of visiting malicious web pages. Afterwards, we leverage machine learning techniques to provide a prediction model that can be used to estimate the risk class of a given user. The results of our experiments show that it is possible to predict with a reasonable accuracy (up to 87%) the users that are more likely to be the victims of web attacks, only by analyzing their browsing history."
2343492,15510,20592,Effective attacks and provable defenses for website fingerprinting,2014,"Website fingerprinting attacks allow a local, passive eavesdropper to identify a user's web activity by leveraging packet sequence information. These attacks break the privacy expected by users of privacy technologies, including low-latency anonymity networks such as Tor. In this paper, we show a new attack that achieves significantly higher accuracy than previous attacks in the same field, further highlighting website fingerprinting as a genuine threat to web privacy. We test our attack under a large open-world experimental setting, where the client can visit pages that the attacker is not aware of. We found that our new attack is much more accurate than previous attempts, especially for an attacker monitoring a set of sites with low base incidence rate. We can correctly determine which of 100 monitored web pages a client is visiting (out of a significantly larger universe) at an 85% true positive rate with a false positive rate of 0.6%, compared to the best of 83% true positive rate with a false positive rate of 6% in previous work.#R##N##R##N#To defend against such attacks, we need provably effective defenses. We show how simulatable, deterministic defenses can be provably private, and we show that bandwidth overhead optimality can be achieved for these defenses by using a supersequence over anonymity sets of packet sequences. We design a new defense by approximating this optimal strategy and demonstrate that this new defense is able to defeat any attack at a lower cost on bandwidth than the previous best."
828808,15510,8839,Itus: an implicit authentication framework for android,2014,"Security and usability issues with pass-locks on mobile devices have prompted researchers to develop implicit authentication (IA) schemes, which continuously and transparently authenticate users using behavioural biometrics. Contemporary IA schemes proposed by the research community are challenging to deploy, and there is a need for a framework that supports: different behavioural classifiers, given that different apps have different requirements; app developers using IA without becoming domain experts; and real-time classification on resource-constrained mobile devices. We present Itus, an IA framework for Android that allows the research community to improve IA schemes incrementally, while allowing app developers to adopt these improvements at their own pace.   We describe the Itus framework and how it provides: ease of use: Itus allows app developers to use IA by changing as few as two lines of their existing code - on the other hand, Itus provides an oracle capable of making advanced recommendations should developers wish to fine-tune the classifiers; flexibility: developers can deploy Itus in an application-specific manner, adapting to their unique needs; extensibility: researchers can contribute new behavioural features and classifiers without worrying about deployment particulars; low performance overhead: Itus operates with minimal performance overhead, allowing app developers to deploy it without compromising end-user experience. These goals are accomplished with an API allowing individual stakeholders to incrementally improve Itus without re-engineering new systems. We implement Itus in two demo apps and measure its performance impact. To our knowledge, Itus is the first open-source extensible IA framework for Android that can be deployed off-the-shelf."
569623,15510,9969,Collusion-Preserving Computation,2012,"In collusion-free protocols, subliminal communication is impossible and parties are thus unable to communicate any information beyond what the protocol allows. Collusion-free protocols are interesting for several reasons, but have specifically attracted attention because they can be used to reduce trust in game-theoretic mechanisms. Collusion-free protocols are impossible to achieve in general when all parties are connected by point-to-point channels, but exist under certain physical assumptions Lepinksi et al., STOCi¾?2005 or when parties are connected in specific network topologies Alwen et al., Cryptoi¾?2008.#R##N##R##N#We provide a clean-slate definition of the stronger notion of collusion preservation. Our goals in revisiting the definition are:To give a definition with respect to arbitrary communication resources including as special cases the communication models from prior work. We can then, in particular, better understand what types of resources enable collusion-preserving protocols.To construct protocols that allow no additional subliminal communication when parties can communicate via other means. This property is not implied by collusion-freeness.To support composition, so protocols can be designed in a modular fashion using sub-protocols run among subsets of the parties.#R##N##R##N#In addition to proposing the definition, we explore implications of our model and show a general feasibility result for collusion-preserving computation of arbitrary functionalities. We formalize a model for concurrently playing multiple extensive-form, mediated games while preserving many important equilibrium notions."
730146,15510,23620,"Authenticated data structures, generically",2014,"An authenticated data structure (ADS) is a data structure whose operations can be carried out by an untrusted  prover , the results of which a  verifier  can efficiently check as authentic. This is done by having the prover produce a compact proof that the verifier can check along with each operation's result. ADSs thus support outsourcing data maintenance and processing tasks to untrusted servers without loss of integrity. Past work on ADSs has focused on particular data structures (or limited classes of data structures), one at a time, often with support only for particular operations.   This paper presents a generic method, using a simple extension to a ML-like functional programming language we call λ• (lambda-auth), with which one can program authenticated operations over any data structure defined by standard type constructors, including recursive types, sums, and products. The programmer writes the data structure largely as usual and it is compiled to code to be run by the prover and verifier. Using a formalization of λ• we prove that all well-typed λ• programs result in code that is secure under the standard cryptographic assumption of collision-resistant hash functions. We have implemented λ• as an extension to the OCaml compiler, and have used it to produce authenticated versions of many interesting data structures including binary search trees, red-black+ trees, skip lists, and more. Performance experiments show that our approach is efficient, giving up little compared to the hand-optimized data structures developed previously."
2183155,15510,20754,Practical Control Flow Integrity and Randomization for Binary Executables,2013,"Control Flow Integrity (CFI) provides a strong protection against modern control-flow hijacking attacks. However, performance and compatibility issues limit its adoption. We propose a new practical and realistic protection method called CCFIR (Compact Control Flow Integrity and Randomization), which addresses the main barriers to CFI adoption. CCFIR collects all legal targets of indirect control-transfer instructions, puts them into a dedicated Springboard section in a random order, and then limits indirect transfers to flow only to them. Using the Springboard section for targets, CCFIR can validate a target more simply and faster than traditional CFI, and provide support for on-site target-randomization as well as better compatibility. Based on these approaches, CCFIR can stop control-flow hijacking attacks including ROP and return-into-libc. Results show that ROP gadgets are all eliminated. We observe that with the wide deployment of ASLR, Windows/x86 PE executables contain enough information in relocation tables which CCFIR can use to find all legal instructions and jump targets reliably, without source code or symbol information. We evaluate our prototype implementation on common web browsers and the SPEC CPU2000 suite: CCFIR protects large applications such as GCC and Firefox completely automatically, and has low performance overhead of about 3.6%/8.6% (average/max) using SPECint2000. Experiments on real-world exploits also show that CCFIR-hardened versions of IE6, Firefox 3.6 and other applications are protected effectively."
1981573,15510,20649,Low-energy encryption for medical devices: security adds an extra design dimension,2013,"Smart medical devices will only be smart if they also include technology to provide security and privacy. In practice this means the inclusion of cryptographic algorithms of sufficient cryptographic strength. For battery operated devices or for passively powered devices, these cryptographic algorithms need highly efficient, low power, low energy realizations. Moreover, unique to cryptographic implementations is that they also need protection against physical tampering either active or passive. This means that countermeasures need to be included during the design process.   Similar to design for low energy, design for physical protection needs to be addressed at  all design abstraction levels . Differently, while skipping one optimization step in a design for low energy or low power, merely reduces the battery life time, skipping a countermeasure, means opening the door for a possible attack. Designing for security requires a thorough threat analysis and a balanced selection of countermeasures.   This paper will discuss the different abstraction layers and design methods applied to obtain low power/low energy and at the same time side-channel and fault attack resistant cryptographic implementations. To provide a variety of security features, including location privacy, it is clear that medical devices need public key cryptography (PKC). It will be illustrated with the design of a low energy elliptic curve based public key programmable co-processor. It only needs 5.1μ of energy in a 0.13μm CMOS technology for one point multiplication and includes a selected set of countermeasures against physical attacks."
2136996,15510,20358,"Here's my cert, so trust me, maybe?: understanding TLS errors on the web",2013,"When browsers report TLS errors, they cannot distinguish between attacks and harmless server misconfigurations; hence they leave it to the user to decide whether continuing is safe. However, actual attacks remain rare. As a result, users quickly become used to false positives that deplete their attention span, making it unlikely that they will pay sufficient scrutiny when a real attack comes along. Consequently, browser vendors should aim to minimize the number of low-risk warnings they report. To guide that process, we perform a large-scale measurement study of common TLS warnings. Using a set of passive network monitors located at different sites, we identify the prevalence of warnings for a total population of about 300,000 users over a nine-month period. We identify low-risk scenarios that consume a large chunk of the user attention budget and make concrete recommendations to browser vendors that will help maintain user attention in high-risk situations. We study the impact on end users with a data set much larger in scale than the data sets used in previous TLS measurement studies. A key novelty of our approach involves the use of internal browser code instead of generic TLS libraries for analysis, providing more accurate and representative results."
1279568,15510,339,ASIST: architectural support for instruction set randomization,2013,"Code injection attacks continue to pose a threat to today's computing systems, as they exploit software vulnerabilities to inject and execute arbitrary, malicious code. Instruction Set Randomization (ISR) is able to protect a system against remote machine code injection attacks by randomizing the instruction set of each process. This way, the attacker will inject invalid code that will fail to execute on the randomized processor. However, all the existing implementations of ISR are based on emulators and binary instrumentation tools that (i) incur a significant runtime performance overhead, (ii) limit the ease of deployment of ISR, (iii) cannot protect the underlying operating system kernel, and (iv) are vulnerable to evasion attempts trying to bypass ISR protection.   To address these issues we propose ASIST: an architecture with hardware and operating system support for ISR. We present the design and implementation of ASIST by modifying and mapping a SPARC processor onto an FPGA board and running our modified Linux kernel to support the new features. The operating system loads the randomization key of each running process into a newly defined register, and the modified processor decodes the process's instructions with this key before execution. Moreover, ASIST protects the system against attacks that exploit kernel vulnerabilities to run arbitrary code with elevated privileges, by using a separate randomization key for the operating system. We show that ASIST transparently protects all applications and the operating system kernel from machine code injection attacks with less than 1.5% runtime overhead, while only requiring 0.7% additional hardware."
1219582,15510,8839,Towards jamming-resistant and competitive medium access in the SINR model,2011,"The efficient coordination of medium access is arguably one of the most relevant applications of distributed computing. Recently, progress has been made in the design of robust medium access (MAC) protocols that guarantee a competitive throughput against a powerful jammer which can block the medium an arbitrary constant fraction (1-e) of the time. These MAC protocols exploit the remaining e-fraction optimally in the sense that a significant part is used for successful transmissions. However, so far these throughput guarantees only hold for rather simplistic interference models such as Unit Disk Graphs.   This paper reports on our first insights on the design of a robust medium access protocol SINRMAC for the more realistic physical interference model which takes into account the signal to interference plus noise ratio (SINR) at the receiver. This model is more difficult, as there is no longer an objective distinction of idling and busy time periods which can be used to dynamically adjust the wireless nodes' backoff periods. We discuss an approach that introduces individual idle/busy thresholds which are adapted dynamically and, unlike the multiplicative backoff periods, in an  additive  manner. We find that a reasonable convergence speed (and throughput) can be achieved if there exists some meaningful upper bound τ on the noise level in the network; surprisingly, however, our first simulation results indicate that adaptive changes of the idly/busy thresholds do not yield a better throughput than static thresholds set to τ."
36235,15510,9874,Delegating a Pairing Can Be Both Secure and Efficient,2014,"Bilinear pairings have been widely used in cryptographic protocols since they provide very interesting functionalities in regard of identity based cryptography, short signatures or cryptographic tools with complex properties. Unfortunately their implementation on limited devices remains complex and even if a lot of work has been done on the subject, the current results in terms of computational complexity may still be prohibitive. This is clearly not for today to find the implementation of a bilinear pairing in every smart card. One possibility to avoid this problem of efficiency is to delegate the pairing computation to a third party. The result should clearly be both secure and efficient. Regarding security, the resulting computation of a pairing e(A,B) by the third party should be verifiable by the smart card. Moreover, if the points A and/or B are secret at the beginning of the protocol, they should also be secret after its execution. Regarding efficiency, besides some specific cases, existing protocols for delegating a pairing are costlier than a true embedded computation inside the smart card. This is due to the fact that they require several exponentiations to check the validity of the result.In this paper we first propose a formal security model for the delegation of pairings that fixes some weakness of the previous models. We also provide efficient ways to delegate the computation of a pairing e(A,B), depending on the status of A and B. Our protocols enable the limited device to verify the value received from the third party with mostly one exponentiation and can be improved to also ensure secrecy of e(A,B)."
2045774,15510,20592,Q: exploit hardening made easy,2011,"Prior work has shown that return oriented programming (ROP) can be used to bypass W⊕X, a software defense that stops shellcode, by reusing instructions from large libraries such as libc. Modern operating systems have since enabled address randomization (ASLR), which randomizes the location of libc, making these techniques unusable in practice. However, modern ASLR implementations leave smaller amounts of executable code unrandomized and it has been unclear whether an attacker can use these small code fragments to construct payloads in the general case.#R##N##R##N#In this paper, we show defenses as currently deployed can be bypassed with new techniques for automatically creating ROP payloads from small amounts of unrandomized code. We propose using semantic program verification techniques for identifying the functionality of gadgets, and design a ROP compiler that is resistant to missing gadget types. To demonstrate our techniques, we build Q, an end-to-end system that automatically generates ROP payloads for a given binary. Q can produce payloads for 80% of Linux /usr/bin programs larger than 20KB. We also show that Q can automatically perform exploit hardening: given an exploit that crashes with defenses on, Q outputs an exploit that bypasses both W⊕X and ASLR. We show that Q can harden nine real-world Linux and Windows exploits, enabling an attacker to automatically bypass defenses as deployed by industry for those programs."
1655046,15510,339,Manufacturing compromise: the emergence of exploit-as-a-service,2012,"We investigate the emergence of the  exploit-as-a-service  model for driveby browser compromise. In this regime, attackers pay for an exploit kit or service to do the dirty work of exploiting a victim's browser, decoupling the complexities of browser and plugin vulnerabilities from the challenges of generating traffic to a website under the attacker's control. Upon a successful exploit, these kits load and execute a binary provided by the attacker, effectively transferring control of a victim's machine to the attacker.   In order to understand the impact of the exploit-as-a-service paradigm on the malware ecosystem, we perform a detailed analysis of the prevalence of exploit kits, the families of malware installed upon a successful exploit, and the volume of traffic that malicious web sites receive. To carry out this study, we analyze 77,000 malicious URLs received from Google Safe Browsing, along with a crowd-sourced feed of blacklisted URLs known to direct to exploit kits. These URLs led to over 10,000 distinct binaries, which we ran in a contained environment.   Our results show that many of the most prominent families of malware now propagate through driveby downloads--32 families in all. Their activities are supported by a handful of exploit kits, with Blackhole accounting for 29% of all malicious URLs in our data, followed in popularity by Incognito. We use DNS traffic from real networks to provide a unique perspective on the popularity of malware families based on the frequency that their binaries are installed by drivebys, as well as the lifetime and popularity of domains funneling users to exploits."
2226231,15510,20754,An Expressive Model for the Web Infrastructure: Definition and Application to the Browser ID SSO System,2014,"The web constitutes a complex infrastructure and, as demonstrated by numerous attacks, rigorous analysis of standards and web applications is indispensable. Inspired by successful prior work, in particular the work by Akhawe et al. as well as Bansal et al., in this work we propose a formal model for the web infrastructure. While unlike prior works, which aim at automatic analysis, our model so far is not directly amenable to automation, it is much more comprehensive and accurate with respect to the standards and specifications. As such, it can serve as a solid basis for the analysis of a broad range of standards and applications. As a case study and another important contribution of our work, we use our model to carry out the first rigorous analysis of the Browser ID system (a.k.a. Mozilla Persona), a recently developed complex real-world single sign-on system that employs technologies such as AJAX, cross-document messaging, and HTML5 web storage. Our analysis revealed a number of very critical flaws that could not have been captured in prior models. We propose fixes for the flaws, formally state relevant security properties, and prove that the fixed system in a setting with a so-called secondary identity provider satisfies these security properties in our model. The fixes for the most critical flaws have already been adopted by Mozilla and our findings have been rewarded by the Mozilla Security Bug Bounty Program."
2538770,15510,9969,The torsion-limit for algebraic function fields and its application to arithmetic secret sharing,2011,"An (n, t, d, n-t)-arithmetic secret sharing scheme (with uniformity) for Fqk over Fq is an Fq-linear secret sharing scheme where the secret is selected from Fqk and each of the n shares is an element of Fq. Moreover, there is t-privacy (in addition, any t shares are uniformly random in Fqt) and, if one considers the d-fold component-wise product of any d sharings, then the d-fold component-wise product of the d respective secrets is (n - t)-wise uniquely determined by it. Such schemes are a fundamental primitive in information-theoretically secure multiparty computation. Perhaps counter-intuitively, secure multi-party computation is a very powerful primitive for communication-efficient two-party cryptography, as shown recently in a series of surprising results from 2007 on. Moreover, the existence of asymptotically good arithmetic secret sharing schemes plays a crucial role in their communication-efficiency: for each d ≥ 2, if A(q) > 2d, where A(q) is Ihara's constant, then there exists an infinite family of such schemes over Fq such that n is unbounded, k = Ω(n) and t = Ω(n), as follows from a result at CRYPTO'06. Our main contribution is a novel paradigm for constructing asymptotically good arithmetic secret sharing schemes from towers of algebraic function fields. It is based on a new limit that, for a tower with a given Ihara limit and given positive integer l, gives information on the cardinality of the l-torsion sub-groups of the associated degree-zero divisor class groups and that we believe is of independent interest. As an application of the bounds we obtain, we relax the condition A(q) > 2d from the CRYPTO'06 result substantially in terms of our torsion-limit. As a consequence, this result now holds over nearly all finite fields Fq. For example, if d=2, it is sufficient that q = 8,9 or q ≥ 16."
1271991,15510,9856,Interrupt-oriented bugdoor programming: a minimalist approach to bugdooring embedded systems firmware,2014,"We demonstrate a simple set of interrupt-related vulnerability primitives that, despite being apparently innocuous, give attackers full control of a microcontroller platform. We then present a novel, minimalist approach to constructing deniable bugdoors for microcontroller firmware, and contrast this approach with the current focus of exploitation research on demonstrations of maximum computational power that malicious computation can achieve. Since the introduction of Return-oriented programming, an ever-increasing number of targets have been demonstrated to unintentionally yield Turing-complete computation environments to attackers controlling the target's various input channels, under ever more restrictive sets of limitations. Yet although modern OS defensive measures indeed require complex computations to bypass, this focus on maximum expressiveness of exploit programming models leads researchers to overlook other research directions for platforms that lack strong defensive measure but occur in mission-critical systems, namely, microcontrollers. In these systems, common exploiter goals such as sensitive code and data exfiltration or arbitrary code execution do not typically require complex computation; instead, a minimal computation is preferred and a simple set of vulnerability primitives typically suffices. We discuss examples of vulnerabilities and the new kinds of tools needed to avoid them in future firmware."
1929878,15510,422,Detecting bots via incremental LS-SVM learning with dynamic feature adaptation,2011,"As botnets continue to proliferate and grow in sophistication, so does the need for more advanced security solutions to effectively detect and defend against such attacks. In particular, botnets such as Conficker have been known to encrypt the communication packets exchanged between bots and their command-and-control server, making it costly for existing botnet detection systems that rely on deep packet inspection (DPI) methods to identify compromised machines. In this paper, we argue that, even in the face of encrypted traffic flows, botnets can still be detected by examining the set of server IP-addresses visited by a client machine in the past. However there are several challenges that must be addressed. First, the set of server IP-addresses visited by client machines may evolve dynamically. Second, the set of client machines used for training and their class labels may also change over time. To overcome these challenges, this paper presents a novel incremental LS-SVM algorithm that is adaptive to both changes in the feature set and class labels of training instances. To evaluate the performance of our algorithm, we have performed experiments on two large-scale datasets, including real-time data collected from peering routers at a large Tier-1 ISP. Experimental results showed that the proposed algorithm produces classification accuracy comparable to its batch counterpart, while consuming significantly less computational resources."
2587873,15510,11223,Protecting users by confining JavaScript with COWL,2014,"Modern web applications are conglomerations of JavaScript written by multiple authors: application developers routinely incorporate code from third-party libraries, and mashup applications synthesize data and code hosted at different sites. In current browsers, a web application's developer and user must trust third-party code in libraries not to leak the user's sensitive information from within applications. Even worse, in the status quo, the only way to implement some mashups is for the user to give her login credentials for one site to the operator of another site. Fundamentally, today's browser security model trades privacy for flexibility because it lacks a sufficient mechanism for confining untrusted code. We present COWL, a robust JavaScript confinement system for modern web browsers. COWL introduces label-based mandatory access control to browsing contexts in a way that is fully backward-compatible with legacy web content. We use a series of case-study applications to motivate COWL's design and demonstrate how COWL allows both the inclusion of untrusted scripts in applications and the building of mashups that combine sensitive information from multiple mutually distrusting origins, all while protecting users' privacy. Measurements of two COWL implementations, one in Firefox and one in Chromium, demonstrate a virtually imperceptible increase in page-load latency."
2484088,15510,20649,Balancing security and utility in medical devices,2013,"Implantable Medical Devices (IMDs) are being embedded increasingly often in patients' bodies to monitor and help treat medical conditions. To facilitate monitoring and control, IMDs are often equipped with wireless interfaces. While convenient, wireless connectivity raises the risk of malicious access to an IMD that can potentially infringe patients' privacy and even endanger their lives.   Thus, while ease of access to IMDs can be vital for timely medical intervention, too much ease is dangerous. Obvious approaches, such as passwords and certificates, are unworkable at large scale given the lack of central authorities and frequent emergencies in medical settings. Additionally, IMDs are heavily constrained in their power consumption and computational capabilities. Designing access-control mechanisms for IMDs that can meet the many constraints of real-world deployment is an important research challenge.   In this paper, we review proposed approaches to the access-control problem for IMDs, including the problem of secure pairing (and key distribution) between an IMD and another device, such as a programmer. (We also treat related technologies, such as body-area networks.) We describe some limitations of well-conceived proposals and reveal security weaknesses in two proposed cryptographic pairing schemes. Our intention is to stimulate yet more inventive and rigorous research in the intriguing and challenging areas of IMD security and medical-device security in general."
1974229,15510,11375,Process firewalls: protecting processes during resource access,2013,"Processes retrieve a variety of resources from the operating system in order to execute properly, but adversaries have several ways to trick processes into retrieving resources of the adversaries' choosing. Such  resource access attacks  use name resolution, race conditions, and/or ambiguities regarding which resources are controlled by adversaries, accounting for 5-10% of CVE entries over the last four years. programmers have found these attacks extremely hard to eliminate because resources are managed  externally to the program , but the operating system does not provide a sufficiently rich system-call API to enable programs to block such attacks. In this paper, we present the Process Firewall, a kernel mechanism that protects processes in manner akin to a network firewall for the system-call interface. Because the Process Firewall only  protects  processes -- rather than sandboxing them -- it can examine their internal state to identify the protection rules necessary to block many of these attacks without the need for program modification or user configuration. We built a prototype Process Firewall for Linux demonstrating: (1) the prevention of several vulnerabilities, including two that were previously-unknown; (2) that this defense can be provided system-wide for less than 4% overhead in a variety of macrobenchmarks; and (3) that it can also improve program performance, shown by Apache handling 3-8% more requests when program resource access checks are replaced by Process Firewall rules. These results show that it is practical for the operating system to protect processes by preventing a variety of resource access attacks system-wide."
2303663,15510,8385,Detecting and analyzing insecure component usage,2012,"Software is commonly built from reusable components that provide desired functionalities. Although component reuse significantly improves software productivity,  insecure component usage  can lead to security vulnerabilities in client applications. For example, we noticed that widely-used IE-based browsers, such as IE Tab, do not enable important security features that IE enables by default, even though they all use the same browser components. This insecure usage renders these IE-based browsers vulnerable to the attacks blocked by IE. To our knowledge, this important security aspect of component reuse has largely been unexplored.   This paper presents the first practical framework for  detecting and analyzing vulnerabilities of insecure component usage . Its goal is to enforce and support secure component reuse. Our core approach is based on differential testing and works as follows. Suppose that component  C  maintains a security policy configuration to block certain malicious behavior. If two clients of component  C , say a reference and a test subject, handle the malicious behavior inconsistently, the test subject uses  C  insecurely. In particular, we model component usage related to a policy based on 1) accesses to the configuration state inside the component and 2) the conditional jumps affected by the data read from the state. We utilize this model to detect inconsistent policy evaluations, which can lead to insecure component usage. We have implemented our technique for Windows applications and used it to detect and analyze insecure usage of popular software components. Our evaluation results show that 1) insecure component usage is a general concern and frequently occurs in widely-used software, and 2) our detection framework is practical and effective at detecting and analyzing insecure component usage. In particular, it detected several serious, new vulnerabilities and helped perform detailed analysis of insecure component usage. We have reported these to the affected software vendors, some of whom have already acknowledged our findings and are actively addressing them."
2547715,15510,22260,PAAS: A Privacy-Preserving Attribute-Based Authentication System for eHealth Networks,2012,"Recently, eHealth systems have replaced paper based medical system due to its prominent features of convenience and accuracy. Also, since the medical data can be stored on any kind of digital devices, people can easily obtain medical services at any time and any place. However, privacy concern over patient medical data draws an increasing attention. In the current eHealth networks, patients are assigned multiple attributes which directly reflect their symptoms, undergoing treatments, etc. Those life-threatened attributes need to be verified by an authorized medical facilities, such as hospitals and clinics. When there is a need for medical services, patients have to be authenticated by showing their identities and the corresponding attributes in order to take appropriate healthcare actions. However, directly disclosing those attributes for verification may expose real identities. Therefore, existing eHealth systems fail to preserve patients' private attribute information while maintaining original functionalities of medical services. To solve this dilemma, we propose a framework called PAAS which leverages users' verifiable attributes to authenticate users in eHealth systems while preserving their privacy issues. In our system, instead of letting centralized infrastructures take care of authentication, our scheme only involves two end users. We also offer authentication strategies with progressive privacy requirements among patients or between patients and physicians. Based on the security and efficiency analysis, we show our framework is better than existing eHealth systems in terms of privacy preservation and practicality."
2421357,15510,339,This network is infected: HosTaGe - a low-interaction honeypot for mobile devices,2013,"In recent years, the number of sophisticated cyber attacks has increased rapidly. At the same time, people tend to utilize unknown, in terms of trustworthiness, wireless networks in their daily life. They connect to these networks, e.g., airports, without knowledge of whether they are safe or infected with actively propagating malware. In traditional networks, malicious behavior can be detected via Intrusion Detection Systems (IDSs). However, IDSs cannot be applied easily to mobile environments and to resource constrained devices. Another common defense mechanism is honeypots, i.e., systems that pretend to be an attractive target to attract malware and attackers. As a honeypot has no productive use, each attempt to access it can be interpreted as an attack. Hence, they can provide an early indication on malicious network environments. Since low interaction honeypots do not demand high CPU or memory requirements, they are suitable to resource constrained devices like smartphones or tablets.   In this paper we present the idea of Honeypot-To-Go. We envision portable honeypots on mobile devices that aim on the fast detection of malicious networks and thus boost the security awareness of users. Moreover, to demonstrate the feasibility of this proposal we present our prototype HosTaGe, a low-interaction honeypot implemented for the Android OS. We present some initial results regarding the performance of this application as well as its ability to detect attacks in a realistic environment. To the best of our knowledge, HosTaGe is the first implementation of a generic low-interaction honeypot for mobile devices."
1395166,15510,20754,Cookieless Monster: Exploring the Ecosystem of Web-Based Device Fingerprinting,2013,"The web has become an essential part of our society and is currently the main medium of information delivery. Billions of users browse the web on a daily basis, and there are single websites that have reached over one billion user accounts. In this environment, the ability to track users and their online habits can be very lucrative for advertising companies, yet very intrusive for the privacy of users. In this paper, we examine how web-based device fingerprinting currently works on the Internet. By analyzing the code of three popular browser-fingerprinting code providers, we reveal the techniques that allow websites to track users without the need of client-side identifiers. Among these techniques, we show how current commercial fingerprinting approaches use questionable practices, such as the circumvention of HTTP proxies to discover a user's real IP address and the installation of intrusive browser plugins. At the same time, we show how fragile the browser ecosystem is against fingerprinting through the use of novel browser-identifying techniques. With so many different vendors involved in browser development, we demonstrate how one can use diversions in the browsers' implementation to distinguish successfully not only the browser-family, but also specific major and minor versions. Browser extensions that help users spoof the user-agent of their browsers are also evaluated. We show that current commercial approaches can bypass the extensions, and, in addition, take advantage of their shortcomings by using them as additional fingerprinting features."
2176147,15510,11375,Practical techniques to obviate setuid-to-root binaries,2014,"Trusted, setuid-to-root binaries have been a substantial, long-lived source of privilege escalation vulnerabilities on Unix systems. Prior work on limiting privilege escalation has only considered privilege from the perspective of the administrator, neglecting the perspective of regular users---the primary reason for having setuid-to-root binaries.   The paper presents a study of the current state of setuid-to-root binaries on Linux, focusing on the 28 most commonly deployed setuid binaries in the Debian and Ubuntu distributions. This study reveals several points where Linux kernel policies and abstractions are a poor fit for the policies desired by the administrator, and root privilege is used to create point solutions. The majority of these point solutions address 8 system calls that require administrator privilege, but also export functionality required by unprivileged users.   This paper demonstrates how least privilege can be achieved on modern systems for non-administrator users. We identify the policies currently encoded in setuid-to-root binaries, and present a framework for expressing and enforcing these policy categories in the kernel. Our prototype, called Protego, deprivileges over 10,000 lines of code by changing only 715 lines of Linux kernel code. Protego also adds additional utilities to keep the kernel policy synchronized with legacy, policy-relevant configuration files, such as /etc/sudoers. Although some previously-privileged binaries may require changes, Protego provides users with the same functionality as Linux and introduces acceptable performance overheads. For instance, a Linux kernel compile incurs less than 2% overhead on Protego."
2382900,15510,8306,Branch regulation: low-overhead protection from code reuse attacks,2012,"Code reuse attacks (CRAs) are recent security exploits that allow attackers to execute arbitrary code on a compromised machine. CRAs, exemplified by return-oriented and jump-oriented programming approaches, reuse fragments of the library code, thus avoiding the need for explicit injection of attack code on the stack. Since the executed code is reused existing code, CRAs bypass current hardware and software security measures that prevent execution from data or stack regions of memory. While software-based full control flow integrity (CFI) checking can protect against CRAs, it includes significant overhead, involves non-trivial effort of constructing a control flow graph, relies on proprietary tools and has potential vulnerabilities due to the presence of unintended branch instructions in architectures such as x86---those branches are not checked by the software CFI. We propose branch regulation (BR), a lightweight hardware-supported protection mechanism against the CRAs that addresses all limitations of software CFI. BR enforces simple control flow rules in hardware at the function granularity to disallow arbitrary control flow transfers from one function into the middle of another function. This prevents common classes of CRAs without the complexity and run-time overhead of full CFI enforcement. BR incurs a slowdown of about 2% and increases the code footprint by less than 1% on the average for the SPEC 2006 benchmarks."
1443405,15510,20754,Understanding Network Forensics Analysis in an Operational Environment,2013,"The manual forensics investigation of security incidents is an opaque process that involves the collection and correlation of diverse evidence. In this work we conduct a complex experiment to expand our understanding of forensics analysis processes. During a period of four weeks we systematically investigated 200 detected security incidents about compromised hosts within a large operational network. We used data from four commonly-used security sources, namely Snort alerts, reconnaissance and vulnerability scanners, blacklists, and a search engine, to manually investigate these incidents. Based on our experiment, we first evaluate the (complementary) utility of the four security data sources and surprisingly find that the search engine provided useful evidence for diagnosing many more incidents than more traditional security sources, i.e., blacklists, reconnaissance and vulnerability reports. Based on our validation, we then identify and make available a list of 138 good Snort signatures, i.e., signatures that were effective in identifying validated malware without producing false positives. In addition, we compare the characteristics of good and regular signatures and highlight a number of differences. For example, we observe that good signatures check on average 2.14 times more bytes and 2.3 times more fields than regular signatures. Our analysis of Snort signatures is essential not only for configuring Snort, but also for establishing best practices and for teaching how to write new IDS signatures."
1108683,15510,339,OAuth Demystified for Mobile Application Developers,2014,"OAuth has become a highly influential protocol due to its swift and wide adoption in the industry. The initial objective of the protocol was specific: it serves the authorization needs for websites. What motivates our work is the realization that the protocol has been significantly re-purposed and re-targeted over the years: (1) all major identity providers, e.g., Facebook, Google and Microsoft, have re-purposed OAuth for user authentication; (2) developers have re-targeted OAuth to the mobile platforms, in addition to the traditional web platform. Therefore, we believe that it is necessary and timely to conduct an in-depth study to demystify OAuth for mobile application developers. Our work consists of two pillars: (1) an in-house study of the OAuth protocol documentation that aims to identify what might be ambiguous or unspecified for mobile developers; (2) a field-study of over 600 popular mobile applications that highlights how well developers fulfill the authentication and authorization goals in practice. The result is really worrisome: among the 149 applications that use OAuth, 89 of them (59.7%) were incorrectly implemented and thus vulnerable. In the paper, we pinpoint the key portions in each OAuth protocol flow that are security critical, but are confusing or unspecified for mobile application developers. We then show several representative cases to concretely explain how real implementations fell into these pitfalls. Our findings have been communicated to vendors of the vulnerable applications. Most vendors positively confirmed the issues, and some have applied fixes. We summarize lessons learned from the study, hoping to provoke further thoughts about clear guidelines for OAuth usage in mobile applications."
2509465,15510,22260,Authorized Private Keyword Search over Encrypted Data in Cloud Computing,2011,"In cloud computing, clients usually outsource their data to the cloud storage servers to reduce the management costs. While those data may contain sensitive personal information, the cloud servers cannot be fully trusted in protecting them. Encryption is a promising way to protect the confidentiality of the outsourced data, but it also introduces much difficulty to performing effective searches over encrypted information. Most existing works do not support efficient searches with complex query conditions, and care needs to be taken when using them because of the potential privacy leakages about the data owners to the data users or the cloud server. In this paper, using on line Personal Health Record (PHR) as a case study, we first show the necessity of search capability authorization that reduces the privacy exposure resulting from the search results, and establish a scalable framework for Authorized Private Keyword Search (APKS) over encrypted cloud data. We then propose two novel solutions for APKS based on a recent cryptographic primitive, Hierarchical Predicate Encryption (HPE). Our solutions enable efficient multi-dimensional keyword searches with range query, allow delegation and revocation of search capabilities. Moreover, we enhance the query privacy which hides users' query keywords against the server. We implement our scheme on a modern workstation, and experimental results demonstrate its suitability for practical usage."
2159807,15510,22260,Harnessing the Cloud for Securely Solving Large-Scale Systems of Linear Equations,2011,"Cloud computing economically enables customers with limited computational resources to outsource large-scale computations to the cloud. However, how to protect customers' confidential data involved in the computations then becomes a major security concern. In this paper, we present a secure outsourcing mechanism for solving large-scale systems of linear equations (LE) in cloud. Because applying traditional approaches like Gaussian elimination or LU decomposition (aka. direct method) to such large-scale LE problems would be prohibitively expensive, we build the secure LE outsourcing mechanism via a completely different approach -- iterative method, which is much easier to implement in practice and only demands relatively simpler matrix-vector operations. Specifically, our mechanism enables a customer to securely harness the cloud for iteratively finding successive approximations to the LE solution, while keeping both the sensitive input and output of the computation private. For robust cheating detection, we further explore the algebraic property of matrix-vector operations and propose an efficient result verification mechanism, which allows the customer to verify all answers received from previous iterative approximations in one batch with high probability. Thorough security analysis and prototype experiments on Amazon EC2 demonstrate the validity and practicality of our proposed design."
2486096,15510,339,Semantics-Aware Android Malware Classification Using Weighted Contextual API Dependency Graphs,2014,"The drastic increase of Android malware has led to a strong interest in developing methods to automate the malware analysis process. Existing automated Android malware detection and classification methods fall into two general categories: 1) signature-based and 2) machine learning-based. Signature-based approaches can be easily evaded by bytecode-level transformation attacks. Prior learning-based works extract features from application syntax, rather than program semantics, and are also subject to evasion. In this paper, we propose a novel semantic-based approach that classifies Android malware via dependency graphs. To battle transformation attacks, we extract a weighted contextual API dependency graph as program semantics to construct feature sets. To fight against malware variants and zero-day malware, we introduce graph similarity metrics to uncover homogeneous application behaviors while tolerating minor implementation differences. We implement a prototype system, DroidSIFT, in 23 thousand lines of Java code. We evaluate our system using 2200 malware samples and 13500 benign samples. Experiments show that our signature detection can correctly label 93\% of malware instances; our anomaly detector is capable of detecting zero-day malware with a low false negative rate (2\%) and an acceptable false positive rate (5.15\%) for a vetting purpose."
967227,15510,339,"Identity, location, disease and more: inferring your secrets from android public resources",2013,"The design of Android is based on a set of unprotected shared resources, including those inherited from Linux (e.g., Linux public directories). However, the dramatic development in Android applications (app for short) makes available a large amount of public background information (e.g., social networks, public online services), which can potentially turn such originally harmless resource sharing into serious privacy breaches. In this paper, we report our work on this important yet understudied problem. We discovered three unexpected channels of information leaks on Android: per-app data-usage statistics, ARP information, and speaker status (on or off). By monitoring these channels, an app without any permission may acquire sensitive information such as smartphone user's identity, the disease condition she is interested in, her geo-locations and her driving route, from top-of-the-line Android apps. Furthermore, we show that using existing and new techniques, this zero-permission app can both determine when its target (a particular application) is running and send out collected data stealthily to a remote adversary. These findings call into question the soundness of the design assumptions on shared resources, and demand effective solutions. To this end, we present a mitigation mechanism for achieving a delicate balance between utility and privacy of such resources."
1642724,15510,20754,Prudent Practices for Designing Malware Experiments: Status Quo and Outlook,2012,"Malware researchers rely on the observation of malicious code in execution to collect datasets for a wide array of experiments, including generation of detection models, study of longitudinal behavior, and validation of prior research. For such research to reflect prudent science, the work needs to address a number of concerns relating to the correct and representative use of the datasets, presentation of methodology in a fashion sufficiently transparent to enable reproducibility, and due consideration of the need not to harm others. In this paper we study the methodological rigor and prudence in 36 academic publications from 2006-2011 that rely on malware execution. 40% of these papers appeared in the 6 highest-ranked academic security conferences. We find frequent shortcomings, including problematic assumptions regarding the use of execution-driven datasets (25% of the papers), absence of description of security precautions taken during experiments (71% of the articles), and oftentimes insufficient description of the experimental setup. Deficiencies occur in top-tier venues and elsewhere alike, highlighting a need for the community to improve its handling of malware datasets. In the hope of aiding authors, reviewers, and readers, we frame guidelines regarding transparency, realism, correctness, and safety for collecting and using malware datasets."
1223164,15510,20774,(Near) optimal resource-competitive broadcast with jamming,2014,"We consider the problem of broadcasting a message from a sender to  n  ≥ 1 receivers in a time-slotted, single-hop, wireless network with a single communication channel. Sending and listening dominate the energy usage of small wireless devices and this is abstracted as a unit cost per time slot. A jamming adversary exists who can disrupt the channel at unit cost per time slot, and aims to prevent the transmission of the message. Let  T  be the number of slots jammed by the adversary. Our goal is to design algorithms whose cost is  resource-competitive , that is, whose per-device cost is a function, preferably  o(T) , of the adversary's cost. Devices must work with limited knowledge. The values  n ,  T , and the adversary's jamming strategy are unknown.   For 1-to-1 communication, we provide an algorithm with an expected cost of  O (√ T ln(1/e) + ln (1/e)), which succeeds with probability at least 1-e for any tunable parameter e>0. For 1-to-n broadcast, we provide a very different algorithm that succeeds with high probability and yields an expected cost per device of O(√ T/n  log  4   T  + log 6   n ). Therefore, the bigger the system, the better advantage achieved over the adversary!   We complement our upper bounds with  tight or nearly tight lower bounds . We prove that any 1-to-1 communication algorithm with constant probability of success has expected cost Ω (√ T ). For 1-to- n  broadcast we show that some node has cost Ω(√ T ). Finally, we consider a more powerful adversary that can spoof messages from the receiver, rather than just jam the channel. We prove that any 1-to-1 communication algorithm in this model has expected cost Ω( T φ- 1 ), where φ = 1+√5 ∕ 2 is the golden ratio. This matches an earlier upper bound of King, Saia, and Young."
1279492,15510,339,Fourth International Workshop on Trustworthy Embedded Devices (TrustED 2014),2013,"Cyber physical systems (CPS) feature a tight combination of and coordination between the system's computational and physical elements. A current NIST report estimates that by the end of the decade, embedded networking and computing components are projected to account for more than half of the value share in diverse sectors, including automotive, consumer electronics, avionics and aerospace, manufacturing, telecommunications, intelligent buildings, and health and medical equipment and further conjectures that future applications of CPS are more transformative than the IT revolution of the past three decades. While the increasing proliferation of embedded systems in general and CPS in particular provide a variety of new possibilities, new risks and challenges emerge. Due to the strong interdisciplinary character, advancement in CPS requires a new systems science that encompasses both physical and computational aspects.   The scope of the Workshop on Trustworthy Embedded Devices (TrustED) is security of embedded devices in general with focus on cyber physical systems and their environments. TrustED 2013 is a continuation of previous workshops in this series, which were held in conjunction with ESORICS 2011 and IEEE Security & Privacy 2012 (see http://trusted.trust.cased.de for details). The goal of this workshop is to bring together experts from academia and research institutes, industry, and government in the field of security and privacy in cyber physical systems."
1166277,15510,21056,DeepCAPTCHA: an image CAPTCHA based on depth perception,2014,"Over the past decade, text-based CAPTCHA (TBC) have become popular in preventing adversarial attacks and spam in many websites and applications including emails services, social platforms, web-based market places, and recommendation systems. However, in addition to several problems with TBC, it has become increasingly difficult to solve in recent years, to keep up with OCR technologies. Image-based CAPTCHA (IBC), on the other hand, is a relatively new concept that promises to overcome key limitations of TBC. In this paper we present an innovative IBC,  DeepCAPTCHA , based on design guidelines, psychological theory and empirical experiments. DeepCAPTCHA exploits the human ability of depth preception. In our IBC users should arrange 3D objects in terms of size (or depth). In our framework for DeepCAPTCHA, we automatically mine 3D models, and use a human-machine Merge Sort algorithm to order these unknown objects. We then create new appearances for these objects at multiplication factor of 200, and present these new images to the end-users for sorting (as CAPTCHA tasks). Humans are able to apply their rapid and reliable object recognition and comparison (arise from years experience with the physical environment) to solve DeepCAPTCHA, while machines are still unable to complete these tasks. Experimental results show that humans can solve DeepCAPTCHA with a high accuracy (~84%) and ease, while machines perform dismally."
1208310,15510,507,Lightweight Query Authentication on Streams,2014,"We consider a  stream outsourcing  setting, where a data owner delegates the management of a set of disjoint data streams to an untrusted server. The owner authenticates his streams via signatures. The server processes continuous queries on the union of the streams for clients trusted by the owner. Along with the results, the server sends proofs of result correctness derived from the owner's signatures, which are verifiable by the clients. We design novel constructions for a collection of fundamental problems over streams represented as linear algebraic queries. In particular, our basic schemes authenticate dynamic vector sums, matrix products, and dot products. These techniques can be adapted for authenticating a wide range of important operations in streaming environments, including group-by queries, joins, in-network aggregation, similarity matching, and event processing. We also present extensions to address the case of sliding window queries, and when multiple clients are interested in different subsets of the data. These methods take advantage of a novel nonce chaining technique that we introduce, which is used to reduce the verification cost without affecting any other costs. All our schemes are lightweight and offer strong cryptographic guarantees derived from formal definitions and proofs. We experimentally confirm the practicality of our schemes in the performance-sensitive streaming setting."
2404389,15510,8235,Secure and efficient in-network processing of exact SUM queries,2011,"In-network aggregation is a popular methodology adopted in wireless sensor networks, which reduces the energy expenditure in processing aggregate queries (such as SUM, MAX, etc.) over the sensor readings. Recently, research has focused on secure in-network aggregation, motivated (i) by the fact that the sensors are usually deployed in open and unsafe environments, and (ii) by new trends such as outsourcing, where the aggregation process is delegated to an untrustworthy service. This new paradigm necessitates the following key security properties: data confidentiality, integrity, authentication, and freshness. The majority of the existing work on the topic is either unsuitable for large-scale sensor networks, or provides only approximate answers for SUM queries (as well as their derivatives, e.g., COUNT, AVG, etc). Moreover, there is currently no approach offering both confidentiality and integrity at the same time. Towards this end, we propose a novel and efficient scheme called SIES. SIES is the first solution that supports Secure In-network processing of Exact SUM queries, satisfying all security properties. It achieves this goal through a combination of homomorphic encryption and secret sharing. Furthermore, SIES is lightweight (it relies on inexpensive hash operations and modular additions/multiplications), and features a very small bandwidth consumption (in the order of a few bytes). Consequently, SIES constitutes an ideal method for resource-constrained sensors."
1580015,15510,23634,Constructing Non-malleable Commitments: A Black-Box Approach,2012,"We propose the first black-box construction of non-malleable commitments according to the standard notion of non-malleability with respect to commitment. Our construction additionally only requires a constant number of rounds and is based only on (black-box use of) one-way functions. Prior to our work, no black-box construction of non-malleable commitments was known (except for relaxed notions of security) in any (polynomial) number of rounds based on any cryptographic assumption. This closes the wide gap existent between black-box and non-black-box constructions for the problem of non-malleable commitments. Our construction relies on (and can be seen as a generalization of) the recent non-malleable commitment scheme of Goyal (STOC 2011). We also show how to get black-box constructions for a host of other cryptographic primitives. We extend our construction to get constant-round concurrent non-malleable commitments, constant-round multi-party coin tossing, and non-malleable statistically hiding commitments (satisfying the notion of non-malleability with respect to opening). All of the mentioned results make only a black-box use of one-way functions. Our primary technical contribution is a novel way of implementing the proof of consistency typically required in the constructions of non-malleable commitments (and other related primitives). We do this by relying on ideas from the ``zero-knowledge from secure multi-party computation paradigm of Ishai, Kushilevitz, Ostrovsky, and Sahai (STOC 2007). We extend in a novel way this ``computation in the head paradigm (which can be though of as bringing powerful error-correcting codes into purely computational setting). To construct a non-malleable commitment scheme, we apply our computation in the head techniques to the recent (constant-round) construction of Goyal. Along the way, we also present a simplification of the construction of Goyal where a part of the protocol is implemented in an information theoretic manner. Such a simplification is crucial for getting a black-box construction. This is done by making use of pair wise-independent hash functions and strong randomness extractors. We show that our techniques have multiple applications, as elaborated in the paper. Hence, we believe our techniques might be useful in other settings in future."
967353,15510,339,Searchable Encryption with Secure and Efficient Updates,2014,"Searchable (symmetric) encryption allows encryption while still enabling search for keywords. Its immediate application is cloud storage where a client outsources its files while the (cloud) service provider should search and selectively retrieve those. Searchable encryption is an active area of research and a number of schemes with different efficiency and security characteristics have been proposed in the literature. Any scheme for practical adoption should be efficient -- i.e. have sub-linear search time --, dynamic -- i.e. allow updates -- and semantically secure to the most possible extent. Unfortunately, efficient, dynamic searchable encryption schemes suffer from various drawbacks. Either they deteriorate from semantic security to the security of deterministic encryption under updates, they require to store information on the client and for deleted files and keywords or they have very large index sizes. All of this is a problem, since we can expect the majority of data to be later added or changed. Since these schemes are also less efficient than deterministic encryption, they are currently an unfavorable choice for encryption in the cloud. In this paper we present the first searchable encryption scheme whose updates leak no more information than the access pattern, that still has asymptotically optimal search time, linear, very small and asymptotically optimal index size and can be implemented without storage on the client (except the key). Our construction is based on the novel idea of learning the index for efficient access from the access pattern itself. Furthermore, we implement our system and show that it is highly efficient for cloud storage."
1517231,15510,20338,Taming the 800 Pound Gorilla: The Rise and Decline of NTP DDoS Attacks,2014,"Distributed Denial of Service (DDoS) attacks based on Network Time Protocol (NTP) amplification, which became prominent in December 2013, have received significant global attention. We chronicle how this attack rapidly rose from obscurity to become the dominant large DDoS vector. Via the lens of five distinct datasets, we characterize the advent and evolution of these attacks. Through a dataset that measures a large fraction of global Internet traffic, we show a three order of magnitude rise in NTP. Using a large darknet, we observe a similar rise in global scanning activity, both malicious and research. We then dissect an active probing dataset, which reveals that the pool of amplifiers totaled 2.2M unique IPs and includes a small number of mega amplifiers, servers that replied to a single tiny probe packet with gigabytes of data. This dataset also allows us, for the first time, to analyze global DDoS attack victims (including ports attacked) and incidents, where we show 437K unique IPs targeted with at least 3 trillion packets, totaling more than a petabyte. Finally, ISP datasets shed light on the local impact of these attacks. In aggregate, we show the magnitude of this major Internet threat, the community's response, and the effect of that response."
51638,15510,20592,TARDIS: time and remanence decay in SRAM to implement secure protocols on embedded devices without clocks,2012,"Lack of a locally trustworthy clock makes security protocols challenging to implement on batteryless embedded devices such as contact smartcards, contactless smartcards, and RFID tags. A device that knows how much time has elapsed between queries from an untrusted reader could better protect against attacks that depend on the existence of a rate-unlimited encryption oracle.#R##N##R##N#The TARDIS (Time and Remanence Decay in SRAM) helps locally maintain a sense of time elapsed without power and without special-purpose hardware. The TARDIS software computes the expiration state of a timer by analyzing the decay of existing on-chip SRAM. The TARDIS enables coarse-grained, hourglass-like timers such that cryptographic software can more deliberately decide how to throttle its response rate. Our experiments demonstrate that the TARDIS can measure time ranging from seconds to several hours depending on hardware parameters. Key challenges to implementing a practical TARDIS include compensating for temperature and handling variation across hardware.#R##N##R##N#Our contributions are (1) the algorithmic building blocks for computing elapsed time from SRAM decay; (2) characterizing TARDIS behavior under different temperatures, capacitors, SRAM sizes, and chips; and (3) three proof-of-concept implementations that use the TARDIS to enable privacy-preserving RFID tags, to deter double swiping of contactless credit cards, and to increase the difficulty of brute-force attacks against e-passports."
695900,15510,9856,SEMAGE: a new image-based two-factor CAPTCHA,2011,"We present SEMAGE ( SE mantically  MA tching ima GE s), a new image-based CAPTCHA that capitalizes on the human ability to define and comprehend image content and to establish  semantic relationships  between them. A SEMAGE challenge asks a user to select  semantically related  images from a given image set. SEMAGE has a two-factor design where in order to pass a challenge the user is required to figure out the content of each image and then understand and identify semantic relationship between a subset of them. Most of the current state-of-the-art image-based systems like Assira [20] only require the user to solve the first level, i.e., image recognition. Utilizing the semantic correlation between images to create more secure and user-friendly challenges makes SEMAGE novel. SEMAGE does not suffer from limitations of traditional image-based approaches such as lacking customization and adaptability. SEMAGE unlike the current text-based systems is also very user-friendly with a high fun factor. These features make it very attractive to web service providers. In addition, SEMAGE is language independent and highly flexible for customizations (both in terms of security and usability levels). SEMAGE is also mobile devices friendly as it does not require the user to type anything. We conduct a first-of-its-kind large-scale user study involving 174 users to gauge and compare accuracy and usability of SEMAGE with existing state-of-the-art CAPTCHA systems like reCAPTCHA (text-based) [6] and Asirra (image-based) [20]. The user study further reinstates our points and shows that users achieve high accuracy using our system and consider our system to be fun and easy."
1090998,15510,9856,Challenges and implications of verifiable builds for security-critical open-source software,2014,"The majority of computer users download compiled software and run it directly on their machine. Apparently, this is also true for open-sourced software -- most users would not compile the available source, and implicitly trust that the available binaries have been compiled from the published source code (i.e., no backdoor has been inserted in the binary). To verify that the official binaries indeed correspond to the released source, one can compile the source of a given application, and then compare the locally generated binaries with the developer-provided official ones. However, such simple verification is non-trivial to achieve in practice, as modern compilers, and more generally, toolchains used in software packaging, have not been designed with verifiability in mind. Rather, the output of compilers is often dependent on parameters that can be strongly tied to the building environment. In this paper, we analyze a widely-used encryption tool, TrueCrypt, to verify its official binary with the corresponding source. We first manually replicate a close match to the official binaries of sixteen most recent versions of TrueCrypt for Windows up to v7.1a, and then explain the remaining differences that can solely be attributed to non-determinism in the build process. Our analysis provides the missing guarantee on official binaries that they are indeed backdoor-free, and makes audits on TrueCrypt's source code more meaningful. Also, we uncover several sources of non-determinism in TrueCrypt's compilation process; these findings may help create future verifiable build processes."
641990,15510,8228,Data-minimizing authentication goes mobile,2012,"Authentication is a prerequisite for proper access control to many eservices. Often, it is carried out by identifying the user, while generally, verification of certified attributes would suffice. Even worse, this kind of authentication makes all the user's transactions linkable and discloses an excessive amount of personal information, and thus erodes the user's privacy. This is in clear contradiction to the data minimization principle put forth in the European data protection legislation.#R##N##R##N#In this paper, we present data-minimizing mobile authentication, which is a kind of attribute-based authentication through the use of anonymous credentials, thereby revealing substantially less personal information about the user. We describe two typical scenarios, design an architecture, and discuss a prototype implemented on a smart phone which minimizes the disclosure of personal data in a user-to-terminal authentication setting. The prototype uses the Identity Mixer anonymous credential system (Idemix) and realizes short-range communication between the smart phone and the terminal using visual channels over which QR codes are exchanged. Furthermore, the security has been improved and unauthorized sharing of credentials prevented by storing the credentials' secret key in a secure element hosted by the mobile phone. Our measurements show that the use of smart phones for data-minimizing authentication can be an actual game changer for a broad deployment of anonymous credential systems."
1731038,15510,9856,Permission evolution in the Android ecosystem,2012,"Android uses a system of permissions to control how apps access sensitive devices and data stores. Unfortunately, we have little understanding of the evolution of Android permissions since their inception (2008).  Is the permission model allowing the Android platform and apps to become more secure?  In this paper, we present arguably the first long-term study that is centered around both permission evolution and usage, of the entire Android ecosystem (platform, third-party apps, and pre-installed apps). First, we study the Android platform to see how the set of permissions has evolved; we find that this set tends to grow, and the growth is not aimed towards providing finer-grained permissions but rather towards offering access to new hardware features; a particular concern is that the set of Dangerous permissions is increasing. Second, we study Android third-party and pre-installed apps to examine whether they follow the  principle of least privilege . We find that this is not the case, as an increasing percentage of the popular apps we study are overprivileged. In addition, the apps tend to use more permissions over time. Third, we highlight some concerns with pre-installed apps, e.g., apps that vendors distribute with the phone; these apps have access to, and use, a larger set of higher-privileged permissions which pose security and privacy risks. At the risk of oversimplification, we state that the Android ecosystem is not becoming more secure from the user's point of view. Our study derives four recommendations for improving the Android security and suggests the need to revisit the practices and policies of the ecosystem."
1798356,15510,339,Detection of On-Road Vehicles Emanating GPS Interference,2014,"The Global Positioning System (GPS) is widely used in critical infrastructures but is vulnerable to radio frequency (RF) interference. A common source of interference are commercial drivers that use GPS jammers to circumvent vehicle tracking systems. Existing mechanisms to detect and identify such interference emitting vehicles on roadways require a large number of specialized detectors or a manual observation process. In this paper, we design a practical, automated system to facilitate enforcement actions. Our system combines information from roadside monitoring points at key locations along the roadway as well as mobile detectors (e.g., smartphones and other mobile GPS systems). Rather than attempting precise localization at a given time, the system exploits the inherent variation in driving speeds and the resulting diverging trajectories of vehicles to uniquely identify the interfering vehicle. Through our experiments on a local highway with a vehicle transmitting interference in the 900MHz ISM band, we found that the vehicle identification rate of our mechanism is 65% for a single-point setup and 100% for a two-point setup. We performed 200 hours of passive monitoring of GPS L1 band on roadways and found two episodes of real interference. We also demonstrate that our mobile detector-based crowdsourced smartphone profiles are sufficiently consistent in time and space to enable reliable interference detection."
1247548,15510,23712,Rethinking Packet Classification for Global Network View of Software-Defined Networking,2014,"In software-defined networking, applications are allowed to access a global view of the network so as to provide sophisticated functionalities, such as quality-oriented service delivery, automatic fault localization, and network verification. All of these functionalities commonly rely on a well-studied technology, packet classification. Unlike the conventional classification problem to search for the action taken at a single switch, the global network view requires to identify the network-wide behavior of the packet, which is defined as a combination of switch actions. Conventional classification methods, however, fail to well support network-wide behaviors, since the search space is complicatedly partitioned due to the combinations. This paper proposes a novel packet classification method that efficiently supports network-wide packet behaviors. Our method utilizes a compressed data structure named the multi-valued decision diagram, allowing it to manipulate the complex search space with several algorithms. Through detailed analysis, we optimize the classification performance as well as the construction of decision diagrams. Experiments with real network datasets show that our method identifies the packet behavior at 20.1 Mpps on a single CPU core with only 8.4 MB memory, by contrast, conventional methods failed to work even with 16 GB memory. We believe that our method is essential for realizing advanced applications that can fully leverage the potential of software defined networking."
691752,15510,8494,CoRaS: A multiprocessor key corruption and random round swapping for power analysis side channel attacks: A DES case study,2012,"Multiprocessor System-on-Chip (MPSoC) is an integral element in state-of-the-art embedded devices, ranging from low-end, mobile phones, PDAs, handheld medical devices up to high-end cars, avionics and robotics. Proper and safe functionality of such embedded systems is mandatory to avoid severe consequences, whereas security is absolutely necessary with “Cashless Wallets” forecasted to be the only means of financial transactions in the near future. Such a scenario places immense onus on the security experts where secure transactions using credit cards or mobile phones or any other embedded devices should not be revealing any footprint to the adversary. Side Channel Attacks (SCA) are considered as one of the most effective attacks on these embedded systems because of their effectiveness in realizing the secret information without physically disassembling the device. We propose an MPSoC architecture to prevent power analysis SCA where a dual-core algorithmic balancing is enforced by corrupting the balanced key and swapping the encryption rounds of a block-cipher at random places, random number of times. A case study using DES cryptography is performed. Our approach, CoRaS, alleviates performance by 0.1% and area by 3.6% compared to the state-of-the-art MPSoC solution, however enhances security and practicality by eliminating its weaknesses."
2177248,15510,339,World-Driven Access Control for Continuous Sensing,2014,"Modern applications increasingly rely on continuous monitoring of video, audio, or other sensor data to provide their functionality, particularly in platforms such as the Microsoft Kinect and Google Glass. Continuous sensing by untrusted applications poses significant privacy challenges for both device users and bystanders. Even honest users will struggle to manage application permissions using existing approaches.   We propose a general, extensible framework for controlling access to sensor data on multi-application continuous sensing platforms. Our approach, world-driven access control, allows real-world objects to explicitly specify access policies. This approach relieves the user's permission management burden while mediating access at the granularity of objects rather than full sensor streams. A trusted policy module on the platform senses policies in the world and modifies applications' views accordingly. For example, world-driven access control allows the system to automatically stop recording in bathrooms or remove bystanders from video frames,without the user prompted to specify or activate such policies. To convey and authenticate policies, we introduce passports, a new kind of certificate that includes both a policy and optionally the code for recognizing a real-world object.   We implement a prototype system and use it to study the feasibility of world-driven access control in practice. Our evaluation suggests that world-driven access control can effectively reduce the user's permission management burden in emerging continuous sensing systems. Our investigation also surfaces key challenges for future access control mechanisms for continuous sensing applications."
145251,15510,374,Local Password Validation Using Self-Organizing Maps,2014,"The commonly used heuristics to promote password strength (e.g. minimum length, forceful use of alphanumeric characters, etc) have been found considerably ineffective and, what is worst, often counterproductive. When cou- pled with the predominancy of dictionary based attacks and leaks of large pass- word data sets, this situation has led, in later years, to the idea that the most useful criterion on which to classify the strength of a candidate password, is the frequency with which it has appeared in the past. Maintaining an updated and representative record of past password choices does, however, require the processing and storage of high volumes of data, mak- ing the schemes thus far proposed centralized. Unfortunately, requiring that users submit their chosen candidate passwords to a central engine for validation may have security implications and does not allow offline password generation. An- other major limitation of the currently proposed systems is the lack of generalisa- tion capability: a password similar to a common password is usually considered safe. In this article, we propose an algorithm which addresses both limitations. It is designed for local operation, avoiding the need to disclose candidate passwords, and is focused on generalisation, recognizing as dangerous not only frequently occurring passwords, but also candidates similar to them. An implementation of this algorithm is released in the form of a Google Chrome browser extension."
918080,15510,208,VeRA - Version Number and Rank Authentication in RPL,2011,"Designing a routing protocol for large low-power and lossy networks (LLNs), consisting of thousands of constrained nodes and unreliable links, presents new challenges. The IPv6 Routing Protocol for Low-power and Lossy Networks (RPL), have been developed by the IETF ROLL Working Group as a preferred routing protocol to provide IPv6 routing functionality in LLNs. RPL provides path diversity by building and maintaining directed acyclic graphs (DAG) rooted at one (or more) gateway. However, an adversary that impersonates a gateway or has compromised one of the nodes close to the gateway can divert a large part of network traffic forward itself and/or exhaust the nodes' batteries. Therefore in RPL, special security care must be taken when the Destination Oriented Directed Acyclic Graph (DODAG) root is updating the Version Number by which reconstruction of the routing topology can be initiated. The same care also must be taken to prevent an internal attacker (compromised DODAG node) to publish decreased Rank value, which causes a large part of the DODAG to connect to the DODAG root via the attacker and give it the ability to eavesdrop a large part of the network traffic forward itself. Unfortunately, the currently available security services in RPL will not protect against a compromised internal node that can construct and disseminate fake messages. In this paper, a new security service is described that prevents any misbehaving node from illegitimately increasing the Version Number and compromise illegitimate decreased Rank values."
2415020,15510,8228,Least Squares Disclosure Attack in Mobile Ad Hoc Networks,2011,"Traffic analysis is considered the most powerful strategy of disclosing the hidden communication relations in an anonymous communication system. Statistical traffic analysis attacks are even more subtle in that the attackers are usually eavesdroppers who do not modify the network's behaviors. Moreover, the attackers even do not need to look into the traffic content, which may be encrypted, in order to analyze the statistical characteristics. Such attacks have been thoroughly investigated for static wireline networks. However, none of these mechanisms can be directly applied to mobile ad hoc networks (MANETs) due to the inability to deal with mobility, the ad hoc infrastructure and the broadcasting nature of wireless transmissions. Recent research conducted on statistical traffic analysis attacks targeting MANETs is restricted to disclosing the end-to-end traffic distribution. In this paper, we present the least squares disclosure attack (LSDA), targeting a popular MANET routing strategy, that is, the position based routing (PBR, a.k.a geographic routing). LSDA utilizes the traffic distribution disclosed by existing solutions, and de-anonymizes the network communication on a per-flow basis by identifying the source and destination of each end-to-end flow. In LSDA, traffic disclosure is modeled as an efficiently solvable least squares problem subject to linear constraints . The empirical study demonstrates that, the proposed solution can de-anonymize the network flows in high accuracy."
2278575,15510,339,PScout: analyzing the Android permission specification,2012,"Modern smartphone operating systems (OSs) have been developed with a greater emphasis on security and protecting privacy. One of the mechanisms these systems use to protect users is a permission system, which requires developers to declare what sensitive resources their applications will use, has users agree with this request when they install the application and constrains the application to the requested resources during runtime. As these permission systems become more common, questions have risen about their design and implementation. In this paper, we perform an analysis of the permission system of the Android smartphone OS in an attempt to begin answering some of these questions. Because the documentation of Android's permission system is incomplete and because we wanted to be able to analyze several versions of Android, we developed PScout, a tool that extracts the permission specification from the Android OS source code using static analysis. PScout overcomes several challenges, such as scalability due to Android's 3.4 million line code base, accounting for permission enforcement across processes due to Android's use of IPC, and abstracting Android's diverse permission checking mechanisms into a single primitive for analysis.   We use PScout to analyze 4 versions of Android spanning version 2.2 up to the recently released Android 4.0. Our main findings are that while Android has over 75 permissions, there is little redundancy in the permission specification. However, if applications could be constrained to only use documented APIs, then about 22% of the non-system permissions are actually unnecessary. Finally, we find that a trade-off exists between enabling least-privilege security with fine-grained permissions and maintaining stability of the permission specification as the Android OS evolves."
800199,15510,8912,Detecting Malicious Javascript in PDF through Document Instrumentation,2014,"An emerging threat vector, embedded malware inside popular document formats, has become rampant since 2008. Owed to its wide-spread use and Javascript support, PDF has been the primary vehicle for delivering embedded exploits. Unfortunately, existing defenses are limited in effectiveness, vulnerable to evasion, or computationally expensive to be employed as an on-line protection system. In this paper, we propose a context-aware approach for detection and confinement of malicious Javascript in PDF. Our approach statically extracts a set of static features and inserts context monitoring code into a document. When an instrumented document is opened, the context monitoring code inside will cooperate with our runtime monitor to detect potential infection attempts in the context of Javascript execution. Thus, our detector can identify malicious documents by using both static and runtime features. To validate the effectiveness of our approach in a real world setting, we first conduct a security analysis, showing that our system is able to remain effective in detection and be robust against evasion attempts even in the presence of sophisticated adversaries. We implement a prototype of the proposed system, and perform extensive experiments using 18623 benign PDF samples and 7370 malicious samples. Our evaluation results demonstrate that our approach can accurately detect and confine malicious Javascript in PDF with minor performance overhead."
214444,15510,20592,Practical comprehensive bounds on surreptitious communication over DNS,2013,"DNS queries represent one of the most common forms of network traffic, and likely the least blocked by sites. As such, DNS provides a highly attractive channel for attackers who wish to communicate surreptitiously across a network perimeter, and indeed a variety of tunneling toolkits exist [7, 10, 13-15]. We develop a novel measurement procedure that fundamentally limits the amount of information that a domain can receive surreptitiously through DNS queries to an upper bound specified by a site's security policy, with the exact setting representing a tradeoff between the scope of potential leakage versus the quantity of possible detections that a site's analysts must investigate.#R##N##R##N#Rooted in lossless compression, our measurement procedure is free from false negatives. For example, we address conventional tunnels that embed the payload in the query names, tunnels that repeatedly query a fixed alphabet of domain names or varying query types, tunnels that embed information in query timing, and communication that employs combinations of these. In an analysis of 230 billion lookups from real production networks, our procedure detected 59 confirmed tunnels. For the enterprise datasets with lookups by individual clients, detecting surreptitious communication that exceeds 4 kB/day imposes an average analyst burden of 1-2 investigations/week."
1631038,15510,20754,On the Feasibility of Internet-Scale Author Identification,2012,"We study techniques for identifying an anonymous author via linguistic stylometry, i.e., comparing the writing style against a corpus of texts of known authorship. We experimentally demonstrate the effectiveness of our techniques with as many as 100,000 candidate authors. Given the increasing availability of writing samples online, our result has serious implications for anonymity and free speech - an anonymous blogger or whistleblower may be unmasked unless they take steps to obfuscate their writing style. While there is a huge body of literature on authorship recognition based on writing style, almost none of it has studied corpora of more than a few hundred authors. The problem becomes qualitatively different at a large scale, as we show, and techniques from prior work fail to scale, both in terms of accuracy and performance. We study a variety of classifiers, both lazy and eager, and show how to handle the huge number of classes. We also develop novel techniques for confidence estimation of classifier outputs. Finally, we demonstrate stylometric authorship recognition on texts written in different contexts. In over 20% of cases, our classifiers can correctly identify an anonymous author given a corpus of texts from 100,000 authors; in about 35% of cases the correct author is one of the top 20 guesses. If we allow the classifier the option of not making a guess, via confidence estimation we are able to increase the precision of the top guess from 20% to over 80% with only a halving of recall."
1691021,15510,9856,"Scalability, fidelity and stealth in the DRAKVUF dynamic malware analysis system",2014,"Malware is one of the biggest security threats on the Internet today and deploying effective defensive solutions requires the rapid analysis of a continuously increasing number of malware samples. With the proliferation of metamorphic malware the analysis is further complicated as the efficacy of signature-based static analysis systems is greatly reduced. While dynamic malware analysis is an effective alternative, the approach faces significant challenges as the ever increasing number of samples requiring analysis places a burden on hardware resources. At the same time modern malware can both detect the monitoring environment and hide in unmonitored corners of the system.   In this paper we present  DRAKVUF , a novel dynamic malware analysis system designed to address these challenges by building on the latest hardware virtualization extensions and the Xen hypervisor. We present a technique for improving stealth by initiating the execution of malware samples without leaving any trace in the analysis machine. We also present novel techniques to eliminate blind-spots created by kernel-mode rootkits by extending the scope of monitoring to include kernel internal functions, and to monitor file-system accesses through the kernel's heap allocations. With extensive tests performed on recent malware samples we show that  DRAKVUF  achieves significant improvements in conserving hardware resources while providing a stealthy, in-depth view into the behavior of modern malware."
1400472,15510,339,"Policy auditing over incomplete logs: theory, implementation and applications",2011,"We present the design, implementation and evaluation of an algorithm that checks audit logs for compliance with privacy and security policies. The algorithm, which we name reduce, addresses two fundamental challenges in compliance checking that arise in practice. First, in order to be applicable to realistic policies, reduce operates on policies expressed in a first-order logic that allows restricted quantification over infinite domains. We build on ideas from logic programming to identify the restricted form of quantified formulas. The logic can, in particular, express all 84 disclosure-related clauses of the HIPAA Privacy Rule, which involve quantification over the infinite set of messages containing personal information. Second, since audit logs are inherently incomplete (they may not contain sufficient information to determine whether a policy is violated or not), reduce proceeds iteratively: in each iteration, it provably checks as much of the policy as possible over the current log and outputs a residual policy that can only be checked when the log is extended with additional information. We prove correctness, termination, time and space complexity results for reduce. We implement reduce and optimize the base implementation using two heuristics for database indexing that are guided by the syntactic structure of policies. The implementation is used to check simulated audit logs for compliance with the HIPAA Privacy Rule. Our experimental results demonstrate that the algorithm is fast enough to be used in practice."
571179,15510,20592,Stitching the gadgets: on the ineffectiveness of coarse-grained control-flow integrity protection,2014,"Return-oriented programming (ROP) offers a robust attack technique that has, not surprisingly, been extensively used to exploit bugs in modern software programs (e.g., web browsers and PDF readers). ROP attacks require no code injection, and have already been shown to be powerful enough to bypass fine-grained memory randomization (ASLR) defenses. To counter this ingenious attack strategy, several proposals for enforcement of (coarse-grained) control-flow integrity (CFI) have emerged. The key argument put forth by these works is that coarse-grained CFI policies are sufficient to prevent ROP attacks. As this reasoning has gained traction, ideas put forth in these proposals have even been incorporated into coarse-grained CFI defenses in widely adopted tools (e.g., Microsoft's EMET framework).#R##N##R##N#In this paper, we provide the first comprehensive security analysis of various CFI solutions (covering kBouncer, ROPecker, CFI for COTS binaries, ROP-Guard, and Microsoft EMET 4.1). A key contribution is in demonstrating that these techniques can be effectively undermined, even under weak adversarial assumptions. More specifically, we show that with bare minimum assumptions, turing-complete and real-world ROP attacks can still be launched even when the strictest of enforcement policies is in use. To do so, we introduce several new ROP attack primitives, and demonstrate the practicality of our approach by transforming existing real-world exploits into more stealthy attacks that bypass coarse-grained CFI defenses."
1838568,15510,10192,Biometrics-Based Authentication: A New Approach,2011,"Authentication is a fundamental issue to any trust-oriented computing system and also a critical part in many security protocols. Performing authentication is notoriously difficult. Biometrics has been widely used and adopted as a promising authentication method due to its advantages over some existing methods, particularly, its resistance to losses incurred by theft of passwords and smart cards. However, biometrics introduces its own challenges, such as being irreplaceable once compromised. Moreover, the use of biometrics introduces privacy concern. In this paper, we propose a simple yet effective biometrics-based authentication solution. The proposed approach introduces new constructs - Reference Subject and Biometric Capsule, and stores the ``difference'' (called Biometric Capsule) between the user and the Reference Subject for authentication without revealing a user's original biometric information. This approach supports replaceability and protect users' privacy. Moreover, the proposed approach creates more advantages: (a) {\it being user-friendly} without any additional burden on users and possessing {\it one-for-all} power; (b) {\it being generic} enough to be applied to various biometrics (e.g., fingerprint, face, iris) or combinations of them; and (c) {\it being adaptive} in terms of security and privacy to fit different authentication models, application requirements, available resources, and trusted or non-fully-trusted environments. The experimental results on iris validate its performance and prove it a practical mechanism."
2338648,15510,20754,Ghost Talk: Mitigating EMI Signal Injection Attacks against Analog Sensors,2013,"Electromagnetic interference (EMI) affects circuits by inducing voltages on conductors. Analog sensing of signals on the order of a few millivolts is particularly sensitive to interference. This work (1) measures the susceptibility of analog sensor systems to signal injection attacks by intentional, low-power emission of chosen electromagnetic waveforms, and (2) proposes defense mechanisms to reduce the risks. Our experiments use specially crafted EMI at varying power and distance to measure susceptibility of sensors in implantable medical devices and consumer electronics. Results show that at distances of 1-2m, consumer electronic devices containing microphones are vulnerable to the injection of bogus audio signals. Our measurements show that in free air, intentional EMI under 10 W can inhibit pacing and induce defibrillation shocks at distances up to 1-2m on implantable cardiac electronic devices. However, with the sensing leads and medical devices immersed in a saline bath to better approximate the human body, the same experiment decreases to about 5 cm. Our defenses range from prevention with simple analog shielding to detection with a signal contamination metric based on the root mean square of waveform amplitudes. Our contribution to securing cardiac devices includes a novel defense mechanism that probes for forged pacing pulses inconsistent with the refractory period of cardiac tissue."
2715111,15510,11330,Leaky Pseudo-Entropy Functions,2011,"Pseudo-random functions (PRFs) introduced by Goldwasser, Goldreich, and Micali (FOCS 1984), are one of the most important building blocks in cryptography. A PRF family is a family of seeded functions ffsg, with the property that no e-cient adversary can tell the difierence between getting oracle access to a random PRF function fs, and getting oracle access to a truly random function. In this work, we consider the problem of constructing pseudo-random functions that are resilient to leakage. Unfortunately, even if a single bit about the secret seed s 2 f0;1g k is leaked, then there is no hope to construct a PRF, since the leakage can simply be the flrst bit of fs(0), and thus fs(0) is distinguishable from uniform. Therefore, when dealing with leakage, we must relax the deflnition. We consider the following relaxation: Instead of requiring that for each input x, the value fs(x) looks random, we require that it looks like it has high min-entropy, even given oracle access to fs everywhere except point x. We call such a function family a pseudo-entropy function (PEF) family. In particular, a leakage-resilient PEF family has the property that given leakage L(s) and given oracle access to fs, it is hard to predict fs on any input that was not queried. We construct such a leakage-resilient PEF family under the DDH assumption (or more generally, assuming the existence of lossy functions with the property that the output size is not much larger than the input size). We also show that leakage-resilient PEFs imply leakage-resilient random-input PRFs, where the requirement is that for a random input r, the value fs(r) looks uniform, even given the leakage L(s) and given oracle access to fs anywhere accept at point r (the leakage L(s) is independent of r, but the oracle fs is present even after the pair (r;fs(r)) is given)."
2303081,15510,20592,The velocity of censorship: high-fidelity detection of microblog post deletions,2013,"Weibo and other popular Chinese microblogging sites are well known for exercising internal censorship, to comply with Chinese government requirements. This research seeks to quantify the mechanisms of this censorship: how fast and how comprehensively posts are deleted. Our analysis considered 2.38 million posts gathered over roughly two months in 2012, with our attention focused on repeatedly visiting sensitive users. This gives us a view of censorship events within minutes of their occurrence, albeit at a cost of our data no longer representing a random sample of the generalWeibo population. We also have a larger 470 million post sampling from Weibo's public timeline, taken over a longer time period, that is more representative of a random sample.#R##N##R##N#We found that deletions happen most heavily in the first hour after a post has been submitted. Focusing on original posts, not reposts/retweets, we observed that nearly 30% of the total deletion events occur within 5- 30 minutes. Nearly 90% of the deletions happen within the first 24 hours. Leveraging our data, we also considered a variety of hypotheses about the mechanisms used by Weibo for censorship, such as the extent to which Weibo's censors use retrospective keyword-based censorship, and how repost/retweet popularity interacts with censorship. We also used natural language processing techniques to analyze which topics were more likely to be censored."
965553,15510,339,"Deduction soundness: prove one, get five for free",2013,"Most computational soundness theorems deal with a limited number of primitives, thereby limiting their applicability. The notion of deduction soundness of Cortier and Warinschi (CCS'11) aims to facilitate soundness theorems for richer frameworks via composition results: deduction soundness can be extended, generically, with asymmetric encryption and public data structures. Unfortunately, that paper also hints at rather serious limitations regarding further composition results: composability with digital signatures seems to be precluded.   In this paper we provide techniques for bypassing the perceived limitations of deduction soundness and demonstrate that it enjoys vastly improved composition properties. More precisely, we show that a deduction sound implementation can be modularly extended with all of the five basic cryptographic primitives (symmetric/asymmetric encryption, message authentication codes, digital signatures, and hash functions). We thus obtain the first soundness framework that allows for the joint use of multiple instances of all of the basic primitives.   In addition, we show how to overcome an important restriction of the bare deduction soundness framework which forbids sending encrypted secret keys. In turn, this prevents its use for the analysis of a large class of interesting protocols (e.g.~key exchange protocols). We allow for more liberal uses of keys as long as they are hidden in a sense that we also define. All primitives typically used to send secret data (symmetric/asymmetric encryption) satisfy our requirement which we also show to be preserved under composition."
1460984,15510,9856,Systems thinking for safety and security,2013,"The fundamental challenge facing security professionals is preventing losses, be they operational, financial or mission losses. As a result, one could argue that security professionals share this challenge with safety professionals. Despite their shared challenge, there is little evidence that recent advances that enable one community to better prevent losses have been shared with the other for possible implementation. Limitations in current safety approaches have led researchers and practitioners to develop new models and techniques. These techniques could potentially benefit the field of security. This paper describes a new systems thinking approach to safety that may be suitable for meeting the challenge of securing complex systems against cyber disruptions. Systems-Theoretic Process Analysis for Security (STPA-Sec) augments traditional security approaches by introducing a top-down analysis process designed to help a multidisciplinary team consisting of security, operations, and domain experts identify and constrain the system from entering vulnerable states that lead to losses. This new framework shifts the focus of the security analysis away from threats as the proximate cause of losses and focuses instead on the broader system structure that allowed the system to enter a vulnerable system state that the threat exploits to produce the disruption leading to the loss."
1246921,15510,23712,OrthCredential: A New Network Capability Design for High-Performance Access Control,2014,"Network architectures for the future Internet envision a variety of novel network services for transmitting, processing, and storaging of data. These network services may involve costly resources that need to be allocated by a service provider. Thus, an important problem is to limit access to authorized users (e.g., Those who have paid for a particular network service). In addition, these resources need to be protected from denial-of-service attacks or attempts to circumvent this access control. Most existing authentication approaches are based on cryptographic techniques. However, the high computational cost of cryptographic operations makes these techniques unsuitable for the data plane of the network, where potentially every packet needs to be checked at Gigabit per second link rates. In this paper, we describe a novel design for data plane capabilities, called OrthCredential, that solves this problem. The main idea is to use a set of orthogonal sequences as credentials that can be verified easily to protect the data plane against various attacks. These orthogonal sequences can be constructed by a Hadamard transform. Our evaluation of a prototype implementation shows that 64-bit credentials only require less than 300 processor cycles for verification, much less than existing access control schemes such as HMAC. And it provides reasonable security properties (e.g., Less than 10 -- 8 probability of successful attack)."
1189225,15510,20754,Automated Analysis of Security Protocols with Global State,2014,"Security APIs, key servers and protocols that need to keep the status of transactions, require to maintain a global, non-monotonic state, e.g., in the form of a database or register. However, existing automated verification tools do not support the analysis of such stateful security protocols - sometimes because of fundamental reasons, such as the encoding of the protocol as Horn clauses, which are inherently monotonic. An exception is the recent tamarin prover which allows specifying protocols as multiset rewrite (MSR) rules, a formalism expressive enough to encode state. As multiset rewriting is a low-level specification language with no direct support for concurrent message passing, encoding protocols correctly is a difficult and error-prone process. We propose a process calculus which is a variant of the applied pi calculus with constructs for manipulation of a global state by processes running in parallel. We show that this language can be translated to MSR rules whilst preserving all security properties expressible in a dedicated first-order logic for security properties. The translation has been implemented in a prototype tool which useqs the tamarin prover as a backend. We apply the tool to several case studies among which a simplified fragment of PKCS#11, the Yubikey security token, and an optimistic contract signing protocol."
2274725,15510,8228,Using opcode-sequences to detect malicious Android applications,2014,"Abstract—Recently, the Android platform has seen its numberof malicious applications increased sharply. Motivated by the easyapplication submission process and the number of alternativemarket places for distributing Android applications, rogue au-thors are developing constantly new malicious programs. Whilecurrent anti-virus software mainly relies on signature detection,the issue of alternative malware detection has to be addressed.In this paper, we present a feature based detection mechanismrelying on opcode-sequences combined with machine learningtechniques. We assess our tool on both a reference dataset knownas Genome Project as well as on a wider sample of 40,000applications retrieved from the Google Play Store.Keywords—Android malware, opcode-sequences, machinelearning I. I NTRODUCTION Over the last year, Android became the most used mobileOperating System around the world with more than 500 milliondevices already activated and around 1.3 million activationsevery single day 1 . This context makes Android attractivefor users, developers and also the attackers who can developand distribute malware easily. While anti-virus vendors donot agree on the market shares of malware owned by theAndroid OS, they acknowledge that this is the favourite targetof rogue authors to spread mobile malware"
144893,15510,11345,Optimal reductions of some decisional problems to the rank problem,2012,"In the last years the use of large matrices and their algebraic properties proved to be useful to instantiate new cryptographic primitives like Lossy Trapdoor Functions and encryption schemes with improved security, like Key Dependent Message resilience. In these constructions the rank of a matrix is assumed to be hard to guess when the matrix is hidden by elementwise exponentiation. This problem, that we call here the Rank Problem, is known to be related to the Decisional Diffie-Hellman problem, but in the known reductions between both problems there appears a loss-factor in the advantage which grows linearly with the rank of the matrix.#R##N##R##N#In this paper, we give a new and better reduction between the Rank problem and the Decisional Diffie-Hellman problem, such that the reduction loss-factor depends logarithmically in the rank. This new reduction can be applied to a number of cryptographic constructions, improving their efficiency. The main idea in the reduction is to build from a DDH tuple a matrix which rank shifts from r to 2r, and then apply a hybrid argument to deal with the general case. In particular this technique widens the range of possible values of the ranks that are tightly related to DDH.#R##N##R##N#On the other hand, the new reduction is optimal as we show the nonexistence of more efficient reductions in a wide class containing all the natural ones (i.e., black-box and algebraic). The result is twofold: there is no (natural) way to build a matrix which rank shifts from r to 2r+α for α>0, and no hybrid argument can improve the logarithmic loss-factor obtained in the new reduction.#R##N##R##N#The techniques used in the paper extend naturally to other algebraic problems like the Decisional Linear or the Decisional 3-Party Diffie- Hellman problems, also obtaining reductions of logarithmic complexity."
2239020,15510,22260,A Formal Framework for Network Security Design Synthesis,2013,"Due to the extensive use of Internet services and emerging security threats, most enterprise networks deploy varieties of security devices for controlling resource access based on organizational security requirements. These requirements are becoming more fine-grained, where access control depends on heterogeneous isolation patterns like access deny, trusted communication, and payload inspection. However, organizations are looking to design usable and optimal security configurations that can harden the network security within enterprise budget constraints. This requires analyzing various alternative security architectures in order to find a security design that satisfies the organizational security requirements as well as the business constraints. In this paper, we present ConfigSynth, an automated framework for synthesizing network security configurations by exploring various security design alternatives to provide an optimal solution. The main design alternatives include different kinds of isolation patterns for traffic flows in different segments of the network. ConfigSynth takes security requirements and business constraints along with the network topology as inputs. Then it synthesizes optimal and cost-effective security configurations satisfying the constraints. ConfigSynth also provides optimal placements of different security devices in the network according to the given network topology. ConfigSynth uses Satisfiability Modulo Theories (SMT) for modeling this synthesis problem. We demonstrate the scalability of the tool using simulated experiments."
106795,15510,10286,Extended-DDH and lossy trapdoor functions,2012,"Lossy Trapdoor Functions (LTFs) were introduced by Peikert and Waters in STOC '08 and since then have found many applications and have proven to be an extremely useful and versatile cryptographic primitive. Lossy trapdoor functions were used to build the first injective trapdoor functions based on DDH, the first IND-CCA cryptosystems based on lattice assumptions, and they are known to imply deterministic encryption, collision resistant hash-functions, oblivious transfer and a host of other important primitives. While LTFs can be instantiated under most known cryptographic hardness assumptions, no constructions until today existed based on generic cryptographic primitives. In this work, we show that any Homomorphic Smooth Hash Proof System, introduced by Cramer and Shoup in EUROCRYPT '02, can be used to construct LTFs. In addition to providing a connection between two important cryptographic primitives --- our construction implies the first construction of LTFs based on the QR assumption.#R##N##R##N#Smooth Hash Proof Systems (SHPs) can be seen as a generalization of the DDH assumption, yet can be built on other cryptographic assumptions, such as the DCR or QR assumptions. Yet, until today, a translation of results proven secure under DDH to results under DCR or QR has always been fraught with difficulties. Thus, as our second goal of this paper, we ask the following question: is it possible to streamline such translations from DDH to QR and other primitives? Our second result formally provides this connection. More specifically, we define an Extended Decisional Diffie Hellman (EDDH) assumption, which is a simple and natural generalization of DDH. We show that EDDH can be instantiated under both the DCR and QR assumptions. This gives a much simpler connection between the DDH and the DCR and QR assumptions and provides an easy way to translate proofs from DDH to DCR or QR. That is, the advantage of the EDDH assumption is that most schemes (including LTFs) proven secure under the DDH assumption can easily be instantiated under the DCR and QR assumptions with almost no change to their proofs of security."
632647,15510,20592,Man vs. machine: practical adversarial detection of malicious crowdsourcing workers,2014,"Recent work in security and systems has embraced the use of machine learning (ML) techniques for identifying misbehavior, e.g. email spam and fake (Sybil) users in social networks. However, ML models are typically derived from fixed datasets, and must be periodically retrained. In adversarial environments, attackers can adapt by modifying their behavior or even sabotaging ML models by polluting training data.#R##N##R##N#In this paper, we perform an empirical study of adversarial attacks against machine learning models in the context of detecting malicious crowdsourcing systems, where sites connect paying users with workers willing to carry out malicious campaigns. By using human workers, these systems can easily circumvent deployed security mechanisms, e.g. CAPTCHAs. We collect a dataset of malicious workers actively performing tasks on Weibo, China's Twitter, and use it to develop ML-based detectors. We show that traditional ML techniques are accurate (95%-99%) in detection but can be highly vulnerable to adversarial attacks, including simple evasion attacks (workers modify their behavior) and powerful poisoning attacks (where administrators tamper with the training set). We quantify the robustness of ML classifiers by evaluating them in a range of practical adversarial models using ground truth data. Our analysis provides a detailed look at practical adversarial attacks on ML models, and helps defenders make informed decisions in the design and configuration of ML detectors."
1373927,15510,9856,TrueClick: automatically distinguishing trick banners from genuine download links,2014,"The ubiquity of Internet advertising has made it a popular target for attackers. One well-known instance of these attacks is the widespread use of  trick banners  that use social engineering techniques to lure victims into clicking on deceptive fake links, potentially leading to a malicious domain or malware. A recent and pervasive trend by attackers is to imitate the download or play buttons in popular file sharing sites (e.g., one-click hosters, video-streaming sites, bittorrent sites) in an attempt to trick users into clicking on these fake banners instead of the genuine link.   In this paper, we explore the problem of automatically assisting Internet users in detecting malicious trick banners and helping them identify the correct link. We present a set of features to characterize trick banners based on their visual properties such as image size, color, placement on the enclosing webpage, whether they contain animation effects, and whether they consistently appear with the same visual properties on consecutive loads of the same webpage. We have implemented a tool called TrueClick, which uses image processing and machine learning techniques to build a classifier based on these features to automatically detect the trick banners on a webpage. Our approach automatically classifies trick banners, and requires no manual effort to compile blacklists as current approaches do. Our experiments show that TrueClick results in a 3.55 factor improvement in correct link selection in the absence of other ad blocking software, and that it can detect trick banners missed by a popular ad detection tool, Adblock Plus."
623537,15510,9766,On Implementing Deniable Storage Encryption for Mobile Devices,2013,"Data confidentiality can be effectively preserved through encryption. In certain situations, this is inadequate, as users may be coerced into disclosing their decryption keys. In this case, the data must be hidden so that its very existence can be denied. Steganographic techniques and deniable encryption algorithms have been devised to address this specific problem. Given the recent proliferation of smartphones and tablets, we examine the feasibility and efficacy of deniable storage encryption for mobile devices. We evaluate existing, and discover new, challenges that can compromise plausibly deniable encryption (PDE) in a mobile environment. To address these obstacles, we design a system called Mobiflage that enables PDE on mobile devices by hiding encrypted volumes within random data on a device’s external storage. We leverage lessons learned from known issues in deniable encryption in the desktop environment, and design new countermeasures for threats specific to mobile systems. Key features of Mobiflage include: deniable file systems with limited impact on throughput; efficient storage use with no data expansion; and restriction/prevention of known sources of leakage and disclosure. We provide a proof-of-concept implementation for the Android OS to assess the feasibility and performance of Mobiflage. We also compile a list of best practices users should follow to restrict other known forms of leakage and collusion that may compromise deniability."
1102168,15510,20796,UNIK: unsupervised social network spam detection,2013,"Social network spam increases explosively with the rapid development and wide usage of various social networks on the Internet. To timely detect spam in large social network sites, it is desirable to discover unsupervised schemes that can save the training cost of supervised schemes. In this work, we first show several limitations of existing unsupervised detection schemes. The main reason behind the limitations is that existing schemes heavily rely on spamming patterns that are constantly changing to avoid detection. Motivated by our observations, we first propose a sybil defense based spam detection scheme SD2 that remarkably outperforms existing schemes by taking the social network relationship into consideration. In order to make it highly robust in facing an increased level of spam attacks, we further design an unsupervised spam detection scheme, called UNIK. Instead of detecting spammers directly, UNIK works by deliberately removing non-spammers from the network, leveraging both the social graph and the user-link graph. The underpinning of UNIK is that while spammers constantly change their patterns to evade detection, non-spammers do not have to do so and thus have a relatively non-volatile pattern. UNIK has comparable performance to SD2 when it is applied to a large social network site, and outperforms SD2 significantly when the level of spam attacks increases. Based on detection results of UNIK, we further analyze several identified spam campaigns in this social network site. The result shows that different spammer clusters demonstrate distinct characteristics, implying the volatility of spamming patterns and the ability of UNIK to automatically extract spam signatures."
2268322,15510,339,The most dangerous code in the world: validating SSL certificates in non-browser software,2012,"SSL (Secure Sockets Layer) is the de facto standard for secure Internet communications. Security of SSL connections against an active network attacker depends on correctly validating public-key certificates presented when the connection is established.   We demonstrate that SSL certificate validation is completely broken in many security-critical applications and libraries. Vulnerable software includes Amazon's EC2 Java library and all cloud clients based on it; Amazon's and PayPal's merchant SDKs responsible for transmitting payment details from e-commerce sites to payment gateways; integrated shopping carts such as osCommerce, ZenCart, Ubercart, and PrestaShop; AdMob code used by mobile websites; Chase mobile banking and several other Android apps and libraries; Java Web-services middleware including Apache Axis, Axis 2, Codehaus XFire, and Pusher library for Android and  all  applications employing this middleware. Any SSL connection from any of these programs is insecure against a man-in-the-middle attack.   The root causes of these vulnerabilities are badly designed APIs of SSL implementations (such as JSSE, OpenSSL, and GnuTLS) and data-transport libraries (such as cURL) which present developers with a confusing array of settings and options. We analyze perils and pitfalls of SSL certificate validation in software based on these APIs and present our recommendations."
923658,15510,10192,Using DE-Optimized LFS Processing to Enhance 4G Communication Security,2011,"Wireless communication networks remain under attack with ill- intentioned hackers routinely gaining unauthorized access through Wireless Access Points-one of the most vulnerable points in an Information Technology (IT) system. The goal here is to demonstrate the feasibility of using Radio Frequency (RF) air monitoring to augment conventional bit-level security at WAPs. The speciﬁc networks of interest include those based on Orthogonal Frequency Division Multiplexing (OFDM), to include 802.11a/g WiFi and 4G 802.16 WiMAX. Proof-of-concept results are presented to demonstrate the effectiveness of a Learning from Signals (LFS) classiﬁer with Gaussian kernel bandwidth parameters optimally determined using Differential Evolution (DE). The resultant DE- optimized LFS classiﬁer is implemented within an RF Distinct Native Attribute (RF-DNA) ﬁngerprinting process with both Time Domain (TD) and Spectral Domain (SD) features input to the classiﬁer. The RF-DNA is used for intra-manufacturer (like-model devices from a given manufacturer) discrimination of IEEE compliant 802.11a WiFi devices and 802.16e WiMAX devices. A comparative performance assessment is provided using results from the proposed DE-optimized LFS classiﬁer and a Bayesian-based Multiple Discriminant Analysis/Maximum Likelihood (MDA/ML) classiﬁer as used in previous demonstrations. The assessment is performed using identical TD and SD ﬁngerprint features for both classiﬁers. Preliminary results of the DE-optimized classiﬁer are very promising, with correct classiﬁcation improvement of 15% to 40% realized over the range of signal to noise ratios considered."
2228876,15510,20358,The company you keep: mobile malware infection rates and inexpensive risk indicators,2014,"There is little information from independent sources in the public domain about mobile malware infection rates. The only previous independent estimate (0.0009%) [11], was based on indirect measurements obtained from domain-name resolution traces. In this paper, we present the first independent study of malware infection rates and associated risk factors using data collected directly from over 55,000 Android devices. We find that the malware infection rates in Android devices estimated using two malware datasets (0.28% and 0.26%), though small, are significantly higher than the previous independent estimate. Based on the hypothesis that some application stores have a greater density of malicious applications and that advertising within applications and cross-promotional deals may act as infection vectors, we investigate whether the set of applications used on a device can serve as an indicator for infection of that device. Our analysis indicates that, while not an accurate indicator of infection by itself, the application set does serve as an inexpensive method for identifying the pool of devices on which more expensive monitoring and analysis mechanisms should be deployed. Using our two malware datasets we show that this indicator performs up to about five times better at identifying infected devices than the baseline of random checks. Such indicators can be used, for example, in the search for new or previously undetected malware. It is therefore a technique that can complement standard malware scanning. Our analysis also demonstrates a marginally significant difference in battery use between infected and clean devices."
2565858,15510,9969,"Efficient Dissection of Composite Problems, with Applications to Cryptanalysis, Knapsacks, and Combinatorial Search Problems",2012,"In this paper we show that a large class of diverse problems have a bicomposite structure which makes it possible to solve them with a new type of algorithm called dissection, which has much better time/memory tradeoffs than previously known algorithms. A typical example is the problem of finding the key of multiple encryption schemes with r independent n-bit keys. All the previous error-free attacks required time T and memory M satisfying $$TM = 2^{rn}$$, and even if false negatives are allowed, no attack could achieve $$TM<2^{3rn/4}$$. Our new technique yields the first algorithm which never errs and finds all the possible keys with a smaller product of TM, such as $$T=2^{4n}$$ time and $$M=2^{n}$$ memory for breaking the sequential execution of $$r=7$$ block ciphers. The improvement ratio we obtain increases in an unbounded way as r increases, and if we allow algorithms which can sometimes miss solutions, we can get even better tradeoffs by combining our dissection technique with parallel collision search. To demonstrate the generality of the new dissection technique, we show how to use it in a generic way in order to attack hash functions with a rebound attack, to solve hard knapsack problems, and to find the shortest solution to a generalized version of Rubik's cube with better time complexities for small memory complexities than the best previously known algorithms."
450520,15510,9969,Near-Linear Unconditionally-Secure Multiparty Computation with a Dishonest Minority,2012,"In the setting of unconditionally-secure MPC, where dishonest players are unbounded and no cryptographic assumptions are used, it was known since the 1980's that an honest majority of players is both necessary and sufficient to achieve privacy and correctness, assuming secure point-to-point and broadcast channels. The main open question that was left is to establish the exact communication complexity.#R##N##R##N#We settle the above question by showing an unconditionally-secure MPC protocol, secure against a dishonest minority of malicious players, that matches the communication complexity of the best known MPC protocol in the honest-but-curious setting. More specifically, we present a new n-player MPC protocol that is secure against a computationally-unbounded malicious adversary that can adaptively corrupt $$t < n/2$$ of the players. For polynomially-large binary circuits that are not too unshaped, our protocol has an amortized communication complexity of $$On \log n + \kappa /n^{const}$$ bits per multiplication i.e.i¾?AND gate, where $$\kappa $$ denotes the security parameter and $${const}\in \mathbb {Z}$$ is an arbitrary non-negative constant. This improves on the previously most efficient protocol with the same security guarantee, which offers an amortized communication complexity of $$On^2 \kappa $$ bits per multiplication gate. For any $$\kappa $$ polynomial in n, the amortized communication cty of our protocol matches the $$On \log n$$ bit communication complexity of the best known MPC protocol with passive security.#R##N##R##N#We introduce several novel techniques that are of independent interest and we believe will have wider applicability. One is a novel idea of computing authentication tags by means of a mini MPC, which allows us to avoid expensive double-sharings; the other is a batch-wise multiplication verification that allows us to speedup Beaver's multiplication triples."
2627934,15510,9969,Generic side-channel distinguishers: improvements and limitations,2011,"The goal of generic side-channel distinguishers is to allow key recoveries against any type of implementation, under minimum assumptions on the underlying hardware. Such distinguishers are particularly interesting in view of recent technological advances. Indeed, the traditional leakage models used in side-channel attacks, based on the Hamming weight or distance of the data contained in an implementation, are progressively invalidated by the increased variability in nanoscale electronic devices. In this paper, we consequently provide two contributions related to the application of side-channel analysis against emerging cryptographic implementations. First, we describe a new statistical test that is aimed to be generic and efficient when exploiting high-dimensional leakages. The proposed distinguisher is fully non-parametric. It formulates the leakage distributions using a copula and discriminates keys based on the detection of an outlier behavior. Next, we provide experiments putting forward the limitations of generic side-channel analysis in advanced scenarios, where leaking devices are protected with countermeasures. Our results exhibit that all non-profiled attacks published so far can sometimes give a false sense of security, due to incorrect leakage models. That is, there exists settings in which an implementation is secure against such non-profiled attacks and can be defeated with profiling. This confirms that the evaluations of cryptographic implementations should always consider profiling, as a worst case scenario."
971475,15510,339,An efficient mobile PACE implementation,2011,"Many future electronic identity cards will be equipped with a contact-less interface. Analysts expect that a significant proportion of future mobile phones support Near Field Communication (NFC) technology. Thus, it is a reasonable approach to use the cell phone as mobile smart card terminal, which in particular supports the Password Authenticated Connection Establishment (PACE) protocol to ensure user consent and to protect the wireless interface between the mobile phone and the smart card. While there are efficient PACE implementations for smart cards, there does not seem to be an efficient and platform independent solution for mobile terminals. Therefore we provide a new implementation using the Java Micro Edition (Java ME), which is supported by almost all modern mobile phones. However, the benchmarks of our first, straightforward PACE implementation on an NFC-enabled mobile phone have shown that improvement is needed. In order to reach a user friendly performance we implemented an optimized version, which, as of now, is restricted to optimizations which can be realized using features of existing Java ME libraries.   In the work at hand we present a review of the relevant algorithms and provide benchmarks of the corresponding arithmetic functions in different Java ME libraries. We discuss the different optimization approaches, introduce our optimized PACE implementation, and provide timings for a desktop PC and a mobile phone in comparison to the straightforward version. Finally, we investigate potential side channel attacks on the optimized implementation."
1266537,15510,9856,Centrality metrics of importance in access behaviors and malware detections,2014,"System objects play different roles in a computer system and exhibit different degrees of importance with respect to system security. Identifying importance metrics can help us to develop more effective and efficient security protection methods. However, there is little previous work on evaluating the importance of objects from the perspective of security. In this paper, we propose a novel approach to evaluate the importance of various system objects based on a bipartite dependency network representation of access behaviors observed in a computer system. We introduce centrality metrics from network science to quantitatively measure the relative importance of system objects and reveal their inherent connections to security properties such as integrity and confidentiality. Furthermore, we propose importance-metric based models to characterize process behaviors and identify abnormal access patterns with respect to confidentiality and integrity. Extensive experimental results on one real-world dataset demonstrate that our model is capable of detecting 7,257 malware samples from 27,840 benign processes at 93.94% TPR under 0.1% FPR. Moreover, a selective protection scheme based on a partial behavioral model of important objects achieves comparable or even better results in malware detection when compared with complete behavior models. This demonstrates the feasibility of the devised importance metrics and presents a promising new approach to malware detection."
2261066,15510,20754,Anon-Pass: Practical Anonymous Subscriptions,2013,"We present the design, security proof, and implementation of an anonymous subscription service. Users register for the service by providing some form of identity, which might or might not be linked to a real-world identity such as a credit card, a web login, or a public key. A user logs on to the system by presenting a credential derived from information received at registration. Each credential allows only a single login in any authentication window, or epoch. Logins are anonymous in the sense that the service cannot distinguish which user is logging in any better than random guessing. This implies unlinkability of a user across different logins. We find that a central tension in an anonymous subscription service is the service provider's desire for a long epoch (to reduce server-side computation) versus users' desire for a short epoch (so they can repeatedly re-anonymize their sessions). We balance this tension by having short epochs, but adding an efficient operation for clients who do not need unlinkability to cheaply re-authenticate themselves for the next time period. We measure performance of a research prototype of our protocol that allows an independent service to offer anonymous access to existing services. We implement a music service, an Android-based subway-pass application, and a web proxy, and show that adding anonymity adds minimal client latency and only requires 33 KB of server memory per active user."
1450015,15510,9856,Do I know you?: efficient and privacy-preserving common friend-finder protocols and applications,2013,"The increasing penetration of Online Social Networks (OSNs) prompts the need for effectively accessing and utilizing social networking information. In numerous applications, users need to make trust and/or access control decisions involving other (possibly stranger) users, and one important factor is often the existence of common social relationships. This motivates the need for secure and privacy-preserving techniques allowing users to assess whether or not they have mutual friends.   This paper introduces the  Common Friends  service, a framework for finding common friends which protects privacy of non-mutual friends and guarantees authenticity of friendships. First, we present a generic construction that reduces to secure computation of set intersection, while ensuring authenticity of announced friends via bearer capabilities. Then, we propose an efficient instantiation, based on Bloom filters, that only incurs a constant number of public-key operations and appreciably low communication overhead. Our software is designed so that developers can easily integrate  Common Friends  into their applications, e.g., to enforce access control based on users' social proximity in a privacy-preserving manner. Finally, we showcase our techniques in the context of an existing application for sharing (tethered) Internet access, whereby users decide to share access depending on the existence of common friends. A comprehensive experimental evaluation attests to the practicality of proposed techniques."
1539240,15510,8806,Do you feel lucky?: a large-scale analysis of risk-rewards trade-offs in cyber security,2014,"A crucial part of a cyber-criminal's job is to balance the risks and rewards of his every action. For example, an expert spammer will tune a bot's email-sending rate to achieve a good throughput with an acceptable risk of being detected. Then, such a cyber-criminal has to choose how to launder the money he made with spamming, and he will have to consider many options (money mules, Bitcoin, etc.) that will offer different returns and risks. Although understanding these trade-offs and coming as close as possible to their optimum is what discriminates winners and losers in the cyber-crime world, there has been little study on this matter, as setting up a large-scale study to study how cyber-criminals deal with these risk-reward trade-offs is challenging.   Computer security competitions provide a great opportunity both to educate students and to study realistic cyber-security scenarios in a controlled environment. Looking to study the risk-reward trade-offs seen in real cyber-security incidents, we designed and hosted a novel format for a Capture the Flag cyber-security contest, involving 89 teams comprising over 1,000 students across the globe. In this paper, we describe the intuition, intent, and design of the contest. Additionally, we present an analysis of the data set collected, evaluate its effectiveness in modeling risk-reward behavior, examine the strategies of the competing teams, and estimate the effectiveness of such strategies."
1474098,15510,8839,Secure unlocking of mobile touch screen devices by simple gestures: you can see it but you can not do it,2013,"With the rich functionalities and enhanced computing capabilities available on mobile computing devices with touch screens, users not only store sensitive information (such as credit card numbers) but also use privacy sensitive applications (such as online banking) on these devices, which make them hot targets for hackers and thieves. To protect private information, such devices typically lock themselves after a few minutes of inactivity and prompt a password/PIN/pattern screen when reactivated. Passwords/PINs/patterns based schemes are inherently vulnerable to shoulder surfing attacks and smudge attacks. Furthermore, passwords/PINs/patterns are inconvenient for users to enter frequently. In this paper, we propose GEAT, a gesture based user authentication scheme for the secure unlocking of touch screen devices. Unlike existing authentication schemes for touch screen devices, which use what user inputs as the authentication secret, GEAT authenticates users mainly based on how they input, using distinguishing features such as finger velocity, device acceleration, and stroke time. Even if attackers see what gesture a user performs, they cannot reproduce the behavior of the user doing gestures through shoulder surfing or smudge attacks. We implemented GEAT on Samsung Focus running Windows, collected 15009 gesture samples from 50 volunteers, and conducted real-world experiments to evaluate GEAT's performance. Experimental results show that our scheme achieves an average equal error rate of 0.5% with 3 gestures using only 25 training samples."
2680715,15510,339,Pseudorandom signatures,2013,"We develop a three-level hierarchy of privacy notions for (unforgeable) digital signature schemes. We first prove mutual independence of existing notions of anonymity and confidentiality, and then show that these are implied by higher privacy goals. The top notion in our hierarchy is  pseudorandomness : signatures with this property hide the entire information about the signing process and cannot be recognized as signatures when transmitted over a public network. This implies very strong unlinkability guarantees across different signers and even different signing algorithms, and gives rise to new forms of private public-key authentication.   We show that one way towards pseudorandom signatures leads over our mid-level notion, called  indistinguishability : such signatures can be simulated using only the public parameters of the scheme. As we reveal, indistinguishable signatures exist in different cryptographic settings (e.g. based on RSA, discrete logarithms, pairings) and can be efficiently lifted to pseudorandomness deploying general transformations using appropriate encoding techniques. We also examine a more direct way for obtaining pseudorandomness for any unforgeable signature scheme. All our transformations work in the standard model. We keep public verifiability of signatures in the setting of system-wide known public keys. Some results even hold if signing keys are disclosed to the adversary --- given that signed messages have high entropy."
2337083,15510,8228,A Novel Role- and Certificate-Based Single Sign-On System for Emergency Rescue Operations,2011,"In large scale disaster management operations with hundreds and thousands of victims, fast access to distributed heterogeneous information of different organizations is required for efficient and reliable dispensation of rescue operations. The development of such emergency systems poses a big challenge, if requirements such as performance, security and reliability have to be fulfilled simultaneously. In this paper, we propose a novel Role integrated Certificate-based Single Sign-On (RC-SSO) solution for fast mobile access between first responders at the incident scene and their distributed organizations. Beside the illustration of operational details of the RC-SSO solution, we validate our concept by implementing an experimental prototype as proof-of-concept for a limited number of users. Furthermore, we design a simulation model to determine the performance boundary of our solution under high user density. In contrast to other related emergency system solutions, our approach does not employ a so-called Identity Provider (IDP) for authentication and authorization process and thus reduces additional communication cost as well. A comparison of our proposed solution to an IDP based classical single sign-on counterparts i.e. Security Assertion Markup Language (SAML) shows that our RC-SSO outperforms these by up to 80%. In addition RC-SSO ensures high data security level with negligible overhead compared to the standard security protocol SSL/TLS."
2759318,15510,20592,Detecting malware domains at the upper DNS hierarchy,2011,"In recent years Internet miscreants have been leveraging the DNS to build malicious network infrastructures for malware command and control. In this paper we propose a novel detection system called Kopis for detecting malware-related domain names. Kopis passively monitors DNS traffic at the upper levels of the DNS hierarchy, and is able to accurately detect malware domains by analyzing global DNS query resolution patterns.#R##N##R##N#Compared to previous DNS reputation systems such as Notos [3] and Exposure [4], which rely on monitoring traffic from local recursive DNS servers, Kopis offers a new vantage point and introduces new traffic features specifically chosen to leverage the global visibility obtained by monitoring network traffic at the upper DNS hierarchy. Unlike previous work Kopis enables DNS operators to independently (i.e., without the need of data from other networks) detect malware domains within their authority, so that action can be taken to stop the abuse. Moreover, unlike previous work, Kopis can detect malware domains even when no IP reputation information is available.#R##N##R##N#We developed a proof-of-concept version of Kopis, and experimented with eight months of real-world data. Our experimental results show that Kopis can achieve high detection rates (e.g., 98.4%) and low false positive rates (e.g., 0.3% or 0.5%). In addition Kopis is able to detect new malware domains days or even weeks before they appear in public blacklists and security forums, and allowed us to discover the rise of a previously unknown DDoS botnet based in China."
767146,15510,20754,Triple Handshakes and Cookie Cutters: Breaking and Fixing Authentication over TLS,2014,"TLS was designed as a transparent channel abstraction to allow developers with no cryptographic expertise to protect their application against attackers that may control some clients, some servers, and may have the capability to tamper with network connections. However, the security guarantees of TLS fall short of those of a secure channel, leading to a variety of attacks. We show how some widespread false beliefs about these guarantees can be exploited to attack popular applications and defeat several standard authentication methods that rely too naively on TLS. We present new client impersonation attacks against TLS renegotiations, wireless networks, challenge-response protocols, and channel-bound cookies. Our attacks exploit combinations of RSA and Diffie-Hellman key exchange, session resumption, and renegotiation to bypass many recent countermeasures. We also demonstrate new ways to exploit known weaknesses of HTTP over TLS. We investigate the root causes for these attacks and propose new countermeasures. At the protocol level, we design and implement two new TLS extensions that strengthen the authentication guarantees of the handshake. At the application level, we develop an exemplary HTTPS client library that implements several mitigations, on top of a previously verified TLS implementation, and verify that their composition provides strong, simple application security."
5036,15510,374,Fine-Grained Access Control System Based on Outsourced Attribute-Based Encryption,2013,"As cloud computing becomes prevalent, more and more sen- sitive data is being centralized into the cloud for sharing, which brings forth new challenges for outsourced data security and privacy. Attribute- based encryption (ABE) is a promising cryptographic primitive, which has been widely applied to design fine-grained access control system re- cently. However, ABE is being criticized for its high scheme overhead as the computational cost grows with the complexity of the access formula. This disadvantage becomes more serious for mobile devices because they have constrained computing resources. Aiming at tackling the challenge above, we present a generic and ef- ficient solution to implement attribute-based access control system by introducing secure outsourcing techniques into ABE. More precisely, two cloud service providers (CSPs), namely key generation-cloud ser- vice provider (KG-CSP) and decryption-cloud service provider (D-CSP) are introduced to perform the outsourced key-issuing and decryption on behalf of attribute authority and users respectively. In order to outsource heavy computation to both CSPs without private information leakage, we formulize an underlying primitive called outsourced ABE (OABE) and propose several constructions with outsourced decryption and key- issuing. Finally, extensive experiment demonstrates that with the help of KG-CSP and D-CSP, efficient key-issuing and decryption are achieved in our constructions."
2363528,15510,339,FANCI: identification of stealthy malicious logic using boolean functional analysis,2013,"Hardware design today bears similarities to software design. Often vendors buy and integrate code acquired from third-party organizations into their designs, especially in embedded/system-on-chip designs. Currently, there is no way to determine if third-party designs have built-in backdoors that can compromise security after deployment.   The key observation we use to approach this problem is that hardware backdoors incorporate logic that is nearly-unused, i.e. stealthy. The wires used in stealthy backdoor circuits almost never influence the outputs of those circuits. Typically, they do so only when triggered using external inputs from an attacker. In this paper, we present FANCI, a tool that flags suspicious wires, in a design, which have the potential to be malicious. FANCI uses scalable, approximate, boolean functional analysis to detect these wires.   Our examination of the TrustHub hardware backdoor benchmark suite shows that FANCI is able to flag all suspicious paths in the benchmarks that are associated with backdoors. Unlike prior work in the area, FANCI is not hindered by incomplete test suite coverage and thus is able to operate in practice without false negatives. Furthermore, FANCI reports low false positive rates: less than 1% of wires are reported as suspicious in most cases. All TrustHub designs were analyzed in a day or less. We also analyze a backdoor-free out-of-order microprocessor core to demonstrate applicability beyond benchmarks."
2291247,15510,9856,Using memory management to detect and extract illegitimate code for malware analysis,2012,"Exploits that successfully attack computers are typically based on some form of shellcode, i.e., illegitimate code that is injected by the attacker to take control of the system. Detecting and gathering such code is the first step to its detailed analysis. The amount and sophistication of modern malware calls for automated mechanisms that perform such detection and extraction.   In this paper, we present a novel generic and fully automatic approach to detect the execution of illegitimate code and extract such code upon detection. The basic idea is to flag certain memory pages as non-executable and utilize a modified page fault handler to react on the attempt to execute code from them. Our modified page fault handler detects if legitimate code is about to be executed or if the code originates from an untrusted location. In such a case, the corresponding memory content is extracted and execution is continued to retrieve more illegitimate code for analysis.   We present an implementation of the approach for the Windows platform called  CWXDetector , which involved reverse-engineering the proprietary memory management system of this operating system. Evaluation results using a large corpus of malicious PDF documents show that our system produces no false positives and has a very low false negative rate. To further demonstrate the universality of our approach, we also used it to detect shellcode execution in  Flash Player, RealVNC client , and  VideoLan Client ."
522690,15510,10286,Fully secure accountable-authority identity-based encryption,2011,"The problem of trust is one of the biggest concerns in any identity-based infrastructure where the key-generation authority (called the PKG) must choose secret keys for participants and therefore be highly trusted by all parties. While some abilities of the PKG are intrinsic to this setting, reducing this trust as much as possible is beneficial to both user and authority as the less trust is placed in it, the less an honest authority can be accused of abusing that trust. Goyal (CRYPTO 2007) defined the notion of Accountable-Authority IBE in which a dishonest PKG who had leaked a user's private key could be proven guilty. Later, Goyal et al. (CCS 2008) asked whether it would be possible to implicate a PKG who produced an unauthorized decoder box, enabling decryption with a noticeable probability but which may not actually grant access to a well-formed key. Formally, would it be possible for a tracing algorithm to implicate a dishonest PKG given only black-box access to such a decoder? Goyal et al. could only provide such a scheme in the weaker setting of selective security, where an adversary must declare at the start of the game which identity it intends to target. In this work, we provide the first fully secure accountable-authority IBE scheme. We prove security from the standard DBDH assumption while losing none of the functionality or security of the original proposal."
1911108,15510,22260,Competitive and Fair Medium Access Despite Reactive Jamming,2011,"Intentional interference constitutes a major threat for communication networks operating over a shared medium where availability is imperative. Jamming attacks are often simple and cheap to implement. Today's jammers can perform physical carrier sensing in order to disrupt communication more efficiently, especially in a network of simple wireless devices such as sensor nodes, which usually operate over a single frequency (or a limited frequency band) and which cannot benefit from the use of spread spectrum or other more advanced technologies. This paper proposes the medium access (MAC) protocol \textsc{Anti Jam} which is provably robust against a powerful reactive adversary who can jam a $(1-\varepsilon)$-portion of the time steps, where $\varepsilon$ is an arbitrary constant. The adversary uses carrier sensing to make informed decisions on when it is most harmful to disrupt communications. Moreover, we allow the adversary to be adaptive and to have complete knowledge of the entire protocol history. Our MAC protocol is able to make efficient use of the non jammed time periods and achieves a $\Theta{(1)}$-competitive throughput in this harsh scenario, if $\varepsilon$ is constant. In addition, \textsc{Anti Jam} features a low convergence time and has excellent fairness properties in the sense that channel access probabilities among nodes do not differ by more than a small constant factor."
1547515,15510,339,Certified computer-aided cryptography: efficient provably secure machine code from high-level implementations,2013,"We present a computer-aided framework for proving concrete security bounds for cryptographic machine code implementations. The front-end of the framework is an interactive verification tool that extends the EasyCrypt framework to reason about relational properties of C-like programs extended with idealised probabilistic operations in the style of code-based security proofs. The framework also incorporates an extension of the CompCert certified compiler to support trusted libraries providing complex arithmetic calculations or instantiating idealized components such as sampling operations. This certified compiler allows us to carry to executable code the security guarantees established at the high-level, and is also instrumented to detect when compilation may interfere with side-channel countermeasures deployed in source code.   We demonstrate the applicability of the framework by applying it to the RSA-OAEP encryption scheme, as standardized in PKCS#1 v2.1. The outcome is a rigorous analysis of the advantage of an adversary to break the security of assembly implementations of the algorithms specified by the standard. The example also provides two contributions of independent interest: it bridges the gap between computer-assisted security proofs and real-world cryptographic implementations as described by standards such as PKCS,and demonstrates the use of the CompCert certified compiler in the context of cryptographic software development."
2779664,15510,9969,New Impossibility Results for Concurrent Composition and a Non-interactive Completeness Theorem for Secure Computation,2012,"We consider the client-server setting for the concurrent composition of secure protocols: in this setting, a single server interacts with multiple clients concurrently, executing with each client a specified protocol where only the client should receive any nontrivial output. Such a setting is easily motivated from an application standpoint. There are important special cases for which positive results are known - such as concurrent zero knowledge protocols - and it has been an open question whether other natural functionalities such as Oblivious Transfer (OT) are possible in this setting. In this work:  We resolve this open question by showing that unfortunately, even in this very limited concurrency setting, broad new impossibility results hold, ruling out not only OT, but in fact all nontrivial finite asymmetric functionalities. Our new negative results hold even if the inputs of all honest parties are fixed in advance, and the adversary receives no auxiliary information.  Along the way, we establish a new unconditional completeness result for asymmetric functionalities, where we characterize func- tionalities that are non-interactively complete secure against active adversaries. When we say that a functionality F is non-interactively complete, we mean that every other asymmetric functionality can be realized by parallel invocations of several copies of F ,w ith no other communication in any direction. Our result subsumes a completeness result of Kilian (STOC'00) that uses protocols which require additional interaction in both directions."
1597041,15510,20338,Scap: stream-oriented network traffic capture and analysis for high-speed networks,2013,"Many network monitoring applications must analyze traffic beyond the network layer to allow for connection-oriented analysis, and achieve resilience to evasion attempts based on TCP segmentation. However, existing network traffic capture frameworks provide applications with just raw packets, and leave complex operations like flow tracking and TCP stream reassembly to application developers. This gap leads to increased application complexity, longer development time, and most importantly, reduced performance due to excessive data copies between the packet capture subsystem and the stream processing module. This paper presents the Stream capture library (Scap), a network monitoring framework built from the ground up for stream-oriented traffic processing. Based on a kernel module that directly handles flow tracking and TCP stream reassembly, Scap delivers to user-level applications flow-level statistics and reassembled streams by minimizing data movement operations and discarding uninteresting traffic at early stages, while it inherently supports parallel processing on multi-core architectures, and uses advanced capabilities of modern network cards. Our experimental evaluation shows that Scap can capture all streams for traffic rates two times higher than other stream reassembly libraries, and can process more than five times higher traffic loads when eight cores are used for parallel stream processing in a pattern matching application."
207494,15510,10286,Solving underdetermined systems of multivariate quadratic equations revisited,2012,"Solving systems of  m        $\mathcal M$    ultivariate       $\mathcal Q$    uadratic (      $\mathcal{MQ}$    ) equations in  n  variables is one of the main challenges of algebraic cryptanalysis. Although the associated       $\mathcal{MQ}$    -problem is proven to be NP-complete, we know that it is solvable in  polynomial time  over fields of even characteristic if either  m  ≥ n  ( n  −1)/2 ( overdetermined  ) or  n  ≥ m  ( m  +1) ( underdetermined  ). It is widely believed that  m  = n  has worst case complexity. Actually in the overdetermined case Grobner Bases algorithms show a gradual decrease in complexity from  m  = n  to  m  ≥ n  ( n  −1)/2 as more and more equations are available. For the underdetermined case no similar behavior was known. Up to now the best way to deal with the case  m   n   m  ( m  +1) was to randomly guess variables until  m  = n  . This article shows how to smartly use additional variables and thus obtain a gradual change of complexity over even characteristics also for the underdetermined case. Namely, we show how a linear change of variables can be used to reduce the overall complexity of solving a       $\mathcal{MQ}$    -system with  m  equations and  n  = ωm  variables for some  ω  ∈ℚ>1 to the complexity of solving a       $\mathcal{MQ}$    -system with only       $(m-\left\lfloor \omega\right\rfloor+1)$    equations and variables, respectively. Our algorithm can be seen as an extension of the previously known algorithm from Kipnis-Patarin-Goubin (extended version of Eurocrypt '99) and improves an algorithm of Courtois  et al.  which eliminates       $\left\lfloor \mbox{log}_2\omega\right\rfloor$    variables. For small  ω  we also adapt our algorithm to fields of odd characteristic. We apply our result to break current instances of the Unbalanced Oil and Vinegar public key signature scheme that uses  n  =3 m  and hence  ω  =3."
1048151,15510,8228,A two dimensional quantization algorithm for CIR-based physical layer authentication,2013,"Recently, channel impulse response (CIR) based physical layer authentication has been studied to enhance the security of wireless communications. However, the reliability of CIR-based authentication is substantially reduced at low signal-to-noise ratio (SNR) conditions due to the presence of communications noise, channel estimation error and mobility induced channel variation. To this end, we integrate additional multipath delay characteristics into the CIR-based physical layer authentication and propose a two dimensional quantization scheme to tolerate these random errors of CIRs for reduced false alarm rate and more reliable spoofing detection. Instead of directly comparing the estimated CIRs from different transmitters for authentication purpose, we first quantize the CIR estimates in two dimensions (i.e., the amplitude dimension and multipath delay dimension) and then differentiate transmitters based on the quantizer outputs with a binary hypothesis testing. More specifically, the quantization intervals are determined by using a searching algorithm based on a guaranteed miss probability of detection of the presence of spoofing attack. A logarithmic likelihood ratio test (LLRT) is used to evaluate the authentication performance, and a threshold with a constant value is used for the decision-making of authentication under the binary hypothesis testing. To verify the effectiveness of proposed algorithm, an orthogonal frequency division multiplexing (OFDM) system is considered in our simulation."
2244029,15510,8806,JSFlow: tracking information flow in JavaScript and its APIs,2014,"JavaScript drives the evolution of the web into a powerful application platform. Increasingly, web applications combine services from different providers. The script inclusion mechanism routinely turns barebone web pages into full-fledged services built up from third-party code. Such code provides a range of facilities from helper utilities (such as jQuery) to readily available services (such as Google Analytics and Tynt). Script inclusion poses a challenge of ensuring that the integrated third-party code respects security and privacy.   This paper presents  JSFlow , a security-enhanced JavaScript interpreter for fine-grained tracking of information flow. We show how to resolve practical challenges for enforcing information-flow policies for the full JavaScript language, as well as tracking information in the presence of libraries, as provided by browser APIs. The interpreter is itself written in JavaScript, which enables deployment as a browser extension. Our experiments with the extension provide in-depth understanding of information manipulation by third-party scripts such as Google Analytics. We find that different sites intended to provide similar services effectuate rather different security policies for the user's sensitive information: some ensure it does not leave the browser, others share it with the originating server, while yet others freely propagate it to third parties."
1764330,15510,339,Outsourced Proofs of Retrievability,2014,"Proofs of Retrievability (POR) are cryptographic proofs that enable a cloud provider to prove that a user can retrieve his file in its entirety. POR need to be frequently executed by the user to ensure that their files stored on the cloud can be fully retrieved at any point in time. To conduct and verify POR, users need to be equipped with devices that have network access, and that can tolerate the (non-negligible) computational overhead incurred by the verification process. This clearly hinders the large-scale adoption of POR by cloud users, since many users increasingly rely on portable devices that have limited computational capacity, or might not always have network access.   In this paper, we introduce the notion of outsourced proofs of retrievability (OPOR), in which users can task an external auditor to perform and verify POR with the cloud provider. We argue that the OPOR setting is subject to security risks that have not been covered by existing POR security models. To remedy that, we propose a formal framework and a security model for OPOR. We then propose an instantiation of OPOR which builds upon the provably-secure private POR scheme due to Shacham and Waters (Asiacrypt'08) and we show its security in our proposed security model. We implement a prototype based on our solution, and evaluate its performance in a realistic cloud setting. Our evaluation results show that our proposal minimizes user effort, incurs negligible overhead on the auditor (compared to the SW scheme), and considerably improves over existing publicly verifiable POR."
2582956,15510,9766,Track Me If You Can: On the Effectiveness of Context-based Identifier Changes in Deployed Mobile Networks,2012,"Location privacy is a major concern in an increasingly connected and highly pervasive network of mobile users. Novel location-based applications and device-to-device services (on these mobile devices) are gaining popularity, but at the same time, these services allow curious service providers and eavesdroppers to track users and their movements. Earlier research efforts on location-privacy preservation, which were mostly based on identifier-change mechanisms in spatio-temporal de-correlation regions called mix-zones, show that coordinated identifier-change techniques are reasonably effective in a simulation setting, although some smart attacks are still possible. However, a thorough analysis of these mechanisms that takes into consideration communication patterns and mobility from a real-life deployment is missing from these results. In this paper, we evaluate in a real-life setting the effectiveness of standard mix-zone-based privacy protection mechanisms against probabilistic tracking attacks. Our exper- iments involved 80 volunteers carrying smartphones for 4 months and being constantly eavesdropped on an adversarial mesh network of standard wireless Access Points (APs). To the best of our knowledge, this is the first study that provides empirical evidence about the effectiveness of mix-zone-based privacy-preserving mechanisms against practical adversaries in upcoming wireless and mobile systems."
1918521,15510,9856,Towards automated integrity protection of C++ virtual function tables in binary programs,2014,"Web browsers are one of the most used, complex, and popular software systems nowadays. They are prone to dangling pointers that result in  use-after-free  vulnerabilites and this is the de-facto way to exploit them. From a technical point of view, an attacker uses a technique called  vtable hijacking  to exploit such bugs. More specifically, she crafts bogus virtual tables and lets a freed C++ object point to it in order to gain control over the program at virtual function call sites.   In this paper, we present a novel approach towards mitigating and detecting such attacks against C++ binary code. We propose a static binary analysis technique to extract virtual function call site information in an automated way. Leveraging this information, we instrument the given binary executable and add runtime policy enforcements to thwart the illegal usage of these call sites. We implemented the proposed techniques in a prototype called T-VIP and successfully hardened three versions of Microsoft's Internet Explorer and Mozilla Firefox. An evaluation with several zero-day exploits demonstrates that our method prevents all of them. Performance benchmarks both on micro and macro level indicate that the overhead is reasonable with about 2.2%, which is only slightly higher compared to recent compiler-based approaches that address this problem."
907466,15510,22164,Encompassing anonymity in signaling games,2014,"Signaling games are an important class of games in the literature of game theory, finding wide spread application in modelling financial behavior in markets, economic reasoning in job searches, and evolutionary behavior in the emergence of languages. Fundamentally, signaling games consist of multiple senders and a common receiver. Each sender belongs to one of multiple types. Senders transmit their messages to the receiver. The receiver takes an action for each received message, which results in a pair of rewards for the receiver and the corresponding sender respectively. Each sender therefore chooses a message that maximizes his/her reward knowing the optimal response of the receiver. In classical signaling games, the senders reward is a deterministic function of the transmitted message and receiver's action, while the receivers reward is a function of the action and belief about the senders' type. Therefore, in a signaling game, the message received provides information about a sender's type which, in practical commercial contexts, is a violation of the sender's anonymity. In this work, the payoff of a signaling game is adjusted to incorporate the information revealed to the receivers such that this information leakage is minimized from the sender's perspective. The existence of Bayesian-Nash equilibrium is proven in this work for the signaling games even after the incorporation of “type anonymity”. In particular, when the reward is modeled as a weighted sum of the anonymity and direct signaling reward, there exists a threshold on the anonymity weighting coefficient; when the coefficient exceeds the threshold, a pooling equilibrium exists—senders of all types transmit the same message, and when the coefficient is below the threshold, a separating equilibrium exists—senders of each type transmit a distinct message. Furthermore when the cardinality of the message set is 2, the separating equilibrium is shown to be the unique Bayesian Nash equilibrium. The proposed signaling game is suitable to model the problem of routing in the datagram networking where Quality of service (delay or throughput) and the source-destination anonymity are competing requirements."
884482,15510,9856,TRESOR-HUNT: attacking CPU-bound encryption,2012,"Hard disk encryption is known to be vulnerable to a number of attacks that aim to directly extract cryptographic key material from system memory. Several approaches to preventing this class of attacks have been proposed, including Tresor [18] and LoopAmnesia [25]. The common goal of these systems is to confine the encryption key and encryption process itself to the CPU, such that sensitive key material is never released into system memory where it could be accessed by a DMA attack.   In this work, we demonstrate that these systems are nevertheless vulnerable to such DMA attacks. Our attack, which we call Tresor-Hunt, relies on the insight that DMA-capable adversaries are not restricted to simply reading physical memory, but can write arbitrary values to memory as well. Tresor-Hunt leverages this insight to inject a ring 0 attack payload that extracts disk encryption keys from the CPU into the target system's memory, from which it can be retrieved using a normal DMA transfer.   Our implementation of this attack demonstrates that it can be constructed in a reliable and  OS-independent  manner that is applicable to any CPU-bound encryption technique, IA32-based system, and DMA-capable peripheral bus. Furthermore, it does not crash the target system or otherwise significantly compromise its integrity. Our evaluation supports the OS-independent nature of the attack, as well as its feasibility in real-world scenarios. Finally, we discuss several countermeasures that might be adopted to mitigate this attack and render CPU-bound encryption systems viable."
698127,15510,20592,Towards reliable storage of 56-bit secrets in human memory,2014,"Challenging the conventional wisdom that users cannot remember cryptographically-strong secrets, we test the hypothesis that users can learn randomly-assigned 56- bit codes (encoded as either 6 words or 12 characters) through spaced repetition. We asked remote research participants to perform a distractor task that required logging into a website 90 times, over up to two weeks, with a password of their choosing. After they entered their chosen password correctly we displayed a short code (4 letters or 2 words, 18.8 bits) that we required them to type. For subsequent logins we added an increasing delay prior to displaying the code, which participants could avoid by typing the code from memory. As participants learned, we added two more codes to comprise a 56.4- bit secret. Overall, 94% of participants eventually typed their entire secret from memory, learning it after a median of 36 logins. The learning component of our system added a median delay of just 6.9 s per login and a total of less than 12 minutes over an average of ten days. 88% were able to recall their codes exactly when asked at least three days later, with only 21% reporting having written their secret down. As one participant wrote with surprise, the words are branded into my brain."
2540740,15510,20754,HomeAlone: Co-residency Detection in the Cloud via Side-Channel Analysis,2011,"Security is a major barrier to enterprise adoption of cloud computing. Physical co-residency with other tenants poses a particular risk, due to pervasive virtualization in the cloud. Recent research has shown how side channels in shared hardware may enable attackers to exfiltrate sensitive data across virtual machines (VMs). In view of such risks, cloud providers may promise physically isolated resources to select tenants, but a challenge remains: Tenants still need to be able to verify physical isolation of their VMs. We introduce Home Alone, a system that lets a tenant verify its VMs' exclusive use of a physical machine. The key idea in Home Alone is to invert the usual application of side channels. Rather than exploiting a side channel as a vector of attack, Home Alone uses a side-channel (in the L2 memory cache) as a novel, defensive detection tool. By analyzing cache usage during periods in which friendly VMs coordinate to avoid portions of the cache, a tenant using Home Alone can detect the activity of a co-resident foe VM. Key technical contributions of Home Alone include classification techniques to analyze cache usage and guest operating system kernel modifications that minimize the performance impact of friendly VMs sidestepping monitored cache portions. Home Alone requires no modification of existing hyper visors and no special action or cooperation by the cloud provider."
1285998,15510,339,Extended cubes: enhancing the cube attack by extracting low-degree non-linear equations,2011,"In this paper, we propose an efficient method for extracting simple low-degree equations (e.g. quadratic ones) in addition to the linear ones, obtainable from the original cube attack by Dinur and Shamir at EUROCRYPT 2009. This extended cube attack can be successfully applied even to cryptosystems in which the original cube attack may fail due to the attacker's inability in finding sufficiently many independent  linear  equations. As an application of our extended method, we exhibit a side channel cube attack against the PRESENT block cipher using the Hamming weight leakage model. Our side channel attack improves upon the previous work of Yang, Wang and Qiao at CANS 2009 from two aspects. First, we use the Hamming weight leakage model which is a more relaxed leakage assumption, supported by many previously known practical results on side channel attacks, compared to the more challenging leakage assumption that the adversary has access to the exact value of the internal state bits as used by Yang et al. Thanks to applying the extended cube method, our attack has also a reduced complexity compared to that of Yang et al. Namely, for PRESENT-80 (80-bit key variant) as considered by Yang et al., our attack has a time complexity 2 16  and data complexity of about 2 13  chosen plaintexts; whereas, that of Yang et al. has time complexity of 2 32  and needs about 2 15  chosen plaintexts. Furthermore, our method directly applies to PRESENT-128 (i.e. 128-bit key variant) with time complexity of 2 64  and the same data complexity of 2 13  chosen plaintexts."
1788711,15510,11223,Dissent in numbers: making strong anonymity scale,2012,"Current anonymous communication systems make a trade-off between weak anonymity among many nodes, via onion routing, and strong anonymity among few nodes, via DC-nets. We develop novel techniques in Dissent, a practical group anonymity system, to increase by over two orders of magnitude the scalability of strong, traffic analysis resistant approaches. Dissent derives its scalability from a client/server architecture, in which many unreliable clients depend on a smaller and more robust, but administratively decentralized, set of servers. Clients trust only that at least one server in the set is honest, but need not know or choose which server to trust. Unlike the quadratic costs of prior peer-to-peer DC-nets schemes, Dissent's client/server design makes communication and processing costs linear in the number of clients, and hence in anonymity set size. Further, Dissent's servers can unilaterally ensure progress, even if clients respond slowly or disconnect at arbitrary times, ensuring robustness against client churn, tail latencies, and DoS attacks. On DeterLab, Dissent scales to 5,000 online participants with latencies as low as 600 milliseconds for 600-client groups. An anonymous Web browsing application also shows that Dissent's performance suffices for interactive communication within smaller local-area groups."
2535948,15510,8912,Scalable optimal countermeasure selection using implicit enumeration on attack countermeasure trees,2012,"Constraints such as limited security investment cost precludes a security decision maker from implementing all possible countermeasures in a system. Existing analytical model-based security optimization strategies do not prevail for the following reasons: (i) none of these model-based methods offer a way to find optimal security solution in the absence of probability assignments to the model, (ii) methods scale badly as size of the system to model increases and (iii) some methods suffer as they use attack trees (AT) whose structure does not allow for the inclusion of countermeasures while others translate the non-state-space model (e.g., attack response tree) into a state-space model hence causing state-space explosion. In this paper, we use a novel AT paradigm called attack countermeasure tree (ACT) whose structure takes into account attacks as well as countermeasures (in the form of detection and mitigation events). We use greedy and branch and bound techniques to study several objective functions with goals such as minimizing the number of countermeasures, security investment cost in the ACT and maximizing the benefit from implementing a certain countermeasure set in the ACT under different constraints. We cast each optimization problem into an integer programming problem which also allows us to find optimal solution even in the absence of probability assignments to the model. Our method scales well for large ACTs and we compare its efficiency with other approaches."
561141,15510,10286,Traceable Group Encryption,2014,"Group encryption GE is the encryption analogue of group signatures. It allows a sender to verifiably encrypt a message for some certified but anonymous member of a group. The sender is further able to convince a verifier that the ciphertext is a well-formed encryption under some group member's public key. As in group signatures, an opening authority is empowered with the capability of identifying the receiver if the need arises. One application of such a scheme is secure repository at an unknown but authorized cloud server, where the archive is made accessible by a judge order in the case of misbehavior, like a server hosting illegal transaction records this is done in order to balance individual rights and society's safety. In this work we describe Traceable GE system, a group encryption with refined tracing capabilities akin to those of the primitive of traceable signatures thus, balancing better privacy vs. safety. Our primitive enjoys the properties of group encryption, and, in addition, it allows the opening authority to reveal a user-specific trapdoor which makes it possible to publicly trace all the ciphertexts encrypted for that user without harming the anonymity of other ciphertexts. In addition, group members are able to non-interactively prove that specific ciphertexts are intended for them or not. This work provides rigorous definitions, concrete constructions in the standard model, and security proofs."
1226801,15510,339,DroidAlarm: an all-sided static analysis tool for Android privilege-escalation malware,2013,"Since smartphones have stored diverse sensitive privacy information, including credit card and so on, a great deal of malware are desired to tamper them. As one of the most prevalent platforms, Android contains sensitive resources that can only be accessed via corresponding APIs, and the APIs can be invoked only when user has authorized permissions in the Android permission model. However, a novel threat called privilege escalation attack may bypass this watchdog. It's presented as that an application with less permissions can access sensitive resources through public interfaces of a more privileged application, which is especially useful for malware to hide sensitive functions by dispersing them into multiple programs. We explore privilege-escalation malware evolution techniques on samples from Android Malware Genome Project. And they have showed great effectiveness against a set of powerful antivirus tools provided by VirusTotal. The detection ratios present different and distinguished reduction, compared to an average 61% detection ratio before transformation. In order to conquer this threat model, we have developed a tool called DroidAlarm to conduct a full-spectrum analysis for identifying potential capability leaks and present concrete capability leak paths by static analysis on Android applications. And we can still alarm all these cases by exposing capability leak paths in them."
314211,15510,20592,PUBCRAWL: protecting users and businesses from CRAWLers,2012,"Web crawlers are automated tools that browse the web to retrieve and analyze information. Although crawlers are useful tools that help users to find content on the web, they may also be malicious. Unfortunately, unauthorized (malicious) crawlers are increasingly becoming a threat for service providers because they typically collect information that attackers can abuse for spamming, phishing, or targeted attacks. In particular, social networking sites are frequent targets of malicious crawling, and there were recent cases of scraped data sold on the black market and used for blackmailing.#R##N##R##N#In this paper, we introduce PUBCRAWL, a novel approach for the detection and containment of crawlers. Our detection is based on the observation that crawler traffic significantly differs from user traffic, even when many users are hidden behind a single proxy. Moreover, we present the first technique for crawler campaign attribution that discovers synchronized traffic coming from multiple hosts. Finally, we introduce a containment strategy that leverages our detection results to efficiently block crawlers while minimizing the impact on legitimate users. Our experimental results in a large, well-known social networking site (receiving tens of millions of requests per day) demonstrate that PUBCRAWL can distinguish between crawlers and users with high accuracy. We have completed our technology transfer, and the social networking site is currently running PUB-CRAWL in production."
2181964,15510,20592,Mining your Ps and Qs: detection of widespread weak keys in network devices,2012,"RSA and DSA can fail catastrophically when used with malfunctioning random number generators, but the extent to which these problems arise in practice has never been comprehensively studied at Internet scale. We perform the largest ever network survey of TLS and SSH servers and present evidence that vulnerable keys are surprisingly widespread. We find that 0.75% of TLS certificates share keys due to insufficient entropy during key generation, and we suspect that another 1.70% come from the same faulty implementations and may be susceptible to compromise. Even more alarmingly, we are able to obtain RSA private keys for 0.50% of TLS hosts and 0.03% of SSH hosts, because their public keys shared nontrivial common factors due to entropy problems, and DSA private keys for 1.03% of SSH hosts, because of insufficient signature randomness. We cluster and investigate the vulnerable hosts, finding that the vast majority appear to be headless or embedded devices. In experiments with three software components commonly used by these devices, we are able to reproduce the vulnerabilities and identify specific software behaviors that induce them, including a boot-time entropy hole in the Linux random number generator. Finally, we suggest defenses and draw lessons for developers, users, and the security community."
1570671,15510,339,"Efficient, context-aware privacy leakage confinement for android applications without firmware modding",2014,"As Android has become the most prevalent operating system in mobile devices, privacy concerns in the Android platform are increasing. A mechanism for efficient runtime enforcement of information-flow security policies in Android apps is desirable to confine privacy leakage. The prior works towards this problem require firmware modification (i.e., modding) and incur considerable runtime overhead. Besides, no effective mechanism is in place to distinguish malicious privacy leakage from those of legitimate uses. In this paper, we take a bytecode rewriting approach. Given an unknown Android app, we selectively insert instrumentation code into the app to keep track of private information and detect leakage at runtime. To distinguish legitimate and malicious leaks, we model the user's decisions with a context-aware policy enforcement mechanism. We have implemented a prototype called Capper and evaluated its efficacy on confining privacy-breaching apps. Our evaluation on 4723 real-world Android applications demonstrates that Capper can effectively track and mitigate privacy leaks. Moreover, after going through a series of optimizations, the instrumentation code only represents a small portion (4.48% on average) of the entire program. The runtime overhead introduced by Capper is also minimal, merely 1.5% for intensive data propagation."
2039049,15510,339,"Network scan detection with LQS: a lightweight, quick and stateful algorithm",2011,"Network scanning reveals valuable information of accessible hosts over the Internet and their offered network services, which allows significant narrowing of potential targets to attack. Addressing and balancing a set of sometimes competing desirable properties is required to make network scanning detection more appealing in practice: 1) fast detection of scanning activity to enable prompt response by intrusion detection and prevention systems; 2) acceptable rate of false alarms, keeping in mind that false alarms may lead to legitimate traffic being penalized; 3) high detection rate with the ability to detect stealthy scanners; 4) efficient use of monitoring system resources; and 5) immunity to evasion. In this paper, we present a scanning detection algorithm designed to accommodate all of these goals.  LQS  is a fast, accurate, and light-weight scan detection algorithm that leverages the key properties of the monitored network environment as variables that affect how the scanning detection algorithm operates. We also present what is, to our knowledge, the first automated way to estimate a reference baseline in the absence of ground truth, for use as an evaluation methodology for scan detection. Using network traces from two sites, we evaluate LQS and compare its scan detection results with those obtained by the state-of-the-art TRW algorithm. Our empirical analysis shows significant improvements over TRW in all of these properties."
994154,15510,11330,SecureME: a hardware-software approach to full system security,2011,"With computing increasingly becoming more dispersed, relying on mobile devices, distributed computing, cloud computing, etc. there is an increasing threat from adversaries obtaining physical access to some of the computer systems through theft or security breaches. With such an untrusted computing node, a key challenge is how to provide secure computing environment where we provide privacy and integrity for data and code of the application. We propose SecureME, a hardware-software mechanism that provides such a secure computing environment. SecureME protects an application from hardware attacks by using a secure processor substrate, and also from the Operating System (OS) through memory cloaking, permission paging, and system call protection. Memory cloaking hides data from the OS but allows the OS to perform regular virtual memory management functions, such as page initialization, copying, and swapping. Permission paging extends the OS paging mechanism to provide a secure way for two applications to establish shared pages for inter-process communication. Finally, system call protection applies spatio-temporal protection for arguments that are passed between the application and the OS. Based on our performance evaluation using microbenchmarks, single-program workloads, and multiprogrammed workloads, we found that SecureME only adds a small execution time overhead compared to a fully unprotected system. Roughly half of the overheads are contributed by the secure processor substrate. SecureME also incurs a negligible additional storage overhead over the secure processor substrate."
74161,15510,20592,Transparent ROP exploit mitigation using indirect branch tracing,2013,"Return-oriented programming (ROP) has become the primary exploitation technique for system compromise in the presence of non-executable page protections. ROP exploits are facilitated mainly by the lack of complete address space randomization coverage or the presence of memory disclosure vulnerabilities, necessitating additional ROP-specific mitigations.#R##N##R##N#In this paper we present a practical runtime ROP exploit prevention technique for the protection of third-party applications. Our approach is based on the detection of abnormal control transfers that take place during ROP code execution. This is achieved using hardware features of commodity processors, which incur negligible runtime overhead and allow for completely transparent operation without requiring any modifications to the protected applications. Our implementation for Windows 7, named kBouncer, can be selectively enabled for installed programs in the same fashion as user-friendly mitigation toolkits like Microsoft's EMET. The results of our evaluation demonstrate that kBouncer has low runtime overhead of up to 4%, when stressed with specially crafted workloads that continuously trigger its core detection component, while it has negligible overhead for actual user applications. In our experiments with in-the-wild ROP exploits, kBouncer successfully protected all tested applications, including Internet Explorer, Adobe Flash Player, and Adobe Reader."
1536494,15510,339,Predictability of Android OpenSSL's pseudo random number generator,2013,"OpenSSL is the most widely used library for SSL/TLS on the Android platform. The security of OpenSSL depends greatly on the unpredictability of its Pseudo Random Number Generator (PRNG). In this paper, we reveal the vulnerability of the OpenSSL PRNG on the Android. We first analyze the architecture of the OpenSSL specific to Android, and the overall operation process of the PRNG from initialization until the session key is generated. Owing to the nature of Android, the Dalvik Virtual Machine in Zygote initializes the states of OpenSSL PRNG early upon booting, and SSL applications copy the PRNG states of Zygote when they start. Therefore, the applications that use OpenSSL generate random data from the same initial states, which is potential problem that may seriously affect the security of Android applications. Next, we investigate the possibility of recovering the initial states of the OpenSSL PRNG. To do so, we should predict the nine external entropy sources of the PRNG. However, we show that these sources can be obtained in practice if the device is fixed. For example, the complexity of the attack was O(2^{32+t}) in our smartphone, where t is the bit complexity for estimating the system boot time. In our experiments, we were able to restore the PRNG states in 74 out of 100 cases. Assuming that we knew the boot time, i.e., t=0, the average time required to restore was 35 min on a PC with four cores (eight threads). Finally, we show that it is possible to recover the PreMasterSecret of the first SSL session with O(2^{58}) computations using the restored PRNG states, if the application is implemented by utilizing org.webkit package and a key exchange scheme is RSA. It shows that the vulnerability of OpenSSL PRNG can be a real threat to the security of Android."
2107845,15510,374,Privacy-Preserving Complex Query Evaluation over Semantically Secure Encrypted Data,2014,"In the last decade, several techniques have been proposed to evalu- ate different types of queries (e.g., range and aggregate queries) over encrypted data in a privacy-preserving manner. However, solutions supporting the privacy- preserving evaluation of complex queries over encrypted data have been devel- oped only recently. Such recent techniques, however, are either insecure or not feasible for practical applications. In this paper, we propose a novel privacy- preserving query processing framework that supports complex queries over en- crypted data in the cloud computing environment and addresses the shortcomings of previous approaches. At a high level, our framework utilizes both homomor- phic encryption and garbled circuit techniques at different stages in query pro- cessing to achieve the best performance, while at the same time protecting the confidentiality of data, privacy of the user's input query and hiding data access patterns. Also, as a part of query processing, we provide an efficient approach to systematically combine the predicate results (in encrypted form) of a query to derive the corresponding query evaluation result in a privacy-preserving manner. We theoretically and empirically analyze the performance of this approach and demonstrate its practical value over the current state-of-the-art techniques. Our proposed framework is very efficient from the user's perspective, thus allowing a user to issue queries even using a resource constrained device (e.g., PDAs and cell phones)."
2578284,15510,8912,Hybrid Control Network Intrusion Detection Systems for Automated Power Distribution Systems,2014,"In this paper, we describe our novel use of network intrusion detection systems (NIDS) for protecting automated distribution systems (ADS) against certain types of cyber attacks in a new way. The novelty consists of using the hybrid control environment rules and model as the baseline for what is normal and what is an anomaly, tailoring the security policies to the physical operation of the system. NIDS sensors in our architecture continuously analyze traffic in the communication medium that comes from embedded controllers, checking if the data and commands exchanged conform to the expected structure of the controllers interactions, and evolution of the system's physical state. Considering its importance in future ADSs, we chose the fault location, isolation and service restoration (FLISR) process as our distribution automation case study for the NIDS deployment. To test our scheme, we emulated the FLISR process using real programmable logic controllers (PLCs) that interact with a simulated physical infrastructure. We used this test bed to examine the capability of our NIDS approach in several attack scenarios. The experimental analysis reveals that our approach is capable of detecting various attacks scenarios including the attacks initiated within the trusted perimeter of the automation network by attackers that have complete knowledge about the communication information exchanged."
2250280,15510,8385,FlowTwist: efficient context-sensitive inside-out taint analysis for large codebases,2014,"Over the past years, widely used platforms such as the Java Class Library have been under constant attack through vulnerabilities that involve a combination of two taint-analysis problems: an integrity problem allowing attackers to trigger sensitive operations within the platform, and a confidentiality problem allowing the attacker to retrieve sensitive information or pointers from the results of those operations. While existing static taint analyses are good at solving either of those problems, we show that they scale prohibitively badly when being applied to situations that require the exploitation of both an integrity and confidentiality problem in combination. The main problem is the huge attack surface of libraries such as the Java Class Library, which exposes thousands of methods potentially controllable by an attacker. In this work we thus present FlowTwist, a novel taint-analysis approach that works inside-out, i.e., tracks data flows from potentially vulnerable calls to the outer level of the API which the attacker might control. This inside-out analysis requires a careful, context-sensitive coordination of both a backward and a forward taint analysis. In this work, we expose a design of the analysis approach based on the IFDS algorithm, and explain several extensions to IFDS that enable not only this coordination but also a helpful reporting of error situations to security analysts. Experiments with the Java Class Library show that, while a simple forward taint-analysis approach does not scale even with much machine power, FlowTwist's algorithm is able to fully analyze the library within 10 minutes."
1193460,15510,339,A clinical study of risk factors related to malware infections,2013,"The success of malicious software (malware) depends upon both technical and human factors. The most security conscious users are vulnerable to zero-day exploits; the best security mechanisms can be circumvented by poor user choices. While there has been significant research addressing the technical aspects of malware attack and defense, there has been much less research reporting on how human behavior interacts with both malware and current malware defenses.   In this paper we describe a proof-of-concept field study designed to examine the interactions between users, anti-virus (anti-malware) software, and malware as they occur on deployed systems. The 4-month study, conducted in a fashion similar to the clinical trials used to evaluate medical interventions, involved 50 subjects whose laptops were instrumented to monitor possible infections and gather data on user behavior. Although the population size was limited, this initial study produced some intriguing, non-intuitive insights into the efficacy of current defenses, particularly with regards to the technical sophistication of end users. We assert that this work shows the feasibility and utility of testing security software through long-term field studies with greater ecological validity than can be achieved through other means."
1358512,15510,8235,Trustworthy data from untrusted databases,2013,"Ensuring the trustworthiness of data retrieved from a database is of utmost importance to users. The correctness of data stored in a database is defined by the faithful execution of only valid (authorized) transactions. In this paper we address the question of whether it is necessary to trust a database server in order to trust the data retrieved from it. The lack of trust arises naturally if the database server is owned by a third party, as in the case of cloud computing. It also arises if the server may have been compromised, or there is a malicious insider. In particular, we reduce the level of trust necessary in order to establish the authenticity and integrity of data at an untrusted server. Earlier work on this problem is limited to situations where there are no updates to the database, or all updates are authorized and vetted by a central trusted entity. This is an unreasonable assumption for a truly dynamic database, as would be expected in many business applications, where multiple clients can update data without having to check with a central server that approves of their changes. We identify the problem of ensuring trustworthiness of data at an untrusted server in the presence of transactional updates that run directly on the database, and develop the first solutions to this problem. Our solutions also provide indemnity for an honest server and assured provenance for all updates to the data. We implement our solution in a prototype system built on top of Oracle with no modifications to the database internals. We also provide an empirical evaluation of the proposed solutions and establish their feasibility."
468125,15510,9969,"Key Recovery Attacks on 3-round Even-Mansour, 8-step LED-128, and Full AES2",2013,"The Even-Mansour EM encryption scheme received a lot of attention in the last couple of years due to its exceptional simplicity and tight security proofs. The original 1-round construction was naturally generalized into r-round structures with one key, two alternating keys, and completely independent keys. In this paper we describe the first key recovery attack on the one-key 3-round version of EM which is asymptotically faster than exhaustive search in the sense that its running time is o2 n rather than O2 n for an n-bit key. We then use the new cryptanalytic techniques in order to improve the best known attacks on several concrete EM-like schemes. In the case of LED-128, the best previously known attack could only be applied to 6 of its 12 steps. In this paper we develop a new attack which increases the number of attacked steps to 8, is slightly faster than the previous attack on 6 steps, and uses about a thousand times less data. Finally, we describe the first attack on the full AES2 which uses two complete AES-128 encryptions and three independent 128-bit keys, and looks exceptionally strong which is about 7 times faster than a standard meet-in-the-middle attack, thus violating its security claim."
802789,15510,20754,SoK: Introspections on Trust and the Semantic Gap,2014,"An essential goal of Virtual Machine Introspection (VMI) is assuring security policy enforcement and overall functionality in the presence of an untrustworthy OS. A fundamental obstacle to this goal is the difficulty in accurately extracting semantic meaning from the hypervisor's hardware level view of a guest OS, called the semantic gap. Over the twelve years since the semantic gap was identified, immense progress has been made in developing powerful VMI tools. Unfortunately, much of this progress has been made at the cost of reintroducing trust into the guest OS, often in direct contradiction to the underlying threat model motivating the introspection. Although this choice is reasonable in some contexts and has facilitated progress, the ultimate goal of reducing the trusted computing base of software systems is best served by a fresh look at the VMI design space. This paper organizes previous work based on the essential design considerations when building a VMI system, and then explains how these design choices dictate the trust model and security properties of the overall system. The paper then observes portions of the VMI design space which have been under-explored, as well as potential adaptations of existing techniques to bridge the semantic gap without trusting the guest OS. Overall, this paper aims to create an essential checkpoint in the broader quest for meaningful trust in virtualized environments through VM introspection."
960788,15510,9856,Distilling critical attack graph surface iteratively through minimum-cost SAT solving,2011,"It has long been recognized that it can be tedious and even infeasible for system administrators to figure out critical security problems residing in full attack graphs, even for small-sized enterprise networks. Therefore a trade-off between analysis accuracy and efficiency needs to be made to achieve a reasonable balance between completeness of the attack graph and its usefulness. In this paper, we provide an approach to  attack graph distillation , so that the user can control the amount of information presented by sifting out the most critical portion of the full attack graph. The user can choose to see only the  k  most critical attack paths, based on specified severity metrics,  e.g . the likelihood for an attacker to carry out certain exploit on certain machine and the chance of success. We transform an dependency attack graph into a Boolean formula and assign cost metrics to attack variables in the formula, based on the severity metrics. We then apply Minimum-Cost SAT Solving (MCSS) to find the most critical path in terms of the least cost incurred for the attacker to deploy multi-step attacks leading to certain crucial assets in the network. An iterative process inspired by Counter Example Guided Abstraction and Refinement (CEGAR) is designed to efficiently guide the MCSS to render solutions that contain a controlled number of realistic attack paths, forming a  critical attack graph surface . Our method can distill critical attack graph surfaces from the full attack graphs generated for moderate-sized enterprise networks in only several minutes. Experiments on various sized network scenarios show that even for a small-sized critical attack graph surface (around 15% the size of the original full attack graph), the calculated risk metrics are good approximation of the values computed with the full attack graph, meaning the distilled critical attack graph surface is able to capture the crucial security problems in an enterprise network for further in-depth analysis."
2149837,15510,20358,Musubi: disintermediated interactive social feeds for mobile devices,2012,"This paper presents Musubi, a mobile social application platform that enables users to share any data type in real-time feeds created by any application on the phone. Musubi is unique in providing a disintermediated service to end users; all communication is supported using public key encryption thus leaking no user information to a third party. Despite the heavy use of cryptography to provide user authentication and access control, users found Musubi simple to use. We embed key exchange within familiar friending actions, and allow users to interact with any friend in their address books without requiring them to join a common network a priori. Our feed abstraction allows users to easily exercise access control. All data reside on the phone, granting users the freedom to apply applications of their choice.   In addition to disintermediating personal messaging, we have created an application platform to support multi-party software with the same respect for personal data. The SocialKit library we created on top of Musubi's trusted communication protocol facilitates the development of multi-party applications and integrates with Musubi to provide a compelling group application experience. SocialKit allows developers to make social, interactive, privacy-honoring applications without needing to host their own servers."
1959566,15510,10286,Expressive key-policy attribute-based encryption with constant-size ciphertexts,2011,"Attribute-based encryption (ABE), as introduced by Sahai and Waters, allows for fine-grained access control on encrypted data. In its key-policy flavor, the primitive enables senders to encrypt messages under a set of attributes and private keys are associated with access structures that specify which ciphertexts the key holder will be allowed to decrypt. In most ABE systems, the ciphertext size grows linearly with the number of ciphertext attributes and the only known exceptions only support restricted forms of threshold access policies.#R##N##R##N#This paper proposes the first key-policy attribute-based encryption (KP-ABE) schemes allowing for non-monotonic access structures (i.e., that may contain negated attributes) and with constant ciphertext size. Towards achieving this goal, we first show that a certain class of identity-based broadcast encryption schemes generically yields monotonic KPABE systems in the selective set model. We then describe a new efficient identity-based revocation mechanism that, when combined with a particular instantiation of our general monotonic construction, gives rise to the first truly expressive KP-ABE realization with constant-size ciphertexts. The downside of these new constructions is that private keys have quadratic size in the number of attributes. On the other hand, they reduce the number of pairing evaluations to a constant, which appears to be a unique feature among expressive KP-ABE schemes."
1711916,15510,208,Manilyzer: Automated Android Malware Detection through Manifest Analysis,2014,"As the world's most popular mobile operating system, Google's Android OS is the principal target of an ever increasing mobile malware threat. To counter this emerging menace, many malware detection techniques have been proposed. A key aspect of many static detection techniques is their reliance on the permissions requested in the AndroidManifest.xml file. Although these permissions are very important, the manifest also contains additional information that can be valuable in identifying malware, which, however, has not been fully utilized by existing studies. In this paper we present Manilyzer, a system that exploits the rich information in the manifest files, produces feature vectors automatically, and uses state-of-the-art machine learning algorithms to classify applications as malicious or benign. We apply Manilyzer to 617 applications (307 malicious, 310 benign) and find that it is very effective: the accuracy is up to 90%, while the false positives and false negatives are both around 10%. In addition to classifying applications, Manilyzer is used to study the trends of permission requests in malicious applications. Through this evaluation and further analysis, it is clear that malware has evolved over time, and not all malware can be detected through static analysis of manifest files. To address this issue, we briefly explore a dynamic analysis technique that monitors network traffic using a packet sniffer."
2238135,15510,10286,Leakage-Flexible CCA-secure Public-Key Encryption: Simple Construction and Free of Pairing,2014,"In AsiaCrypti¾?2013, Qin and Liu proposed a new approach to CCA-security of Public-Key Encryption PKE in the presence of bounded key-leakage, from any universal hash proof system due to Cramer and Shoup and any one-time lossy filter a simplified version of lossy algebraic filters, due to Hofheinz. They presented two instantiations under the DDH and DCR assumptions, which result in leakage rate defined as the ratio of leakage amount to the secret-key length of 1/2-o1. In this paper, we extend their work to broader assumptions and to flexible leakage rate, more specifically to leakage rate of 1-o1.#R##N##R##N#We introduce the Refined Subgroup Indistinguishability RSI assumption, which is a subclass of subgroup indistinguishability assumptions, including many standard number-theoretical assumptions, like the quadratic residuosity assumption, the decisional composite residuosity assumption and the subgroup decision assumption over a group of known order defined by Boneh et al.We show that universal hash proof UHP system and one-time lossy filter OT-LF can be simply and efficiently constructed from the RSI assumption. Applying Qin and Liu's paradigm gives simple and efficient PKE schemes under the RSI assumption.With the RSI assumption over a specific group free of pairing, public parameters of UHP and OT-LF can be chosen in a flexible way, resulting in a leakage-flexible CCA-secure PKE scheme. More specifically, we get the first CCA-secure PKE with leakage rate of 1-o1 without pairing."
2551959,15510,9969,A Dynamic Tradeoff Between Active and Passive Corruptions in Secure Multi-Party Computation,2013,"At STOC '87, Goldreich et al. presented two protocols for secure multi-party computation (MPC) among n parties: The first proto- col provides passive security against t < n corrupted parties. The second protocol provides even active security, but only against t < n/2 corrupted parties. Although these protocols provide security against the provably highest possible number of corruptions, each of them has its limitation: The first protocol is rendered completely insecure in presence of a sin- gle active corruption, and the second protocol is rendered completely insecure in presence of ⌈n/2⌉ passive corruptions. At Crypto 2006, Ishai et al. combined these two protocols into a single protocol which provides passive security against t < n corruptions and active security against t < n/2 corruptions. This protocol unifies the security guarantees of the passive world and the active world (best of both worlds). However, the corruption threshold t < n can be tolerated only when all corruptions are passive. With a single active corruption, the threshold is reduced to t < n/2. As our main result, we introduce a dynamic tradeoff between active and passive corruptions: We present a protocol which provides security against t < n passive corruptions, against t < n/2 active corruptions, and everything in between. In particular, our protocol provides full secu- rity against k active corruptions, as long as less than n − k parties are corrupted in total, for any unknown k. The main technical contribution is a new secret sharing scheme that, in the reconstruction phase, releases secrecy gradually. This allows to con- struct non-robust MPC protocols which, in case of an abort, still pro- vide some level of secrecy. Furthermore, using similar techniques, we also construct protocols for reactive MPC with hybrid security, i.e., different thresholds for secrecy, correctness, robustness, and fairness. Intuitively, the more corrupted parties, the less security is guaranteed."
781509,15510,20754,Understanding Insider Threat: A Framework for Characterising Attacks,2014,"The threat that insiders pose to businesses, institutions and governmental organisations continues to be of serious concern. Recent industry surveys and academic literature provide unequivocal evidence to support the significance of this threat and its prevalence. Despite this, however, there is still no unifying framework to fully characterise insider attacks and to facilitate an understanding of the problem, its many components and how they all fit together. In this paper, we focus on this challenge and put forward a grounded framework for understanding and reflecting on the threat that insiders pose. Specifically, we propose a novel conceptualisation that is heavily grounded in insider-threat case studies, existing literature and relevant psychological theory. The framework identifies several key elements within the problem space, concentrating not only on noteworthy events and indicators- technical and behavioural- of potential attacks, but also on attackers (e.g., the motivation behind malicious threats and the human factors related to unintentional ones), and on the range of attacks being witnessed. The real value of our framework is in its emphasis on bringing together and defining clearly the various aspects of insider threat, all based on real-world cases and pertinent literature. This can therefore act as a platform for general understanding of the threat, and also for reflection, modelling past attacks and looking for useful patterns."
2121301,15510,339,DroidRay: a security evaluation system for customized android firmwares,2014,"Android mobile devices are enjoying a lion's market share in smartphones and mobile devices. This also attracts malware writers to target the Android platform. Recently, we have discovered a new Android malware distribution channel: releasing malicious firmwares with pre-installed malware to the wild. This poses significant risk since users of mobile devices cannot change the content of the malicious firmwares. Furthermore, pre-installed applications have  more permissions (i.e., silent installation) than other legitimate mobile apps, so they can download more malware or access users' confidential information. To understand and address this new form of malware distribution channel, we design and implement DroidRay: a security evaluation system for customized Android firmwares. DroidRay uses both static and dynamic analyses to evaluate the firmware security on both the application and system levels. To understand the impact of this new malware distribution channel, we analyze 250 Android firmwares and 24,009 pre-installed applications. We reveal how the malicious firmware and pre-installed malware are injected, and discovered 1,947 (8.1%) pre-installed applications have signature vulnerability and 19 (7.6%) firmwares contain pre-installed malware. In addition, 142 (56.8%) firmwares have the default signature vulnerability, five (2.0%) firmwares contain malicious hosts file, at most 40 (16.0%) firmwares have the native level privilege escalation vulnerability and at least 249 (99.6%) firmwares have the Java level privilege escalation vulnerability. Lastly, we investigate a real-world case of a pre-installed zero-day malware known as CEPlugnew, which involves 348,018 infected Android smartphones, and we show its degree and geographical penetration. This shows the significance of this new malware distribution channel, and DroidRay is an effective tool to combat this new form of malware spreading."
129738,15510,293,On the Effectiveness of Traffic Analysis against Anonymity Networks Using Flow Records,2014,"We investigate the feasibility of mounting a de-anonymization attack against Tor and similar low-latency anonymous communication systems by using NetFlow records. Previous research has shown that adversaries with the ability to eavesdrop in real time at a few internet exchange points can effectively monitor a significant part of the network paths from Tor nodes to destination servers. However, the capacity of current networks makes packet-level monitoring at such a scale quite challenging. We hypothesize that adversaries could use less accurate but readily available monitoring facilities, such as Cisco's NetFlow, to mount large-scale traffic analysis attacks. In this paper, we assess the feasibility and effectiveness of traffic analysis attacks against Tor using NetFlow data. We present an active traffic analysis technique based on perturbing the characteristics of user traffic at the server side, and observing a similar perturbation at the client side through statistical correlation. We evaluate the accuracy of our method using both in-lab testing and data gathered from a public Tor relay serving hundreds of users. Our method revealed the actual sources of anonymous traffic with 100% accuracy for the in-lab tests, and achieved an overall accuracy of 81.6% for the real-world experiments with a false positive rate of 5.5%."
2176152,15510,20348,Bringing up OpenSky: a large-scale ADS-B sensor network for research,2014,"Automatic Dependent Surveillance-Broadcast (ADS-B) is one of the key components of the next generation air transportation system. Since ADS-B will become mandatory by 2020 for most airspaces, it is important that aspects such as capacity, applications, and security are investigated by an independent research community. However, large-scale real-world data was previously only accessible to a few closed industrial and governmental groups because it required specialized and expensive equipment. To enable researchers to conduct experimental studies based on real data, we developed OpenSky, a sensor network based on low-cost hardware connected over the Internet.   OpenSky is based on off-the-shelf ADS-B sensors distributed to volunteers throughout Central Europe. It covers 720,000 sq km 2 , is able to capture more than 30% of the commercial air traffic in Europe, and enables researchers to analyze billions of ADS-B messages. In this paper, we report on the challenges we faced during the development and deployment of this participatory network and the insights we gained over the last two years of operations as a service to academic research groups. We go on to provide real-world insights about the possibilities and limitations of such low-cost sensor networks concerning air traffic surveillance and further applications such as multilateration."
892991,15510,20754,Quid-Pro-Quo-tocols: Strengthening Semi-honest Protocols with Dual Execution,2012,"Known protocols for secure two-party computation that are designed to provide full security against malicious behavior are significantly less efficient than protocols intended only to thwart semi-honest adversaries. We present a concrete design and implementation of protocols achieving security guarantees that are much stronger than are possible with semi-honest protocols, at minimal extra cost. Specifically, we consider protocols in which a malicious adversary may learn a single (arbitrary) bit of additional information about the honest party's input. Correctness of the honest party's output is still guaranteed. Adapting prior work of Mohassel and Franklin, the basic idea in our protocols is to conduct two separate runs of a (specific) semi-honest, garbled-circuit protocol, with the parties swapping roles, followed by an inexpensive secure equality test. We provide a rigorous definition and prove that this protocol leaks no more than one additional bit against a malicious adversary. In addition, we propose some heuristic enhancements to reduce the overall information a cheating adversary learns. Our experiments show that protocols meeting this security level can be implemented at cost very close to that of protocols that only achieve semi-honest security. Our results indicate that this model enables the large-scale, practical applications possible within the semi-honest security model, while providing dramatically stronger security guarantees."
1993973,15510,339,Neighborhood watch: security and privacy analysis of automatic meter reading systems,2012,"Research on smart meters has shown that fine-grained energy usage data poses privacy risks since it allows inferences about activities inside the home. While smart meter deployments are very limited, more than 40 million meters in the United States have been equipped with Automatic Meter Reading (AMR) technology over the past decades. AMR utilizes wireless communication for remotely collecting usage data from electricity, gas, and water meters. Yet to the best of our knowledge, AMR has so far received no attention from the security research community. In this paper, we conduct a security and privacy analysis of this technology. Based on our reverse engineering and experimentation, we find that the technology lacks basic security measures to ensure privacy, integrity, and authenticity of the data. Moreover, the AMR meters we examined continuously broadcast their energy usage data over insecure wireless links every 30s, even though these broadcasts can only be received when a truck from the utility company passes by. We show how this design allows any individual to monitor energy usage from hundreds of homes in a neighborhood with modest technical effort and how this data allows identifying unoccupied residences or people's routines. To cope with the issues, we recommend security remedies, including a solution based on defensive jamming that may be easier to deploy than upgrading the meters themselves."
1527887,15510,10228,RERUM: Building a reliable IoT upon privacy- and security- enabled smart objects,2014,"The Internet of Things (IoT) provides a platform for the interconnection of a plethora of smart objects. It has been widely accepted for providing Information and Communication Technologies (ICT) applications in many “smart” environments, such as cities, buildings, metering, and even agriculture. For several reasons though such applications have yet to achieve wide adoption; a major hurdle is the lack of user trust in the IoT and its role in everyday activities. RERUM, a recently started FP7 European Union project. aims to develop a framework which will allow IoT applications to consider security and privacy mechanisms early in their design phase, ensuring a configurable balance between reliability (requiring secure, trustworthy and precise data) and privacy (requiring data minimization for private information, like location). The RERUM framework will comprise an architecture, built upon novel network protocols and interfaces as well as the design of smart objects hardware. To highlight the challenges and evaluate the framework, RERUM will employ several Smart City application scenarios, which will be deployed and evaluated in real-world testbeds in two Smart Cities participating in the project. Here we detail the key technologies RERUM will investigate over the coming three years to reach its vision for IoT security, privacy and trust."
645764,15510,10228,Integrating trust establishment into routing protocols of today's MANETs,2013,"Conventional network protocols and its security mechanisms fail to cope with arising challenges in trust. Well known concepts from the domain of Trusted Computing can be applied to the example of mobile ad-hoc networks (MANETs) in order to establish extended trust capabilities between devices. The approach of such an anchor of trust in MANETs shows interesting possibilities since no central instances such as Access Points are involved in those networks. The communication between directly connected devices of the network is protected by a cryptographic protocol making use of a Trusted Platform Module (TPM) that serves as root-of-trust on each device. Such a hardware chip allows devices to attest the local system state and assess states of remote systems. Building on this, transmission of routing and payload data can be restricted to devices in trustworthy states. The resulting mobile ad-hoc network, by using this protocol, is protected against many of today's security threats. Single malicious devices are automatically recognised and excluded from participation in the network by all devices. Especially the dissemination of misleading routing information, which affects the availability of the whole network, is effectively prevented by the developed protocol. Thus, it is shown that the device itself is secured by a hardware TPM. Also the communication is secured, by verifying the device's state between the counterparts."
2054265,15510,9856,Understanding visual perceptions of usability and security of Android's graphical password pattern,2014,"This paper reports the results of a user study of the Android graphical password system using an alternative survey methodology, pairwise preferences, that requests participants to select between pairs of patterns indicating either a security or usability preference. By carefully selecting password pairs to isolate a visual feature, a visual perception of usability and security of different features can be measured. We conducted a large IRB-approved survey using pairwise preferences which attracted 384 participants on Amazon Mechanical Turk. Analyzing the results, we find that visual features that can be attributed to complexity indicated a stronger perception of security, while spatial features, such as shifts up/down or left/right are not strong indicators for security or usability. We extended and applied the survey data by building logistic models to  predict  perception preferences by training on features used in the survey and other features proposed in related work. The logistic model accurately predicted preferences above 70%, twice the rate of random guessing, and the strongest feature in classification is  password distance , the total length of all lines in the pattern, a feature  not  used in the online survey. This result provides insight into the  internal visual calculus  of users when comparing choices and selecting visual passwords, and the ultimate goal of this work is to leverage the visual calculus to design systems where inherent perceptions for usability coincides with a known metric of security."
1533542,15510,20754,Implementing TLS with Verified Cryptographic Security,2013,"TLS is possibly the most used protocol for secure communications, with a 18-year history of flaws and fixes, ranging from its protocol logic to its cryptographic design, and from the Internet standard to its diverse implementations. We develop a verified reference implementation of TLS 1.2. Our code fully supports its wire formats, ciphersuites, sessions and connections, re-handshakes and resumptions, alerts and errors, and data fragmentation, as prescribed in the RFCs; it interoperates with mainstream web browsers and servers. At the same time, our code is carefully structured to enable its modular, automated verification, from its main API down to computational assumptions on its cryptographic algorithms. Our implementation is written in F# and specified in F7. We present security specifications for its main components, such as authenticated stream encryption for the record layer and key establishment for the handshake. We describe their verification using the F7 typechecker. To this end, we equip each cryptographic primitive and construction of TLS with a new typed interface that captures its security properties, and we gradually replace concrete implementations with ideal functionalities. We finally typecheck the protocol state machine, and obtain precise security theorems for TLS, as it is implemented and deployed. We also revisit classic attacks and report a few new ones."
2321859,15510,11058,Caisson: a hardware description language for secure information flow,2011,"Information flow is an important security property that must be incorporated from the ground up, including at hardware design time, to provide a formal basis for a system's root of trust. We incorporate insights and techniques from designing information-flow secure programming languages to provide a new perspective on designing secure hardware. We describe a new hardware description language, Caisson, that combines domain-specific abstractions common to hardware design with insights from type-based techniques used in secure programming languages. The proper combination of these elements allows for an expressive, provably-secure HDL that operates at a familiar level of abstraction to the target audience of the language, hardware architects.   We have implemented a compiler for Caisson that translates designs into Verilog and then synthesizes the designs using existing tools. As an example of Caisson's usefulness we have addressed an open problem in secure hardware by creating the first-ever provably information-flow secure processor with micro-architectural features including pipelining and cache. We synthesize the secure processor and empirically compare it in terms of chip area, power consumption, and clock frequency with both a standard (insecure) commercial processor and also a processor augmented at the gate level to dynamically track information flow. Our processor is competitive with the insecure processor and significantly better than dynamic tracking."
